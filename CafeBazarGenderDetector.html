<!DOCTYPE html>
<html>
<head><meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<title>CafeBazarGenderDetector</title><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.1.10/require.min.js"></script>




<style type="text/css">
    pre { line-height: 125%; }
td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }
span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }
td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }
span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }
.highlight .hll { background-color: var(--jp-cell-editor-active-background) }
.highlight { background: var(--jp-cell-editor-background); color: var(--jp-mirror-editor-variable-color) }
.highlight .c { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment */
.highlight .err { color: var(--jp-mirror-editor-error-color) } /* Error */
.highlight .k { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword */
.highlight .o { color: var(--jp-mirror-editor-operator-color); font-weight: bold } /* Operator */
.highlight .p { color: var(--jp-mirror-editor-punctuation-color) } /* Punctuation */
.highlight .ch { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Hashbang */
.highlight .cm { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Multiline */
.highlight .cp { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Preproc */
.highlight .cpf { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.PreprocFile */
.highlight .c1 { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Single */
.highlight .cs { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Special */
.highlight .kc { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Constant */
.highlight .kd { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Declaration */
.highlight .kn { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Namespace */
.highlight .kp { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Pseudo */
.highlight .kr { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Reserved */
.highlight .kt { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Type */
.highlight .m { color: var(--jp-mirror-editor-number-color) } /* Literal.Number */
.highlight .s { color: var(--jp-mirror-editor-string-color) } /* Literal.String */
.highlight .ow { color: var(--jp-mirror-editor-operator-color); font-weight: bold } /* Operator.Word */
.highlight .w { color: var(--jp-mirror-editor-variable-color) } /* Text.Whitespace */
.highlight .mb { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Bin */
.highlight .mf { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Float */
.highlight .mh { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Hex */
.highlight .mi { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Integer */
.highlight .mo { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Oct */
.highlight .sa { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Affix */
.highlight .sb { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Backtick */
.highlight .sc { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Char */
.highlight .dl { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Delimiter */
.highlight .sd { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Doc */
.highlight .s2 { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Double */
.highlight .se { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Escape */
.highlight .sh { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Heredoc */
.highlight .si { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Interpol */
.highlight .sx { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Other */
.highlight .sr { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Regex */
.highlight .s1 { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Single */
.highlight .ss { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Symbol */
.highlight .il { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Integer.Long */
  </style>
<style type="text/css">
    div#notebook {
 font-family: sans-serif;
 font-size: 13pt;
 line-height: 170%;
 color: #cdd2e9;
 -webkit-font-smoothing: antialiased !important;
 padding-top: 25px !important;
}
body,
div.body {
 font-family: sans-serif;
 font-size: 13pt;
 color: #a2b0c7;
 background-color: #262931;
 background: #262931;
 -webkit-font-smoothing: antialiased !important;
}
body.notebook_app {
 padding: 0;
 background-color: #262931;
 background: #262931;
 padding-right: 0px !important;
 overflow-y: hidden;
}
a {
 font-family: sans-serif;
 color: #a2b0c7;
 -webkit-font-smoothing: antialiased !important;
}
a:hover,
a:focus {
 color: #d8dcee;
 -webkit-font-smoothing: antialiased !important;
}
div#maintoolbar {
 position: absolute;
 width: 90%;
 margin-left: -10%;
 padding-right: 8%;
 float: left;
 background: transparent !important;
}
#maintoolbar {
 margin-bottom: -3px;
 margin-top: 0px;
 border: 0px;
 min-height: 27px;
 padding-top: 2px;
 padding-bottom: 0px;
}
#maintoolbar .container {
 width: 75%;
 margin-right: auto;
 margin-left: auto;
}
.list_header,
div#notebook_list_header.row.list_header {
 font-size: 14pt;
 color: #d8dcee;
 background-color: transparent;
 height: 35px;
}
i.fa.fa-folder {
 display: inline-block;
 font: normal normal normal 14px "FontAwesome";
 font-family: "FontAwesome" !important;
 text-rendering: auto;
 -webkit-font-smoothing: antialiased;
 font-size: 18px;
 -moz-osx-font-smoothing: grayscale;
}
#running .panel-group .panel .panel-heading {
 font-size: 14pt;
 color: #a2b0c7;
 padding: 8px 8px;
 background: #2e3642;
 background-color: #2e3642;
}
#running .panel-group .panel .panel-heading a {
 font-size: 14pt;
 color: #a2b0c7;
}
#running .panel-group .panel .panel-heading a:focus,
#running .panel-group .panel .panel-heading a:hover {
 font-size: 14pt;
 color: #a2b0c7;
}
#running .panel-group .panel .panel-body .list_container .list_item {
 background: #384152;
 background-color: #384152;
 padding: 2px;
 border-bottom: 2px solid rgba(80,92,133,.22);
}
#running .panel-group .panel .panel-body .list_container .list_item:hover {
 background: #384152;
 background-color: #384152;
}
#running .panel-group .panel .panel-body {
 padding: 2px;
}
button#refresh_running_list {
 border: none !important;
}
button#refresh_cluster_list {
 border: none !important;
}
div.running_list_info.toolbar_info {
 font-size: 15px;
 padding: 4px 0 4px 0;
 margin-top: 5px;
 margin-bottom: 8px;
 height: 24px;
 line-height: 24px;
 text-shadow: none;
}
.list_placeholder {
 font-weight: normal;
}
#tree-selector {
 padding: 0px;
 border-color: transparent;
}
#project_name > ul > li > a > i.fa.fa-home {
 color: #4c8be2;
 font-size: 17pt;
 display: inline-block;
 position: static;
 padding: 0px 0px;
 font-weight: normal;
 text-align: center;
 vertical-align: text-top;
}
.fa-folder:before {
 color: #4c8be2;
}
.fa-arrow-up:before {
 font-size: 14px;
}
.fa-arrow-down:before {
 font-size: 14px;
}
span#last-modified.btn.btn-xs.btn-default.sort-action:hover .fa,
span#sort-name.btn.btn-xs.btn-default.sort-action:hover .fa {
 color: #4c8be2;
}
.folder_icon:before {
 display: inline-block;
 font: normal normal normal 14px/1 FontAwesome;
 font-size: inherit;
 text-rendering: auto;
 -webkit-font-smoothing: antialiased;
 -moz-osx-font-smoothing: grayscale;
 content: "\f07b";
 color: #4c8be2;
}
.notebook_icon:before {
 display: inline-block;
 font: normal normal normal 14px/1 FontAwesome;
 font-size: inherit;
 text-rendering: auto;
 -webkit-font-smoothing: antialiased;
 -moz-osx-font-smoothing: grayscale;
 content: "\f02d";
 position: relative;
 color: #48a667 !important;
 top: 0px;
}
.file_icon:before {
 display: inline-block;
 font: normal normal normal 14px/1 FontAwesome;
 font-size: inherit;
 text-rendering: auto;
 -webkit-font-smoothing: antialiased;
 -moz-osx-font-smoothing: grayscale;
 content: "\f15b";
 position: relative;
 top: 0px;
 color: #899ab8 !important;
}
#project_name a {
 display: inline-flex;
 padding-left: 7px;
 margin-left: -2px;
 text-align: -webkit-auto;
 vertical-align: baseline;
 font-size: 18px;
}
div#notebook_toolbar div.dynamic-instructions {
 font-family: sans-serif;
 font-size: 17px;
 color: #546379;
}
span#login_widget > .button,
#logout {
 font-family: "Proxima Nova", sans-serif;
 color: #a2b0c7;
 background: transparent;
 background-color: transparent;
 border: 2px solid #3a4452;
 font-weight: normal;
 box-shadow: none;
 text-shadow: none;
 border-radius: 3px;
 margin-right: 10px;
 padding: 2px 7px;
}
span#login_widget > .button:hover,
#logout:hover {
 color: #4c8be2;
 background-color: transparent;
 background: transparent;
 border: 2px solid #4c8be2;
 background-image: none;
 box-shadow: none !important;
 border-radius: 3px;
}
span#login_widget > .button:focus,
#logout:focus,
span#login_widget > .button.focus,
#logout.focus,
span#login_widget > .button:active,
#logout:active,
span#login_widget > .button.active,
#logout.active,
.open > .dropdown-togglespan#login_widget > .button,
.open > .dropdown-toggle#logout {
 color: #e4e8ee;
 background-color: #a2b0c7;
 background: #a2b0c7;
 border-color: #a2b0c7;
 background-image: none;
 box-shadow: none !important;
 border-radius: 2px;
}
body > #header #header-container {
 padding-bottom: 0px;
 padding-top: 4px;
 box-sizing: border-box;
 -moz-box-sizing: border-box;
 -webkit-box-sizing: border-box;
}
body > #header {
 background: #262931;
 background-color: #262931;
 position: relative;
 z-index: 100;
}
.list_container {
 font-size: 13pt;
 color: #a2b0c7;
 border: none;
 text-shadow: none !important;
}
.list_container > div {
 border-bottom: 1px solid rgba(80,92,133,.22);
 font-size: 13pt;
}
.list_header > div,
.list_item > div {
 padding-top: 6px;
 padding-bottom: 2px;
 padding-left: 0px;
}
.list_header > div .item_link,
.list_item > div .item_link {
 margin-left: -1px;
 vertical-align: middle;
 line-height: 22px;
 font-size: 13pt;
}
.item_icon {
 color: #4c8be2;
 font-size: 13pt;
 vertical-align: middle;
}
.list_item input:not([type="checkbox"]) {
 padding-right: 0px;
 height: 1.75em;
 width: 25%;
 margin: 0px 0 0;
 margin-top: 0px;
}
.list_header > div .item_link,
.list_item > div .item_link {
 margin-left: -1px;
 vertical-align: middle;
 line-height: 1.5em;
 font-size: 12pt;
 display: inline-table;
 position: static;
}
#button-select-all {
 height: 34px;
 min-width: 55px;
 z-index: 0;
 border: none !important;
 padding-top: 0px;
 padding-bottom: 0px;
 margin-bottom: 0px;
 margin-top: 0px;
 left: -3px;
 border-radius: 0px !important;
}
#button-select-all:focus,
#button-select-all:active:focus,
#button-select-all.active:focus,
#button-select-all.focus,
#button-select-all:active.focus,
#button-select-all.active.focus {
 background-color: #3a4452 !important;
 background: #3a4452 !important;
}
button#tree-selector-btn {
 height: 34px;
 font-size: 12.0pt;
 border: none;
 left: 0px;
 border-radius: 0px !important;
}
input#select-all.pull-left.tree-selector {
 margin-left: 7px;
 margin-right: 2px;
 margin-top: 2px;
 top: 4px;
}
input[type="radio"],
input[type="checkbox"] {
 margin-top: 1px;
 line-height: normal;
}
.delete-button {
 border: none !important;
}
i.fa.fa-trash {
 font-size: 13.5pt;
}
.list_container a {
 font-size: 16px;
 color: #a2b0c7;
 border: none;
 text-shadow: none !important;
 font-weight: normal;
 font-style: normal;
}
div.list_container a:hover {
 color: #d8dcee;
}
.list_header > div input,
.list_item > div input {
 margin-right: 7px;
 margin-left: 12px;
 vertical-align: baseline;
 line-height: 22px;
 position: relative;
 top: -1px;
}
div.list_item:hover {
 background-color: rgba(80,92,133,.05);
}
.breadcrumb > li {
 font-size: 12.0pt;
 color: #a2b0c7;
 border: none;
 text-shadow: none !important;
}
.breadcrumb > li + li:before {
 content: "/\00a0";
 padding: 0px;
 color: #a2b0c7;
 font-size: 18px;
}
#project_name > .breadcrumb {
 padding: 0px;
 margin-bottom: 0px;
 background-color: transparent;
 font-weight: normal;
 margin-top: -2px;
}
ul#tabs a {
 font-family: sans-serif;
 font-size: 13.5pt;
 font-weight: normal;
 font-style: normal;
 text-shadow: none !important;
}
.nav-tabs {
 font-family: sans-serif;
 font-size: 13.5pt;
 font-weight: normal;
 font-style: normal;
 background-color: transparent;
 border-color: transparent;
 text-shadow: none !important;
 border: 2px solid transparent;
}
.nav-tabs > li > a:active,
.nav-tabs > li > a:focus,
.nav-tabs > li > a:hover,
.nav-tabs > li.active > a,
.nav-tabs > li.active > a:focus,
.nav-tabs > li.active > a:hover,
.nav-tabs > li.active > a,
.nav-tabs > li.active > a:hover,
.nav-tabs > li.active > a:focus {
 color: #4c8be2;
 background-color: transparent;
 border-color: transparent;
 border-bottom: 2px solid transparent;
}
.nav > li.disabled > a,
.nav > li.disabled > a:hover {
 color: #546379;
}
.nav-tabs > li > a:before {
 content: "";
 position: absolute;
 width: 100%;
 height: 2px;
 bottom: -2px;
 left: 0;
 background-color: #4c8be2;
 visibility: hidden;
 -webkit-transform: perspective(0)scaleX(0);
 transform: perspective(0)scaleX(0);
 -webkit-transition: ease 220ms;
 transition: ease 220ms;
 -webkit-font-smoothing: antialiased !important;
}
.nav-tabs > li > a:hover:before {
 visibility: visible;
 -webkit-transform: perspective(1)scaleX(1);
 transform: perspective(1)scaleX(1);
}
.nav-tabs > li.active > a:before {
 content: "";
 position: absolute;
 width: 100%;
 height: 2px;
 bottom: -2px;
 left: 0;
 background-color: #4c8be2;
 visibility: visible;
 -webkit-transform: perspective(1)scaleX(1);
 transform: perspective(1)scaleX(1);
 -webkit-font-smoothing: subpixel-antialiased !important;
}
div#notebook {
 font-family: sans-serif;
 font-size: 13pt;
 padding-top: 4px;
}
.notebook_app {
 background-color: #262931;
}
#notebook-container {
 padding: 13px 2px;
 background-color: #262931;
 min-height: 0px;
 box-shadow: none;
 width: 980px;
 margin-right: auto;
 margin-left: auto;
}
div#ipython-main-app.container {
 width: 980px;
 margin-right: auto;
 margin-left: auto;
 margin-right: auto;
 margin-left: auto;
}
.container {
 width: 980px;
 margin-right: auto;
 margin-left: auto;
}
div#menubar-container {
 width: 100%;
 width: 980px;
}
div#header-container {
 width: 980px;
}
.notebook_app #header,
.edit_app #header {
 box-shadow: none !important;
 background-color: #262931;
 border-bottom: 2px solid rgba(80,92,133,.22);
}
#header,
.edit_app #header {
 font-family: sans-serif;
 font-size: 13pt;
 box-shadow: none;
 background-color: #262931;
}
#header .header-bar,
.edit_app #header .header-bar {
 background: #262931;
 background-color: #262931;
}
body > #header .header-bar {
 width: 100%;
 background: #262931;
}
span.checkpoint_status,
span.autosave_status {
 font-size: small;
 display: none;
}
#menubar,
div#menubar {
 background-color: #262931;
 padding-top: 0px !important;
}
#menubar .navbar,
.navbar-default {
 background-color: #262931;
 margin-bottom: 0px;
 margin-top: 0px;
}
.navbar {
 border: none;
}
div.navbar-text,
.navbar-text,
.navbar-text.indicator_area,
p.navbar-text.indicator_area {
 margin-top: 8px !important;
 margin-bottom: 0px;
 color: #4c8be2;
}
.navbar-default {
 font-family: sans-serif;
 font-size: 13pt;
 background-color: #262931;
 border-color: #343d4b;
 line-height: 1.5em;
 padding-bottom: 0px;
}
.navbar-default .navbar-nav > li > a {
 font-family: sans-serif;
 font-size: 13pt;
 color: #a2b0c7;
 display: block;
 line-height: 1.5em;
 padding-top: 14px;
 padding-bottom: 11px;
}
.navbar-default .navbar-nav > li > a:hover,
.navbar-default .navbar-nav > li > a:focus {
 color: #d8dcee !important;
 background-color: rgba(80,92,133,.22) !important;
 border-color: #343d4b !important;
 line-height: 1.5em;
 transition: 80ms ease;
}
.navbar-default .navbar-nav > .open > a,
.navbar-default .navbar-nav > .open > a:hover,
.navbar-default .navbar-nav > .open > a:focus {
 color: #e4e8ee;
 background-color: #384251;
 border-color: #384251;
 line-height: 1.5em;
}
.navbar-nav > li > .dropdown-menu {
 margin-top: 0px;
}
.navbar-nav {
 margin: 0;
}
div.notification_widget.info,
.notification_widget.info,
.notification_widget:active:hover,
.notification_widget.active:hover,
.open > .dropdown-toggle.notification_widget:hover,
.notification_widget:active:focus,
.notification_widget.active:focus,
.open > .dropdown-toggle.notification_widget:focus,
.notification_widget:active.focus,
.notification_widget.active.focus,
.open > .dropdown-toggle.notification_widget.focus,
div#notification_notebook.notification_widget.btn.btn-xs.navbar-btn,
div#notification_notebook.notification_widget.btn.btn-xs.navbar-btn:hover,
div#notification_notebook.notification_widget.btn.btn-xs.navbar-btn:focus {
 color: #899ab8 !important;
 background-color: transparent !important;
 border-color: transparent !important;
 padding-bottom: 0px !important;
 margin-bottom: 0px !important;
 font-size: 9pt !important;
 z-index: 0;
}
div#notification_notebook.notification_widget.btn.btn-xs.navbar-btn {
 font-size: 9pt !important;
 z-index: 0;
}
.notification_widget {
 color: #4c8be2;
 z-index: -500;
 font-size: 9pt;
 background: transparent;
 background-color: transparent;
 margin-right: 3px;
 border: none;
}
.notification_widget,
div.notification_widget {
 margin-right: 0px;
 margin-left: 0px;
 padding-right: 0px;
 vertical-align: text-top !important;
 margin-top: 6px !important;
 background: transparent !important;
 background-color: transparent !important;
 font-size: 9pt !important;
 border: none;
}
.navbar-btn.btn-xs:hover {
 border: none !important;
 background: transparent !important;
 background-color: transparent !important;
 color: #a2b0c7 !important;
}
div.notification_widget.info,
.notification_widget.info {
 display: none !important;
}
.edit_mode .modal_indicator:before {
 display: none;
}
.command_mode .modal_indicator:before {
 display: none;
}
.item_icon {
 color: #4c8be2;
}
.item_buttons .kernel-name {
 font-size: 13pt;
 color: #4c8be2;
}
.running_notebook_icon:before {
 color: #48a667 !important;
 font: normal normal normal 15px/1 FontAwesome;
 font-size: 15px;
 text-rendering: auto;
 -webkit-font-smoothing: antialiased;
 -moz-osx-font-smoothing: grayscale;
 content: "\f10c";
 vertical-align: middle;
 position: static;
 display: inherit;
}
.item_buttons .running-indicator {
 padding-top: 4px;
 color: #48a667;
 font-family: sans-serif;
 text-rendering: auto;
 -webkit-font-smoothing: antialiased;
}
#notification_trusted {
 font-family: sans-serif;
 border: none;
 background: transparent;
 background-color: transparent;
 margin-bottom: 0px !important;
 vertical-align: bottom !important;
 color: #546379 !important;
 cursor: default !important;
}
#notification_area,
div.notification_area {
 float: right !important;
 position: static;
 cursor: pointer;
 padding-top: 6px;
 padding-right: 4px;
}
div#notification_notebook.notification_widget.btn.btn-xs.navbar-btn {
 font-size: 9pt !important;
 z-index: 0;
 margin-top: -5px !important;
}
#modal_indicator {
 float: right !important;
 color: #4c8be2;
 background: #262931;
 background-color: #262931;
 margin-top: 8px !important;
 margin-left: 0px;
}
#kernel_indicator {
 float: right !important;
 color: #4c8be2;
 background: #262931;
 background-color: #262931;
 border-left: 2px solid #4c8be2;
 padding-top: 0px;
 padding-bottom: 4px;
 margin-top: 10px !important;
 margin-left: -2px;
 padding-left: 5px !important;
}
#kernel_indicator .kernel_indicator_name {
 font-size: 17px;
 color: #4c8be2;
 background: #262931;
 background-color: #262931;
 padding-left: 5px;
 padding-right: 5px;
 margin-top: 4px;
 vertical-align: text-top;
 padding-bottom: 0px;
}
.kernel_idle_icon:before {
 display: inline-block;
 font: normal normal normal 22px/1 FontAwesome;
 font-size: 22px;
 text-rendering: auto;
 -webkit-font-smoothing: antialiased;
 cursor: pointer;
 margin-left: 0px !important;
 opacity: 0.7;
 vertical-align: bottom;
 margin-top: 1px;
 content: "\f1db";
}
.kernel_busy_icon:before {
 display: inline-block;
 font: normal normal normal 22px/1 FontAwesome;
 font-size: 22px;
 -webkit-animation: pulsate 2s infinite ease-out;
 animation: pulsate 2s infinite ease-out;
 text-rendering: auto;
 -webkit-font-smoothing: antialiased;
 cursor: pointer;
 margin-left: 0px !important;
 vertical-align: bottom;
 margin-top: 1px;
 content: "\f111";
}
@-webkit-keyframes pulsate {
 0% {
  -webkit-transform: scale(1.0,1.0);
  opacity: 0.8;
 }
 8% {
  -webkit-transform: scale(1.0,1.0);
  opacity: 0.8;
 }
 50% {
  -webkit-transform: scale(0.75,0.75);
  opacity: 0.3;
 }
 92% {
  -webkit-transform: scale(1.0,1.0);
  opacity: 0.8;
 }
 100% {
  -webkit-transform: scale(1.0,1.0);
  opacity: 0.8;
 }
}
div.notification_widget.info,
.notification_widget.info,
.notification_widget:active:hover,
.notification_widget.active:hover,
.open > .dropdown-toggle.notification_widget:hover,
.notification_widget:active:focus,
.notification_widget.active:focus,
.open > .dropdown-toggle.notification_widget:focus,
.notification_widget:active.focus,
.notification_widget.active.focus,
.open > .dropdown-toggle.notification_widget.focus,
div#notification_notebook.notification_widget.btn.btn-xs.navbar-btn,
div#notification_notebook.notification_widget.btn.btn-xs.navbar-btn:hover,
div#notification_notebook.notification_widget.btn.btn-xs.navbar-btn:focus {
 color: #899ab8;
 background-color: #262931;
 border-color: #262931;
}
#notification_area,
div.notification_area {
 float: right !important;
 position: static;
}
.notification_widget,
div.notification_widget {
 margin-right: 0px;
 margin-left: 0px;
 padding-right: 0px;
 vertical-align: text-top !important;
 margin-top: 6px !important;
 z-index: 1000;
}
#kernel_logo_widget,
#kernel_logo_widget .current_kernel_logo {
 display: none;
}
div#ipython_notebook {
 display: none;
}
i.fa.fa-icon {
 -webkit-font-smoothing: antialiased;
 -moz-osx-font-smoothing: grayscale;
 text-rendering: auto;
}
.fa {
 display: inline-block;
 font: normal normal normal 10pt/1 "FontAwesome", sans-serif;
 text-rendering: auto;
 -webkit-font-smoothing: antialiased;
 -moz-osx-font-smoothing: grayscale;
}
.dropdown-menu {
 font-family: sans-serif;
 font-size: 13pt;
 box-shadow: none;
 padding: 0px;
 text-align: left;
 border: none;
 background-color: #384251;
 background: #384251;
 line-height: 1;
}
.dropdown-menu:hover {
 font-family: sans-serif;
 font-size: 13pt;
 box-shadow: none;
 padding: 0px;
 text-align: left;
 border: none;
 background-color: #384251;
 box-shadow: none;
 line-height: 1;
}
.dropdown-menu > li > a {
 font-family: sans-serif;
 font-size: 12.0pt;
 display: block;
 padding: 10px 20px 9px 10px;
 color: #a2b0c7;
 background-color: #384251;
 background: #384251;
}
.dropdown-menu > li > a:hover,
.dropdown-menu > li > a:focus {
 color: #d8dcee;
 background-color: #343d4b;
 background: #343d4b;
 border-color: #343d4b;
 transition: 200ms ease;
}
.dropdown-menu .divider {
 height: 1px;
 margin: 0px 0px;
 overflow: hidden;
 background-color: rgba(80,92,133,.45);
}
.dropdown-submenu > .dropdown-menu {
 display: none;
 top: 2px !important;
 left: 100%;
 margin-top: -2px;
 margin-left: 0px;
 padding-top: 0px;
 transition: 200ms ease;
}
.dropdown-menu > .disabled > a,
.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
 font-family: sans-serif;
 font-size: 12.0pt;
 font-weight: normal;
 color: #546379;
 padding: none;
 display: block;
 clear: both;
 white-space: nowrap;
}
.dropdown-submenu > a:after {
 color: #a2b0c7;
 margin-right: -16px;
 margin-top: 0px;
 display: inline-block;
}
.dropdown-submenu:hover > a:after,
.dropdown-submenu:active > a:after,
.dropdown-submenu:focus > a:after,
.dropdown-submenu:visited > a:after {
 color: #4c8be2;
 margin-right: -16px;
 display: inline-block !important;
}
div.kse-dropdown > .dropdown-menu,
.kse-dropdown > .dropdown-menu {
 min-width: 0;
 top: 94%;
}
.btn,
.btn-default {
 font-family: sans-serif;
 color: #a2b0c7;
 background: #3a4452;
 background-color: #3a4452;
 border: 2px solid #3a4452;
 font-weight: normal;
 box-shadow: none;
 text-shadow: none;
 border-radius: 3px;
 font-size: initial;
}
.btn:hover,
.btn:active:hover,
.btn.active:hover,
.btn-default:hover,
.open > .dropdown-toggle.btn-default:hover,
.open > .dropdown-toggle.btn:hover {
 color: #4c8be2;
 border: 2px solid #363f4c;
 background-color: #363f4c;
 background: #363f4c;
 background-image: none;
 box-shadow: none !important;
 border-radius: 3px;
}
.btn:active,
.btn.active,
.btn:active:focus,
.btn.active:focus,
.btn:active.focus,
.btn.active.focus,
.btn-default:focus,
.btn-default.focus,
.btn-default:active,
.btn-default.active,
.btn-default:active:hover,
.btn-default.active:hover,
.btn-default:active:focus,
.btn-default.active:focus,
.btn-default:active.focus,
.btn-default.active.focus,
.open > .dropdown-toggle.btn:focus,
.open > .dropdown-toggle.btn.focus,
.open > .dropdown-toggle.btn-default:hover,
.open > .dropdown-toggle.btn-default:focus,
.open > .dropdown-toggle.btn-default.hover,
.open > .dropdown-toggle.btn-default.focus {
 color: #4c8be2;
 border: 2px solid #363f4c;
 background-color: #363f4c !important;
 background: #363f4c !important;
 background-image: none;
 box-shadow: none !important;
 border-radius: 3px;
}
.btn-default:active:hover,
.btn-default.active:hover,
.btn-default:active:focus,
.btn-default.active:focus,
.btn-default:active.focus,
.btn-default.active.focus {
 color: #157bff !important;
 background-color: #3a4452;
 border-color: #33517c !important;
 transition: 2000ms ease;
}
.btn:focus,
.btn.focus,
.btn:active:focus,
.btn.active:focus,
.btn:active,
.btn.active,
.btn:active.focus,
.btn.active.focus {
 color: #157bff !important;
 outline: none !important;
 outline-width: 0px !important;
 background: #33517c !important;
 background-color: #33517c !important;
 border-color: #33517c !important;
 transition: 200ms ease !important;
}
.item_buttons > .btn,
.item_buttons > .btn-group,
.item_buttons > .input-group {
 font-size: 13pt;
 background: transparent;
 background-color: transparent;
 border: 0px solid #2e3642;
 border-bottom: 2px solid transparent;
 margin-left: 5px;
 padding-top: 4px !important;
}
.item_buttons > .btn:hover,
.item_buttons > .btn-group:hover,
.item_buttons > .input-group:hover,
.item_buttons > .btn.active,
.item_buttons > .btn-group.active,
.item_buttons > .input-group.active,
.item_buttons > .btn.focus {
 margin-left: 5px;
 background: #2a313c;
 padding-top: 4px !important;
 background-color: transparent;
 border: 0px solid transparent;
 border-bottom: 2px solid #4c8be2;
 border-radius: 0px;
 transition: none;
}
.item_buttons {
 line-height: 1.5em !important;
}
.item_buttons .btn {
 min-width: 11ex;
}
.btn-group > .btn:first-child {
 margin-left: 3px;
}
.btn-group > .btn-mini,
.btn-sm,
.btn-group-sm > .btn,
.btn-xs,
.btn-group-xs > .btn,
.alternate_upload .btn-upload,
.btn-group,
.btn-group-vertical {
 font-size: inherit;
 font-weight: normal;
 height: inherit;
 line-height: inherit;
}
.btn-xs,
.btn-group-xs > .btn {
 font-size: initial !important;
 background-image: none;
 font-weight: normal;
 text-shadow: none;
 display: inline-table;
 padding: 2px 5px;
 line-height: 1.45;
}
.btn-group > .btn:first-child {
 margin-left: 3px;
}
div#new-buttons > button,
#new-buttons > button,
div#refresh_notebook_list,
#refresh_notebook_list {
 background: transparent;
 background-color: transparent;
 border: none;
}
div#new-buttons > button:hover,
#new-buttons > button:hover,
div#refresh_notebook_list,
#refresh_notebook_list,
div.alternate_upload .btn-upload,
.alternate_upload .btn-upload,
div.dynamic-buttons > button,
.dynamic-buttons > button,
.dynamic-buttons > button:focus,
.dynamic-buttons > button:active:focus,
.dynamic-buttons > button.active:focus,
.dynamic-buttons > button.focus,
.dynamic-buttons > button:active.focus,
.dynamic-buttons > button.active.focus,
#new-buttons > button:focus,
#new-buttons > button:active:focus,
#new-buttons > button.active:focus,
#new-buttons > button.focus,
#new-buttons > button:active.focus,
#new-buttons > button.active.focus,
.alternate_upload .btn-upload:focus,
.alternate_upload .btn-upload:active:focus,
.alternate_upload .btn-upload.active:focus,
.alternate_upload .btn-upload.focus,
.alternate_upload .btn-upload:active.focus,
.alternate_upload .btn-upload.active.focus {
 background: transparent !important;
 background-color: transparent !important;
 border: none !important;
}
.alternate_upload input.fileinput {
 text-align: center;
 vertical-align: bottom;
 margin-left: -.5ex;
 display: inline-table;
 border: solid 0px #3a4452;
 margin-bottom: -1ex;
}
.alternate_upload .btn-upload {
 display: inline-table;
 background: transparent;
 border: none;
}
.btn-group .btn + .btn,
.btn-group .btn + .btn-group,
.btn-group .btn-group + .btn,
.btn-group .btn-group + .btn-group {
 margin-left: -2px;
}
.btn-group > .btn:first-child:not(:last-child):not(.dropdown-toggle) {
 border-bottom-right-radius: 0;
 border-top-right-radius: 0;
 z-index: 2;
}
.dropdown-header {
 font-family: sans-serif !important;
 font-size: 13pt !important;
 color: #4c8be2 !important;
 border-bottom: none !important;
 padding: 0px !important;
 margin: 6px 6px 0px !important;
}
span#last-modified.btn.btn-xs.btn-default.sort-action,
span#sort-name.btn.btn-xs.btn-default.sort-action,
span#file-size.btn.btn-xs.btn-default.sort-action {
 font-family: sans-serif;
 font-size: 16px;
 background-color: transparent;
 background: transparent;
 border: none;
 color: #a2b0c7;
 padding-bottom: 0px;
 margin-bottom: 0px;
 vertical-align: sub;
}
span#last-modified.btn.btn-xs.btn-default.sort-action {
 margin-left: 19px;
}
button.close {
 border: 0px none;
 font-family: sans-serif;
 font-size: 20pt;
 font-weight: normal;
}
.dynamic-buttons {
 padding-top: 0px;
 display: inline-block;
}
.close {
 color: #dc6972;
 opacity: .5;
 text-shadow: none;
 font-weight: normal;
}
.close:hover {
 color: #dc6972;
 opacity: 1;
 font-weight: normal;
}
div.nbext-enable-btns .btn[disabled],
div.nbext-enable-btns .btn[disabled]:hover,
.btn-default.disabled,
.btn-default[disabled],
.btn-default.disabled:hover,
.btn-default[disabled]:hover,
fieldset[disabled] .btn-default:hover,
.btn-default.disabled:focus,
.btn-default[disabled]:focus,
fieldset[disabled] .btn-default:focus,
.btn-default.disabled.focus,
.btn-default[disabled].focus,
fieldset[disabled] .btn-default.focus {
 color: #92a2bd;
 background: #38424f;
 background-color: #38424f;
 border-color: #38424f;
 transition: 200ms ease;
}
.input-group-addon {
 padding: 2px 5px;
 font-size: 13pt;
 font-weight: normal;
 height: auto;
 color: #a2b0c7;
 text-align: center;
 background-color: transparent;
 border: 2px solid transparent !important;
 text-transform: capitalize;
}
a.btn.btn-default.input-group-addon:hover {
 background: transparent !important;
 background-color: transparent !important;
}
.btn-group > .btn + .dropdown-toggle {
 padding-left: 8px;
 padding-right: 8px;
 height: 100%;
}
.btn-group > .btn + .dropdown-toggle:hover {
 background: #363f4c !important;
}
.input-group-btn {
 position: relative;
 font-size: inherit;
 white-space: nowrap;
 background: #2e3642;
 background-color: #2e3642;
 border: none;
}
.input-group-btn:hover {
 background: #2a313c;
 background-color: #2a313c;
 border: none;
}
.input-group-btn:first-child > .btn,
.input-group-btn:first-child > .btn-group {
 background: #2e3642;
 background-color: #2e3642;
 border: none;
 margin-left: 2px;
 margin-right: -1px;
 font-size: inherit;
}
.input-group-btn:first-child > .btn:hover,
.input-group-btn:first-child > .btn-group:hover {
 background: #363f4c;
 background-color: #363f4c;
 border: none;
 font-size: inherit;
 transition: 200ms ease;
}
div.modal .btn-group > .btn:first-child {
 background: #2e3642;
 background-color: #2e3642;
 border: 1px solid #2c343f;
 margin-top: 0px !important;
 margin-left: 0px;
 margin-bottom: 2px;
}
div.modal .btn-group > .btn:first-child:hover {
 background: #2a313c;
 background-color: #2a313c;
 border: 1px solid #2a313c;
 transition: 200ms ease;
}
div.modal > button,
div.modal-footer > button {
 background: #2e3642;
 background-color: #2e3642;
 border-color: #2e3642;
}
div.modal > button:hover,
div.modal-footer > button:hover {
 background: #2a313c;
 background-color: #2a313c;
 border-color: #2a313c;
 transition: 200ms ease;
}
.modal-content {
 font-family: sans-serif;
 font-size: 12.0pt;
 position: relative;
 background: #2e3642;
 background-color: #2e3642;
 border: none;
 border-radius: 1px;
 background-clip: padding-box;
 outline: none;
}
.modal-header {
 font-family: sans-serif;
 font-size: 13pt;
 color: #a2b0c7;
 background: #2e3642;
 background-color: #2e3642;
 border-color: rgba(80,92,133,.22);
 padding: 12px;
 min-height: 16.4286px;
}
.modal-content h4 {
 font-family: sans-serif;
 font-size: 16pt;
 color: #a2b0c7;
 padding: 5px;
}
.modal-body {
 background-color: #384152;
 position: relative;
 padding: 15px;
}
.modal-footer {
 padding: 8px;
 text-align: right;
 background-color: #384152;
 border-top: none;
}
.alert-info {
 background-color: #4a5467;
 border-color: rgba(80,92,133,.22);
 color: #a2b0c7;
}
.modal-header .close {
 margin-top: -5px;
 font-size: 25pt;
}
.modal-backdrop,
.modal-backdrop.in {
 opacity: 0.85;
 background-color: notebook-bg;
}
div.panel,
div.panel-default,
.panel,
.panel-default {
 font-family: sans-serif;
 font-size: 13pt;
 background-color: #384152;
 color: #a2b0c7;
 margin-bottom: 14px;
 border: 0;
 box-shadow: none;
}
div.panel > .panel-heading,
div.panel-default > .panel-heading {
 font-size: 14pt;
 color: #a2b0c7;
 background: #2e3642;
 background-color: #2e3642;
 border: 0;
}
.modal .modal-dialog {
 min-width: 950px;
 margin: 50px auto;
}
div.container-fluid {
 margin-right: auto;
 margin-left: auto;
 padding-left: 0px;
 padding-right: 5px;
}
div.form-control,
.form-control {
 font-family: sans-serif;
 font-size: initial;
 color: #a2b0c7;
 background-color: #2a313c;
 border: 1px solid #2a313c !important;
 margin-left: 2px;
 box-shadow: none;
 transition: border-color 0.15s ease-in-out 0s, box-shadow 0.15s ease-in-out 0s;
}
.form-control-static {
 min-height: inherit;
 height: inherit;
}
.form-group.list-group-item {
 color: #a2b0c7;
 background-color: #384152;
 border-color: rgba(80,92,133,.22);
 margin-bottom: 0px;
}
.form-group .input-group {
 float: left;
}
input,
button,
select,
textarea {
 background-color: #2a313c;
 font-weight: normal;
 border: 1px solid rgba(80,92,133,.22);
}
select.form-control.select-xs {
 height: 33px;
 font-size: 13pt;
}
.toolbar select,
.toolbar label {
 width: auto;
 vertical-align: middle;
 margin-right: 0px;
 margin-bottom: 0px;
 display: inline;
 font-size: 92%;
 margin-left: 10px;
 padding: 0px;
 background: #3a4452 !important;
 background-color: #3a4452 !important;
 border: 2px solid #3a4452 !important;
}
.form-control:focus {
 border-color: #4c8be2;
 outline: 2px solid #3572c6;
 -webkit-box-shadow: none;
}
::-webkit-input-placeholder {
 color: #546379;
}
::-moz-placeholder {
 color: #546379;
}
:-ms-input-placeholder {
 color: #546379;
}
:-moz-placeholder {
 color: #546379;
}
[dir="ltr"] #find-and-replace .input-group-btn + .form-control {
 border: 2px solid rgba(80,92,133,.22) !important;
}
[dir="ltr"] #find-and-replace .input-group-btn + .form-control:focus {
 border-color: #4c8be2;
 outline: 2px solid #3572c6;
 -webkit-box-shadow: none;
 box-shadow: none;
}
div.output.output_scroll {
 box-shadow: none;
}
::-webkit-scrollbar {
 width: 11px;
 max-height: 9px;
 background-color: #292d3a;
 border-radius: 3px;
 border: none;
}
::-webkit-scrollbar-track {
 background: #292d3a;
 border: none;
 width: 11px;
 max-height: 9px;
}
::-webkit-scrollbar-thumb {
 border-radius: 2px;
 border: none;
 background: #3f4555;
 background-clip: content-box;
 width: 11px;
}
HTML,
body,
div,
dl,
dt,
dd,
ul,
ol,
li,
h1,
h2,
h3,
h4,
h5,
h6,
pre,
code,
form,
fieldset,
legend,
input,
button,
textarea,
p,
blockquote,
th,
td,
span,
a {
 text-rendering: geometricPrecision;
 -webkit-font-smoothing: subpixel-antialiased;
 font-weight: 400;
}
div.input_area {
 background-color: #303845;
 background: #303845;
 padding-right: 1.2em;
 border: 0px;
 border-radius: 0px;
 border-top-right-radius: 4px;
 border-bottom-right-radius: 4px;
}
div.cell {
 padding: 0px;
 background: #303845;
 background-color: #303845;
 border: medium solid #262931;
 border-radius: 4px;
 top: 0;
}
div.cell.selected {
 background: #303845;
 background-color: #303845;
 border: medium solid #262931;
 padding: 0px;
 border-radius: 5px;
}
.edit_mode div.cell.selected {
 padding: 0px;
 background: #303845;
 background-color: #303845;
 border: medium solid #262931;
 border-radius: 5px;
}
div.cell.edit_mode {
 padding: 0px;
 background: #303845;
 background-color: #303845;
}
div.CodeMirror-sizer {
 margin-left: 0px;
 margin-bottom: -21px;
 border-right-width: 16px;
 min-height: 37px;
 padding-right: 0px;
 padding-bottom: 0px;
 margin-top: 0px;
}
div.cell.selected:before,
.edit_mode div.cell.selected:before,
div.cell.selected:before,
div.cell.selected.jupyter-soft-selected:before {
 background: #303845 !important;
 border: none;
 border-radius: 3px;
 position: absolute;
 display: block;
 top: 0px;
 left: 0px;
 width: 0px;
 height: 100%;
}
div.cell.text_cell.selected::before,
.edit_mode div.cell.text_cell.selected:before,
div.cell.text_cell.selected:before,
div.cell.text_cell.selected.jupyter-soft-selected:before {
 background: #303845 !important;
 background-color: #303845 !important;
 border-color: #2769c3 !important;
}
div.cell.code_cell .input {
 border-left: 5px solid #303845 !important;
 border-radius: 3px;
 border-bottom-left-radius: 3px;
 border-top-left-radius: 3px;
}
div.cell.code_cell.selected .input {
 border-left: 5px solid #2769c3 !important;
 border-radius: 3px;
}
.edit_mode div.cell.code_cell.selected .input {
 border-left: 5px solid #33517c !important;
 border-radius: 3px;
}
.edit_mode div.cell.selected:before {
 height: 100%;
 border-left: 5px solid #33517c !important;
 border-radius: 3px;
}
div.cell.jupyter-soft-selected,
div.cell.selected.jupyter-soft-selected {
 border-left-color: #33517c !important;
 border-left-width: 0px !important;
 padding-left: 7px !important;
 border-right-color: #33517c !important;
 border-right-width: 0px !important;
 background: #33517c !important;
 border-radius: 6px !important;
}
div.cell.selected.jupyter-soft-selected .input {
 border-left: 5px solid #303845 !important;
}
div.cell.selected.jupyter-soft-selected {
 border-left-color: #2769c3;
 border-color: #262931;
 padding-left: 7px;
 border-radius: 6px;
}
div.cell.code_cell.selected .input {
 border-left: none;
 border-radius: 3px;
}
div.cell.selected.jupyter-soft-selected .prompt,
div.cell.text_cell.selected.jupyter-soft-selected .prompt {
 top: 0;
 border-left: #303845 !important;
 border-radius: 2px;
}
div.cell.text_cell.selected.jupyter-soft-selected .input_prompt {
 border-left: none !important;
}
div.cell.text_cell.jupyter-soft-selected,
div.cell.text_cell.selected.jupyter-soft-selected {
 border-left-color: #33517c !important;
 border-left-width: 0px !important;
 padding-left: 26px !important;
 border-right-color: #33517c !important;
 border-right-width: 0px !important;
 background: #33517c !important;
 border-radius: 5px !important;
}
div.cell.jupyter-soft-selected .input,
div.cell.selected.jupyter-soft-selected .input {
 border-left-color: #33517c !important;
}
div.prompt,
.prompt {
 font-family: monospace, monospace;
 font-size: 9pt !important;
 font-weight: normal;
 color: #446489;
 line-height: 170%;
 padding: 0px;
 padding-top: 4px;
 padding-left: 0px;
 padding-right: 1px;
 text-align: right !important;
 min-width: 11.5ex !important;
 width: 11.5ex !important;
}
div.prompt.input_prompt {
 font-size: 9pt !important;
 background-color: #303845;
 border-top: 0px;
 border-top-right-radius: 0px;
 border-bottom-left-radius: 0px;
 border-bottom-right-radius: 0px;
 padding-right: 3px;
 min-width: 11.5ex;
 width: 11.5ex !important;
}
div.cell.code_cell .input_prompt {
 border-right: 2px solid #3572c6;
}
div.cell.selected .prompt {
 top: 0;
}
.edit_mode div.cell.selected .prompt {
 top: 0;
}
.edit_mode div.cell.selected .prompt {
 top: 0;
}
.run_this_cell {
 visibility: hidden;
 color: transparent;
 padding-top: 0px;
 padding-bottom: 0px;
 padding-left: 3px;
 padding-right: 12px;
 width: 1.5ex;
 width: 0ex;
 background: transparent;
 background-color: transparent;
}
div.code_cell:hover div.input .run_this_cell {
 visibility: visible;
}
div.cell.code_cell.rendered.selected .run_this_cell:hover {
 background-color: #282e39;
 background: #282e39;
 color: #2769c3 !important;
}
div.cell.code_cell.rendered.unselected .run_this_cell:hover {
 background-color: #282e39;
 background: #282e39;
 color: #2769c3 !important;
}
i.fa-step-forward.fa {
 display: inline-block;
 font: normal normal normal 9px "FontAwesome";
}
.fa-step-forward:before {
 content: "\f04b";
}
div.cell.selected.jupyter-soft-selected .run_this_cell,
div.cell.selected.jupyter-soft-selected .run_this_cell:hover,
div.cell.unselected.jupyter-soft-selected .run_this_cell:hover,
div.cell.code_cell.rendered.selected.jupyter-soft-selected .run_this_cell:hover,
div.cell.code_cell.rendered.unselected.jupyter-soft-selected .run_this_cell:hover {
 background-color: #33517c !important;
 background: #33517c !important;
 color: #33517c !important;
}
div.output_wrapper {
 background-color: #384151;
 border: 0px;
 left: 0px;
 margin-bottom: 0em;
 margin-top: 0em;
 border-top-right-radius: 0px;
 border-top-left-radius: 0px;
}
div.output_subarea.output_text.output_stream.output_stdout,
div.output_subarea.output_text {
 font-family: monospace, monospace;
 font-size: 8.5pt !important;
 line-height: 150% !important;
 background-color: #384151;
 color: #cdd2e9;
 border-top-right-radius: 0px;
 border-top-left-radius: 0px;
 margin-left: 11.5px;
}
div.output_area pre {
 font-family: monospace, monospace;
 font-size: 8.5pt !important;
 line-height: 151% !important;
 color: #cdd2e9;
 border-top-right-radius: 0px;
 border-top-left-radius: 0px;
}
div.output_area {
 display: -webkit-box;
}
div.output_html {
 font-family: monospace, monospace;
 font-size: 8.5pt;
 color: #dbdfef;
 background-color: #384151;
 background: #384151;
}
div.output_subarea {
 overflow-x: auto;
 padding: 1.2em !important;
 -webkit-box-flex: 1;
 -moz-box-flex: 1;
 box-flex: 1;
 flex: 1;
}
div.btn.btn-default.output_collapsed {
 background: #242a33;
 background-color: #242a33;
 border-color: #242a33;
}
div.btn.btn-default.output_collapsed:hover {
 background: #1f252d;
 background-color: #1f252d;
 border-color: #1f252d;
}
div.prompt.output_prompt {
 font-family: monospace, monospace;
 font-weight: bold !important;
 background-color: #384151;
 color: transparent;
 border-bottom-left-radius: 4px;
 border-top-right-radius: 0px;
 border-top-left-radius: 0px;
 border-bottom-right-radius: 0px;
 min-width: 11.5ex !important;
 width: 11.5ex !important;
 border-right: 2px solid transparent;
}
div.out_prompt_overlay.prompt {
 font-family: monospace, monospace;
 font-weight: bold !important;
 background-color: #384151;
 border-bottom-left-radius: 2px;
 border-top-right-radius: 0px;
 border-top-left-radius: 0px;
 border-bottom-right-radius: 0px;
 min-width: 11.5ex !important;
 width: 11.5ex !important;
 border-right: 2px solid transparent;
 color: transparent;
}
div.out_prompt_overlay.prompt:hover {
 background-color: #3e4458;
 box-shadow: none !important;
 border: none;
 border-bottom-left-radius: 2px;
 -webkit-border-: 2px;
 -moz-border-radius: 2px;
 border-top-right-radius: 0px;
 border-top-left-radius: 0px;
 min-width: 11.5ex !important;
 width: 11.5ex !important;
 border-right: 2px solid #3e4458 !important;
}
div.cell.code_cell .output_prompt {
 border-right: 2px solid transparent;
 color: transparent;
}
div.cell.selected .output_prompt,
div.cell.selected .out_prompt_overlay.prompt {
 border-left: 5px solid #33517c;
 border-right: 2px solid #384151;
 border-radius: 0px !important;
}
.edit_mode div.cell.selected .output_prompt,
.edit_mode div.cell.selected .out_prompt_overlay.prompt {
 border-left: 5px solid #33517c;
 border-right: 2px solid #384151;
 border-radius: 0px !important;
}
div.text_cell,
div.text_cell_render pre,
div.text_cell_render {
 font-family: sans-serif;
 font-size: 13pt;
 line-height: 130% !important;
 color: #abc1e2;
 background: #303845;
 background-color: #303845;
 border-radius: 0px;
}
div .text_cell_render {
 padding: 0.4em 0.4em 0.4em 0.4em;
}
div.cell.text_cell .CodeMirror-lines {
 padding-top: .7em !important;
 padding-bottom: .4em !important;
 padding-left: .5em !important;
 padding-right: .5em !important;
 margin-top: .4em;
 margin-bottom: .3em;
}
div.cell.text_cell.unrendered div.input_area,
div.cell.text_cell.rendered div.input_area {
 background-color: #303845;
 background: #303845;
 border: 0px;
 border-radius: 2px;
}
div.cell.text_cell .CodeMirror,
div.cell.text_cell .CodeMirror pre {
 line-height: 170% !important;
}
div.cell.text_cell.rendered.selected {
 font-family: sans-serif;
 line-height: 170% !important;
 background: #303845;
 background-color: #303845;
 border-radius: 0px;
}
div.cell.text_cell.unrendered.selected {
 font-family: sans-serif;
 line-height: 170% !important;
 background: #303845;
 background-color: #303845;
 border-radius: 0px;
}
div.cell.text_cell.selected {
 font-family: sans-serif;
 line-height: 170% !important;
 background: #303845;
 background-color: #303845;
 border-radius: 0px;
}
.edit_mode div.cell.text_cell.selected {
 font-family: sans-serif;
 line-height: 170% !important;
 background: #303845;
 background-color: #303845;
 border-radius: 0px;
}
div.text_cell.unrendered,
div.text_cell.unrendered.selected,
div.edit_mode div.text_cell.unrendered {
 font-family: sans-serif;
 line-height: 170% !important;
 background: #303845;
 background-color: #303845;
 border-radius: 0px;
}
div.cell.text_cell .prompt {
 border-right: 0;
 min-width: 11.5ex !important;
 width: 11.5ex !important;
}
div.cell.text_cell.rendered .prompt {
 font-family: monospace, monospace;
 font-size: 9.5pt !important;
 font-weight: normal;
 color: #446489 !important;
 text-align: right !important;
 min-width: 14.5ex !important;
 width: 14.5ex !important;
 background-color: #303845;
 border-right: 2px solid rgba(53,114,198,.5);
 border-left: 4px solid #303845;
}
div.cell.text_cell.unrendered .prompt {
 font-family: monospace, monospace;
 font-size: 9.5pt !important;
 font-weight: normal;
 color: #446489 !important;
 text-align: right !important;
 min-width: 14.5ex !important;
 width: 14.5ex !important;
 border-right: 2px solid rgba(53,114,198,.5);
 border-left: 4px solid #303845;
 background-color: #303845;
}
div.cell.text_cell.rendered .prompt {
 border-right: 2px solid rgba(53,114,198,.5);
}
div.cell.text_cell.rendered.selected .prompt {
 top: 0;
 border-left: 4px solid #2769c3;
 border-right: 2px solid rgba(53,114,198,.5);
}
div.text_cell.unrendered.selected .prompt,
div.text_cell.rendered.selected .prompt {
 top: 0;
 background: #303845;
 border-left: 4px solid #33517c;
 border-right: 2px solid rgba(53,114,198,.5);
}
div.rendered_html code {
 font-family: monospace, monospace;
 font-size: 11pt;
 padding-top: 3px;
 padding-left: 2px;
 color: #cdd2e9;
 background: #2a313c;
 background-color: #2a313c;
}
pre,
code,
kbd,
samp {
 white-space: pre-wrap;
}
.well code,
code {
 font-family: monospace, monospace;
 font-size: 11pt !important;
 line-height: 170% !important;
 color: #abc1e2;
 background: #2a313c;
 background-color: #2a313c;
 border-color: #2a313c;
}
kbd {
 padding: 1px;
 font-size: 11pt;
 font-weight: 800;
 color: #cdd2e9;
 background-color: transparent !important;
 border: 0;
 box-shadow: none;
}
pre {
 display: block;
 padding: 8.5px;
 margin: 0 0 9px;
 font-size: 12.0pt;
 line-height: 1.42857143;
 color: #cdd2e9;
 background-color: #2a313c;
 border: 1px solid #2a313c;
 border-radius: 2px;
}
div.rendered_html {
 color: #abc1e2;
}
.rendered_html * + ul {
 margin-top: .4em;
 margin-bottom: .3em;
}
.rendered_html * + p {
 margin-top: .5em;
 margin-bottom: .5em;
}
div.rendered_html pre {
 font-family: monospace, monospace;
 font-size: 11pt !important;
 line-height: 170% !important;
 color: #abc1e2 !important;
 background: #2a313c;
 background-color: #2a313c;
 max-width: 80%;
 border-radius: 0px;
 border-left: 3px solid #2a313c;
 max-width: 80%;
 border-radius: 0px;
 padding-left: 5px;
 margin-left: 6px;
}
div.text_cell_render pre,
div.text_cell_render code {
 font-family: monospace, monospace;
 font-size: 11pt !important;
 line-height: 170% !important;
 color: #abc1e2;
 background: #262931;
 background-color: #262931;
 max-width: 80%;
 border-radius: 0px;
 border-left: none;
}
div.text_cell_render pre {
 border-left: 3px solid #3572c6 !important;
 max-width: 80%;
 border-radius: 0px;
 padding-left: 5px;
 margin-left: 6px;
}
div.text_cell_render h1,
div.rendered_html h1,
div.text_cell_render h2,
div.rendered_html h2,
div.text_cell_render h3,
div.rendered_html h3,
div.text_cell_render h4,
div.rendered_html h4,
div.text_cell_render h5,
div.rendered_html h5 {
 font-family: sans-serif;
 margin: 0.4em .2em .3em .2em !important;
}
.rendered_html h1:first-child,
.rendered_html h2:first-child,
.rendered_html h3:first-child,
.rendered_html h4:first-child,
.rendered_html h5:first-child,
.rendered_html h6:first-child {
 margin-top: 0.2em !important;
 margin-bottom: 0.2em !important;
}
.rendered_html h1,
.text_cell_render h1 {
 color: #4c8be2 !important;
 font-size: 200%;
 text-align: left;
 font-style: normal;
 font-weight: normal;
}
.rendered_html h2,
.text_cell_render h2 {
 color: #4c8be2 !important;
 font-size: 170%;
 font-style: normal;
 font-weight: normal;
}
.rendered_html h3,
.text_cell_render h3 {
 color: #4c8be2 !important;
 font-size: 140%;
 font-style: normal;
 font-weight: normal;
}
.rendered_html h4,
.text_cell_render h4 {
 color: #4c8be2 !important;
 font-size: 110%;
 font-style: normal;
 font-weight: normal;
}
.rendered_html h5,
.text_cell_render h5 {
 color: #4c8be2 !important;
 font-size: 100%;
 font-style: normal;
 font-weight: normal;
}
hr {
 margin-top: 8px;
 margin-bottom: 10px;
 border: 0;
 border-top: 1px solid #4c8be2;
}
.rendered_html hr {
 color: #4c8be2;
 background-color: #4c8be2;
 margin-right: 2em;
}
#complete > select > option:hover {
 background: #343d4b;
 background-color: #343d4b;
}
div#_vivaldi-spatnav-focus-indicator._vivaldi-spatnav-focus-indicator {
 position: absolute;
 z-index: 9999999999;
 top: 0px;
 left: 0px;
 box-shadow: none;
 pointer-events: none;
 border-radius: 2px;
}
.rendered_html tr,
.rendered_html th,
.rendered_html td {
 text-align: left;
 vertical-align: middle;
 padding: 0.42em 0.47em;
 line-height: normal;
 white-space: normal;
 max-width: none;
 border: none;
}
.rendered_html td {
 font-family: sans-serif !important;
 font-size: 9.3pt;
}
.rendered_html table {
 font-family: sans-serif !important;
 margin-left: 8px;
 margin-right: auto;
 border: none;
 border-collapse: collapse;
 border-spacing: 0;
 color: #dbdfef;
 table-layout: fixed;
}
.rendered_html thead {
 font-family: sans-serif !important;
 font-size: 10.3pt !important;
 background: #2e3642;
 color: #d4d8ec;
 border-bottom: 1px solid #2e3642;
 vertical-align: bottom;
}
.rendered_html tbody tr:nth-child(odd) {
 background: #434d61;
}
.rendered_html tbody tr {
 background: #3d4658;
}
.rendered_html tbody tr:hover:nth-child(odd) {
 background: #414b5e;
}
.rendered_html tbody tr:hover {
 background: #3b4355;
}
.rendered_html * + table {
 margin-top: .05em;
}
div.widget-area {
 background-color: #384151;
 background: #384151;
 color: #cdd2e9;
}
div.widget-area a {
 font-family: sans-serif;
 font-size: 12.0pt;
 font-weight: normal;
 font-style: normal;
 color: #a2b0c7;
 text-shadow: none !important;
}
div.widget-area a:hover,
div.widget-area a:focus {
 font-family: sans-serif;
 font-size: 12.0pt;
 font-weight: normal;
 font-style: normal;
 color: #d8dcee;
 background: rgba(80,92,133,.22);
 background-color: rgba(80,92,133,.22);
 border-color: transparent;
 background-image: none;
 text-shadow: none !important;
}
div.widget_item.btn-group > button.btn.btn-default.widget-combo-btn,
div.widget_item.btn-group > button.btn.btn-default.widget-combo-btn:hover {
 background: #2c343f;
 background-color: #2c343f;
 border: 2px solid #2c343f !important;
 font-size: inherit;
 z-index: 0;
}
div.jupyter-widgets.widget-hprogress.widget-hbox {
 display: inline-table !important;
 width: 38% !important;
 margin-left: 10px;
}
div.jupyter-widgets.widget-hprogress.widget-hbox .widget-label,
div.widget-hbox .widget-label,
.widget-hbox .widget-label,
.widget-inline-hbox .widget-label,
div.widget-label {
 text-align: -webkit-auto !important;
 margin-left: 15px !important;
 max-width: 240px !important;
 min-width: 100px !important;
 vertical-align: text-top !important;
 color: #cdd2e9 !important;
 font-size: 14px !important;
}
.widget-hprogress .progress {
 flex-grow: 1;
 height: 20px;
 margin-top: auto;
 margin-left: 12px;
 margin-bottom: auto;
 width: 300px;
}
.progress {
 overflow: hidden;
 height: 22px;
 margin-bottom: 10px;
 padding-left: 10px;
 background-color: #546379 !important;
 border-radius: 2px;
 -webkit-box-shadow: none;
 box-shadow: none;
 z-index: 10;
}
.progress-bar-danger {
 background-color: #e74c3c !important;
}
.progress-bar-info {
 background-color: #3498db !important;
}
.progress-bar-warning {
 background-color: #ff914d !important;
}
.progress-bar-success {
 background-color: #83a83b !important;
}
.widget-select select {
 margin-left: 12px;
}
.rendered_html :link {
 font-family: sans-serif;
 font-size: 100%;
 color: #4c8be2;
 text-decoration: underline;
}
.rendered_html :visited,
.rendered_html :visited:active,
.rendered_html :visited:focus {
 color: #6297e0;
}
.rendered_html :visited:hover,
.rendered_html :link:hover {
 font-family: sans-serif;
 font-size: 100%;
 color: #1671ef;
}
div.cell.text_cell a.anchor-link:link {
 font-size: inherit;
 text-decoration: none;
 padding: 0px 20px;
 visibility: none;
 color: rgba(0,0,0,.32);
}
div.cell.text_cell a.anchor-link:link:hover {
 font-size: inherit;
 color: #61afef;
}
.navbar-text {
 margin-top: 4px;
 margin-bottom: 0px;
}
#clusters > a {
 color: #61afef;
 text-decoration: underline;
 cursor: auto;
}
#clusters > a:hover {
 color: #4c8be2;
 text-decoration: underline;
 cursor: auto;
}
#nbextensions-configurator-container > div.row.container-fluid.nbext-selector > h3 {
 font-size: 17px;
 margin-top: 5px;
 margin-bottom: 8px;
 height: 24px;
 padding: 4px 0 4px 0;
}
div#nbextensions-configurator-container.container,
#nbextensions-configurator-container.container {
 width: 100%;
 margin-right: auto;
 margin-left: auto;
}
div.nbext-selector > nav > .nav > li > a {
 font-family: sans-serif;
 font-size: 10.5pt;
 padding: 2px 5px;
}
div.nbext-selector > nav > .nav > li > a:hover {
 background: transparent;
}
div.nbext-selector > nav > .nav > li:hover {
 background-color: rgba(80,92,133,.22) !important;
 background: rgba(80,92,133,.22) !important;
}
div.nbext-selector > nav > .nav > li.active:hover {
 background: transparent !important;
 background-color: transparent !important;
}
.nav-pills > li.active > a,
.nav-pills > li.active > a:active,
.nav-pills > li.active > a:hover,
.nav-pills > li.active > a:focus {
 color: #e4e8ee;
 background-color: rgba(80,92,133,.22) !important;
 background: rgba(80,92,133,.22) !important;
 -webkit-backface-visibility: hidden;
 -webkit-font-smoothing: subpixel-antialiased !important;
}
div.nbext-readme > .nbext-readme-contents > .rendered_html {
 font-family: sans-serif;
 font-size: 11.5pt;
 line-height: 145%;
 padding: 1em 1em;
 color: #abc1e2;
 background-color: #303845;
 -webkit-box-shadow: none;
 -moz-box-shadow: none;
 box-shadow: none;
}
.nbext-icon,
.nbext-desc,
.nbext-compat-div,
.nbext-enable-btns,
.nbext-params {
 margin-bottom: 8px;
 font-size: 11.5pt;
}
div.nbext-readme > .nbext-readme-contents {
 padding: 0;
 overflow-y: hidden;
}
div.nbext-readme > .nbext-readme-contents:not(:empty) {
 margin-top: 0.5em;
 margin-bottom: 2em;
 border: none;
 border-top-color: rgba(53,114,198,.2);
}
.nbext-showhide-incompat {
 padding-bottom: 0.5em;
 color: #92a2bd;
 font-size: 10.5pt;
}
.nbext-filter-menu.dropdown-menu > li > a:hover,
.nbext-filter-menu.dropdown-menu > li > a:focus,
.nbext-filter-menu.dropdown-menu > li > a.ui-state-focus {
 color: #d8dcee !important;
 background-color: #343d4b !important;
 background: #343d4b !important;
 border-color: #343d4b !important;
}
.nbext-filter-input-wrap > .nbext-filter-input-subwrap,
.nbext-filter-input-wrap > .nbext-filter-input-subwrap > input {
 border: none;
 outline: none;
 background-color: transparent;
 padding: 0;
 vertical-align: middle;
 margin-top: -2px;
}
span.rendered_html code {
 background-color: transparent;
 color: #a2b0c7;
}
#nbextensions-configurator-container > div.row.container-fluid.nbext-selector {
 padding-left: 0px;
 padding-right: 0px;
}
.nbext-filter-menu {
 max-height: 55vh !important;
 overflow-y: auto;
 outline: none;
 border: none;
}
.nbext-filter-menu:hover {
 border: none;
}
.alert-warning {
 background-color: #384152;
 border-color: #384152;
 color: #a2b0c7;
}
.notification_widget.danger {
 color: #ffffff;
 background-color: #e74c3c;
 border-color: #e74c3c;
 padding-right: 5px;
}
#nbextensions-configurator-container > div.nbext-buttons.tree-buttons.no-padding.pull-right > span > button {
 border: none !important;
}
button#refresh_running_list {
 border: none !important;
}
mark,
.mark {
 background-color: #303845;
 color: #abc1e2;
 padding: .15em;
}
a.text-warning,
a.text-warning:hover {
 color: #546379;
}
a.text-warning.bg-warning {
 background-color: #262931;
}
span.bg-success.text-success {
 background-color: transparent;
 color: #48a667;
}
span.bg-danger.text-danger {
 background-color: #262931;
 color: #dc6972;
}
.has-success .input-group-addon {
 color: #48a667;
 border-color: transparent;
 background: inherit;
 background-color: rgba(83,180,115,.10);
}
.has-success .form-control {
 border-color: #48a667;
 -webkit-box-shadow: inset 0 1px 1px rgba(0,0,0,0.025);
 box-shadow: inset 0 1px 1px rgba(0,0,0,0.025);
}
.has-error .input-group-addon {
 color: #dc6972;
 border-color: transparent;
 background: inherit;
 background-color: rgba(192,57,67,.10);
}
.has-error .form-control {
 border-color: #dc6972;
 -webkit-box-shadow: inset 0 1px 1px rgba(0,0,0,0.025);
 box-shadow: inset 0 1px 1px rgba(0,0,0,0.025);
}
.kse-input-group-pretty > kbd {
 font-family: monospace, monospace;
 color: #a2b0c7;
 font-weight: normal;
 background: transparent;
}
.kse-input-group-pretty > kbd {
 font-family: monospace, monospace;
 color: #a2b0c7;
 font-weight: normal;
 background: transparent;
}
div.nbext-enable-btns .btn[disabled],
div.nbext-enable-btns .btn[disabled]:hover,
.btn-default.disabled,
.btn-default[disabled] {
 background: #38424f;
 background-color: #38424f;
 color: #98a8c1;
}
label#Keyword-Filter {
 display: none;
}
.input-group .nbext-list-btn-add,
.input-group-btn:last-child > .btn-group > .btn {
 background: #2e3642;
 background-color: #2e3642;
 border-color: #2e3642;
 border: 2px solid #2e3642;
}
.input-group .nbext-list-btn-add:hover,
.input-group-btn:last-child > .btn-group > .btn:hover {
 background: #2a313c;
 background-color: #2a313c;
 border-color: #2a313c;
 border: 2px solid #2a313c;
}
#notebook-container > div.cell.code_cell.rendered.selected > div.widget-area > div.widget-subarea > div > div.widget_item.btn-group > button.btn.btn-default.dropdown-toggle.widget-combo-carrot-btn {
 background: #2e3642;
 background-color: #2e3642;
 border-color: #2e3642;
}
#notebook-container > div.cell.code_cell.rendered.selected > div.widget-area > div.widget-subarea > div > div.widget_item.btn-group > button.btn.btn-default.dropdown-toggle.widget-combo-carrot-btn:hover {
 background: #2a313c;
 background-color: #2a313c;
 border-color: #2a313c;
}
.ui-widget-content {
 background: #3a4452;
 background-color: #3a4452;
 border: 2px solid #3a4452;
 color: #a2b0c7;
}
div.collapsible_headings_toggle {
 color: rgba(80,92,133,.45) !important;
}
div.collapsible_headings_toggle:hover {
 color: #4c8be2 !important;
}
.collapsible_headings_toggle .h1,
.collapsible_headings_toggle .h2,
.collapsible_headings_toggle .h3,
.collapsible_headings_toggle .h4,
.collapsible_headings_toggle .h5,
.collapsible_headings_toggle .h6 {
 margin: 0.3em .4em 0em 0em !important;
 line-height: 1.2 !important;
}
div.collapsible_headings_toggle .fa-caret-down:before,
div.collapsible_headings_toggle .fa-caret-right:before {
 font-size: xx-large;
 transition: transform 1000ms;
 transform: none !important;
}
.collapsible_headings_collapsed.collapsible_headings_ellipsis .rendered_html h1:after,
.collapsible_headings_collapsed.collapsible_headings_ellipsis .rendered_html h2:after,
.collapsible_headings_collapsed.collapsible_headings_ellipsis .rendered_html h3:after,
.collapsible_headings_collapsed.collapsible_headings_ellipsis .rendered_html h4:after,
.collapsible_headings_collapsed.collapsible_headings_ellipsis .rendered_html h5:after,
.collapsible_headings_collapsed.collapsible_headings_ellipsis .rendered_html h6:after {
 position: absolute;
 right: 0;
 bottom: 20% !important;
 content: "[\002026]";
 color: rgba(80,92,133,.45) !important;
 padding: 0.5em 0em 0em 0em !important;
}
.collapsible_headings_ellipsis .rendered_html h1,
.collapsible_headings_ellipsis .rendered_html h2,
.collapsible_headings_ellipsis .rendered_html h3,
.collapsible_headings_ellipsis .rendered_html h4,
.collapsible_headings_ellipsis .rendered_html h5,
.collapsible_headings_ellipsis .rendered_html h6,
.collapsible_headings_toggle .fa {
 transition: transform 1000ms !important;
 -webkit-transform: inherit !important;
 -moz-transform: inherit !important;
 -ms-transform: inherit !important;
 -o-transform: inherit !important;
 transform: inherit !important;
 padding-right: 0px !important;
}
#toc-wrapper {
 z-index: 90;
 position: fixed !important;
 display: flex;
 flex-direction: column;
 overflow: hidden;
 padding: 10px;
 border-style: solid;
 border-width: thin;
 border-right-width: medium !important;
 background-color: #262931 !important;
}
#toc-wrapper.ui-draggable.ui-resizable.sidebar-wrapper {
 border-color: rgba(80,92,133,.22) !important;
}
#toc a,
#navigate_menu a,
.toc {
 color: #a2b0c7 !important;
 font-size: 11pt !important;
}
#toc li > span:hover {
 background-color: #343d4b !important;
}
#toc a:hover,
#navigate_menu a:hover,
.toc {
 color: #e4e8ee !important;
 font-size: 11pt !important;
}
#toc-wrapper .toc-item-num {
 color: #4c8be2 !important;
 font-size: 11pt !important;
}
input.raw_input {
 font-family: monospace, monospace;
 font-size: 11pt !important;
 color: #cdd2e9;
 background-color: #2a313c;
 border-color: #282f39;
 background: #282f39;
 width: auto;
 vertical-align: baseline;
 padding: 0em 0.25em;
 margin: 0em 0.25em;
 -webkit-box-shadow: none;
 box-shadow: none;
}
audio,
video {
 display: inline;
 vertical-align: middle;
 align-content: center;
 margin-left: 20%;
}
.cmd-palette .modal-body {
 padding: 0px;
 margin: 0px;
}
.cmd-palette form {
 background: #293547;
 background-color: #293547;
}
.typeahead-field input:last-child,
.typeahead-hint {
 background: #293547;
 background-color: #293547;
 z-index: 1;
}
.typeahead-field input {
 font-family: sans-serif;
 color: #cdd2e9;
 border: none;
 font-size: 28pt;
 display: inline-block;
 line-height: inherit;
 padding: 3px 10px;
 height: 70px;
}
.typeahead-select {
 background-color: #293547;
}
body > div.modal.cmd-palette.typeahead-field {
 display: table;
 border-collapse: separate;
 background-color: #2b3850;
}
.typeahead-container button {
 font-family: sans-serif;
 font-size: 28pt;
 background-color: #2e3642;
 border: none;
 display: inline-block;
 line-height: inherit;
 padding: 3px 10px;
 height: 70px;
}
.typeahead-search-icon {
 min-width: 40px;
 min-height: 55px;
 display: block;
 vertical-align: middle;
 text-align: center;
}
.typeahead-container button:focus,
.typeahead-container button:hover {
 color: #d8dcee;
 background-color: #2a313c;
 border-color: #363f4c;
}
.typeahead-list > li.typeahead-group.active > a,
.typeahead-list > li.typeahead-group > a,
.typeahead-list > li.typeahead-group > a:focus,
.typeahead-list > li.typeahead-group > a:hover {
 display: none;
}
.typeahead-dropdown > li > a,
.typeahead-list > li > a {
 color: #a2b0c7;
 text-decoration: none;
}
.typeahead-dropdown,
.typeahead-list {
 font-family: sans-serif;
 font-size: 13pt;
 color: #a2b0c7;
 background-color: #202937;
 border: none;
 background-clip: padding-box;
 margin-top: 0px;
 padding: 3px 2px 3px 0px;
 line-height: 1.7;
}
.typeahead-dropdown > li.active > a,
.typeahead-dropdown > li > a:focus,
.typeahead-dropdown > li > a:hover,
.typeahead-list > li.active > a,
.typeahead-list > li > a:focus,
.typeahead-list > li > a:hover {
 color: #d8dcee;
 background-color: #2b3850;
 border-color: #2b3850;
}
.command-shortcut:before {
 content: "(command)";
 padding-right: 3px;
 color: #546379;
}
.edit-shortcut:before {
 content: "(edit)";
 padding-right: 3px;
 color: #546379;
}
ul.typeahead-list i {
 margin-left: 1px;
 width: 18px;
 margin-right: 10px;
}
ul.typeahead-list {
 max-height: 50vh;
 overflow: auto;
}
.typeahead-list > li {
 position: relative;
 border: none;
}
div.input.typeahead-hint,
input.typeahead-hint,
body > div.modal.cmd-palette.in > div > div > div > form > div > div.typeahead-field > span.typeahead-query > input.typeahead-hint {
 color: #546379 !important;
 background-color: transparent;
 padding: 3px 10px;
}
.typeahead-dropdown > li > a,
.typeahead-list > li > a {
 display: block;
 padding: 5px;
 clear: both;
 font-weight: 400;
 line-height: 1.7;
 border: 1px solid #202937;
 border-bottom-color: rgba(80,92,133,.45);
}
body > div.modal.cmd-palette.in > div {
 min-width: 750px;
 margin: 150px auto;
}
.typeahead-container strong {
 font-weight: bolder;
 color: #4c8be2;
}
#find-and-replace #replace-preview .match,
#find-and-replace #replace-preview .insert {
 color: #ffffff;
 background-color: #2769c3;
 border-color: #2769c3;
 border-style: solid;
 border-width: 1px;
 border-radius: 0px;
}
#find-and-replace #replace-preview .replace .match {
 background-color: #dc6972;
 border-color: #dc6972;
 border-radius: 0px;
}
#find-and-replace #replace-preview .replace .insert {
 background-color: #48a667;
 border-color: #48a667;
 border-radius: 0px;
}
.jupyter-dashboard-menu-item.selected::before {
 font-family: 'FontAwesome' !important;
 content: '\f00c' !important;
 position: absolute !important;
 color: #4c8be2 !important;
 left: 0px !important;
 top: 13px !important;
 font-size: 12px !important;
}
.shortcut_key,
span.shortcut_key {
 display: inline-block;
 width: 16ex;
 text-align: right;
 font-family: monospace;
}
.jupyter-keybindings {
 padding: 1px;
 line-height: 24px;
 border-bottom: 1px solid rgba(80,92,133,.22);
}
.jupyter-keybindings i {
 background: #2a313c;
 font-size: small;
 padding: 5px;
 margin-left: 7px;
}
div#short-key-bindings-intro.well,
.well {
 background-color: #2e3642;
 border: 1px solid #2e3642;
 color: #a2b0c7;
 border-radius: 2px;
 -webkit-box-shadow: none;
 box-shadow: none;
}
#texteditor-backdrop {
 background: #262931;
 background-color: #262931;
}
#texteditor-backdrop #texteditor-container .CodeMirror-gutter,
#texteditor-backdrop #texteditor-container .CodeMirror-gutters {
 background: #343c4b;
 background-color: #343c4b;
 color: #667fb1;
}
.edit_app #menubar .navbar {
 margin-bottom: 0px;
}
#texteditor-backdrop #texteditor-container {
 padding: 0px;
 background-color: #303845;
 box-shadow: none;
}
.terminal-app {
 background: #262931;
}
.terminal-app > #header {
 background: #262931;
}
.terminal-app .terminal {
 font-family: monospace, monospace;
 font-size: 11pt;
 line-height: 170%;
 color: #cdd2e9;
 background: #303845;
 padding: 0.4em;
 border-radius: 2px;
 -webkit-box-shadow: none;
 box-shadow: none;
}
.terminal .xterm-viewport {
 background-color: #303845;
 color: #cdd2e9;
 overflow-y: auto;
}
.terminal .xterm-color-0 {
 color: #4c8be2;
}
.terminal .xterm-color-1 {
 color: #e39194;
}
.terminal .xterm-color-2 {
 color: #caa6ec;
}
.terminal .xterm-color-3 {
 color: #e39194;
}
.terminal .xterm-color-4 {
 color: #efaa8e;
}
.terminal .xterm-color-5 {
 color: #8fca9a;
}
.terminal .xterm-color-6 {
 color: #77abe7;
}
.terminal .xterm-color-7 {
 color: #77abe7;
}
.terminal .xterm-color-8 {
 color: #61afef;
}
.terminal .xterm-color-9 {
 color: #8fca9a;
}
.terminal .xterm-color-10 {
 color: #e39194;
}
.terminal .xterm-color-14 {
 color: #77abe7;
}
.terminal .xterm-bg-color-15 {
 background-color: #303845;
}
.terminal:not(.xterm-cursor-style-underline):not(.xterm-cursor-style-bar) .terminal-cursor {
 background-color: #4c8be2;
 color: #303845;
}
.terminal:not(.focus) .terminal-cursor {
 outline: 1px solid #4c8be2;
 outline-offset: -1px;
}
.celltoolbar {
 font-size: 100%;
 padding-top: 3px;
 border-color: transparent;
 border-bottom: thin solid rgba(53,114,198,.2);
 background: transparent;
}
.cell-tag,
.tags-input input,
.tags-input button {
 color: #a2b0c7;
 background-color: #262931;
 background-image: none;
 border: 1px solid #a2b0c7;
 border-radius: 1px;
 box-shadow: none;
 width: inherit;
 font-size: inherit;
 height: 22px;
 line-height: 22px;
}
#notebook-container > div.cell.code_cell.rendered.selected > div.input > div.inner_cell > div.ctb_hideshow.ctb_show > div > div > button,
#notebook-container > div.input > div.inner_cell > div.ctb_hideshow.ctb_show > div > div > button {
 font-size: 10pt;
 color: #a2b0c7;
 background-color: #262931;
 background-image: none;
 border: 1px solid #a2b0c7;
 border-radius: 1px;
 box-shadow: none;
 width: inherit;
 font-size: inherit;
 height: 22px;
 line-height: 22px;
}
div#pager #pager-contents {
 background: #262931 !important;
 background-color: #262931 !important;
}
div#pager pre {
 color: #cdd2e9 !important;
 background: #303845 !important;
 background-color: #303845 !important;
 padding: 0.4em;
}
div#pager .ui-resizable-handle {
 top: 0px;
 height: 8px;
 background: #4c8be2 !important;
 border-top: 1px solid #4c8be2;
 border-bottom: 1px solid #4c8be2;
}
div.CodeMirror,
div.CodeMirror pre {
 font-family: monospace, monospace;
 font-size: 11pt;
 line-height: 170%;
 color: #cdd2e9;
}
div.CodeMirror-lines {
 padding-bottom: .9em;
 padding-left: .5em;
 padding-right: 1.5em;
 padding-top: .7em;
}
span.ansiblack,
.ansi-black-fg {
 color: #2b303b;
}
span.ansiblue,
.ansi-blue-fg,
.ansi-blue-intense-fg {
 color: #61afef;
}
span.ansigray,
.ansi-gray-fg,
.ansi-gray-intense-fg {
 color: #899ab8;
}
span.ansigreen,
.ansi-green-fg {
 color: #8fca9a;
}
.ansi-green-intense-fg {
 color: #899ab8;
}
span.ansipurple,
.ansi-purple-fg,
.ansi-purple-intense-fg {
 color: #b399ef;
}
span.ansicyan,
.ansi-cyan-fg,
.ansi-cyan-intense-fg {
 color: #b399ef;
}
span.ansiyellow,
.ansi-yellow-fg,
.ansi-yellow-intense-fg {
 color: #ddd7a3;
}
span.ansired,
.ansi-red-fg,
.ansi-red-intense-fg {
 color: #e39194;
}
div.output-stderr {
 background-color: #e39194;
}
div.output-stderr pre {
 color: #d0d4e6;
}
div.js-error {
 color: #e39194;
}
.ipython_tooltip {
 font-family: monospace, monospace;
 font-size: 11pt;
 line-height: 170%;
 border: 2px solid #2b333f;
 background: #3c4657;
 background-color: #3c4657;
 border-radius: 2px;
 overflow-x: visible;
 overflow-y: visible;
 box-shadow: none;
 position: absolute;
 z-index: 1000;
}
.ipython_tooltip .tooltiptext pre {
 font-family: monospace, monospace;
 font-size: 11pt;
 line-height: 170%;
 background: #3c4657;
 background-color: #3c4657;
 color: #cdd2e9;
 overflow-x: visible;
 overflow-y: visible;
 max-width: 900px;
}
div#tooltip.ipython_tooltip {
 overflow-x: wrap;
 overflow-y: visible;
 max-width: 800px;
}
div.tooltiptext.bigtooltip {
 overflow-x: visible;
 overflow-y: scroll;
 height: 400px;
 max-width: 800px;
}
.cm-s-ipython.CodeMirror {
 font-family: monospace, monospace;
 font-size: 11pt;
 background: #303845;
 color: #cdd2e9;
 border-radius: 2px;
 font-style: normal;
 font-weight: normal;
}
.cm-s-ipython div.CodeMirror-selected {
 background: #42495e;
}
.CodeMirror-gutters {
 border: none;
 border-right: 1px solid #343c4b !important;
 background-color: #343c4b !important;
 background: #343c4b !important;
 border-radius: 0px;
 white-space: nowrap;
}
.cm-s-ipython .CodeMirror-gutters {
 background: #343c4b;
 border: none;
 border-radius: 0px;
 width: 36px;
}
.cm-s-ipython .CodeMirror-linenumber {
 color: #667fb1;
}
.CodeMirror-sizer {
 margin-left: 40px;
}
.CodeMirror-linenumber,
div.CodeMirror-linenumber,
.CodeMirror-gutter.CodeMirror-linenumberdiv.CodeMirror-gutter.CodeMirror-linenumber {
 padding-right: 1px;
 margin-left: 0px;
 margin: 0px;
 width: 26px !important;
 padding: 0px;
 text-align: right;
}
.CodeMirror-linenumber {
 color: #667fb1;
}
.cm-s-ipython .CodeMirror-cursor {
 border-left: 2px solid #0095ff !important;
}
.cm-s-ipython span.cm-comment {
 color: #667fb1;
 font-style: italic;
}
.cm-s-ipython span.cm-atom {
 color: #caa6ec;
}
.cm-s-ipython span.cm-number {
 color: #efaa8e;
}
.cm-s-ipython span.cm-property {
 color: #cdd2e9;
}
.cm-s-ipython span.cm-attribute {
 color: #cdd2e9;
}
.cm-s-ipython span.cm-keyword {
 color: #caa6ec;
 font-weight: normal;
}
.cm-s-ipython span.cm-string {
 color: #8fca9a;
}
.cm-s-ipython span.cm-meta {
 color: #ddd7a3;
}
.cm-s-ipython span.cm-operator {
 color: #77abe7;
}
.cm-s-ipython span.cm-builtin {
 color: #e39194;
}
.cm-s-ipython span.cm-variable {
 color: #cdd2e9;
}
.cm-s-ipython span.cm-variable-2 {
 color: #e39194;
}
.cm-s-ipython span.cm-variable-3 {
 color: #ddd7a3;
}
.cm-s-ipython span.cm-def {
 color: #77abe7;
 font-weight: normal;
}
.cm-s-ipython span.cm-error {
 background: rgba(191,97,106,.4);
}
.cm-s-ipython span.cm-tag {
 color: #caa6ec;
}
.cm-s-ipython span.cm-link {
 color: #61afef;
}
.cm-s-ipython span.cm-storage {
 color: #caa6ec;
}
.cm-s-ipython span.cm-entity {
 color: #e39194;
}
.cm-s-ipython span.cm-quote {
 color: #8fca9a;
}
div.CodeMirror span.CodeMirror-matchingbracket {
 color: #ffffff;
 font-weight: bold;
 background-color: #4c8be2;
}
div.CodeMirror span.CodeMirror-nonmatchingbracket {
 color: #ffffff;
 font-weight: bold;
 background: rgba(191,97,106,.4) !important;
}
.cm-header-1 {
 font-size: 215%;
}
.cm-header-2 {
 font-size: 180%;
}
.cm-header-3 {
 font-size: 150%;
}
.cm-header-4 {
 font-size: 120%;
}
.cm-header-5 {
 font-size: 100%;
}
.cm-s-default .cm-hr {
 color: #77abe7;
}
div.cell.text_cell .cm-s-default .cm-header {
 font-family: sans-serif;
 font-weight: normal;
 color: #4c8be2 !important;
 margin-top: 0.3em !important;
 margin-bottom: 0.3em !important;
}
div.cell.text_cell .cm-s-default span.cm-variable-2 {
 color: #abc1e2 !important;
}
div.cell.text_cell .cm-s-default span.cm-variable-3 {
 color: #ddd7a3 !important;
}
.cm-s-default span.cm-comment {
 color: #667fb1 !important;
}
.cm-s-default .cm-tag {
 color: #8fb36a;
}
.cm-s-default .cm-builtin {
 color: #e39194;
}
.cm-s-default .cm-string {
 color: #8fca9a;
}
.cm-s-default .cm-keyword {
 color: #caa6ec;
}
.cm-s-default .cm-number {
 color: #efaa8e;
}
.cm-s-default .cm-error {
 color: #caa6ec;
}
.cm-s-default .cm-link {
 color: #61afef;
}
.cm-s-default .cm-atom {
 color: #efaa8e;
}
.cm-s-default .cm-def {
 color: #77abe7;
}
.CodeMirror-cursor {
 border-left: 2px solid #0095ff !important;
 border-right: none;
 width: 0;
}
.cm-s-default div.CodeMirror-selected {
 background: #42495e;
}
.cm-s-default .cm-selected {
 background: #42495e;
}
.MathJax_Display,
.MathJax {
 border: 0 !important;
 font-size: 100% !important;
 text-align: center !important;
 margin: 0em !important;
 line-height: 2.25 !important;
}
.MathJax:focus,
body :focus .MathJax {
 display: inline-block !important;
}
.MathJax:focus,
body :focus .MathJax {
 display: inline-block !important;
}
.completions {
 position: absolute;
 z-index: 110;
 overflow: hidden;
 border: medium solid #3572c6;
 box-shadow: none;
 line-height: 1;
}
.completions select {
 background: #303845;
 background-color: #303845;
 outline: none;
 border: none;
 padding: 0px;
 margin: 0px;
 margin-left: 2px;
 overflow: auto;
 font-family: monospace, monospace;
 font-size: 11pt;
 color: #cdd2e9;
 width: auto;
}
div#maintoolbar {
 display: none !important;
}
#header-container {
 display: none !important;
}

<script>
    MathJax.Hub.Config({
        "HTML-CSS": {
            /*preferredFont: "TeX",*/
            /*availableFonts: ["TeX", "STIX"],*/
            styles: {
                scale: 100,
                ".MathJax_Display": {
                    "font-size": "100%",
                }
            }
        }
    });
</script>
    
  </style>



<style type="text/css">
/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*
 * Mozilla scrollbar styling
 */

/* use standard opaque scrollbars for most nodes */
[data-jp-theme-scrollbars='true'] {
  scrollbar-color: rgb(var(--jp-scrollbar-thumb-color))
    var(--jp-scrollbar-background-color);
}

/* for code nodes, use a transparent style of scrollbar. These selectors
 * will match lower in the tree, and so will override the above */
[data-jp-theme-scrollbars='true'] .CodeMirror-hscrollbar,
[data-jp-theme-scrollbars='true'] .CodeMirror-vscrollbar {
  scrollbar-color: rgba(var(--jp-scrollbar-thumb-color), 0.5) transparent;
}

/* tiny scrollbar */

.jp-scrollbar-tiny {
  scrollbar-color: rgba(var(--jp-scrollbar-thumb-color), 0.5) transparent;
  scrollbar-width: thin;
}

/*
 * Webkit scrollbar styling
 */

/* use standard opaque scrollbars for most nodes */

[data-jp-theme-scrollbars='true'] ::-webkit-scrollbar,
[data-jp-theme-scrollbars='true'] ::-webkit-scrollbar-corner {
  background: var(--jp-scrollbar-background-color);
}

[data-jp-theme-scrollbars='true'] ::-webkit-scrollbar-thumb {
  background: rgb(var(--jp-scrollbar-thumb-color));
  border: var(--jp-scrollbar-thumb-margin) solid transparent;
  background-clip: content-box;
  border-radius: var(--jp-scrollbar-thumb-radius);
}

[data-jp-theme-scrollbars='true'] ::-webkit-scrollbar-track:horizontal {
  border-left: var(--jp-scrollbar-endpad) solid
    var(--jp-scrollbar-background-color);
  border-right: var(--jp-scrollbar-endpad) solid
    var(--jp-scrollbar-background-color);
}

[data-jp-theme-scrollbars='true'] ::-webkit-scrollbar-track:vertical {
  border-top: var(--jp-scrollbar-endpad) solid
    var(--jp-scrollbar-background-color);
  border-bottom: var(--jp-scrollbar-endpad) solid
    var(--jp-scrollbar-background-color);
}

/* for code nodes, use a transparent style of scrollbar */

[data-jp-theme-scrollbars='true'] .CodeMirror-hscrollbar::-webkit-scrollbar,
[data-jp-theme-scrollbars='true'] .CodeMirror-vscrollbar::-webkit-scrollbar,
[data-jp-theme-scrollbars='true']
  .CodeMirror-hscrollbar::-webkit-scrollbar-corner,
[data-jp-theme-scrollbars='true']
  .CodeMirror-vscrollbar::-webkit-scrollbar-corner {
  background-color: transparent;
}

[data-jp-theme-scrollbars='true']
  .CodeMirror-hscrollbar::-webkit-scrollbar-thumb,
[data-jp-theme-scrollbars='true']
  .CodeMirror-vscrollbar::-webkit-scrollbar-thumb {
  background: rgba(var(--jp-scrollbar-thumb-color), 0.5);
  border: var(--jp-scrollbar-thumb-margin) solid transparent;
  background-clip: content-box;
  border-radius: var(--jp-scrollbar-thumb-radius);
}

[data-jp-theme-scrollbars='true']
  .CodeMirror-hscrollbar::-webkit-scrollbar-track:horizontal {
  border-left: var(--jp-scrollbar-endpad) solid transparent;
  border-right: var(--jp-scrollbar-endpad) solid transparent;
}

[data-jp-theme-scrollbars='true']
  .CodeMirror-vscrollbar::-webkit-scrollbar-track:vertical {
  border-top: var(--jp-scrollbar-endpad) solid transparent;
  border-bottom: var(--jp-scrollbar-endpad) solid transparent;
}

/* tiny scrollbar */

.jp-scrollbar-tiny::-webkit-scrollbar,
.jp-scrollbar-tiny::-webkit-scrollbar-corner {
  background-color: transparent;
  height: 4px;
  width: 4px;
}

.jp-scrollbar-tiny::-webkit-scrollbar-thumb {
  background: rgba(var(--jp-scrollbar-thumb-color), 0.5);
}

.jp-scrollbar-tiny::-webkit-scrollbar-track:horizontal {
  border-left: 0px solid transparent;
  border-right: 0px solid transparent;
}

.jp-scrollbar-tiny::-webkit-scrollbar-track:vertical {
  border-top: 0px solid transparent;
  border-bottom: 0px solid transparent;
}

/*
 * Phosphor
 */

.lm-ScrollBar[data-orientation='horizontal'] {
  min-height: 16px;
  max-height: 16px;
  min-width: 45px;
  border-top: 1px solid #a0a0a0;
}

.lm-ScrollBar[data-orientation='vertical'] {
  min-width: 16px;
  max-width: 16px;
  min-height: 45px;
  border-left: 1px solid #a0a0a0;
}

.lm-ScrollBar-button {
  background-color: #f0f0f0;
  background-position: center center;
  min-height: 15px;
  max-height: 15px;
  min-width: 15px;
  max-width: 15px;
}

.lm-ScrollBar-button:hover {
  background-color: #dadada;
}

.lm-ScrollBar-button.lm-mod-active {
  background-color: #cdcdcd;
}

.lm-ScrollBar-track {
  background: #f0f0f0;
}

.lm-ScrollBar-thumb {
  background: #cdcdcd;
}

.lm-ScrollBar-thumb:hover {
  background: #bababa;
}

.lm-ScrollBar-thumb.lm-mod-active {
  background: #a0a0a0;
}

.lm-ScrollBar[data-orientation='horizontal'] .lm-ScrollBar-thumb {
  height: 100%;
  min-width: 15px;
  border-left: 1px solid #a0a0a0;
  border-right: 1px solid #a0a0a0;
}

.lm-ScrollBar[data-orientation='vertical'] .lm-ScrollBar-thumb {
  width: 100%;
  min-height: 15px;
  border-top: 1px solid #a0a0a0;
  border-bottom: 1px solid #a0a0a0;
}

.lm-ScrollBar[data-orientation='horizontal']
  .lm-ScrollBar-button[data-action='decrement'] {
  background-image: var(--jp-icon-caret-left);
  background-size: 17px;
}

.lm-ScrollBar[data-orientation='horizontal']
  .lm-ScrollBar-button[data-action='increment'] {
  background-image: var(--jp-icon-caret-right);
  background-size: 17px;
}

.lm-ScrollBar[data-orientation='vertical']
  .lm-ScrollBar-button[data-action='decrement'] {
  background-image: var(--jp-icon-caret-up);
  background-size: 17px;
}

.lm-ScrollBar[data-orientation='vertical']
  .lm-ScrollBar-button[data-action='increment'] {
  background-image: var(--jp-icon-caret-down);
  background-size: 17px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/


/* <DEPRECATED> */ .p-Widget, /* </DEPRECATED> */
.lm-Widget {
  box-sizing: border-box;
  position: relative;
  overflow: hidden;
  cursor: default;
}


/* <DEPRECATED> */ .p-Widget.p-mod-hidden, /* </DEPRECATED> */
.lm-Widget.lm-mod-hidden {
  display: none !important;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/


/* <DEPRECATED> */ .p-CommandPalette, /* </DEPRECATED> */
.lm-CommandPalette {
  display: flex;
  flex-direction: column;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}


/* <DEPRECATED> */ .p-CommandPalette-search, /* </DEPRECATED> */
.lm-CommandPalette-search {
  flex: 0 0 auto;
}


/* <DEPRECATED> */ .p-CommandPalette-content, /* </DEPRECATED> */
.lm-CommandPalette-content {
  flex: 1 1 auto;
  margin: 0;
  padding: 0;
  min-height: 0;
  overflow: auto;
  list-style-type: none;
}


/* <DEPRECATED> */ .p-CommandPalette-header, /* </DEPRECATED> */
.lm-CommandPalette-header {
  overflow: hidden;
  white-space: nowrap;
  text-overflow: ellipsis;
}


/* <DEPRECATED> */ .p-CommandPalette-item, /* </DEPRECATED> */
.lm-CommandPalette-item {
  display: flex;
  flex-direction: row;
}


/* <DEPRECATED> */ .p-CommandPalette-itemIcon, /* </DEPRECATED> */
.lm-CommandPalette-itemIcon {
  flex: 0 0 auto;
}


/* <DEPRECATED> */ .p-CommandPalette-itemContent, /* </DEPRECATED> */
.lm-CommandPalette-itemContent {
  flex: 1 1 auto;
  overflow: hidden;
}


/* <DEPRECATED> */ .p-CommandPalette-itemShortcut, /* </DEPRECATED> */
.lm-CommandPalette-itemShortcut {
  flex: 0 0 auto;
}


/* <DEPRECATED> */ .p-CommandPalette-itemLabel, /* </DEPRECATED> */
.lm-CommandPalette-itemLabel {
  overflow: hidden;
  white-space: nowrap;
  text-overflow: ellipsis;
}

.lm-close-icon {
	border:1px solid transparent;
  background-color: transparent;
  position: absolute;
	z-index:1;
	right:3%;
	top: 0;
	bottom: 0;
	margin: auto;
	padding: 7px 0;
	display: none;
	vertical-align: middle;
  outline: 0;
  cursor: pointer;
}
.lm-close-icon:after {
	content: "X";
	display: block;
	width: 15px;
	height: 15px;
	text-align: center;
	color:#000;
	font-weight: normal;
	font-size: 12px;
	cursor: pointer;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/


/* <DEPRECATED> */ .p-DockPanel, /* </DEPRECATED> */
.lm-DockPanel {
  z-index: 0;
}


/* <DEPRECATED> */ .p-DockPanel-widget, /* </DEPRECATED> */
.lm-DockPanel-widget {
  z-index: 0;
}


/* <DEPRECATED> */ .p-DockPanel-tabBar, /* </DEPRECATED> */
.lm-DockPanel-tabBar {
  z-index: 1;
}


/* <DEPRECATED> */ .p-DockPanel-handle, /* </DEPRECATED> */
.lm-DockPanel-handle {
  z-index: 2;
}


/* <DEPRECATED> */ .p-DockPanel-handle.p-mod-hidden, /* </DEPRECATED> */
.lm-DockPanel-handle.lm-mod-hidden {
  display: none !important;
}


/* <DEPRECATED> */ .p-DockPanel-handle:after, /* </DEPRECATED> */
.lm-DockPanel-handle:after {
  position: absolute;
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  content: '';
}


/* <DEPRECATED> */
.p-DockPanel-handle[data-orientation='horizontal'],
/* </DEPRECATED> */
.lm-DockPanel-handle[data-orientation='horizontal'] {
  cursor: ew-resize;
}


/* <DEPRECATED> */
.p-DockPanel-handle[data-orientation='vertical'],
/* </DEPRECATED> */
.lm-DockPanel-handle[data-orientation='vertical'] {
  cursor: ns-resize;
}


/* <DEPRECATED> */
.p-DockPanel-handle[data-orientation='horizontal']:after,
/* </DEPRECATED> */
.lm-DockPanel-handle[data-orientation='horizontal']:after {
  left: 50%;
  min-width: 8px;
  transform: translateX(-50%);
}


/* <DEPRECATED> */
.p-DockPanel-handle[data-orientation='vertical']:after,
/* </DEPRECATED> */
.lm-DockPanel-handle[data-orientation='vertical']:after {
  top: 50%;
  min-height: 8px;
  transform: translateY(-50%);
}


/* <DEPRECATED> */ .p-DockPanel-overlay, /* </DEPRECATED> */
.lm-DockPanel-overlay {
  z-index: 3;
  box-sizing: border-box;
  pointer-events: none;
}


/* <DEPRECATED> */ .p-DockPanel-overlay.p-mod-hidden, /* </DEPRECATED> */
.lm-DockPanel-overlay.lm-mod-hidden {
  display: none !important;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/


/* <DEPRECATED> */ .p-Menu, /* </DEPRECATED> */
.lm-Menu {
  z-index: 10000;
  position: absolute;
  white-space: nowrap;
  overflow-x: hidden;
  overflow-y: auto;
  outline: none;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}


/* <DEPRECATED> */ .p-Menu-content, /* </DEPRECATED> */
.lm-Menu-content {
  margin: 0;
  padding: 0;
  display: table;
  list-style-type: none;
}


/* <DEPRECATED> */ .p-Menu-item, /* </DEPRECATED> */
.lm-Menu-item {
  display: table-row;
}


/* <DEPRECATED> */
.p-Menu-item.p-mod-hidden,
.p-Menu-item.p-mod-collapsed,
/* </DEPRECATED> */
.lm-Menu-item.lm-mod-hidden,
.lm-Menu-item.lm-mod-collapsed {
  display: none !important;
}


/* <DEPRECATED> */
.p-Menu-itemIcon,
.p-Menu-itemSubmenuIcon,
/* </DEPRECATED> */
.lm-Menu-itemIcon,
.lm-Menu-itemSubmenuIcon {
  display: table-cell;
  text-align: center;
}


/* <DEPRECATED> */ .p-Menu-itemLabel, /* </DEPRECATED> */
.lm-Menu-itemLabel {
  display: table-cell;
  text-align: left;
}


/* <DEPRECATED> */ .p-Menu-itemShortcut, /* </DEPRECATED> */
.lm-Menu-itemShortcut {
  display: table-cell;
  text-align: right;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/


/* <DEPRECATED> */ .p-MenuBar, /* </DEPRECATED> */
.lm-MenuBar {
  outline: none;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}


/* <DEPRECATED> */ .p-MenuBar-content, /* </DEPRECATED> */
.lm-MenuBar-content {
  margin: 0;
  padding: 0;
  display: flex;
  flex-direction: row;
  list-style-type: none;
}


/* <DEPRECATED> */ .p--MenuBar-item, /* </DEPRECATED> */
.lm-MenuBar-item {
  box-sizing: border-box;
}


/* <DEPRECATED> */
.p-MenuBar-itemIcon,
.p-MenuBar-itemLabel,
/* </DEPRECATED> */
.lm-MenuBar-itemIcon,
.lm-MenuBar-itemLabel {
  display: inline-block;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/


/* <DEPRECATED> */ .p-ScrollBar, /* </DEPRECATED> */
.lm-ScrollBar {
  display: flex;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}


/* <DEPRECATED> */
.p-ScrollBar[data-orientation='horizontal'],
/* </DEPRECATED> */
.lm-ScrollBar[data-orientation='horizontal'] {
  flex-direction: row;
}


/* <DEPRECATED> */
.p-ScrollBar[data-orientation='vertical'],
/* </DEPRECATED> */
.lm-ScrollBar[data-orientation='vertical'] {
  flex-direction: column;
}


/* <DEPRECATED> */ .p-ScrollBar-button, /* </DEPRECATED> */
.lm-ScrollBar-button {
  box-sizing: border-box;
  flex: 0 0 auto;
}


/* <DEPRECATED> */ .p-ScrollBar-track, /* </DEPRECATED> */
.lm-ScrollBar-track {
  box-sizing: border-box;
  position: relative;
  overflow: hidden;
  flex: 1 1 auto;
}


/* <DEPRECATED> */ .p-ScrollBar-thumb, /* </DEPRECATED> */
.lm-ScrollBar-thumb {
  box-sizing: border-box;
  position: absolute;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/


/* <DEPRECATED> */ .p-SplitPanel-child, /* </DEPRECATED> */
.lm-SplitPanel-child {
  z-index: 0;
}


/* <DEPRECATED> */ .p-SplitPanel-handle, /* </DEPRECATED> */
.lm-SplitPanel-handle {
  z-index: 1;
}


/* <DEPRECATED> */ .p-SplitPanel-handle.p-mod-hidden, /* </DEPRECATED> */
.lm-SplitPanel-handle.lm-mod-hidden {
  display: none !important;
}


/* <DEPRECATED> */ .p-SplitPanel-handle:after, /* </DEPRECATED> */
.lm-SplitPanel-handle:after {
  position: absolute;
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  content: '';
}


/* <DEPRECATED> */
.p-SplitPanel[data-orientation='horizontal'] > .p-SplitPanel-handle,
/* </DEPRECATED> */
.lm-SplitPanel[data-orientation='horizontal'] > .lm-SplitPanel-handle {
  cursor: ew-resize;
}


/* <DEPRECATED> */
.p-SplitPanel[data-orientation='vertical'] > .p-SplitPanel-handle,
/* </DEPRECATED> */
.lm-SplitPanel[data-orientation='vertical'] > .lm-SplitPanel-handle {
  cursor: ns-resize;
}


/* <DEPRECATED> */
.p-SplitPanel[data-orientation='horizontal'] > .p-SplitPanel-handle:after,
/* </DEPRECATED> */
.lm-SplitPanel[data-orientation='horizontal'] > .lm-SplitPanel-handle:after {
  left: 50%;
  min-width: 8px;
  transform: translateX(-50%);
}


/* <DEPRECATED> */
.p-SplitPanel[data-orientation='vertical'] > .p-SplitPanel-handle:after,
/* </DEPRECATED> */
.lm-SplitPanel[data-orientation='vertical'] > .lm-SplitPanel-handle:after {
  top: 50%;
  min-height: 8px;
  transform: translateY(-50%);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/


/* <DEPRECATED> */ .p-TabBar, /* </DEPRECATED> */
.lm-TabBar {
  display: flex;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}


/* <DEPRECATED> */ .p-TabBar[data-orientation='horizontal'], /* </DEPRECATED> */
.lm-TabBar[data-orientation='horizontal'] {
  flex-direction: row;
}


/* <DEPRECATED> */ .p-TabBar[data-orientation='vertical'], /* </DEPRECATED> */
.lm-TabBar[data-orientation='vertical'] {
  flex-direction: column;
}


/* <DEPRECATED> */ .p-TabBar-content, /* </DEPRECATED> */
.lm-TabBar-content {
  margin: 0;
  padding: 0;
  display: flex;
  flex: 1 1 auto;
  list-style-type: none;
}


/* <DEPRECATED> */
.p-TabBar[data-orientation='horizontal'] > .p-TabBar-content,
/* </DEPRECATED> */
.lm-TabBar[data-orientation='horizontal'] > .lm-TabBar-content {
  flex-direction: row;
}


/* <DEPRECATED> */
.p-TabBar[data-orientation='vertical'] > .p-TabBar-content,
/* </DEPRECATED> */
.lm-TabBar[data-orientation='vertical'] > .lm-TabBar-content {
  flex-direction: column;
}


/* <DEPRECATED> */ .p-TabBar-tab, /* </DEPRECATED> */
.lm-TabBar-tab {
  display: flex;
  flex-direction: row;
  box-sizing: border-box;
  overflow: hidden;
}


/* <DEPRECATED> */
.p-TabBar-tabIcon,
.p-TabBar-tabCloseIcon,
/* </DEPRECATED> */
.lm-TabBar-tabIcon,
.lm-TabBar-tabCloseIcon {
  flex: 0 0 auto;
}


/* <DEPRECATED> */ .p-TabBar-tabLabel, /* </DEPRECATED> */
.lm-TabBar-tabLabel {
  flex: 1 1 auto;
  overflow: hidden;
  white-space: nowrap;
}


.lm-TabBar-tabInput {
  user-select: all;
  width: 100%;
  box-sizing : border-box;
}


/* <DEPRECATED> */ .p-TabBar-tab.p-mod-hidden, /* </DEPRECATED> */
.lm-TabBar-tab.lm-mod-hidden {
  display: none !important;
}


/* <DEPRECATED> */ .p-TabBar.p-mod-dragging .p-TabBar-tab, /* </DEPRECATED> */
.lm-TabBar.lm-mod-dragging .lm-TabBar-tab {
  position: relative;
}


/* <DEPRECATED> */
.p-TabBar.p-mod-dragging[data-orientation='horizontal'] .p-TabBar-tab,
/* </DEPRECATED> */
.lm-TabBar.lm-mod-dragging[data-orientation='horizontal'] .lm-TabBar-tab {
  left: 0;
  transition: left 150ms ease;
}


/* <DEPRECATED> */
.p-TabBar.p-mod-dragging[data-orientation='vertical'] .p-TabBar-tab,
/* </DEPRECATED> */
.lm-TabBar.lm-mod-dragging[data-orientation='vertical'] .lm-TabBar-tab {
  top: 0;
  transition: top 150ms ease;
}


/* <DEPRECATED> */
.p-TabBar.p-mod-dragging .p-TabBar-tab.p-mod-dragging,
/* </DEPRECATED> */
.lm-TabBar.lm-mod-dragging .lm-TabBar-tab.lm-mod-dragging {
  transition: none;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/


/* <DEPRECATED> */ .p-TabPanel-tabBar, /* </DEPRECATED> */
.lm-TabPanel-tabBar {
  z-index: 1;
}


/* <DEPRECATED> */ .p-TabPanel-stackedPanel, /* </DEPRECATED> */
.lm-TabPanel-stackedPanel {
  z-index: 0;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

@charset "UTF-8";
html{
  -webkit-box-sizing:border-box;
          box-sizing:border-box; }

*,
*::before,
*::after{
  -webkit-box-sizing:inherit;
          box-sizing:inherit; }

body{
  font-size:14px;
  font-weight:400;
  letter-spacing:0;
  line-height:1.28581;
  text-transform:none;
  color:#182026;
  font-family:-apple-system, "BlinkMacSystemFont", "Segoe UI", "Roboto", "Oxygen", "Ubuntu", "Cantarell", "Open Sans", "Helvetica Neue", "Icons16", sans-serif; }

p{
  margin-bottom:10px;
  margin-top:0; }

small{
  font-size:12px; }

strong{
  font-weight:600; }

::-moz-selection{
  background:rgba(125, 188, 255, 0.6); }

::selection{
  background:rgba(125, 188, 255, 0.6); }
.bp3-heading{
  color:#182026;
  font-weight:600;
  margin:0 0 10px;
  padding:0; }
  .bp3-dark .bp3-heading{
    color:#f5f8fa; }

h1.bp3-heading, .bp3-running-text h1{
  font-size:36px;
  line-height:40px; }

h2.bp3-heading, .bp3-running-text h2{
  font-size:28px;
  line-height:32px; }

h3.bp3-heading, .bp3-running-text h3{
  font-size:22px;
  line-height:25px; }

h4.bp3-heading, .bp3-running-text h4{
  font-size:18px;
  line-height:21px; }

h5.bp3-heading, .bp3-running-text h5{
  font-size:16px;
  line-height:19px; }

h6.bp3-heading, .bp3-running-text h6{
  font-size:14px;
  line-height:16px; }
.bp3-ui-text{
  font-size:14px;
  font-weight:400;
  letter-spacing:0;
  line-height:1.28581;
  text-transform:none; }

.bp3-monospace-text{
  font-family:monospace;
  text-transform:none; }

.bp3-text-muted{
  color:#5c7080; }
  .bp3-dark .bp3-text-muted{
    color:#a7b6c2; }

.bp3-text-disabled{
  color:rgba(92, 112, 128, 0.6); }
  .bp3-dark .bp3-text-disabled{
    color:rgba(167, 182, 194, 0.6); }

.bp3-text-overflow-ellipsis{
  overflow:hidden;
  text-overflow:ellipsis;
  white-space:nowrap;
  word-wrap:normal; }
.bp3-running-text{
  font-size:14px;
  line-height:1.5; }
  .bp3-running-text h1{
    color:#182026;
    font-weight:600;
    margin-bottom:20px;
    margin-top:40px; }
    .bp3-dark .bp3-running-text h1{
      color:#f5f8fa; }
  .bp3-running-text h2{
    color:#182026;
    font-weight:600;
    margin-bottom:20px;
    margin-top:40px; }
    .bp3-dark .bp3-running-text h2{
      color:#f5f8fa; }
  .bp3-running-text h3{
    color:#182026;
    font-weight:600;
    margin-bottom:20px;
    margin-top:40px; }
    .bp3-dark .bp3-running-text h3{
      color:#f5f8fa; }
  .bp3-running-text h4{
    color:#182026;
    font-weight:600;
    margin-bottom:20px;
    margin-top:40px; }
    .bp3-dark .bp3-running-text h4{
      color:#f5f8fa; }
  .bp3-running-text h5{
    color:#182026;
    font-weight:600;
    margin-bottom:20px;
    margin-top:40px; }
    .bp3-dark .bp3-running-text h5{
      color:#f5f8fa; }
  .bp3-running-text h6{
    color:#182026;
    font-weight:600;
    margin-bottom:20px;
    margin-top:40px; }
    .bp3-dark .bp3-running-text h6{
      color:#f5f8fa; }
  .bp3-running-text hr{
    border:none;
    border-bottom:1px solid rgba(16, 22, 26, 0.15);
    margin:20px 0; }
    .bp3-dark .bp3-running-text hr{
      border-color:rgba(255, 255, 255, 0.15); }
  .bp3-running-text p{
    margin:0 0 10px;
    padding:0; }

.bp3-text-large{
  font-size:16px; }

.bp3-text-small{
  font-size:12px; }
a{
  color:#106ba3;
  text-decoration:none; }
  a:hover{
    color:#106ba3;
    cursor:pointer;
    text-decoration:underline; }
  a .bp3-icon, a .bp3-icon-standard, a .bp3-icon-large{
    color:inherit; }
  a code,
  .bp3-dark a code{
    color:inherit; }
  .bp3-dark a,
  .bp3-dark a:hover{
    color:#48aff0; }
    .bp3-dark a .bp3-icon, .bp3-dark a .bp3-icon-standard, .bp3-dark a .bp3-icon-large,
    .bp3-dark a:hover .bp3-icon,
    .bp3-dark a:hover .bp3-icon-standard,
    .bp3-dark a:hover .bp3-icon-large{
      color:inherit; }
.bp3-running-text code, .bp3-code{
  font-family:monospace;
  text-transform:none;
  background:rgba(255, 255, 255, 0.7);
  border-radius:3px;
  -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2);
          box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2);
  color:#5c7080;
  font-size:smaller;
  padding:2px 5px; }
  .bp3-dark .bp3-running-text code, .bp3-running-text .bp3-dark code, .bp3-dark .bp3-code{
    background:rgba(16, 22, 26, 0.3);
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4);
    color:#a7b6c2; }
  .bp3-running-text a > code, a > .bp3-code{
    color:#137cbd; }
    .bp3-dark .bp3-running-text a > code, .bp3-running-text .bp3-dark a > code, .bp3-dark a > .bp3-code{
      color:inherit; }

.bp3-running-text pre, .bp3-code-block{
  font-family:monospace;
  text-transform:none;
  background:rgba(255, 255, 255, 0.7);
  border-radius:3px;
  -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.15);
          box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.15);
  color:#182026;
  display:block;
  font-size:13px;
  line-height:1.4;
  margin:10px 0;
  padding:13px 15px 12px;
  word-break:break-all;
  word-wrap:break-word; }
  .bp3-dark .bp3-running-text pre, .bp3-running-text .bp3-dark pre, .bp3-dark .bp3-code-block{
    background:rgba(16, 22, 26, 0.3);
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4);
    color:#f5f8fa; }
  .bp3-running-text pre > code, .bp3-code-block > code{
    background:none;
    -webkit-box-shadow:none;
            box-shadow:none;
    color:inherit;
    font-size:inherit;
    padding:0; }

.bp3-running-text kbd, .bp3-key{
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  background:#ffffff;
  border-radius:3px;
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.2);
  color:#5c7080;
  display:-webkit-inline-box;
  display:-ms-inline-flexbox;
  display:inline-flex;
  font-family:inherit;
  font-size:12px;
  height:24px;
  -webkit-box-pack:center;
      -ms-flex-pack:center;
          justify-content:center;
  line-height:24px;
  min-width:24px;
  padding:3px 6px;
  vertical-align:middle; }
  .bp3-running-text kbd .bp3-icon, .bp3-key .bp3-icon, .bp3-running-text kbd .bp3-icon-standard, .bp3-key .bp3-icon-standard, .bp3-running-text kbd .bp3-icon-large, .bp3-key .bp3-icon-large{
    margin-right:5px; }
  .bp3-dark .bp3-running-text kbd, .bp3-running-text .bp3-dark kbd, .bp3-dark .bp3-key{
    background:#394b59;
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.4);
    color:#a7b6c2; }
.bp3-running-text blockquote, .bp3-blockquote{
  border-left:solid 4px rgba(167, 182, 194, 0.5);
  margin:0 0 10px;
  padding:0 20px; }
  .bp3-dark .bp3-running-text blockquote, .bp3-running-text .bp3-dark blockquote, .bp3-dark .bp3-blockquote{
    border-color:rgba(115, 134, 148, 0.5); }
.bp3-running-text ul,
.bp3-running-text ol, .bp3-list{
  margin:10px 0;
  padding-left:30px; }
  .bp3-running-text ul li:not(:last-child), .bp3-running-text ol li:not(:last-child), .bp3-list li:not(:last-child){
    margin-bottom:5px; }
  .bp3-running-text ul ol, .bp3-running-text ol ol, .bp3-list ol,
  .bp3-running-text ul ul,
  .bp3-running-text ol ul,
  .bp3-list ul{
    margin-top:5px; }

.bp3-list-unstyled{
  list-style:none;
  margin:0;
  padding:0; }
  .bp3-list-unstyled li{
    padding:0; }
.bp3-rtl{
  text-align:right; }

.bp3-dark{
  color:#f5f8fa; }

:focus{
  outline:rgba(19, 124, 189, 0.6) auto 2px;
  outline-offset:2px;
  -moz-outline-radius:6px; }

.bp3-focus-disabled :focus{
  outline:none !important; }
  .bp3-focus-disabled :focus ~ .bp3-control-indicator{
    outline:none !important; }

.bp3-alert{
  max-width:400px;
  padding:20px; }

.bp3-alert-body{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex; }
  .bp3-alert-body .bp3-icon{
    font-size:40px;
    margin-right:20px;
    margin-top:0; }

.bp3-alert-contents{
  word-break:break-word; }

.bp3-alert-footer{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-orient:horizontal;
  -webkit-box-direction:reverse;
      -ms-flex-direction:row-reverse;
          flex-direction:row-reverse;
  margin-top:10px; }
  .bp3-alert-footer .bp3-button{
    margin-left:10px; }
.bp3-breadcrumbs{
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  cursor:default;
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -ms-flex-wrap:wrap;
      flex-wrap:wrap;
  height:30px;
  list-style:none;
  margin:0;
  padding:0; }
  .bp3-breadcrumbs > li{
    -webkit-box-align:center;
        -ms-flex-align:center;
            align-items:center;
    display:-webkit-box;
    display:-ms-flexbox;
    display:flex; }
    .bp3-breadcrumbs > li::after{
      background:url("data:image/svg+xml,%3csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 16 16'%3e%3cpath fill-rule='evenodd' clip-rule='evenodd' d='M10.71 7.29l-4-4a1.003 1.003 0 00-1.42 1.42L8.59 8 5.3 11.29c-.19.18-.3.43-.3.71a1.003 1.003 0 001.71.71l4-4c.18-.18.29-.43.29-.71 0-.28-.11-.53-.29-.71z' fill='%235C7080'/%3e%3c/svg%3e");
      content:"";
      display:block;
      height:16px;
      margin:0 5px;
      width:16px; }
    .bp3-breadcrumbs > li:last-of-type::after{
      display:none; }

.bp3-breadcrumb,
.bp3-breadcrumb-current,
.bp3-breadcrumbs-collapsed{
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  display:-webkit-inline-box;
  display:-ms-inline-flexbox;
  display:inline-flex;
  font-size:16px; }

.bp3-breadcrumb,
.bp3-breadcrumbs-collapsed{
  color:#5c7080; }

.bp3-breadcrumb:hover{
  text-decoration:none; }

.bp3-breadcrumb.bp3-disabled{
  color:rgba(92, 112, 128, 0.6);
  cursor:not-allowed; }

.bp3-breadcrumb .bp3-icon{
  margin-right:5px; }

.bp3-breadcrumb-current{
  color:inherit;
  font-weight:600; }
  .bp3-breadcrumb-current .bp3-input{
    font-size:inherit;
    font-weight:inherit;
    vertical-align:baseline; }

.bp3-breadcrumbs-collapsed{
  background:#ced9e0;
  border:none;
  border-radius:3px;
  cursor:pointer;
  margin-right:2px;
  padding:1px 5px;
  vertical-align:text-bottom; }
  .bp3-breadcrumbs-collapsed::before{
    background:url("data:image/svg+xml,%3csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 16 16'%3e%3cg fill='%235C7080'%3e%3ccircle cx='2' cy='8.03' r='2'/%3e%3ccircle cx='14' cy='8.03' r='2'/%3e%3ccircle cx='8' cy='8.03' r='2'/%3e%3c/g%3e%3c/svg%3e") center no-repeat;
    content:"";
    display:block;
    height:16px;
    width:16px; }
  .bp3-breadcrumbs-collapsed:hover{
    background:#bfccd6;
    color:#182026;
    text-decoration:none; }

.bp3-dark .bp3-breadcrumb,
.bp3-dark .bp3-breadcrumbs-collapsed{
  color:#a7b6c2; }

.bp3-dark .bp3-breadcrumbs > li::after{
  color:#a7b6c2; }

.bp3-dark .bp3-breadcrumb.bp3-disabled{
  color:rgba(167, 182, 194, 0.6); }

.bp3-dark .bp3-breadcrumb-current{
  color:#f5f8fa; }

.bp3-dark .bp3-breadcrumbs-collapsed{
  background:rgba(16, 22, 26, 0.4); }
  .bp3-dark .bp3-breadcrumbs-collapsed:hover{
    background:rgba(16, 22, 26, 0.6);
    color:#f5f8fa; }
.bp3-button{
  display:-webkit-inline-box;
  display:-ms-inline-flexbox;
  display:inline-flex;
  -webkit-box-orient:horizontal;
  -webkit-box-direction:normal;
      -ms-flex-direction:row;
          flex-direction:row;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  border:none;
  border-radius:3px;
  cursor:pointer;
  font-size:14px;
  -webkit-box-pack:center;
      -ms-flex-pack:center;
          justify-content:center;
  padding:5px 10px;
  text-align:left;
  vertical-align:middle;
  min-height:30px;
  min-width:30px; }
  .bp3-button > *{
    -webkit-box-flex:0;
        -ms-flex-positive:0;
            flex-grow:0;
    -ms-flex-negative:0;
        flex-shrink:0; }
  .bp3-button > .bp3-fill{
    -webkit-box-flex:1;
        -ms-flex-positive:1;
            flex-grow:1;
    -ms-flex-negative:1;
        flex-shrink:1; }
  .bp3-button::before,
  .bp3-button > *{
    margin-right:7px; }
  .bp3-button:empty::before,
  .bp3-button > :last-child{
    margin-right:0; }
  .bp3-button:empty{
    padding:0 !important; }
  .bp3-button:disabled, .bp3-button.bp3-disabled{
    cursor:not-allowed; }
  .bp3-button.bp3-fill{
    display:-webkit-box;
    display:-ms-flexbox;
    display:flex;
    width:100%; }
  .bp3-button.bp3-align-right,
  .bp3-align-right .bp3-button{
    text-align:right; }
  .bp3-button.bp3-align-left,
  .bp3-align-left .bp3-button{
    text-align:left; }
  .bp3-button:not([class*="bp3-intent-"]){
    background-color:#f5f8fa;
    background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.8)), to(rgba(255, 255, 255, 0)));
    background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.8), rgba(255, 255, 255, 0));
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
    color:#182026; }
    .bp3-button:not([class*="bp3-intent-"]):hover{
      background-clip:padding-box;
      background-color:#ebf1f5;
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1); }
    .bp3-button:not([class*="bp3-intent-"]):active, .bp3-button:not([class*="bp3-intent-"]).bp3-active{
      background-color:#d8e1e8;
      background-image:none;
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2); }
    .bp3-button:not([class*="bp3-intent-"]):disabled, .bp3-button:not([class*="bp3-intent-"]).bp3-disabled{
      background-color:rgba(206, 217, 224, 0.5);
      background-image:none;
      -webkit-box-shadow:none;
              box-shadow:none;
      color:rgba(92, 112, 128, 0.6);
      cursor:not-allowed;
      outline:none; }
      .bp3-button:not([class*="bp3-intent-"]):disabled.bp3-active, .bp3-button:not([class*="bp3-intent-"]):disabled.bp3-active:hover, .bp3-button:not([class*="bp3-intent-"]).bp3-disabled.bp3-active, .bp3-button:not([class*="bp3-intent-"]).bp3-disabled.bp3-active:hover{
        background:rgba(206, 217, 224, 0.7); }
  .bp3-button.bp3-intent-primary{
    background-color:#137cbd;
    background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.1)), to(rgba(255, 255, 255, 0)));
    background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.1), rgba(255, 255, 255, 0));
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
    color:#ffffff; }
    .bp3-button.bp3-intent-primary:hover, .bp3-button.bp3-intent-primary:active, .bp3-button.bp3-intent-primary.bp3-active{
      color:#ffffff; }
    .bp3-button.bp3-intent-primary:hover{
      background-color:#106ba3;
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2); }
    .bp3-button.bp3-intent-primary:active, .bp3-button.bp3-intent-primary.bp3-active{
      background-color:#0e5a8a;
      background-image:none;
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2); }
    .bp3-button.bp3-intent-primary:disabled, .bp3-button.bp3-intent-primary.bp3-disabled{
      background-color:rgba(19, 124, 189, 0.5);
      background-image:none;
      border-color:transparent;
      -webkit-box-shadow:none;
              box-shadow:none;
      color:rgba(255, 255, 255, 0.6); }
  .bp3-button.bp3-intent-success{
    background-color:#0f9960;
    background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.1)), to(rgba(255, 255, 255, 0)));
    background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.1), rgba(255, 255, 255, 0));
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
    color:#ffffff; }
    .bp3-button.bp3-intent-success:hover, .bp3-button.bp3-intent-success:active, .bp3-button.bp3-intent-success.bp3-active{
      color:#ffffff; }
    .bp3-button.bp3-intent-success:hover{
      background-color:#0d8050;
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2); }
    .bp3-button.bp3-intent-success:active, .bp3-button.bp3-intent-success.bp3-active{
      background-color:#0a6640;
      background-image:none;
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2); }
    .bp3-button.bp3-intent-success:disabled, .bp3-button.bp3-intent-success.bp3-disabled{
      background-color:rgba(15, 153, 96, 0.5);
      background-image:none;
      border-color:transparent;
      -webkit-box-shadow:none;
              box-shadow:none;
      color:rgba(255, 255, 255, 0.6); }
  .bp3-button.bp3-intent-warning{
    background-color:#d9822b;
    background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.1)), to(rgba(255, 255, 255, 0)));
    background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.1), rgba(255, 255, 255, 0));
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
    color:#ffffff; }
    .bp3-button.bp3-intent-warning:hover, .bp3-button.bp3-intent-warning:active, .bp3-button.bp3-intent-warning.bp3-active{
      color:#ffffff; }
    .bp3-button.bp3-intent-warning:hover{
      background-color:#bf7326;
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2); }
    .bp3-button.bp3-intent-warning:active, .bp3-button.bp3-intent-warning.bp3-active{
      background-color:#a66321;
      background-image:none;
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2); }
    .bp3-button.bp3-intent-warning:disabled, .bp3-button.bp3-intent-warning.bp3-disabled{
      background-color:rgba(217, 130, 43, 0.5);
      background-image:none;
      border-color:transparent;
      -webkit-box-shadow:none;
              box-shadow:none;
      color:rgba(255, 255, 255, 0.6); }
  .bp3-button.bp3-intent-danger{
    background-color:#db3737;
    background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.1)), to(rgba(255, 255, 255, 0)));
    background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.1), rgba(255, 255, 255, 0));
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
    color:#ffffff; }
    .bp3-button.bp3-intent-danger:hover, .bp3-button.bp3-intent-danger:active, .bp3-button.bp3-intent-danger.bp3-active{
      color:#ffffff; }
    .bp3-button.bp3-intent-danger:hover{
      background-color:#c23030;
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2); }
    .bp3-button.bp3-intent-danger:active, .bp3-button.bp3-intent-danger.bp3-active{
      background-color:#a82a2a;
      background-image:none;
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2); }
    .bp3-button.bp3-intent-danger:disabled, .bp3-button.bp3-intent-danger.bp3-disabled{
      background-color:rgba(219, 55, 55, 0.5);
      background-image:none;
      border-color:transparent;
      -webkit-box-shadow:none;
              box-shadow:none;
      color:rgba(255, 255, 255, 0.6); }
  .bp3-button[class*="bp3-intent-"] .bp3-button-spinner .bp3-spinner-head{
    stroke:#ffffff; }
  .bp3-button.bp3-large,
  .bp3-large .bp3-button{
    min-height:40px;
    min-width:40px;
    font-size:16px;
    padding:5px 15px; }
    .bp3-button.bp3-large::before,
    .bp3-button.bp3-large > *,
    .bp3-large .bp3-button::before,
    .bp3-large .bp3-button > *{
      margin-right:10px; }
    .bp3-button.bp3-large:empty::before,
    .bp3-button.bp3-large > :last-child,
    .bp3-large .bp3-button:empty::before,
    .bp3-large .bp3-button > :last-child{
      margin-right:0; }
  .bp3-button.bp3-small,
  .bp3-small .bp3-button{
    min-height:24px;
    min-width:24px;
    padding:0 7px; }
  .bp3-button.bp3-loading{
    position:relative; }
    .bp3-button.bp3-loading[class*="bp3-icon-"]::before{
      visibility:hidden; }
    .bp3-button.bp3-loading .bp3-button-spinner{
      margin:0;
      position:absolute; }
    .bp3-button.bp3-loading > :not(.bp3-button-spinner){
      visibility:hidden; }
  .bp3-button[class*="bp3-icon-"]::before{
    font-family:"Icons16", sans-serif;
    font-size:16px;
    font-style:normal;
    font-weight:400;
    line-height:1;
    -moz-osx-font-smoothing:grayscale;
    -webkit-font-smoothing:antialiased;
    color:#5c7080; }
  .bp3-button .bp3-icon, .bp3-button .bp3-icon-standard, .bp3-button .bp3-icon-large{
    color:#5c7080; }
    .bp3-button .bp3-icon.bp3-align-right, .bp3-button .bp3-icon-standard.bp3-align-right, .bp3-button .bp3-icon-large.bp3-align-right{
      margin-left:7px; }
  .bp3-button .bp3-icon:first-child:last-child,
  .bp3-button .bp3-spinner + .bp3-icon:last-child{
    margin:0 -7px; }
  .bp3-dark .bp3-button:not([class*="bp3-intent-"]){
    background-color:#394b59;
    background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.05)), to(rgba(255, 255, 255, 0)));
    background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.05), rgba(255, 255, 255, 0));
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
    color:#f5f8fa; }
    .bp3-dark .bp3-button:not([class*="bp3-intent-"]):hover, .bp3-dark .bp3-button:not([class*="bp3-intent-"]):active, .bp3-dark .bp3-button:not([class*="bp3-intent-"]).bp3-active{
      color:#f5f8fa; }
    .bp3-dark .bp3-button:not([class*="bp3-intent-"]):hover{
      background-color:#30404d;
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-button:not([class*="bp3-intent-"]):active, .bp3-dark .bp3-button:not([class*="bp3-intent-"]).bp3-active{
      background-color:#202b33;
      background-image:none;
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2); }
    .bp3-dark .bp3-button:not([class*="bp3-intent-"]):disabled, .bp3-dark .bp3-button:not([class*="bp3-intent-"]).bp3-disabled{
      background-color:rgba(57, 75, 89, 0.5);
      background-image:none;
      -webkit-box-shadow:none;
              box-shadow:none;
      color:rgba(167, 182, 194, 0.6); }
      .bp3-dark .bp3-button:not([class*="bp3-intent-"]):disabled.bp3-active, .bp3-dark .bp3-button:not([class*="bp3-intent-"]).bp3-disabled.bp3-active{
        background:rgba(57, 75, 89, 0.7); }
    .bp3-dark .bp3-button:not([class*="bp3-intent-"]) .bp3-button-spinner .bp3-spinner-head{
      background:rgba(16, 22, 26, 0.5);
      stroke:#8a9ba8; }
    .bp3-dark .bp3-button:not([class*="bp3-intent-"])[class*="bp3-icon-"]::before{
      color:#a7b6c2; }
    .bp3-dark .bp3-button:not([class*="bp3-intent-"]) .bp3-icon, .bp3-dark .bp3-button:not([class*="bp3-intent-"]) .bp3-icon-standard, .bp3-dark .bp3-button:not([class*="bp3-intent-"]) .bp3-icon-large{
      color:#a7b6c2; }
  .bp3-dark .bp3-button[class*="bp3-intent-"]{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-button[class*="bp3-intent-"]:hover{
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-button[class*="bp3-intent-"]:active, .bp3-dark .bp3-button[class*="bp3-intent-"].bp3-active{
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2); }
    .bp3-dark .bp3-button[class*="bp3-intent-"]:disabled, .bp3-dark .bp3-button[class*="bp3-intent-"].bp3-disabled{
      background-image:none;
      -webkit-box-shadow:none;
              box-shadow:none;
      color:rgba(255, 255, 255, 0.3); }
    .bp3-dark .bp3-button[class*="bp3-intent-"] .bp3-button-spinner .bp3-spinner-head{
      stroke:#8a9ba8; }
  .bp3-button:disabled::before,
  .bp3-button:disabled .bp3-icon, .bp3-button:disabled .bp3-icon-standard, .bp3-button:disabled .bp3-icon-large, .bp3-button.bp3-disabled::before,
  .bp3-button.bp3-disabled .bp3-icon, .bp3-button.bp3-disabled .bp3-icon-standard, .bp3-button.bp3-disabled .bp3-icon-large, .bp3-button[class*="bp3-intent-"]::before,
  .bp3-button[class*="bp3-intent-"] .bp3-icon, .bp3-button[class*="bp3-intent-"] .bp3-icon-standard, .bp3-button[class*="bp3-intent-"] .bp3-icon-large{
    color:inherit !important; }
  .bp3-button.bp3-minimal{
    background:none;
    -webkit-box-shadow:none;
            box-shadow:none; }
    .bp3-button.bp3-minimal:hover{
      background:rgba(167, 182, 194, 0.3);
      -webkit-box-shadow:none;
              box-shadow:none;
      color:#182026;
      text-decoration:none; }
    .bp3-button.bp3-minimal:active, .bp3-button.bp3-minimal.bp3-active{
      background:rgba(115, 134, 148, 0.3);
      -webkit-box-shadow:none;
              box-shadow:none;
      color:#182026; }
    .bp3-button.bp3-minimal:disabled, .bp3-button.bp3-minimal:disabled:hover, .bp3-button.bp3-minimal.bp3-disabled, .bp3-button.bp3-minimal.bp3-disabled:hover{
      background:none;
      color:rgba(92, 112, 128, 0.6);
      cursor:not-allowed; }
      .bp3-button.bp3-minimal:disabled.bp3-active, .bp3-button.bp3-minimal:disabled:hover.bp3-active, .bp3-button.bp3-minimal.bp3-disabled.bp3-active, .bp3-button.bp3-minimal.bp3-disabled:hover.bp3-active{
        background:rgba(115, 134, 148, 0.3); }
    .bp3-dark .bp3-button.bp3-minimal{
      background:none;
      -webkit-box-shadow:none;
              box-shadow:none;
      color:inherit; }
      .bp3-dark .bp3-button.bp3-minimal:hover, .bp3-dark .bp3-button.bp3-minimal:active, .bp3-dark .bp3-button.bp3-minimal.bp3-active{
        background:none;
        -webkit-box-shadow:none;
                box-shadow:none; }
      .bp3-dark .bp3-button.bp3-minimal:hover{
        background:rgba(138, 155, 168, 0.15); }
      .bp3-dark .bp3-button.bp3-minimal:active, .bp3-dark .bp3-button.bp3-minimal.bp3-active{
        background:rgba(138, 155, 168, 0.3);
        color:#f5f8fa; }
      .bp3-dark .bp3-button.bp3-minimal:disabled, .bp3-dark .bp3-button.bp3-minimal:disabled:hover, .bp3-dark .bp3-button.bp3-minimal.bp3-disabled, .bp3-dark .bp3-button.bp3-minimal.bp3-disabled:hover{
        background:none;
        color:rgba(167, 182, 194, 0.6);
        cursor:not-allowed; }
        .bp3-dark .bp3-button.bp3-minimal:disabled.bp3-active, .bp3-dark .bp3-button.bp3-minimal:disabled:hover.bp3-active, .bp3-dark .bp3-button.bp3-minimal.bp3-disabled.bp3-active, .bp3-dark .bp3-button.bp3-minimal.bp3-disabled:hover.bp3-active{
          background:rgba(138, 155, 168, 0.3); }
    .bp3-button.bp3-minimal.bp3-intent-primary{
      color:#106ba3; }
      .bp3-button.bp3-minimal.bp3-intent-primary:hover, .bp3-button.bp3-minimal.bp3-intent-primary:active, .bp3-button.bp3-minimal.bp3-intent-primary.bp3-active{
        background:none;
        -webkit-box-shadow:none;
                box-shadow:none;
        color:#106ba3; }
      .bp3-button.bp3-minimal.bp3-intent-primary:hover{
        background:rgba(19, 124, 189, 0.15);
        color:#106ba3; }
      .bp3-button.bp3-minimal.bp3-intent-primary:active, .bp3-button.bp3-minimal.bp3-intent-primary.bp3-active{
        background:rgba(19, 124, 189, 0.3);
        color:#106ba3; }
      .bp3-button.bp3-minimal.bp3-intent-primary:disabled, .bp3-button.bp3-minimal.bp3-intent-primary.bp3-disabled{
        background:none;
        color:rgba(16, 107, 163, 0.5); }
        .bp3-button.bp3-minimal.bp3-intent-primary:disabled.bp3-active, .bp3-button.bp3-minimal.bp3-intent-primary.bp3-disabled.bp3-active{
          background:rgba(19, 124, 189, 0.3); }
      .bp3-button.bp3-minimal.bp3-intent-primary .bp3-button-spinner .bp3-spinner-head{
        stroke:#106ba3; }
      .bp3-dark .bp3-button.bp3-minimal.bp3-intent-primary{
        color:#48aff0; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-primary:hover{
          background:rgba(19, 124, 189, 0.2);
          color:#48aff0; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-primary:active, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-primary.bp3-active{
          background:rgba(19, 124, 189, 0.3);
          color:#48aff0; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-primary:disabled, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-primary.bp3-disabled{
          background:none;
          color:rgba(72, 175, 240, 0.5); }
          .bp3-dark .bp3-button.bp3-minimal.bp3-intent-primary:disabled.bp3-active, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-primary.bp3-disabled.bp3-active{
            background:rgba(19, 124, 189, 0.3); }
    .bp3-button.bp3-minimal.bp3-intent-success{
      color:#0d8050; }
      .bp3-button.bp3-minimal.bp3-intent-success:hover, .bp3-button.bp3-minimal.bp3-intent-success:active, .bp3-button.bp3-minimal.bp3-intent-success.bp3-active{
        background:none;
        -webkit-box-shadow:none;
                box-shadow:none;
        color:#0d8050; }
      .bp3-button.bp3-minimal.bp3-intent-success:hover{
        background:rgba(15, 153, 96, 0.15);
        color:#0d8050; }
      .bp3-button.bp3-minimal.bp3-intent-success:active, .bp3-button.bp3-minimal.bp3-intent-success.bp3-active{
        background:rgba(15, 153, 96, 0.3);
        color:#0d8050; }
      .bp3-button.bp3-minimal.bp3-intent-success:disabled, .bp3-button.bp3-minimal.bp3-intent-success.bp3-disabled{
        background:none;
        color:rgba(13, 128, 80, 0.5); }
        .bp3-button.bp3-minimal.bp3-intent-success:disabled.bp3-active, .bp3-button.bp3-minimal.bp3-intent-success.bp3-disabled.bp3-active{
          background:rgba(15, 153, 96, 0.3); }
      .bp3-button.bp3-minimal.bp3-intent-success .bp3-button-spinner .bp3-spinner-head{
        stroke:#0d8050; }
      .bp3-dark .bp3-button.bp3-minimal.bp3-intent-success{
        color:#3dcc91; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-success:hover{
          background:rgba(15, 153, 96, 0.2);
          color:#3dcc91; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-success:active, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-success.bp3-active{
          background:rgba(15, 153, 96, 0.3);
          color:#3dcc91; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-success:disabled, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-success.bp3-disabled{
          background:none;
          color:rgba(61, 204, 145, 0.5); }
          .bp3-dark .bp3-button.bp3-minimal.bp3-intent-success:disabled.bp3-active, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-success.bp3-disabled.bp3-active{
            background:rgba(15, 153, 96, 0.3); }
    .bp3-button.bp3-minimal.bp3-intent-warning{
      color:#bf7326; }
      .bp3-button.bp3-minimal.bp3-intent-warning:hover, .bp3-button.bp3-minimal.bp3-intent-warning:active, .bp3-button.bp3-minimal.bp3-intent-warning.bp3-active{
        background:none;
        -webkit-box-shadow:none;
                box-shadow:none;
        color:#bf7326; }
      .bp3-button.bp3-minimal.bp3-intent-warning:hover{
        background:rgba(217, 130, 43, 0.15);
        color:#bf7326; }
      .bp3-button.bp3-minimal.bp3-intent-warning:active, .bp3-button.bp3-minimal.bp3-intent-warning.bp3-active{
        background:rgba(217, 130, 43, 0.3);
        color:#bf7326; }
      .bp3-button.bp3-minimal.bp3-intent-warning:disabled, .bp3-button.bp3-minimal.bp3-intent-warning.bp3-disabled{
        background:none;
        color:rgba(191, 115, 38, 0.5); }
        .bp3-button.bp3-minimal.bp3-intent-warning:disabled.bp3-active, .bp3-button.bp3-minimal.bp3-intent-warning.bp3-disabled.bp3-active{
          background:rgba(217, 130, 43, 0.3); }
      .bp3-button.bp3-minimal.bp3-intent-warning .bp3-button-spinner .bp3-spinner-head{
        stroke:#bf7326; }
      .bp3-dark .bp3-button.bp3-minimal.bp3-intent-warning{
        color:#ffb366; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-warning:hover{
          background:rgba(217, 130, 43, 0.2);
          color:#ffb366; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-warning:active, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-warning.bp3-active{
          background:rgba(217, 130, 43, 0.3);
          color:#ffb366; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-warning:disabled, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-warning.bp3-disabled{
          background:none;
          color:rgba(255, 179, 102, 0.5); }
          .bp3-dark .bp3-button.bp3-minimal.bp3-intent-warning:disabled.bp3-active, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-warning.bp3-disabled.bp3-active{
            background:rgba(217, 130, 43, 0.3); }
    .bp3-button.bp3-minimal.bp3-intent-danger{
      color:#c23030; }
      .bp3-button.bp3-minimal.bp3-intent-danger:hover, .bp3-button.bp3-minimal.bp3-intent-danger:active, .bp3-button.bp3-minimal.bp3-intent-danger.bp3-active{
        background:none;
        -webkit-box-shadow:none;
                box-shadow:none;
        color:#c23030; }
      .bp3-button.bp3-minimal.bp3-intent-danger:hover{
        background:rgba(219, 55, 55, 0.15);
        color:#c23030; }
      .bp3-button.bp3-minimal.bp3-intent-danger:active, .bp3-button.bp3-minimal.bp3-intent-danger.bp3-active{
        background:rgba(219, 55, 55, 0.3);
        color:#c23030; }
      .bp3-button.bp3-minimal.bp3-intent-danger:disabled, .bp3-button.bp3-minimal.bp3-intent-danger.bp3-disabled{
        background:none;
        color:rgba(194, 48, 48, 0.5); }
        .bp3-button.bp3-minimal.bp3-intent-danger:disabled.bp3-active, .bp3-button.bp3-minimal.bp3-intent-danger.bp3-disabled.bp3-active{
          background:rgba(219, 55, 55, 0.3); }
      .bp3-button.bp3-minimal.bp3-intent-danger .bp3-button-spinner .bp3-spinner-head{
        stroke:#c23030; }
      .bp3-dark .bp3-button.bp3-minimal.bp3-intent-danger{
        color:#ff7373; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-danger:hover{
          background:rgba(219, 55, 55, 0.2);
          color:#ff7373; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-danger:active, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-danger.bp3-active{
          background:rgba(219, 55, 55, 0.3);
          color:#ff7373; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-danger:disabled, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-danger.bp3-disabled{
          background:none;
          color:rgba(255, 115, 115, 0.5); }
          .bp3-dark .bp3-button.bp3-minimal.bp3-intent-danger:disabled.bp3-active, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-danger.bp3-disabled.bp3-active{
            background:rgba(219, 55, 55, 0.3); }
  .bp3-button.bp3-outlined{
    background:none;
    -webkit-box-shadow:none;
            box-shadow:none;
    border:1px solid rgba(24, 32, 38, 0.2);
    -webkit-box-sizing:border-box;
            box-sizing:border-box; }
    .bp3-button.bp3-outlined:hover{
      background:rgba(167, 182, 194, 0.3);
      -webkit-box-shadow:none;
              box-shadow:none;
      color:#182026;
      text-decoration:none; }
    .bp3-button.bp3-outlined:active, .bp3-button.bp3-outlined.bp3-active{
      background:rgba(115, 134, 148, 0.3);
      -webkit-box-shadow:none;
              box-shadow:none;
      color:#182026; }
    .bp3-button.bp3-outlined:disabled, .bp3-button.bp3-outlined:disabled:hover, .bp3-button.bp3-outlined.bp3-disabled, .bp3-button.bp3-outlined.bp3-disabled:hover{
      background:none;
      color:rgba(92, 112, 128, 0.6);
      cursor:not-allowed; }
      .bp3-button.bp3-outlined:disabled.bp3-active, .bp3-button.bp3-outlined:disabled:hover.bp3-active, .bp3-button.bp3-outlined.bp3-disabled.bp3-active, .bp3-button.bp3-outlined.bp3-disabled:hover.bp3-active{
        background:rgba(115, 134, 148, 0.3); }
    .bp3-dark .bp3-button.bp3-outlined{
      background:none;
      -webkit-box-shadow:none;
              box-shadow:none;
      color:inherit; }
      .bp3-dark .bp3-button.bp3-outlined:hover, .bp3-dark .bp3-button.bp3-outlined:active, .bp3-dark .bp3-button.bp3-outlined.bp3-active{
        background:none;
        -webkit-box-shadow:none;
                box-shadow:none; }
      .bp3-dark .bp3-button.bp3-outlined:hover{
        background:rgba(138, 155, 168, 0.15); }
      .bp3-dark .bp3-button.bp3-outlined:active, .bp3-dark .bp3-button.bp3-outlined.bp3-active{
        background:rgba(138, 155, 168, 0.3);
        color:#f5f8fa; }
      .bp3-dark .bp3-button.bp3-outlined:disabled, .bp3-dark .bp3-button.bp3-outlined:disabled:hover, .bp3-dark .bp3-button.bp3-outlined.bp3-disabled, .bp3-dark .bp3-button.bp3-outlined.bp3-disabled:hover{
        background:none;
        color:rgba(167, 182, 194, 0.6);
        cursor:not-allowed; }
        .bp3-dark .bp3-button.bp3-outlined:disabled.bp3-active, .bp3-dark .bp3-button.bp3-outlined:disabled:hover.bp3-active, .bp3-dark .bp3-button.bp3-outlined.bp3-disabled.bp3-active, .bp3-dark .bp3-button.bp3-outlined.bp3-disabled:hover.bp3-active{
          background:rgba(138, 155, 168, 0.3); }
    .bp3-button.bp3-outlined.bp3-intent-primary{
      color:#106ba3; }
      .bp3-button.bp3-outlined.bp3-intent-primary:hover, .bp3-button.bp3-outlined.bp3-intent-primary:active, .bp3-button.bp3-outlined.bp3-intent-primary.bp3-active{
        background:none;
        -webkit-box-shadow:none;
                box-shadow:none;
        color:#106ba3; }
      .bp3-button.bp3-outlined.bp3-intent-primary:hover{
        background:rgba(19, 124, 189, 0.15);
        color:#106ba3; }
      .bp3-button.bp3-outlined.bp3-intent-primary:active, .bp3-button.bp3-outlined.bp3-intent-primary.bp3-active{
        background:rgba(19, 124, 189, 0.3);
        color:#106ba3; }
      .bp3-button.bp3-outlined.bp3-intent-primary:disabled, .bp3-button.bp3-outlined.bp3-intent-primary.bp3-disabled{
        background:none;
        color:rgba(16, 107, 163, 0.5); }
        .bp3-button.bp3-outlined.bp3-intent-primary:disabled.bp3-active, .bp3-button.bp3-outlined.bp3-intent-primary.bp3-disabled.bp3-active{
          background:rgba(19, 124, 189, 0.3); }
      .bp3-button.bp3-outlined.bp3-intent-primary .bp3-button-spinner .bp3-spinner-head{
        stroke:#106ba3; }
      .bp3-dark .bp3-button.bp3-outlined.bp3-intent-primary{
        color:#48aff0; }
        .bp3-dark .bp3-button.bp3-outlined.bp3-intent-primary:hover{
          background:rgba(19, 124, 189, 0.2);
          color:#48aff0; }
        .bp3-dark .bp3-button.bp3-outlined.bp3-intent-primary:active, .bp3-dark .bp3-button.bp3-outlined.bp3-intent-primary.bp3-active{
          background:rgba(19, 124, 189, 0.3);
          color:#48aff0; }
        .bp3-dark .bp3-button.bp3-outlined.bp3-intent-primary:disabled, .bp3-dark .bp3-button.bp3-outlined.bp3-intent-primary.bp3-disabled{
          background:none;
          color:rgba(72, 175, 240, 0.5); }
          .bp3-dark .bp3-button.bp3-outlined.bp3-intent-primary:disabled.bp3-active, .bp3-dark .bp3-button.bp3-outlined.bp3-intent-primary.bp3-disabled.bp3-active{
            background:rgba(19, 124, 189, 0.3); }
    .bp3-button.bp3-outlined.bp3-intent-success{
      color:#0d8050; }
      .bp3-button.bp3-outlined.bp3-intent-success:hover, .bp3-button.bp3-outlined.bp3-intent-success:active, .bp3-button.bp3-outlined.bp3-intent-success.bp3-active{
        background:none;
        -webkit-box-shadow:none;
                box-shadow:none;
        color:#0d8050; }
      .bp3-button.bp3-outlined.bp3-intent-success:hover{
        background:rgba(15, 153, 96, 0.15);
        color:#0d8050; }
      .bp3-button.bp3-outlined.bp3-intent-success:active, .bp3-button.bp3-outlined.bp3-intent-success.bp3-active{
        background:rgba(15, 153, 96, 0.3);
        color:#0d8050; }
      .bp3-button.bp3-outlined.bp3-intent-success:disabled, .bp3-button.bp3-outlined.bp3-intent-success.bp3-disabled{
        background:none;
        color:rgba(13, 128, 80, 0.5); }
        .bp3-button.bp3-outlined.bp3-intent-success:disabled.bp3-active, .bp3-button.bp3-outlined.bp3-intent-success.bp3-disabled.bp3-active{
          background:rgba(15, 153, 96, 0.3); }
      .bp3-button.bp3-outlined.bp3-intent-success .bp3-button-spinner .bp3-spinner-head{
        stroke:#0d8050; }
      .bp3-dark .bp3-button.bp3-outlined.bp3-intent-success{
        color:#3dcc91; }
        .bp3-dark .bp3-button.bp3-outlined.bp3-intent-success:hover{
          background:rgba(15, 153, 96, 0.2);
          color:#3dcc91; }
        .bp3-dark .bp3-button.bp3-outlined.bp3-intent-success:active, .bp3-dark .bp3-button.bp3-outlined.bp3-intent-success.bp3-active{
          background:rgba(15, 153, 96, 0.3);
          color:#3dcc91; }
        .bp3-dark .bp3-button.bp3-outlined.bp3-intent-success:disabled, .bp3-dark .bp3-button.bp3-outlined.bp3-intent-success.bp3-disabled{
          background:none;
          color:rgba(61, 204, 145, 0.5); }
          .bp3-dark .bp3-button.bp3-outlined.bp3-intent-success:disabled.bp3-active, .bp3-dark .bp3-button.bp3-outlined.bp3-intent-success.bp3-disabled.bp3-active{
            background:rgba(15, 153, 96, 0.3); }
    .bp3-button.bp3-outlined.bp3-intent-warning{
      color:#bf7326; }
      .bp3-button.bp3-outlined.bp3-intent-warning:hover, .bp3-button.bp3-outlined.bp3-intent-warning:active, .bp3-button.bp3-outlined.bp3-intent-warning.bp3-active{
        background:none;
        -webkit-box-shadow:none;
                box-shadow:none;
        color:#bf7326; }
      .bp3-button.bp3-outlined.bp3-intent-warning:hover{
        background:rgba(217, 130, 43, 0.15);
        color:#bf7326; }
      .bp3-button.bp3-outlined.bp3-intent-warning:active, .bp3-button.bp3-outlined.bp3-intent-warning.bp3-active{
        background:rgba(217, 130, 43, 0.3);
        color:#bf7326; }
      .bp3-button.bp3-outlined.bp3-intent-warning:disabled, .bp3-button.bp3-outlined.bp3-intent-warning.bp3-disabled{
        background:none;
        color:rgba(191, 115, 38, 0.5); }
        .bp3-button.bp3-outlined.bp3-intent-warning:disabled.bp3-active, .bp3-button.bp3-outlined.bp3-intent-warning.bp3-disabled.bp3-active{
          background:rgba(217, 130, 43, 0.3); }
      .bp3-button.bp3-outlined.bp3-intent-warning .bp3-button-spinner .bp3-spinner-head{
        stroke:#bf7326; }
      .bp3-dark .bp3-button.bp3-outlined.bp3-intent-warning{
        color:#ffb366; }
        .bp3-dark .bp3-button.bp3-outlined.bp3-intent-warning:hover{
          background:rgba(217, 130, 43, 0.2);
          color:#ffb366; }
        .bp3-dark .bp3-button.bp3-outlined.bp3-intent-warning:active, .bp3-dark .bp3-button.bp3-outlined.bp3-intent-warning.bp3-active{
          background:rgba(217, 130, 43, 0.3);
          color:#ffb366; }
        .bp3-dark .bp3-button.bp3-outlined.bp3-intent-warning:disabled, .bp3-dark .bp3-button.bp3-outlined.bp3-intent-warning.bp3-disabled{
          background:none;
          color:rgba(255, 179, 102, 0.5); }
          .bp3-dark .bp3-button.bp3-outlined.bp3-intent-warning:disabled.bp3-active, .bp3-dark .bp3-button.bp3-outlined.bp3-intent-warning.bp3-disabled.bp3-active{
            background:rgba(217, 130, 43, 0.3); }
    .bp3-button.bp3-outlined.bp3-intent-danger{
      color:#c23030; }
      .bp3-button.bp3-outlined.bp3-intent-danger:hover, .bp3-button.bp3-outlined.bp3-intent-danger:active, .bp3-button.bp3-outlined.bp3-intent-danger.bp3-active{
        background:none;
        -webkit-box-shadow:none;
                box-shadow:none;
        color:#c23030; }
      .bp3-button.bp3-outlined.bp3-intent-danger:hover{
        background:rgba(219, 55, 55, 0.15);
        color:#c23030; }
      .bp3-button.bp3-outlined.bp3-intent-danger:active, .bp3-button.bp3-outlined.bp3-intent-danger.bp3-active{
        background:rgba(219, 55, 55, 0.3);
        color:#c23030; }
      .bp3-button.bp3-outlined.bp3-intent-danger:disabled, .bp3-button.bp3-outlined.bp3-intent-danger.bp3-disabled{
        background:none;
        color:rgba(194, 48, 48, 0.5); }
        .bp3-button.bp3-outlined.bp3-intent-danger:disabled.bp3-active, .bp3-button.bp3-outlined.bp3-intent-danger.bp3-disabled.bp3-active{
          background:rgba(219, 55, 55, 0.3); }
      .bp3-button.bp3-outlined.bp3-intent-danger .bp3-button-spinner .bp3-spinner-head{
        stroke:#c23030; }
      .bp3-dark .bp3-button.bp3-outlined.bp3-intent-danger{
        color:#ff7373; }
        .bp3-dark .bp3-button.bp3-outlined.bp3-intent-danger:hover{
          background:rgba(219, 55, 55, 0.2);
          color:#ff7373; }
        .bp3-dark .bp3-button.bp3-outlined.bp3-intent-danger:active, .bp3-dark .bp3-button.bp3-outlined.bp3-intent-danger.bp3-active{
          background:rgba(219, 55, 55, 0.3);
          color:#ff7373; }
        .bp3-dark .bp3-button.bp3-outlined.bp3-intent-danger:disabled, .bp3-dark .bp3-button.bp3-outlined.bp3-intent-danger.bp3-disabled{
          background:none;
          color:rgba(255, 115, 115, 0.5); }
          .bp3-dark .bp3-button.bp3-outlined.bp3-intent-danger:disabled.bp3-active, .bp3-dark .bp3-button.bp3-outlined.bp3-intent-danger.bp3-disabled.bp3-active{
            background:rgba(219, 55, 55, 0.3); }
    .bp3-button.bp3-outlined:disabled, .bp3-button.bp3-outlined.bp3-disabled, .bp3-button.bp3-outlined:disabled:hover, .bp3-button.bp3-outlined.bp3-disabled:hover{
      border-color:rgba(92, 112, 128, 0.1); }
    .bp3-dark .bp3-button.bp3-outlined{
      border-color:rgba(255, 255, 255, 0.4); }
      .bp3-dark .bp3-button.bp3-outlined:disabled, .bp3-dark .bp3-button.bp3-outlined:disabled:hover, .bp3-dark .bp3-button.bp3-outlined.bp3-disabled, .bp3-dark .bp3-button.bp3-outlined.bp3-disabled:hover{
        border-color:rgba(255, 255, 255, 0.2); }
    .bp3-button.bp3-outlined.bp3-intent-primary{
      border-color:rgba(16, 107, 163, 0.6); }
      .bp3-button.bp3-outlined.bp3-intent-primary:disabled, .bp3-button.bp3-outlined.bp3-intent-primary.bp3-disabled{
        border-color:rgba(16, 107, 163, 0.2); }
      .bp3-dark .bp3-button.bp3-outlined.bp3-intent-primary{
        border-color:rgba(72, 175, 240, 0.6); }
        .bp3-dark .bp3-button.bp3-outlined.bp3-intent-primary:disabled, .bp3-dark .bp3-button.bp3-outlined.bp3-intent-primary.bp3-disabled{
          border-color:rgba(72, 175, 240, 0.2); }
    .bp3-button.bp3-outlined.bp3-intent-success{
      border-color:rgba(13, 128, 80, 0.6); }
      .bp3-button.bp3-outlined.bp3-intent-success:disabled, .bp3-button.bp3-outlined.bp3-intent-success.bp3-disabled{
        border-color:rgba(13, 128, 80, 0.2); }
      .bp3-dark .bp3-button.bp3-outlined.bp3-intent-success{
        border-color:rgba(61, 204, 145, 0.6); }
        .bp3-dark .bp3-button.bp3-outlined.bp3-intent-success:disabled, .bp3-dark .bp3-button.bp3-outlined.bp3-intent-success.bp3-disabled{
          border-color:rgba(61, 204, 145, 0.2); }
    .bp3-button.bp3-outlined.bp3-intent-warning{
      border-color:rgba(191, 115, 38, 0.6); }
      .bp3-button.bp3-outlined.bp3-intent-warning:disabled, .bp3-button.bp3-outlined.bp3-intent-warning.bp3-disabled{
        border-color:rgba(191, 115, 38, 0.2); }
      .bp3-dark .bp3-button.bp3-outlined.bp3-intent-warning{
        border-color:rgba(255, 179, 102, 0.6); }
        .bp3-dark .bp3-button.bp3-outlined.bp3-intent-warning:disabled, .bp3-dark .bp3-button.bp3-outlined.bp3-intent-warning.bp3-disabled{
          border-color:rgba(255, 179, 102, 0.2); }
    .bp3-button.bp3-outlined.bp3-intent-danger{
      border-color:rgba(194, 48, 48, 0.6); }
      .bp3-button.bp3-outlined.bp3-intent-danger:disabled, .bp3-button.bp3-outlined.bp3-intent-danger.bp3-disabled{
        border-color:rgba(194, 48, 48, 0.2); }
      .bp3-dark .bp3-button.bp3-outlined.bp3-intent-danger{
        border-color:rgba(255, 115, 115, 0.6); }
        .bp3-dark .bp3-button.bp3-outlined.bp3-intent-danger:disabled, .bp3-dark .bp3-button.bp3-outlined.bp3-intent-danger.bp3-disabled{
          border-color:rgba(255, 115, 115, 0.2); }

a.bp3-button{
  text-align:center;
  text-decoration:none;
  -webkit-transition:none;
  transition:none; }
  a.bp3-button, a.bp3-button:hover, a.bp3-button:active{
    color:#182026; }
  a.bp3-button.bp3-disabled{
    color:rgba(92, 112, 128, 0.6); }

.bp3-button-text{
  -webkit-box-flex:0;
      -ms-flex:0 1 auto;
          flex:0 1 auto; }

.bp3-button.bp3-align-left .bp3-button-text, .bp3-button.bp3-align-right .bp3-button-text,
.bp3-button-group.bp3-align-left .bp3-button-text,
.bp3-button-group.bp3-align-right .bp3-button-text{
  -webkit-box-flex:1;
      -ms-flex:1 1 auto;
          flex:1 1 auto; }
.bp3-button-group{
  display:-webkit-inline-box;
  display:-ms-inline-flexbox;
  display:inline-flex; }
  .bp3-button-group .bp3-button{
    -webkit-box-flex:0;
        -ms-flex:0 0 auto;
            flex:0 0 auto;
    position:relative;
    z-index:4; }
    .bp3-button-group .bp3-button:focus{
      z-index:5; }
    .bp3-button-group .bp3-button:hover{
      z-index:6; }
    .bp3-button-group .bp3-button:active, .bp3-button-group .bp3-button.bp3-active{
      z-index:7; }
    .bp3-button-group .bp3-button:disabled, .bp3-button-group .bp3-button.bp3-disabled{
      z-index:3; }
    .bp3-button-group .bp3-button[class*="bp3-intent-"]{
      z-index:9; }
      .bp3-button-group .bp3-button[class*="bp3-intent-"]:focus{
        z-index:10; }
      .bp3-button-group .bp3-button[class*="bp3-intent-"]:hover{
        z-index:11; }
      .bp3-button-group .bp3-button[class*="bp3-intent-"]:active, .bp3-button-group .bp3-button[class*="bp3-intent-"].bp3-active{
        z-index:12; }
      .bp3-button-group .bp3-button[class*="bp3-intent-"]:disabled, .bp3-button-group .bp3-button[class*="bp3-intent-"].bp3-disabled{
        z-index:8; }
  .bp3-button-group:not(.bp3-minimal) > .bp3-popover-wrapper:not(:first-child) .bp3-button,
  .bp3-button-group:not(.bp3-minimal) > .bp3-button:not(:first-child){
    border-bottom-left-radius:0;
    border-top-left-radius:0; }
  .bp3-button-group:not(.bp3-minimal) > .bp3-popover-wrapper:not(:last-child) .bp3-button,
  .bp3-button-group:not(.bp3-minimal) > .bp3-button:not(:last-child){
    border-bottom-right-radius:0;
    border-top-right-radius:0;
    margin-right:-1px; }
  .bp3-button-group.bp3-minimal .bp3-button{
    background:none;
    -webkit-box-shadow:none;
            box-shadow:none; }
    .bp3-button-group.bp3-minimal .bp3-button:hover{
      background:rgba(167, 182, 194, 0.3);
      -webkit-box-shadow:none;
              box-shadow:none;
      color:#182026;
      text-decoration:none; }
    .bp3-button-group.bp3-minimal .bp3-button:active, .bp3-button-group.bp3-minimal .bp3-button.bp3-active{
      background:rgba(115, 134, 148, 0.3);
      -webkit-box-shadow:none;
              box-shadow:none;
      color:#182026; }
    .bp3-button-group.bp3-minimal .bp3-button:disabled, .bp3-button-group.bp3-minimal .bp3-button:disabled:hover, .bp3-button-group.bp3-minimal .bp3-button.bp3-disabled, .bp3-button-group.bp3-minimal .bp3-button.bp3-disabled:hover{
      background:none;
      color:rgba(92, 112, 128, 0.6);
      cursor:not-allowed; }
      .bp3-button-group.bp3-minimal .bp3-button:disabled.bp3-active, .bp3-button-group.bp3-minimal .bp3-button:disabled:hover.bp3-active, .bp3-button-group.bp3-minimal .bp3-button.bp3-disabled.bp3-active, .bp3-button-group.bp3-minimal .bp3-button.bp3-disabled:hover.bp3-active{
        background:rgba(115, 134, 148, 0.3); }
    .bp3-dark .bp3-button-group.bp3-minimal .bp3-button{
      background:none;
      -webkit-box-shadow:none;
              box-shadow:none;
      color:inherit; }
      .bp3-dark .bp3-button-group.bp3-minimal .bp3-button:hover, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button:active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-active{
        background:none;
        -webkit-box-shadow:none;
                box-shadow:none; }
      .bp3-dark .bp3-button-group.bp3-minimal .bp3-button:hover{
        background:rgba(138, 155, 168, 0.15); }
      .bp3-dark .bp3-button-group.bp3-minimal .bp3-button:active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-active{
        background:rgba(138, 155, 168, 0.3);
        color:#f5f8fa; }
      .bp3-dark .bp3-button-group.bp3-minimal .bp3-button:disabled, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button:disabled:hover, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-disabled, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-disabled:hover{
        background:none;
        color:rgba(167, 182, 194, 0.6);
        cursor:not-allowed; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button:disabled.bp3-active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button:disabled:hover.bp3-active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-disabled.bp3-active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-disabled:hover.bp3-active{
          background:rgba(138, 155, 168, 0.3); }
    .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary{
      color:#106ba3; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:hover, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary.bp3-active{
        background:none;
        -webkit-box-shadow:none;
                box-shadow:none;
        color:#106ba3; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:hover{
        background:rgba(19, 124, 189, 0.15);
        color:#106ba3; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary.bp3-active{
        background:rgba(19, 124, 189, 0.3);
        color:#106ba3; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:disabled, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary.bp3-disabled{
        background:none;
        color:rgba(16, 107, 163, 0.5); }
        .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:disabled.bp3-active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary.bp3-disabled.bp3-active{
          background:rgba(19, 124, 189, 0.3); }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary .bp3-button-spinner .bp3-spinner-head{
        stroke:#106ba3; }
      .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary{
        color:#48aff0; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:hover{
          background:rgba(19, 124, 189, 0.2);
          color:#48aff0; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary.bp3-active{
          background:rgba(19, 124, 189, 0.3);
          color:#48aff0; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:disabled, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary.bp3-disabled{
          background:none;
          color:rgba(72, 175, 240, 0.5); }
          .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:disabled.bp3-active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary.bp3-disabled.bp3-active{
            background:rgba(19, 124, 189, 0.3); }
    .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success{
      color:#0d8050; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:hover, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success.bp3-active{
        background:none;
        -webkit-box-shadow:none;
                box-shadow:none;
        color:#0d8050; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:hover{
        background:rgba(15, 153, 96, 0.15);
        color:#0d8050; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success.bp3-active{
        background:rgba(15, 153, 96, 0.3);
        color:#0d8050; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:disabled, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success.bp3-disabled{
        background:none;
        color:rgba(13, 128, 80, 0.5); }
        .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:disabled.bp3-active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success.bp3-disabled.bp3-active{
          background:rgba(15, 153, 96, 0.3); }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success .bp3-button-spinner .bp3-spinner-head{
        stroke:#0d8050; }
      .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success{
        color:#3dcc91; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:hover{
          background:rgba(15, 153, 96, 0.2);
          color:#3dcc91; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success.bp3-active{
          background:rgba(15, 153, 96, 0.3);
          color:#3dcc91; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:disabled, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success.bp3-disabled{
          background:none;
          color:rgba(61, 204, 145, 0.5); }
          .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:disabled.bp3-active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success.bp3-disabled.bp3-active{
            background:rgba(15, 153, 96, 0.3); }
    .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning{
      color:#bf7326; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:hover, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning.bp3-active{
        background:none;
        -webkit-box-shadow:none;
                box-shadow:none;
        color:#bf7326; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:hover{
        background:rgba(217, 130, 43, 0.15);
        color:#bf7326; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning.bp3-active{
        background:rgba(217, 130, 43, 0.3);
        color:#bf7326; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:disabled, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning.bp3-disabled{
        background:none;
        color:rgba(191, 115, 38, 0.5); }
        .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:disabled.bp3-active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning.bp3-disabled.bp3-active{
          background:rgba(217, 130, 43, 0.3); }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning .bp3-button-spinner .bp3-spinner-head{
        stroke:#bf7326; }
      .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning{
        color:#ffb366; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:hover{
          background:rgba(217, 130, 43, 0.2);
          color:#ffb366; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning.bp3-active{
          background:rgba(217, 130, 43, 0.3);
          color:#ffb366; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:disabled, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning.bp3-disabled{
          background:none;
          color:rgba(255, 179, 102, 0.5); }
          .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:disabled.bp3-active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning.bp3-disabled.bp3-active{
            background:rgba(217, 130, 43, 0.3); }
    .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger{
      color:#c23030; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:hover, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger.bp3-active{
        background:none;
        -webkit-box-shadow:none;
                box-shadow:none;
        color:#c23030; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:hover{
        background:rgba(219, 55, 55, 0.15);
        color:#c23030; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger.bp3-active{
        background:rgba(219, 55, 55, 0.3);
        color:#c23030; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:disabled, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger.bp3-disabled{
        background:none;
        color:rgba(194, 48, 48, 0.5); }
        .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:disabled.bp3-active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger.bp3-disabled.bp3-active{
          background:rgba(219, 55, 55, 0.3); }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger .bp3-button-spinner .bp3-spinner-head{
        stroke:#c23030; }
      .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger{
        color:#ff7373; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:hover{
          background:rgba(219, 55, 55, 0.2);
          color:#ff7373; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger.bp3-active{
          background:rgba(219, 55, 55, 0.3);
          color:#ff7373; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:disabled, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger.bp3-disabled{
          background:none;
          color:rgba(255, 115, 115, 0.5); }
          .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:disabled.bp3-active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger.bp3-disabled.bp3-active{
            background:rgba(219, 55, 55, 0.3); }
  .bp3-button-group .bp3-popover-wrapper,
  .bp3-button-group .bp3-popover-target{
    display:-webkit-box;
    display:-ms-flexbox;
    display:flex;
    -webkit-box-flex:1;
        -ms-flex:1 1 auto;
            flex:1 1 auto; }
  .bp3-button-group.bp3-fill{
    display:-webkit-box;
    display:-ms-flexbox;
    display:flex;
    width:100%; }
  .bp3-button-group .bp3-button.bp3-fill,
  .bp3-button-group.bp3-fill .bp3-button:not(.bp3-fixed){
    -webkit-box-flex:1;
        -ms-flex:1 1 auto;
            flex:1 1 auto; }
  .bp3-button-group.bp3-vertical{
    -webkit-box-align:stretch;
        -ms-flex-align:stretch;
            align-items:stretch;
    -webkit-box-orient:vertical;
    -webkit-box-direction:normal;
        -ms-flex-direction:column;
            flex-direction:column;
    vertical-align:top; }
    .bp3-button-group.bp3-vertical.bp3-fill{
      height:100%;
      width:unset; }
    .bp3-button-group.bp3-vertical .bp3-button{
      margin-right:0 !important;
      width:100%; }
    .bp3-button-group.bp3-vertical:not(.bp3-minimal) > .bp3-popover-wrapper:first-child .bp3-button,
    .bp3-button-group.bp3-vertical:not(.bp3-minimal) > .bp3-button:first-child{
      border-radius:3px 3px 0 0; }
    .bp3-button-group.bp3-vertical:not(.bp3-minimal) > .bp3-popover-wrapper:last-child .bp3-button,
    .bp3-button-group.bp3-vertical:not(.bp3-minimal) > .bp3-button:last-child{
      border-radius:0 0 3px 3px; }
    .bp3-button-group.bp3-vertical:not(.bp3-minimal) > .bp3-popover-wrapper:not(:last-child) .bp3-button,
    .bp3-button-group.bp3-vertical:not(.bp3-minimal) > .bp3-button:not(:last-child){
      margin-bottom:-1px; }
  .bp3-button-group.bp3-align-left .bp3-button{
    text-align:left; }
  .bp3-dark .bp3-button-group:not(.bp3-minimal) > .bp3-popover-wrapper:not(:last-child) .bp3-button,
  .bp3-dark .bp3-button-group:not(.bp3-minimal) > .bp3-button:not(:last-child){
    margin-right:1px; }
  .bp3-dark .bp3-button-group.bp3-vertical > .bp3-popover-wrapper:not(:last-child) .bp3-button,
  .bp3-dark .bp3-button-group.bp3-vertical > .bp3-button:not(:last-child){
    margin-bottom:1px; }
.bp3-callout{
  font-size:14px;
  line-height:1.5;
  background-color:rgba(138, 155, 168, 0.15);
  border-radius:3px;
  padding:10px 12px 9px;
  position:relative;
  width:100%; }
  .bp3-callout[class*="bp3-icon-"]{
    padding-left:40px; }
    .bp3-callout[class*="bp3-icon-"]::before{
      font-family:"Icons20", sans-serif;
      font-size:20px;
      font-style:normal;
      font-weight:400;
      line-height:1;
      -moz-osx-font-smoothing:grayscale;
      -webkit-font-smoothing:antialiased;
      color:#5c7080;
      left:10px;
      position:absolute;
      top:10px; }
  .bp3-callout.bp3-callout-icon{
    padding-left:40px; }
    .bp3-callout.bp3-callout-icon > .bp3-icon:first-child{
      color:#5c7080;
      left:10px;
      position:absolute;
      top:10px; }
  .bp3-callout .bp3-heading{
    line-height:20px;
    margin-bottom:5px;
    margin-top:0; }
    .bp3-callout .bp3-heading:last-child{
      margin-bottom:0; }
  .bp3-dark .bp3-callout{
    background-color:rgba(138, 155, 168, 0.2); }
    .bp3-dark .bp3-callout[class*="bp3-icon-"]::before{
      color:#a7b6c2; }
  .bp3-callout.bp3-intent-primary{
    background-color:rgba(19, 124, 189, 0.15); }
    .bp3-callout.bp3-intent-primary[class*="bp3-icon-"]::before,
    .bp3-callout.bp3-intent-primary > .bp3-icon:first-child,
    .bp3-callout.bp3-intent-primary .bp3-heading{
      color:#106ba3; }
    .bp3-dark .bp3-callout.bp3-intent-primary{
      background-color:rgba(19, 124, 189, 0.25); }
      .bp3-dark .bp3-callout.bp3-intent-primary[class*="bp3-icon-"]::before,
      .bp3-dark .bp3-callout.bp3-intent-primary > .bp3-icon:first-child,
      .bp3-dark .bp3-callout.bp3-intent-primary .bp3-heading{
        color:#48aff0; }
  .bp3-callout.bp3-intent-success{
    background-color:rgba(15, 153, 96, 0.15); }
    .bp3-callout.bp3-intent-success[class*="bp3-icon-"]::before,
    .bp3-callout.bp3-intent-success > .bp3-icon:first-child,
    .bp3-callout.bp3-intent-success .bp3-heading{
      color:#0d8050; }
    .bp3-dark .bp3-callout.bp3-intent-success{
      background-color:rgba(15, 153, 96, 0.25); }
      .bp3-dark .bp3-callout.bp3-intent-success[class*="bp3-icon-"]::before,
      .bp3-dark .bp3-callout.bp3-intent-success > .bp3-icon:first-child,
      .bp3-dark .bp3-callout.bp3-intent-success .bp3-heading{
        color:#3dcc91; }
  .bp3-callout.bp3-intent-warning{
    background-color:rgba(217, 130, 43, 0.15); }
    .bp3-callout.bp3-intent-warning[class*="bp3-icon-"]::before,
    .bp3-callout.bp3-intent-warning > .bp3-icon:first-child,
    .bp3-callout.bp3-intent-warning .bp3-heading{
      color:#bf7326; }
    .bp3-dark .bp3-callout.bp3-intent-warning{
      background-color:rgba(217, 130, 43, 0.25); }
      .bp3-dark .bp3-callout.bp3-intent-warning[class*="bp3-icon-"]::before,
      .bp3-dark .bp3-callout.bp3-intent-warning > .bp3-icon:first-child,
      .bp3-dark .bp3-callout.bp3-intent-warning .bp3-heading{
        color:#ffb366; }
  .bp3-callout.bp3-intent-danger{
    background-color:rgba(219, 55, 55, 0.15); }
    .bp3-callout.bp3-intent-danger[class*="bp3-icon-"]::before,
    .bp3-callout.bp3-intent-danger > .bp3-icon:first-child,
    .bp3-callout.bp3-intent-danger .bp3-heading{
      color:#c23030; }
    .bp3-dark .bp3-callout.bp3-intent-danger{
      background-color:rgba(219, 55, 55, 0.25); }
      .bp3-dark .bp3-callout.bp3-intent-danger[class*="bp3-icon-"]::before,
      .bp3-dark .bp3-callout.bp3-intent-danger > .bp3-icon:first-child,
      .bp3-dark .bp3-callout.bp3-intent-danger .bp3-heading{
        color:#ff7373; }
  .bp3-running-text .bp3-callout{
    margin:20px 0; }
.bp3-card{
  background-color:#ffffff;
  border-radius:3px;
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.15), 0 0 0 rgba(16, 22, 26, 0), 0 0 0 rgba(16, 22, 26, 0);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.15), 0 0 0 rgba(16, 22, 26, 0), 0 0 0 rgba(16, 22, 26, 0);
  padding:20px;
  -webkit-transition:-webkit-transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9), -webkit-box-shadow 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:-webkit-transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9), -webkit-box-shadow 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9), box-shadow 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9), box-shadow 200ms cubic-bezier(0.4, 1, 0.75, 0.9), -webkit-transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9), -webkit-box-shadow 200ms cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-card.bp3-dark,
  .bp3-dark .bp3-card{
    background-color:#30404d;
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4), 0 0 0 rgba(16, 22, 26, 0), 0 0 0 rgba(16, 22, 26, 0);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4), 0 0 0 rgba(16, 22, 26, 0), 0 0 0 rgba(16, 22, 26, 0); }

.bp3-elevation-0{
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.15), 0 0 0 rgba(16, 22, 26, 0), 0 0 0 rgba(16, 22, 26, 0);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.15), 0 0 0 rgba(16, 22, 26, 0), 0 0 0 rgba(16, 22, 26, 0); }
  .bp3-elevation-0.bp3-dark,
  .bp3-dark .bp3-elevation-0{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4), 0 0 0 rgba(16, 22, 26, 0), 0 0 0 rgba(16, 22, 26, 0);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4), 0 0 0 rgba(16, 22, 26, 0), 0 0 0 rgba(16, 22, 26, 0); }

.bp3-elevation-1{
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.2); }
  .bp3-elevation-1.bp3-dark,
  .bp3-dark .bp3-elevation-1{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.4); }

.bp3-elevation-2{
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 1px 1px rgba(16, 22, 26, 0.2), 0 2px 6px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 1px 1px rgba(16, 22, 26, 0.2), 0 2px 6px rgba(16, 22, 26, 0.2); }
  .bp3-elevation-2.bp3-dark,
  .bp3-dark .bp3-elevation-2{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 1px 1px rgba(16, 22, 26, 0.4), 0 2px 6px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 1px 1px rgba(16, 22, 26, 0.4), 0 2px 6px rgba(16, 22, 26, 0.4); }

.bp3-elevation-3{
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2); }
  .bp3-elevation-3.bp3-dark,
  .bp3-dark .bp3-elevation-3{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4); }

.bp3-elevation-4{
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 4px 8px rgba(16, 22, 26, 0.2), 0 18px 46px 6px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 4px 8px rgba(16, 22, 26, 0.2), 0 18px 46px 6px rgba(16, 22, 26, 0.2); }
  .bp3-elevation-4.bp3-dark,
  .bp3-dark .bp3-elevation-4{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 4px 8px rgba(16, 22, 26, 0.4), 0 18px 46px 6px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 4px 8px rgba(16, 22, 26, 0.4), 0 18px 46px 6px rgba(16, 22, 26, 0.4); }

.bp3-card.bp3-interactive:hover{
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
  cursor:pointer; }
  .bp3-card.bp3-interactive:hover.bp3-dark,
  .bp3-dark .bp3-card.bp3-interactive:hover{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4); }

.bp3-card.bp3-interactive:active{
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.2);
  opacity:0.9;
  -webkit-transition-duration:0;
          transition-duration:0; }
  .bp3-card.bp3-interactive:active.bp3-dark,
  .bp3-dark .bp3-card.bp3-interactive:active{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.4); }

.bp3-collapse{
  height:0;
  overflow-y:hidden;
  -webkit-transition:height 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:height 200ms cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-collapse .bp3-collapse-body{
    -webkit-transition:-webkit-transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
    transition:-webkit-transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
    transition:transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
    transition:transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9), -webkit-transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9); }
    .bp3-collapse .bp3-collapse-body[aria-hidden="true"]{
      display:none; }

.bp3-context-menu .bp3-popover-target{
  display:block; }

.bp3-context-menu-popover-target{
  position:fixed; }

.bp3-divider{
  border-bottom:1px solid rgba(16, 22, 26, 0.15);
  border-right:1px solid rgba(16, 22, 26, 0.15);
  margin:5px; }
  .bp3-dark .bp3-divider{
    border-color:rgba(16, 22, 26, 0.4); }
.bp3-dialog-container{
  opacity:1;
  -webkit-transform:scale(1);
          transform:scale(1);
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-pack:center;
      -ms-flex-pack:center;
          justify-content:center;
  min-height:100%;
  pointer-events:none;
  -webkit-user-select:none;
     -moz-user-select:none;
      -ms-user-select:none;
          user-select:none;
  width:100%; }
  .bp3-dialog-container.bp3-overlay-enter > .bp3-dialog, .bp3-dialog-container.bp3-overlay-appear > .bp3-dialog{
    opacity:0;
    -webkit-transform:scale(0.5);
            transform:scale(0.5); }
  .bp3-dialog-container.bp3-overlay-enter-active > .bp3-dialog, .bp3-dialog-container.bp3-overlay-appear-active > .bp3-dialog{
    opacity:1;
    -webkit-transform:scale(1);
            transform:scale(1);
    -webkit-transition-delay:0;
            transition-delay:0;
    -webkit-transition-duration:300ms;
            transition-duration:300ms;
    -webkit-transition-property:opacity, -webkit-transform;
    transition-property:opacity, -webkit-transform;
    transition-property:opacity, transform;
    transition-property:opacity, transform, -webkit-transform;
    -webkit-transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11);
            transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11); }
  .bp3-dialog-container.bp3-overlay-exit > .bp3-dialog{
    opacity:1;
    -webkit-transform:scale(1);
            transform:scale(1); }
  .bp3-dialog-container.bp3-overlay-exit-active > .bp3-dialog{
    opacity:0;
    -webkit-transform:scale(0.5);
            transform:scale(0.5);
    -webkit-transition-delay:0;
            transition-delay:0;
    -webkit-transition-duration:300ms;
            transition-duration:300ms;
    -webkit-transition-property:opacity, -webkit-transform;
    transition-property:opacity, -webkit-transform;
    transition-property:opacity, transform;
    transition-property:opacity, transform, -webkit-transform;
    -webkit-transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11);
            transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11); }

.bp3-dialog{
  background:#ebf1f5;
  border-radius:6px;
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 4px 8px rgba(16, 22, 26, 0.2), 0 18px 46px 6px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 4px 8px rgba(16, 22, 26, 0.2), 0 18px 46px 6px rgba(16, 22, 26, 0.2);
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-orient:vertical;
  -webkit-box-direction:normal;
      -ms-flex-direction:column;
          flex-direction:column;
  margin:30px 0;
  padding-bottom:20px;
  pointer-events:all;
  -webkit-user-select:text;
     -moz-user-select:text;
      -ms-user-select:text;
          user-select:text;
  width:500px; }
  .bp3-dialog:focus{
    outline:0; }
  .bp3-dialog.bp3-dark,
  .bp3-dark .bp3-dialog{
    background:#293742;
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 4px 8px rgba(16, 22, 26, 0.4), 0 18px 46px 6px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 4px 8px rgba(16, 22, 26, 0.4), 0 18px 46px 6px rgba(16, 22, 26, 0.4);
    color:#f5f8fa; }

.bp3-dialog-header{
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  background:#ffffff;
  border-radius:6px 6px 0 0;
  -webkit-box-shadow:0 1px 0 rgba(16, 22, 26, 0.15);
          box-shadow:0 1px 0 rgba(16, 22, 26, 0.15);
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-flex:0;
      -ms-flex:0 0 auto;
          flex:0 0 auto;
  min-height:40px;
  padding-left:20px;
  padding-right:5px; }
  .bp3-dialog-header .bp3-icon-large,
  .bp3-dialog-header .bp3-icon{
    color:#5c7080;
    -webkit-box-flex:0;
        -ms-flex:0 0 auto;
            flex:0 0 auto;
    margin-right:10px; }
  .bp3-dialog-header .bp3-heading{
    overflow:hidden;
    text-overflow:ellipsis;
    white-space:nowrap;
    word-wrap:normal;
    -webkit-box-flex:1;
        -ms-flex:1 1 auto;
            flex:1 1 auto;
    line-height:inherit;
    margin:0; }
    .bp3-dialog-header .bp3-heading:last-child{
      margin-right:20px; }
  .bp3-dark .bp3-dialog-header{
    background:#30404d;
    -webkit-box-shadow:0 1px 0 rgba(16, 22, 26, 0.4);
            box-shadow:0 1px 0 rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-dialog-header .bp3-icon-large,
    .bp3-dark .bp3-dialog-header .bp3-icon{
      color:#a7b6c2; }

.bp3-dialog-body{
  -webkit-box-flex:1;
      -ms-flex:1 1 auto;
          flex:1 1 auto;
  line-height:18px;
  margin:20px; }

.bp3-dialog-footer{
  -webkit-box-flex:0;
      -ms-flex:0 0 auto;
          flex:0 0 auto;
  margin:0 20px; }

.bp3-dialog-footer-actions{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-pack:end;
      -ms-flex-pack:end;
          justify-content:flex-end; }
  .bp3-dialog-footer-actions .bp3-button{
    margin-left:10px; }
.bp3-drawer{
  background:#ffffff;
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 4px 8px rgba(16, 22, 26, 0.2), 0 18px 46px 6px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 4px 8px rgba(16, 22, 26, 0.2), 0 18px 46px 6px rgba(16, 22, 26, 0.2);
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-orient:vertical;
  -webkit-box-direction:normal;
      -ms-flex-direction:column;
          flex-direction:column;
  margin:0;
  padding:0; }
  .bp3-drawer:focus{
    outline:0; }
  .bp3-drawer.bp3-position-top{
    height:50%;
    left:0;
    right:0;
    top:0; }
    .bp3-drawer.bp3-position-top.bp3-overlay-enter, .bp3-drawer.bp3-position-top.bp3-overlay-appear{
      -webkit-transform:translateY(-100%);
              transform:translateY(-100%); }
    .bp3-drawer.bp3-position-top.bp3-overlay-enter-active, .bp3-drawer.bp3-position-top.bp3-overlay-appear-active{
      -webkit-transform:translateY(0);
              transform:translateY(0);
      -webkit-transition-delay:0;
              transition-delay:0;
      -webkit-transition-duration:200ms;
              transition-duration:200ms;
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9); }
    .bp3-drawer.bp3-position-top.bp3-overlay-exit{
      -webkit-transform:translateY(0);
              transform:translateY(0); }
    .bp3-drawer.bp3-position-top.bp3-overlay-exit-active{
      -webkit-transform:translateY(-100%);
              transform:translateY(-100%);
      -webkit-transition-delay:0;
              transition-delay:0;
      -webkit-transition-duration:100ms;
              transition-duration:100ms;
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-drawer.bp3-position-bottom{
    bottom:0;
    height:50%;
    left:0;
    right:0; }
    .bp3-drawer.bp3-position-bottom.bp3-overlay-enter, .bp3-drawer.bp3-position-bottom.bp3-overlay-appear{
      -webkit-transform:translateY(100%);
              transform:translateY(100%); }
    .bp3-drawer.bp3-position-bottom.bp3-overlay-enter-active, .bp3-drawer.bp3-position-bottom.bp3-overlay-appear-active{
      -webkit-transform:translateY(0);
              transform:translateY(0);
      -webkit-transition-delay:0;
              transition-delay:0;
      -webkit-transition-duration:200ms;
              transition-duration:200ms;
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9); }
    .bp3-drawer.bp3-position-bottom.bp3-overlay-exit{
      -webkit-transform:translateY(0);
              transform:translateY(0); }
    .bp3-drawer.bp3-position-bottom.bp3-overlay-exit-active{
      -webkit-transform:translateY(100%);
              transform:translateY(100%);
      -webkit-transition-delay:0;
              transition-delay:0;
      -webkit-transition-duration:100ms;
              transition-duration:100ms;
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-drawer.bp3-position-left{
    bottom:0;
    left:0;
    top:0;
    width:50%; }
    .bp3-drawer.bp3-position-left.bp3-overlay-enter, .bp3-drawer.bp3-position-left.bp3-overlay-appear{
      -webkit-transform:translateX(-100%);
              transform:translateX(-100%); }
    .bp3-drawer.bp3-position-left.bp3-overlay-enter-active, .bp3-drawer.bp3-position-left.bp3-overlay-appear-active{
      -webkit-transform:translateX(0);
              transform:translateX(0);
      -webkit-transition-delay:0;
              transition-delay:0;
      -webkit-transition-duration:200ms;
              transition-duration:200ms;
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9); }
    .bp3-drawer.bp3-position-left.bp3-overlay-exit{
      -webkit-transform:translateX(0);
              transform:translateX(0); }
    .bp3-drawer.bp3-position-left.bp3-overlay-exit-active{
      -webkit-transform:translateX(-100%);
              transform:translateX(-100%);
      -webkit-transition-delay:0;
              transition-delay:0;
      -webkit-transition-duration:100ms;
              transition-duration:100ms;
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-drawer.bp3-position-right{
    bottom:0;
    right:0;
    top:0;
    width:50%; }
    .bp3-drawer.bp3-position-right.bp3-overlay-enter, .bp3-drawer.bp3-position-right.bp3-overlay-appear{
      -webkit-transform:translateX(100%);
              transform:translateX(100%); }
    .bp3-drawer.bp3-position-right.bp3-overlay-enter-active, .bp3-drawer.bp3-position-right.bp3-overlay-appear-active{
      -webkit-transform:translateX(0);
              transform:translateX(0);
      -webkit-transition-delay:0;
              transition-delay:0;
      -webkit-transition-duration:200ms;
              transition-duration:200ms;
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9); }
    .bp3-drawer.bp3-position-right.bp3-overlay-exit{
      -webkit-transform:translateX(0);
              transform:translateX(0); }
    .bp3-drawer.bp3-position-right.bp3-overlay-exit-active{
      -webkit-transform:translateX(100%);
              transform:translateX(100%);
      -webkit-transition-delay:0;
              transition-delay:0;
      -webkit-transition-duration:100ms;
              transition-duration:100ms;
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
  .bp3-position-right):not(.bp3-vertical){
    bottom:0;
    right:0;
    top:0;
    width:50%; }
    .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right):not(.bp3-vertical).bp3-overlay-enter, .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right):not(.bp3-vertical).bp3-overlay-appear{
      -webkit-transform:translateX(100%);
              transform:translateX(100%); }
    .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right):not(.bp3-vertical).bp3-overlay-enter-active, .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right):not(.bp3-vertical).bp3-overlay-appear-active{
      -webkit-transform:translateX(0);
              transform:translateX(0);
      -webkit-transition-delay:0;
              transition-delay:0;
      -webkit-transition-duration:200ms;
              transition-duration:200ms;
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9); }
    .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right):not(.bp3-vertical).bp3-overlay-exit{
      -webkit-transform:translateX(0);
              transform:translateX(0); }
    .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right):not(.bp3-vertical).bp3-overlay-exit-active{
      -webkit-transform:translateX(100%);
              transform:translateX(100%);
      -webkit-transition-delay:0;
              transition-delay:0;
      -webkit-transition-duration:100ms;
              transition-duration:100ms;
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
  .bp3-position-right).bp3-vertical{
    bottom:0;
    height:50%;
    left:0;
    right:0; }
    .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right).bp3-vertical.bp3-overlay-enter, .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right).bp3-vertical.bp3-overlay-appear{
      -webkit-transform:translateY(100%);
              transform:translateY(100%); }
    .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right).bp3-vertical.bp3-overlay-enter-active, .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right).bp3-vertical.bp3-overlay-appear-active{
      -webkit-transform:translateY(0);
              transform:translateY(0);
      -webkit-transition-delay:0;
              transition-delay:0;
      -webkit-transition-duration:200ms;
              transition-duration:200ms;
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9); }
    .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right).bp3-vertical.bp3-overlay-exit{
      -webkit-transform:translateY(0);
              transform:translateY(0); }
    .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right).bp3-vertical.bp3-overlay-exit-active{
      -webkit-transform:translateY(100%);
              transform:translateY(100%);
      -webkit-transition-delay:0;
              transition-delay:0;
      -webkit-transition-duration:100ms;
              transition-duration:100ms;
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-drawer.bp3-dark,
  .bp3-dark .bp3-drawer{
    background:#30404d;
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 4px 8px rgba(16, 22, 26, 0.4), 0 18px 46px 6px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 4px 8px rgba(16, 22, 26, 0.4), 0 18px 46px 6px rgba(16, 22, 26, 0.4);
    color:#f5f8fa; }

.bp3-drawer-header{
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  border-radius:0;
  -webkit-box-shadow:0 1px 0 rgba(16, 22, 26, 0.15);
          box-shadow:0 1px 0 rgba(16, 22, 26, 0.15);
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-flex:0;
      -ms-flex:0 0 auto;
          flex:0 0 auto;
  min-height:40px;
  padding:5px;
  padding-left:20px;
  position:relative; }
  .bp3-drawer-header .bp3-icon-large,
  .bp3-drawer-header .bp3-icon{
    color:#5c7080;
    -webkit-box-flex:0;
        -ms-flex:0 0 auto;
            flex:0 0 auto;
    margin-right:10px; }
  .bp3-drawer-header .bp3-heading{
    overflow:hidden;
    text-overflow:ellipsis;
    white-space:nowrap;
    word-wrap:normal;
    -webkit-box-flex:1;
        -ms-flex:1 1 auto;
            flex:1 1 auto;
    line-height:inherit;
    margin:0; }
    .bp3-drawer-header .bp3-heading:last-child{
      margin-right:20px; }
  .bp3-dark .bp3-drawer-header{
    -webkit-box-shadow:0 1px 0 rgba(16, 22, 26, 0.4);
            box-shadow:0 1px 0 rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-drawer-header .bp3-icon-large,
    .bp3-dark .bp3-drawer-header .bp3-icon{
      color:#a7b6c2; }

.bp3-drawer-body{
  -webkit-box-flex:1;
      -ms-flex:1 1 auto;
          flex:1 1 auto;
  line-height:18px;
  overflow:auto; }

.bp3-drawer-footer{
  -webkit-box-shadow:inset 0 1px 0 rgba(16, 22, 26, 0.15);
          box-shadow:inset 0 1px 0 rgba(16, 22, 26, 0.15);
  -webkit-box-flex:0;
      -ms-flex:0 0 auto;
          flex:0 0 auto;
  padding:10px 20px;
  position:relative; }
  .bp3-dark .bp3-drawer-footer{
    -webkit-box-shadow:inset 0 1px 0 rgba(16, 22, 26, 0.4);
            box-shadow:inset 0 1px 0 rgba(16, 22, 26, 0.4); }
.bp3-editable-text{
  cursor:text;
  display:inline-block;
  max-width:100%;
  position:relative;
  vertical-align:top;
  white-space:nowrap; }
  .bp3-editable-text::before{
    bottom:-3px;
    left:-3px;
    position:absolute;
    right:-3px;
    top:-3px;
    border-radius:3px;
    content:"";
    -webkit-transition:background-color 100ms cubic-bezier(0.4, 1, 0.75, 0.9), -webkit-box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
    transition:background-color 100ms cubic-bezier(0.4, 1, 0.75, 0.9), -webkit-box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
    transition:background-color 100ms cubic-bezier(0.4, 1, 0.75, 0.9), box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
    transition:background-color 100ms cubic-bezier(0.4, 1, 0.75, 0.9), box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9), -webkit-box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-editable-text:hover::before{
    -webkit-box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.15);
            box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.15); }
  .bp3-editable-text.bp3-editable-text-editing::before{
    background-color:#ffffff;
    -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
  .bp3-editable-text.bp3-disabled::before{
    -webkit-box-shadow:none;
            box-shadow:none; }
  .bp3-editable-text.bp3-intent-primary .bp3-editable-text-input,
  .bp3-editable-text.bp3-intent-primary .bp3-editable-text-content{
    color:#137cbd; }
  .bp3-editable-text.bp3-intent-primary:hover::before{
    -webkit-box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(19, 124, 189, 0.4);
            box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(19, 124, 189, 0.4); }
  .bp3-editable-text.bp3-intent-primary.bp3-editable-text-editing::before{
    -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
  .bp3-editable-text.bp3-intent-success .bp3-editable-text-input,
  .bp3-editable-text.bp3-intent-success .bp3-editable-text-content{
    color:#0f9960; }
  .bp3-editable-text.bp3-intent-success:hover::before{
    -webkit-box-shadow:0 0 0 0 rgba(15, 153, 96, 0), 0 0 0 0 rgba(15, 153, 96, 0), inset 0 0 0 1px rgba(15, 153, 96, 0.4);
            box-shadow:0 0 0 0 rgba(15, 153, 96, 0), 0 0 0 0 rgba(15, 153, 96, 0), inset 0 0 0 1px rgba(15, 153, 96, 0.4); }
  .bp3-editable-text.bp3-intent-success.bp3-editable-text-editing::before{
    -webkit-box-shadow:0 0 0 1px #0f9960, 0 0 0 3px rgba(15, 153, 96, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px #0f9960, 0 0 0 3px rgba(15, 153, 96, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
  .bp3-editable-text.bp3-intent-warning .bp3-editable-text-input,
  .bp3-editable-text.bp3-intent-warning .bp3-editable-text-content{
    color:#d9822b; }
  .bp3-editable-text.bp3-intent-warning:hover::before{
    -webkit-box-shadow:0 0 0 0 rgba(217, 130, 43, 0), 0 0 0 0 rgba(217, 130, 43, 0), inset 0 0 0 1px rgba(217, 130, 43, 0.4);
            box-shadow:0 0 0 0 rgba(217, 130, 43, 0), 0 0 0 0 rgba(217, 130, 43, 0), inset 0 0 0 1px rgba(217, 130, 43, 0.4); }
  .bp3-editable-text.bp3-intent-warning.bp3-editable-text-editing::before{
    -webkit-box-shadow:0 0 0 1px #d9822b, 0 0 0 3px rgba(217, 130, 43, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px #d9822b, 0 0 0 3px rgba(217, 130, 43, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
  .bp3-editable-text.bp3-intent-danger .bp3-editable-text-input,
  .bp3-editable-text.bp3-intent-danger .bp3-editable-text-content{
    color:#db3737; }
  .bp3-editable-text.bp3-intent-danger:hover::before{
    -webkit-box-shadow:0 0 0 0 rgba(219, 55, 55, 0), 0 0 0 0 rgba(219, 55, 55, 0), inset 0 0 0 1px rgba(219, 55, 55, 0.4);
            box-shadow:0 0 0 0 rgba(219, 55, 55, 0), 0 0 0 0 rgba(219, 55, 55, 0), inset 0 0 0 1px rgba(219, 55, 55, 0.4); }
  .bp3-editable-text.bp3-intent-danger.bp3-editable-text-editing::before{
    -webkit-box-shadow:0 0 0 1px #db3737, 0 0 0 3px rgba(219, 55, 55, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px #db3737, 0 0 0 3px rgba(219, 55, 55, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
  .bp3-dark .bp3-editable-text:hover::before{
    -webkit-box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(255, 255, 255, 0.15);
            box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(255, 255, 255, 0.15); }
  .bp3-dark .bp3-editable-text.bp3-editable-text-editing::before{
    background-color:rgba(16, 22, 26, 0.3);
    -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
  .bp3-dark .bp3-editable-text.bp3-disabled::before{
    -webkit-box-shadow:none;
            box-shadow:none; }
  .bp3-dark .bp3-editable-text.bp3-intent-primary .bp3-editable-text-content{
    color:#48aff0; }
  .bp3-dark .bp3-editable-text.bp3-intent-primary:hover::before{
    -webkit-box-shadow:0 0 0 0 rgba(72, 175, 240, 0), 0 0 0 0 rgba(72, 175, 240, 0), inset 0 0 0 1px rgba(72, 175, 240, 0.4);
            box-shadow:0 0 0 0 rgba(72, 175, 240, 0), 0 0 0 0 rgba(72, 175, 240, 0), inset 0 0 0 1px rgba(72, 175, 240, 0.4); }
  .bp3-dark .bp3-editable-text.bp3-intent-primary.bp3-editable-text-editing::before{
    -webkit-box-shadow:0 0 0 1px #48aff0, 0 0 0 3px rgba(72, 175, 240, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px #48aff0, 0 0 0 3px rgba(72, 175, 240, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
  .bp3-dark .bp3-editable-text.bp3-intent-success .bp3-editable-text-content{
    color:#3dcc91; }
  .bp3-dark .bp3-editable-text.bp3-intent-success:hover::before{
    -webkit-box-shadow:0 0 0 0 rgba(61, 204, 145, 0), 0 0 0 0 rgba(61, 204, 145, 0), inset 0 0 0 1px rgba(61, 204, 145, 0.4);
            box-shadow:0 0 0 0 rgba(61, 204, 145, 0), 0 0 0 0 rgba(61, 204, 145, 0), inset 0 0 0 1px rgba(61, 204, 145, 0.4); }
  .bp3-dark .bp3-editable-text.bp3-intent-success.bp3-editable-text-editing::before{
    -webkit-box-shadow:0 0 0 1px #3dcc91, 0 0 0 3px rgba(61, 204, 145, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px #3dcc91, 0 0 0 3px rgba(61, 204, 145, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
  .bp3-dark .bp3-editable-text.bp3-intent-warning .bp3-editable-text-content{
    color:#ffb366; }
  .bp3-dark .bp3-editable-text.bp3-intent-warning:hover::before{
    -webkit-box-shadow:0 0 0 0 rgba(255, 179, 102, 0), 0 0 0 0 rgba(255, 179, 102, 0), inset 0 0 0 1px rgba(255, 179, 102, 0.4);
            box-shadow:0 0 0 0 rgba(255, 179, 102, 0), 0 0 0 0 rgba(255, 179, 102, 0), inset 0 0 0 1px rgba(255, 179, 102, 0.4); }
  .bp3-dark .bp3-editable-text.bp3-intent-warning.bp3-editable-text-editing::before{
    -webkit-box-shadow:0 0 0 1px #ffb366, 0 0 0 3px rgba(255, 179, 102, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px #ffb366, 0 0 0 3px rgba(255, 179, 102, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
  .bp3-dark .bp3-editable-text.bp3-intent-danger .bp3-editable-text-content{
    color:#ff7373; }
  .bp3-dark .bp3-editable-text.bp3-intent-danger:hover::before{
    -webkit-box-shadow:0 0 0 0 rgba(255, 115, 115, 0), 0 0 0 0 rgba(255, 115, 115, 0), inset 0 0 0 1px rgba(255, 115, 115, 0.4);
            box-shadow:0 0 0 0 rgba(255, 115, 115, 0), 0 0 0 0 rgba(255, 115, 115, 0), inset 0 0 0 1px rgba(255, 115, 115, 0.4); }
  .bp3-dark .bp3-editable-text.bp3-intent-danger.bp3-editable-text-editing::before{
    -webkit-box-shadow:0 0 0 1px #ff7373, 0 0 0 3px rgba(255, 115, 115, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px #ff7373, 0 0 0 3px rgba(255, 115, 115, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }

.bp3-editable-text-input,
.bp3-editable-text-content{
  color:inherit;
  display:inherit;
  font:inherit;
  letter-spacing:inherit;
  max-width:inherit;
  min-width:inherit;
  position:relative;
  resize:none;
  text-transform:inherit;
  vertical-align:top; }

.bp3-editable-text-input{
  background:none;
  border:none;
  -webkit-box-shadow:none;
          box-shadow:none;
  padding:0;
  white-space:pre-wrap;
  width:100%; }
  .bp3-editable-text-input::-webkit-input-placeholder{
    color:rgba(92, 112, 128, 0.6);
    opacity:1; }
  .bp3-editable-text-input::-moz-placeholder{
    color:rgba(92, 112, 128, 0.6);
    opacity:1; }
  .bp3-editable-text-input:-ms-input-placeholder{
    color:rgba(92, 112, 128, 0.6);
    opacity:1; }
  .bp3-editable-text-input::-ms-input-placeholder{
    color:rgba(92, 112, 128, 0.6);
    opacity:1; }
  .bp3-editable-text-input::placeholder{
    color:rgba(92, 112, 128, 0.6);
    opacity:1; }
  .bp3-editable-text-input:focus{
    outline:none; }
  .bp3-editable-text-input::-ms-clear{
    display:none; }

.bp3-editable-text-content{
  overflow:hidden;
  padding-right:2px;
  text-overflow:ellipsis;
  white-space:pre; }
  .bp3-editable-text-editing > .bp3-editable-text-content{
    left:0;
    position:absolute;
    visibility:hidden; }
  .bp3-editable-text-placeholder > .bp3-editable-text-content{
    color:rgba(92, 112, 128, 0.6); }
    .bp3-dark .bp3-editable-text-placeholder > .bp3-editable-text-content{
      color:rgba(167, 182, 194, 0.6); }

.bp3-editable-text.bp3-multiline{
  display:block; }
  .bp3-editable-text.bp3-multiline .bp3-editable-text-content{
    overflow:auto;
    white-space:pre-wrap;
    word-wrap:break-word; }
.bp3-divider{
  border-bottom:1px solid rgba(16, 22, 26, 0.15);
  border-right:1px solid rgba(16, 22, 26, 0.15);
  margin:5px; }
  .bp3-dark .bp3-divider{
    border-color:rgba(16, 22, 26, 0.4); }
.bp3-control-group{
  -webkit-transform:translateZ(0);
          transform:translateZ(0);
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-orient:horizontal;
  -webkit-box-direction:normal;
      -ms-flex-direction:row;
          flex-direction:row;
  -webkit-box-align:stretch;
      -ms-flex-align:stretch;
          align-items:stretch; }
  .bp3-control-group > *{
    -webkit-box-flex:0;
        -ms-flex-positive:0;
            flex-grow:0;
    -ms-flex-negative:0;
        flex-shrink:0; }
  .bp3-control-group > .bp3-fill{
    -webkit-box-flex:1;
        -ms-flex-positive:1;
            flex-grow:1;
    -ms-flex-negative:1;
        flex-shrink:1; }
  .bp3-control-group .bp3-button,
  .bp3-control-group .bp3-html-select,
  .bp3-control-group .bp3-input,
  .bp3-control-group .bp3-select{
    position:relative; }
  .bp3-control-group .bp3-input{
    border-radius:inherit;
    z-index:2; }
    .bp3-control-group .bp3-input:focus{
      border-radius:3px;
      z-index:14; }
    .bp3-control-group .bp3-input[class*="bp3-intent"]{
      z-index:13; }
      .bp3-control-group .bp3-input[class*="bp3-intent"]:focus{
        z-index:15; }
    .bp3-control-group .bp3-input[readonly], .bp3-control-group .bp3-input:disabled, .bp3-control-group .bp3-input.bp3-disabled{
      z-index:1; }
  .bp3-control-group .bp3-input-group[class*="bp3-intent"] .bp3-input{
    z-index:13; }
    .bp3-control-group .bp3-input-group[class*="bp3-intent"] .bp3-input:focus{
      z-index:15; }
  .bp3-control-group .bp3-button,
  .bp3-control-group .bp3-html-select select,
  .bp3-control-group .bp3-select select{
    -webkit-transform:translateZ(0);
            transform:translateZ(0);
    border-radius:inherit;
    z-index:4; }
    .bp3-control-group .bp3-button:focus,
    .bp3-control-group .bp3-html-select select:focus,
    .bp3-control-group .bp3-select select:focus{
      z-index:5; }
    .bp3-control-group .bp3-button:hover,
    .bp3-control-group .bp3-html-select select:hover,
    .bp3-control-group .bp3-select select:hover{
      z-index:6; }
    .bp3-control-group .bp3-button:active,
    .bp3-control-group .bp3-html-select select:active,
    .bp3-control-group .bp3-select select:active{
      z-index:7; }
    .bp3-control-group .bp3-button[readonly], .bp3-control-group .bp3-button:disabled, .bp3-control-group .bp3-button.bp3-disabled,
    .bp3-control-group .bp3-html-select select[readonly],
    .bp3-control-group .bp3-html-select select:disabled,
    .bp3-control-group .bp3-html-select select.bp3-disabled,
    .bp3-control-group .bp3-select select[readonly],
    .bp3-control-group .bp3-select select:disabled,
    .bp3-control-group .bp3-select select.bp3-disabled{
      z-index:3; }
    .bp3-control-group .bp3-button[class*="bp3-intent"],
    .bp3-control-group .bp3-html-select select[class*="bp3-intent"],
    .bp3-control-group .bp3-select select[class*="bp3-intent"]{
      z-index:9; }
      .bp3-control-group .bp3-button[class*="bp3-intent"]:focus,
      .bp3-control-group .bp3-html-select select[class*="bp3-intent"]:focus,
      .bp3-control-group .bp3-select select[class*="bp3-intent"]:focus{
        z-index:10; }
      .bp3-control-group .bp3-button[class*="bp3-intent"]:hover,
      .bp3-control-group .bp3-html-select select[class*="bp3-intent"]:hover,
      .bp3-control-group .bp3-select select[class*="bp3-intent"]:hover{
        z-index:11; }
      .bp3-control-group .bp3-button[class*="bp3-intent"]:active,
      .bp3-control-group .bp3-html-select select[class*="bp3-intent"]:active,
      .bp3-control-group .bp3-select select[class*="bp3-intent"]:active{
        z-index:12; }
      .bp3-control-group .bp3-button[class*="bp3-intent"][readonly], .bp3-control-group .bp3-button[class*="bp3-intent"]:disabled, .bp3-control-group .bp3-button[class*="bp3-intent"].bp3-disabled,
      .bp3-control-group .bp3-html-select select[class*="bp3-intent"][readonly],
      .bp3-control-group .bp3-html-select select[class*="bp3-intent"]:disabled,
      .bp3-control-group .bp3-html-select select[class*="bp3-intent"].bp3-disabled,
      .bp3-control-group .bp3-select select[class*="bp3-intent"][readonly],
      .bp3-control-group .bp3-select select[class*="bp3-intent"]:disabled,
      .bp3-control-group .bp3-select select[class*="bp3-intent"].bp3-disabled{
        z-index:8; }
  .bp3-control-group .bp3-input-group > .bp3-icon,
  .bp3-control-group .bp3-input-group > .bp3-button,
  .bp3-control-group .bp3-input-group > .bp3-input-action{
    z-index:16; }
  .bp3-control-group .bp3-select::after,
  .bp3-control-group .bp3-html-select::after,
  .bp3-control-group .bp3-select > .bp3-icon,
  .bp3-control-group .bp3-html-select > .bp3-icon{
    z-index:17; }
  .bp3-control-group .bp3-select:focus-within{
    z-index:5; }
  .bp3-control-group:not(.bp3-vertical) > *:not(.bp3-divider){
    margin-right:-1px; }
  .bp3-control-group:not(.bp3-vertical) > .bp3-divider:not(:first-child){
    margin-left:6px; }
  .bp3-dark .bp3-control-group:not(.bp3-vertical) > *:not(.bp3-divider){
    margin-right:0; }
  .bp3-dark .bp3-control-group:not(.bp3-vertical) > .bp3-button + .bp3-button{
    margin-left:1px; }
  .bp3-control-group .bp3-popover-wrapper,
  .bp3-control-group .bp3-popover-target{
    border-radius:inherit; }
  .bp3-control-group > :first-child{
    border-radius:3px 0 0 3px; }
  .bp3-control-group > :last-child{
    border-radius:0 3px 3px 0;
    margin-right:0; }
  .bp3-control-group > :only-child{
    border-radius:3px;
    margin-right:0; }
  .bp3-control-group .bp3-input-group .bp3-button{
    border-radius:3px; }
  .bp3-control-group .bp3-numeric-input:not(:first-child) .bp3-input-group{
    border-bottom-left-radius:0;
    border-top-left-radius:0; }
  .bp3-control-group.bp3-fill{
    width:100%; }
  .bp3-control-group > .bp3-fill{
    -webkit-box-flex:1;
        -ms-flex:1 1 auto;
            flex:1 1 auto; }
  .bp3-control-group.bp3-fill > *:not(.bp3-fixed){
    -webkit-box-flex:1;
        -ms-flex:1 1 auto;
            flex:1 1 auto; }
  .bp3-control-group.bp3-vertical{
    -webkit-box-orient:vertical;
    -webkit-box-direction:normal;
        -ms-flex-direction:column;
            flex-direction:column; }
    .bp3-control-group.bp3-vertical > *{
      margin-top:-1px; }
    .bp3-control-group.bp3-vertical > :first-child{
      border-radius:3px 3px 0 0;
      margin-top:0; }
    .bp3-control-group.bp3-vertical > :last-child{
      border-radius:0 0 3px 3px; }
.bp3-control{
  cursor:pointer;
  display:block;
  margin-bottom:10px;
  position:relative;
  text-transform:none; }
  .bp3-control input:checked ~ .bp3-control-indicator{
    background-color:#137cbd;
    background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.1)), to(rgba(255, 255, 255, 0)));
    background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.1), rgba(255, 255, 255, 0));
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
    color:#ffffff; }
  .bp3-control:hover input:checked ~ .bp3-control-indicator{
    background-color:#106ba3;
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2); }
  .bp3-control input:not(:disabled):active:checked ~ .bp3-control-indicator{
    background:#0e5a8a;
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2); }
  .bp3-control input:disabled:checked ~ .bp3-control-indicator{
    background:rgba(19, 124, 189, 0.5);
    -webkit-box-shadow:none;
            box-shadow:none; }
  .bp3-dark .bp3-control input:checked ~ .bp3-control-indicator{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4); }
  .bp3-dark .bp3-control:hover input:checked ~ .bp3-control-indicator{
    background-color:#106ba3;
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4); }
  .bp3-dark .bp3-control input:not(:disabled):active:checked ~ .bp3-control-indicator{
    background-color:#0e5a8a;
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2); }
  .bp3-dark .bp3-control input:disabled:checked ~ .bp3-control-indicator{
    background:rgba(14, 90, 138, 0.5);
    -webkit-box-shadow:none;
            box-shadow:none; }
  .bp3-control:not(.bp3-align-right){
    padding-left:26px; }
    .bp3-control:not(.bp3-align-right) .bp3-control-indicator{
      margin-left:-26px; }
  .bp3-control.bp3-align-right{
    padding-right:26px; }
    .bp3-control.bp3-align-right .bp3-control-indicator{
      margin-right:-26px; }
  .bp3-control.bp3-disabled{
    color:rgba(92, 112, 128, 0.6);
    cursor:not-allowed; }
  .bp3-control.bp3-inline{
    display:inline-block;
    margin-right:20px; }
  .bp3-control input{
    left:0;
    opacity:0;
    position:absolute;
    top:0;
    z-index:-1; }
  .bp3-control .bp3-control-indicator{
    background-clip:padding-box;
    background-color:#f5f8fa;
    background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.8)), to(rgba(255, 255, 255, 0)));
    background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.8), rgba(255, 255, 255, 0));
    border:none;
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
    cursor:pointer;
    display:inline-block;
    font-size:16px;
    height:1em;
    margin-right:10px;
    margin-top:-3px;
    position:relative;
    -webkit-user-select:none;
       -moz-user-select:none;
        -ms-user-select:none;
            user-select:none;
    vertical-align:middle;
    width:1em; }
    .bp3-control .bp3-control-indicator::before{
      content:"";
      display:block;
      height:1em;
      width:1em; }
  .bp3-control:hover .bp3-control-indicator{
    background-color:#ebf1f5; }
  .bp3-control input:not(:disabled):active ~ .bp3-control-indicator{
    background:#d8e1e8;
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2); }
  .bp3-control input:disabled ~ .bp3-control-indicator{
    background:rgba(206, 217, 224, 0.5);
    -webkit-box-shadow:none;
            box-shadow:none;
    cursor:not-allowed; }
  .bp3-control input:focus ~ .bp3-control-indicator{
    outline:rgba(19, 124, 189, 0.6) auto 2px;
    outline-offset:2px;
    -moz-outline-radius:6px; }
  .bp3-control.bp3-align-right .bp3-control-indicator{
    float:right;
    margin-left:10px;
    margin-top:1px; }
  .bp3-control.bp3-large{
    font-size:16px; }
    .bp3-control.bp3-large:not(.bp3-align-right){
      padding-left:30px; }
      .bp3-control.bp3-large:not(.bp3-align-right) .bp3-control-indicator{
        margin-left:-30px; }
    .bp3-control.bp3-large.bp3-align-right{
      padding-right:30px; }
      .bp3-control.bp3-large.bp3-align-right .bp3-control-indicator{
        margin-right:-30px; }
    .bp3-control.bp3-large .bp3-control-indicator{
      font-size:20px; }
    .bp3-control.bp3-large.bp3-align-right .bp3-control-indicator{
      margin-top:0; }
  .bp3-control.bp3-checkbox input:indeterminate ~ .bp3-control-indicator{
    background-color:#137cbd;
    background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.1)), to(rgba(255, 255, 255, 0)));
    background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.1), rgba(255, 255, 255, 0));
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
    color:#ffffff; }
  .bp3-control.bp3-checkbox:hover input:indeterminate ~ .bp3-control-indicator{
    background-color:#106ba3;
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2); }
  .bp3-control.bp3-checkbox input:not(:disabled):active:indeterminate ~ .bp3-control-indicator{
    background:#0e5a8a;
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2); }
  .bp3-control.bp3-checkbox input:disabled:indeterminate ~ .bp3-control-indicator{
    background:rgba(19, 124, 189, 0.5);
    -webkit-box-shadow:none;
            box-shadow:none; }
  .bp3-dark .bp3-control.bp3-checkbox input:indeterminate ~ .bp3-control-indicator{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4); }
  .bp3-dark .bp3-control.bp3-checkbox:hover input:indeterminate ~ .bp3-control-indicator{
    background-color:#106ba3;
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4); }
  .bp3-dark .bp3-control.bp3-checkbox input:not(:disabled):active:indeterminate ~ .bp3-control-indicator{
    background-color:#0e5a8a;
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2); }
  .bp3-dark .bp3-control.bp3-checkbox input:disabled:indeterminate ~ .bp3-control-indicator{
    background:rgba(14, 90, 138, 0.5);
    -webkit-box-shadow:none;
            box-shadow:none; }
  .bp3-control.bp3-checkbox .bp3-control-indicator{
    border-radius:3px; }
  .bp3-control.bp3-checkbox input:checked ~ .bp3-control-indicator::before{
    background-image:url("data:image/svg+xml,%3csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 16 16'%3e%3cpath fill-rule='evenodd' clip-rule='evenodd' d='M12 5c-.28 0-.53.11-.71.29L7 9.59l-2.29-2.3a1.003 1.003 0 00-1.42 1.42l3 3c.18.18.43.29.71.29s.53-.11.71-.29l5-5A1.003 1.003 0 0012 5z' fill='white'/%3e%3c/svg%3e"); }
  .bp3-control.bp3-checkbox input:indeterminate ~ .bp3-control-indicator::before{
    background-image:url("data:image/svg+xml,%3csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 16 16'%3e%3cpath fill-rule='evenodd' clip-rule='evenodd' d='M11 7H5c-.55 0-1 .45-1 1s.45 1 1 1h6c.55 0 1-.45 1-1s-.45-1-1-1z' fill='white'/%3e%3c/svg%3e"); }
  .bp3-control.bp3-radio .bp3-control-indicator{
    border-radius:50%; }
  .bp3-control.bp3-radio input:checked ~ .bp3-control-indicator::before{
    background-image:radial-gradient(#ffffff, #ffffff 28%, transparent 32%); }
  .bp3-control.bp3-radio input:checked:disabled ~ .bp3-control-indicator::before{
    opacity:0.5; }
  .bp3-control.bp3-radio input:focus ~ .bp3-control-indicator{
    -moz-outline-radius:16px; }
  .bp3-control.bp3-switch input ~ .bp3-control-indicator{
    background:rgba(167, 182, 194, 0.5); }
  .bp3-control.bp3-switch:hover input ~ .bp3-control-indicator{
    background:rgba(115, 134, 148, 0.5); }
  .bp3-control.bp3-switch input:not(:disabled):active ~ .bp3-control-indicator{
    background:rgba(92, 112, 128, 0.5); }
  .bp3-control.bp3-switch input:disabled ~ .bp3-control-indicator{
    background:rgba(206, 217, 224, 0.5); }
    .bp3-control.bp3-switch input:disabled ~ .bp3-control-indicator::before{
      background:rgba(255, 255, 255, 0.8); }
  .bp3-control.bp3-switch input:checked ~ .bp3-control-indicator{
    background:#137cbd; }
  .bp3-control.bp3-switch:hover input:checked ~ .bp3-control-indicator{
    background:#106ba3; }
  .bp3-control.bp3-switch input:checked:not(:disabled):active ~ .bp3-control-indicator{
    background:#0e5a8a; }
  .bp3-control.bp3-switch input:checked:disabled ~ .bp3-control-indicator{
    background:rgba(19, 124, 189, 0.5); }
    .bp3-control.bp3-switch input:checked:disabled ~ .bp3-control-indicator::before{
      background:rgba(255, 255, 255, 0.8); }
  .bp3-control.bp3-switch:not(.bp3-align-right){
    padding-left:38px; }
    .bp3-control.bp3-switch:not(.bp3-align-right) .bp3-control-indicator{
      margin-left:-38px; }
  .bp3-control.bp3-switch.bp3-align-right{
    padding-right:38px; }
    .bp3-control.bp3-switch.bp3-align-right .bp3-control-indicator{
      margin-right:-38px; }
  .bp3-control.bp3-switch .bp3-control-indicator{
    border:none;
    border-radius:1.75em;
    -webkit-box-shadow:none !important;
            box-shadow:none !important;
    min-width:1.75em;
    -webkit-transition:background-color 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
    transition:background-color 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
    width:auto; }
    .bp3-control.bp3-switch .bp3-control-indicator::before{
      background:#ffffff;
      border-radius:50%;
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 1px 1px rgba(16, 22, 26, 0.2);
      height:calc(1em - 4px);
      left:0;
      margin:2px;
      position:absolute;
      -webkit-transition:left 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
      transition:left 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
      width:calc(1em - 4px); }
  .bp3-control.bp3-switch input:checked ~ .bp3-control-indicator::before{
    left:calc(100% - 1em); }
  .bp3-control.bp3-switch.bp3-large:not(.bp3-align-right){
    padding-left:45px; }
    .bp3-control.bp3-switch.bp3-large:not(.bp3-align-right) .bp3-control-indicator{
      margin-left:-45px; }
  .bp3-control.bp3-switch.bp3-large.bp3-align-right{
    padding-right:45px; }
    .bp3-control.bp3-switch.bp3-large.bp3-align-right .bp3-control-indicator{
      margin-right:-45px; }
  .bp3-dark .bp3-control.bp3-switch input ~ .bp3-control-indicator{
    background:rgba(16, 22, 26, 0.5); }
  .bp3-dark .bp3-control.bp3-switch:hover input ~ .bp3-control-indicator{
    background:rgba(16, 22, 26, 0.7); }
  .bp3-dark .bp3-control.bp3-switch input:not(:disabled):active ~ .bp3-control-indicator{
    background:rgba(16, 22, 26, 0.9); }
  .bp3-dark .bp3-control.bp3-switch input:disabled ~ .bp3-control-indicator{
    background:rgba(57, 75, 89, 0.5); }
    .bp3-dark .bp3-control.bp3-switch input:disabled ~ .bp3-control-indicator::before{
      background:rgba(16, 22, 26, 0.4); }
  .bp3-dark .bp3-control.bp3-switch input:checked ~ .bp3-control-indicator{
    background:#137cbd; }
  .bp3-dark .bp3-control.bp3-switch:hover input:checked ~ .bp3-control-indicator{
    background:#106ba3; }
  .bp3-dark .bp3-control.bp3-switch input:checked:not(:disabled):active ~ .bp3-control-indicator{
    background:#0e5a8a; }
  .bp3-dark .bp3-control.bp3-switch input:checked:disabled ~ .bp3-control-indicator{
    background:rgba(14, 90, 138, 0.5); }
    .bp3-dark .bp3-control.bp3-switch input:checked:disabled ~ .bp3-control-indicator::before{
      background:rgba(16, 22, 26, 0.4); }
  .bp3-dark .bp3-control.bp3-switch .bp3-control-indicator::before{
    background:#394b59;
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4); }
  .bp3-dark .bp3-control.bp3-switch input:checked ~ .bp3-control-indicator::before{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4); }
  .bp3-control.bp3-switch .bp3-switch-inner-text{
    font-size:0.7em;
    text-align:center; }
  .bp3-control.bp3-switch .bp3-control-indicator-child:first-child{
    line-height:0;
    margin-left:0.5em;
    margin-right:1.2em;
    visibility:hidden; }
  .bp3-control.bp3-switch .bp3-control-indicator-child:last-child{
    line-height:1em;
    margin-left:1.2em;
    margin-right:0.5em;
    visibility:visible; }
  .bp3-control.bp3-switch input:checked ~ .bp3-control-indicator .bp3-control-indicator-child:first-child{
    line-height:1em;
    visibility:visible; }
  .bp3-control.bp3-switch input:checked ~ .bp3-control-indicator .bp3-control-indicator-child:last-child{
    line-height:0;
    visibility:hidden; }
  .bp3-dark .bp3-control{
    color:#f5f8fa; }
    .bp3-dark .bp3-control.bp3-disabled{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-control .bp3-control-indicator{
      background-color:#394b59;
      background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.05)), to(rgba(255, 255, 255, 0)));
      background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.05), rgba(255, 255, 255, 0));
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-control:hover .bp3-control-indicator{
      background-color:#30404d; }
    .bp3-dark .bp3-control input:not(:disabled):active ~ .bp3-control-indicator{
      background:#202b33;
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2); }
    .bp3-dark .bp3-control input:disabled ~ .bp3-control-indicator{
      background:rgba(57, 75, 89, 0.5);
      -webkit-box-shadow:none;
              box-shadow:none;
      cursor:not-allowed; }
    .bp3-dark .bp3-control.bp3-checkbox input:disabled:checked ~ .bp3-control-indicator, .bp3-dark .bp3-control.bp3-checkbox input:disabled:indeterminate ~ .bp3-control-indicator{
      color:rgba(167, 182, 194, 0.6); }
.bp3-file-input{
  cursor:pointer;
  display:inline-block;
  height:30px;
  position:relative; }
  .bp3-file-input input{
    margin:0;
    min-width:200px;
    opacity:0; }
    .bp3-file-input input:disabled + .bp3-file-upload-input,
    .bp3-file-input input.bp3-disabled + .bp3-file-upload-input{
      background:rgba(206, 217, 224, 0.5);
      -webkit-box-shadow:none;
              box-shadow:none;
      color:rgba(92, 112, 128, 0.6);
      cursor:not-allowed;
      resize:none; }
      .bp3-file-input input:disabled + .bp3-file-upload-input::after,
      .bp3-file-input input.bp3-disabled + .bp3-file-upload-input::after{
        background-color:rgba(206, 217, 224, 0.5);
        background-image:none;
        -webkit-box-shadow:none;
                box-shadow:none;
        color:rgba(92, 112, 128, 0.6);
        cursor:not-allowed;
        outline:none; }
        .bp3-file-input input:disabled + .bp3-file-upload-input::after.bp3-active, .bp3-file-input input:disabled + .bp3-file-upload-input::after.bp3-active:hover,
        .bp3-file-input input.bp3-disabled + .bp3-file-upload-input::after.bp3-active,
        .bp3-file-input input.bp3-disabled + .bp3-file-upload-input::after.bp3-active:hover{
          background:rgba(206, 217, 224, 0.7); }
      .bp3-dark .bp3-file-input input:disabled + .bp3-file-upload-input, .bp3-dark
      .bp3-file-input input.bp3-disabled + .bp3-file-upload-input{
        background:rgba(57, 75, 89, 0.5);
        -webkit-box-shadow:none;
                box-shadow:none;
        color:rgba(167, 182, 194, 0.6); }
        .bp3-dark .bp3-file-input input:disabled + .bp3-file-upload-input::after, .bp3-dark
        .bp3-file-input input.bp3-disabled + .bp3-file-upload-input::after{
          background-color:rgba(57, 75, 89, 0.5);
          background-image:none;
          -webkit-box-shadow:none;
                  box-shadow:none;
          color:rgba(167, 182, 194, 0.6); }
          .bp3-dark .bp3-file-input input:disabled + .bp3-file-upload-input::after.bp3-active, .bp3-dark
          .bp3-file-input input.bp3-disabled + .bp3-file-upload-input::after.bp3-active{
            background:rgba(57, 75, 89, 0.7); }
  .bp3-file-input.bp3-file-input-has-selection .bp3-file-upload-input{
    color:#182026; }
  .bp3-dark .bp3-file-input.bp3-file-input-has-selection .bp3-file-upload-input{
    color:#f5f8fa; }
  .bp3-file-input.bp3-fill{
    width:100%; }
  .bp3-file-input.bp3-large,
  .bp3-large .bp3-file-input{
    height:40px; }
  .bp3-file-input .bp3-file-upload-input-custom-text::after{
    content:attr(bp3-button-text); }

.bp3-file-upload-input{
  -webkit-appearance:none;
     -moz-appearance:none;
          appearance:none;
  background:#ffffff;
  border:none;
  border-radius:3px;
  -webkit-box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
  color:#182026;
  font-size:14px;
  font-weight:400;
  height:30px;
  line-height:30px;
  outline:none;
  padding:0 10px;
  -webkit-transition:-webkit-box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:-webkit-box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9), -webkit-box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
  vertical-align:middle;
  overflow:hidden;
  text-overflow:ellipsis;
  white-space:nowrap;
  word-wrap:normal;
  color:rgba(92, 112, 128, 0.6);
  left:0;
  padding-right:80px;
  position:absolute;
  right:0;
  top:0;
  -webkit-user-select:none;
     -moz-user-select:none;
      -ms-user-select:none;
          user-select:none; }
  .bp3-file-upload-input::-webkit-input-placeholder{
    color:rgba(92, 112, 128, 0.6);
    opacity:1; }
  .bp3-file-upload-input::-moz-placeholder{
    color:rgba(92, 112, 128, 0.6);
    opacity:1; }
  .bp3-file-upload-input:-ms-input-placeholder{
    color:rgba(92, 112, 128, 0.6);
    opacity:1; }
  .bp3-file-upload-input::-ms-input-placeholder{
    color:rgba(92, 112, 128, 0.6);
    opacity:1; }
  .bp3-file-upload-input::placeholder{
    color:rgba(92, 112, 128, 0.6);
    opacity:1; }
  .bp3-file-upload-input:focus, .bp3-file-upload-input.bp3-active{
    -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
  .bp3-file-upload-input[type="search"], .bp3-file-upload-input.bp3-round{
    border-radius:30px;
    -webkit-box-sizing:border-box;
            box-sizing:border-box;
    padding-left:10px; }
  .bp3-file-upload-input[readonly]{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.15);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.15); }
  .bp3-file-upload-input:disabled, .bp3-file-upload-input.bp3-disabled{
    background:rgba(206, 217, 224, 0.5);
    -webkit-box-shadow:none;
            box-shadow:none;
    color:rgba(92, 112, 128, 0.6);
    cursor:not-allowed;
    resize:none; }
  .bp3-file-upload-input::after{
    background-color:#f5f8fa;
    background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.8)), to(rgba(255, 255, 255, 0)));
    background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.8), rgba(255, 255, 255, 0));
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
    color:#182026;
    min-height:24px;
    min-width:24px;
    overflow:hidden;
    text-overflow:ellipsis;
    white-space:nowrap;
    word-wrap:normal;
    border-radius:3px;
    content:"Browse";
    line-height:24px;
    margin:3px;
    position:absolute;
    right:0;
    text-align:center;
    top:0;
    width:70px; }
    .bp3-file-upload-input::after:hover{
      background-clip:padding-box;
      background-color:#ebf1f5;
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1); }
    .bp3-file-upload-input::after:active, .bp3-file-upload-input::after.bp3-active{
      background-color:#d8e1e8;
      background-image:none;
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2); }
    .bp3-file-upload-input::after:disabled, .bp3-file-upload-input::after.bp3-disabled{
      background-color:rgba(206, 217, 224, 0.5);
      background-image:none;
      -webkit-box-shadow:none;
              box-shadow:none;
      color:rgba(92, 112, 128, 0.6);
      cursor:not-allowed;
      outline:none; }
      .bp3-file-upload-input::after:disabled.bp3-active, .bp3-file-upload-input::after:disabled.bp3-active:hover, .bp3-file-upload-input::after.bp3-disabled.bp3-active, .bp3-file-upload-input::after.bp3-disabled.bp3-active:hover{
        background:rgba(206, 217, 224, 0.7); }
  .bp3-file-upload-input:hover::after{
    background-clip:padding-box;
    background-color:#ebf1f5;
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1); }
  .bp3-file-upload-input:active::after{
    background-color:#d8e1e8;
    background-image:none;
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2); }
  .bp3-large .bp3-file-upload-input{
    font-size:16px;
    height:40px;
    line-height:40px;
    padding-right:95px; }
    .bp3-large .bp3-file-upload-input[type="search"], .bp3-large .bp3-file-upload-input.bp3-round{
      padding:0 15px; }
    .bp3-large .bp3-file-upload-input::after{
      min-height:30px;
      min-width:30px;
      line-height:30px;
      margin:5px;
      width:85px; }
  .bp3-dark .bp3-file-upload-input{
    background:rgba(16, 22, 26, 0.3);
    -webkit-box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
    color:#f5f8fa;
    color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-file-upload-input::-webkit-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-file-upload-input::-moz-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-file-upload-input:-ms-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-file-upload-input::-ms-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-file-upload-input::placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-file-upload-input:focus{
      -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px #137cbd, 0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-file-upload-input[readonly]{
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-file-upload-input:disabled, .bp3-dark .bp3-file-upload-input.bp3-disabled{
      background:rgba(57, 75, 89, 0.5);
      -webkit-box-shadow:none;
              box-shadow:none;
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-file-upload-input::after{
      background-color:#394b59;
      background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.05)), to(rgba(255, 255, 255, 0)));
      background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.05), rgba(255, 255, 255, 0));
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
      color:#f5f8fa; }
      .bp3-dark .bp3-file-upload-input::after:hover, .bp3-dark .bp3-file-upload-input::after:active, .bp3-dark .bp3-file-upload-input::after.bp3-active{
        color:#f5f8fa; }
      .bp3-dark .bp3-file-upload-input::after:hover{
        background-color:#30404d;
        -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
                box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4); }
      .bp3-dark .bp3-file-upload-input::after:active, .bp3-dark .bp3-file-upload-input::after.bp3-active{
        background-color:#202b33;
        background-image:none;
        -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2);
                box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2); }
      .bp3-dark .bp3-file-upload-input::after:disabled, .bp3-dark .bp3-file-upload-input::after.bp3-disabled{
        background-color:rgba(57, 75, 89, 0.5);
        background-image:none;
        -webkit-box-shadow:none;
                box-shadow:none;
        color:rgba(167, 182, 194, 0.6); }
        .bp3-dark .bp3-file-upload-input::after:disabled.bp3-active, .bp3-dark .bp3-file-upload-input::after.bp3-disabled.bp3-active{
          background:rgba(57, 75, 89, 0.7); }
      .bp3-dark .bp3-file-upload-input::after .bp3-button-spinner .bp3-spinner-head{
        background:rgba(16, 22, 26, 0.5);
        stroke:#8a9ba8; }
    .bp3-dark .bp3-file-upload-input:hover::after{
      background-color:#30404d;
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-file-upload-input:active::after{
      background-color:#202b33;
      background-image:none;
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2); }
.bp3-file-upload-input::after{
  -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
          box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1); }
.bp3-form-group{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-orient:vertical;
  -webkit-box-direction:normal;
      -ms-flex-direction:column;
          flex-direction:column;
  margin:0 0 15px; }
  .bp3-form-group label.bp3-label{
    margin-bottom:5px; }
  .bp3-form-group .bp3-control{
    margin-top:7px; }
  .bp3-form-group .bp3-form-helper-text{
    color:#5c7080;
    font-size:12px;
    margin-top:5px; }
  .bp3-form-group.bp3-intent-primary .bp3-form-helper-text{
    color:#106ba3; }
  .bp3-form-group.bp3-intent-success .bp3-form-helper-text{
    color:#0d8050; }
  .bp3-form-group.bp3-intent-warning .bp3-form-helper-text{
    color:#bf7326; }
  .bp3-form-group.bp3-intent-danger .bp3-form-helper-text{
    color:#c23030; }
  .bp3-form-group.bp3-inline{
    -webkit-box-align:start;
        -ms-flex-align:start;
            align-items:flex-start;
    -webkit-box-orient:horizontal;
    -webkit-box-direction:normal;
        -ms-flex-direction:row;
            flex-direction:row; }
    .bp3-form-group.bp3-inline.bp3-large label.bp3-label{
      line-height:40px;
      margin:0 10px 0 0; }
    .bp3-form-group.bp3-inline label.bp3-label{
      line-height:30px;
      margin:0 10px 0 0; }
  .bp3-form-group.bp3-disabled .bp3-label,
  .bp3-form-group.bp3-disabled .bp3-text-muted,
  .bp3-form-group.bp3-disabled .bp3-form-helper-text{
    color:rgba(92, 112, 128, 0.6) !important; }
  .bp3-dark .bp3-form-group.bp3-intent-primary .bp3-form-helper-text{
    color:#48aff0; }
  .bp3-dark .bp3-form-group.bp3-intent-success .bp3-form-helper-text{
    color:#3dcc91; }
  .bp3-dark .bp3-form-group.bp3-intent-warning .bp3-form-helper-text{
    color:#ffb366; }
  .bp3-dark .bp3-form-group.bp3-intent-danger .bp3-form-helper-text{
    color:#ff7373; }
  .bp3-dark .bp3-form-group .bp3-form-helper-text{
    color:#a7b6c2; }
  .bp3-dark .bp3-form-group.bp3-disabled .bp3-label,
  .bp3-dark .bp3-form-group.bp3-disabled .bp3-text-muted,
  .bp3-dark .bp3-form-group.bp3-disabled .bp3-form-helper-text{
    color:rgba(167, 182, 194, 0.6) !important; }
.bp3-input-group{
  display:block;
  position:relative; }
  .bp3-input-group .bp3-input{
    position:relative;
    width:100%; }
    .bp3-input-group .bp3-input:not(:first-child){
      padding-left:30px; }
    .bp3-input-group .bp3-input:not(:last-child){
      padding-right:30px; }
  .bp3-input-group .bp3-input-action,
  .bp3-input-group > .bp3-input-left-container,
  .bp3-input-group > .bp3-button,
  .bp3-input-group > .bp3-icon{
    position:absolute;
    top:0; }
    .bp3-input-group .bp3-input-action:first-child,
    .bp3-input-group > .bp3-input-left-container:first-child,
    .bp3-input-group > .bp3-button:first-child,
    .bp3-input-group > .bp3-icon:first-child{
      left:0; }
    .bp3-input-group .bp3-input-action:last-child,
    .bp3-input-group > .bp3-input-left-container:last-child,
    .bp3-input-group > .bp3-button:last-child,
    .bp3-input-group > .bp3-icon:last-child{
      right:0; }
  .bp3-input-group .bp3-button{
    min-height:24px;
    min-width:24px;
    margin:3px;
    padding:0 7px; }
    .bp3-input-group .bp3-button:empty{
      padding:0; }
  .bp3-input-group > .bp3-input-left-container,
  .bp3-input-group > .bp3-icon{
    z-index:1; }
  .bp3-input-group > .bp3-input-left-container > .bp3-icon,
  .bp3-input-group > .bp3-icon{
    color:#5c7080; }
    .bp3-input-group > .bp3-input-left-container > .bp3-icon:empty,
    .bp3-input-group > .bp3-icon:empty{
      font-family:"Icons16", sans-serif;
      font-size:16px;
      font-style:normal;
      font-weight:400;
      line-height:1;
      -moz-osx-font-smoothing:grayscale;
      -webkit-font-smoothing:antialiased; }
  .bp3-input-group > .bp3-input-left-container > .bp3-icon,
  .bp3-input-group > .bp3-icon,
  .bp3-input-group .bp3-input-action > .bp3-spinner{
    margin:7px; }
  .bp3-input-group .bp3-tag{
    margin:5px; }
  .bp3-input-group .bp3-input:not(:focus) + .bp3-button.bp3-minimal:not(:hover):not(:focus),
  .bp3-input-group .bp3-input:not(:focus) + .bp3-input-action .bp3-button.bp3-minimal:not(:hover):not(:focus){
    color:#5c7080; }
    .bp3-dark .bp3-input-group .bp3-input:not(:focus) + .bp3-button.bp3-minimal:not(:hover):not(:focus), .bp3-dark
    .bp3-input-group .bp3-input:not(:focus) + .bp3-input-action .bp3-button.bp3-minimal:not(:hover):not(:focus){
      color:#a7b6c2; }
    .bp3-input-group .bp3-input:not(:focus) + .bp3-button.bp3-minimal:not(:hover):not(:focus) .bp3-icon, .bp3-input-group .bp3-input:not(:focus) + .bp3-button.bp3-minimal:not(:hover):not(:focus) .bp3-icon-standard, .bp3-input-group .bp3-input:not(:focus) + .bp3-button.bp3-minimal:not(:hover):not(:focus) .bp3-icon-large,
    .bp3-input-group .bp3-input:not(:focus) + .bp3-input-action .bp3-button.bp3-minimal:not(:hover):not(:focus) .bp3-icon,
    .bp3-input-group .bp3-input:not(:focus) + .bp3-input-action .bp3-button.bp3-minimal:not(:hover):not(:focus) .bp3-icon-standard,
    .bp3-input-group .bp3-input:not(:focus) + .bp3-input-action .bp3-button.bp3-minimal:not(:hover):not(:focus) .bp3-icon-large{
      color:#5c7080; }
  .bp3-input-group .bp3-input:not(:focus) + .bp3-button.bp3-minimal:disabled,
  .bp3-input-group .bp3-input:not(:focus) + .bp3-input-action .bp3-button.bp3-minimal:disabled{
    color:rgba(92, 112, 128, 0.6) !important; }
    .bp3-input-group .bp3-input:not(:focus) + .bp3-button.bp3-minimal:disabled .bp3-icon, .bp3-input-group .bp3-input:not(:focus) + .bp3-button.bp3-minimal:disabled .bp3-icon-standard, .bp3-input-group .bp3-input:not(:focus) + .bp3-button.bp3-minimal:disabled .bp3-icon-large,
    .bp3-input-group .bp3-input:not(:focus) + .bp3-input-action .bp3-button.bp3-minimal:disabled .bp3-icon,
    .bp3-input-group .bp3-input:not(:focus) + .bp3-input-action .bp3-button.bp3-minimal:disabled .bp3-icon-standard,
    .bp3-input-group .bp3-input:not(:focus) + .bp3-input-action .bp3-button.bp3-minimal:disabled .bp3-icon-large{
      color:rgba(92, 112, 128, 0.6) !important; }
  .bp3-input-group.bp3-disabled{
    cursor:not-allowed; }
    .bp3-input-group.bp3-disabled .bp3-icon{
      color:rgba(92, 112, 128, 0.6); }
  .bp3-input-group.bp3-large .bp3-button{
    min-height:30px;
    min-width:30px;
    margin:5px; }
  .bp3-input-group.bp3-large > .bp3-input-left-container > .bp3-icon,
  .bp3-input-group.bp3-large > .bp3-icon,
  .bp3-input-group.bp3-large .bp3-input-action > .bp3-spinner{
    margin:12px; }
  .bp3-input-group.bp3-large .bp3-input{
    font-size:16px;
    height:40px;
    line-height:40px; }
    .bp3-input-group.bp3-large .bp3-input[type="search"], .bp3-input-group.bp3-large .bp3-input.bp3-round{
      padding:0 15px; }
    .bp3-input-group.bp3-large .bp3-input:not(:first-child){
      padding-left:40px; }
    .bp3-input-group.bp3-large .bp3-input:not(:last-child){
      padding-right:40px; }
  .bp3-input-group.bp3-small .bp3-button{
    min-height:20px;
    min-width:20px;
    margin:2px; }
  .bp3-input-group.bp3-small .bp3-tag{
    min-height:20px;
    min-width:20px;
    margin:2px; }
  .bp3-input-group.bp3-small > .bp3-input-left-container > .bp3-icon,
  .bp3-input-group.bp3-small > .bp3-icon,
  .bp3-input-group.bp3-small .bp3-input-action > .bp3-spinner{
    margin:4px; }
  .bp3-input-group.bp3-small .bp3-input{
    font-size:12px;
    height:24px;
    line-height:24px;
    padding-left:8px;
    padding-right:8px; }
    .bp3-input-group.bp3-small .bp3-input[type="search"], .bp3-input-group.bp3-small .bp3-input.bp3-round{
      padding:0 12px; }
    .bp3-input-group.bp3-small .bp3-input:not(:first-child){
      padding-left:24px; }
    .bp3-input-group.bp3-small .bp3-input:not(:last-child){
      padding-right:24px; }
  .bp3-input-group.bp3-fill{
    -webkit-box-flex:1;
        -ms-flex:1 1 auto;
            flex:1 1 auto;
    width:100%; }
  .bp3-input-group.bp3-round .bp3-button,
  .bp3-input-group.bp3-round .bp3-input,
  .bp3-input-group.bp3-round .bp3-tag{
    border-radius:30px; }
  .bp3-dark .bp3-input-group .bp3-icon{
    color:#a7b6c2; }
  .bp3-dark .bp3-input-group.bp3-disabled .bp3-icon{
    color:rgba(167, 182, 194, 0.6); }
  .bp3-input-group.bp3-intent-primary .bp3-input{
    -webkit-box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px #137cbd, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px #137cbd, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input-group.bp3-intent-primary .bp3-input:focus{
      -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input-group.bp3-intent-primary .bp3-input[readonly]{
      -webkit-box-shadow:inset 0 0 0 1px #137cbd;
              box-shadow:inset 0 0 0 1px #137cbd; }
    .bp3-input-group.bp3-intent-primary .bp3-input:disabled, .bp3-input-group.bp3-intent-primary .bp3-input.bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none; }
  .bp3-input-group.bp3-intent-primary > .bp3-icon{
    color:#106ba3; }
    .bp3-dark .bp3-input-group.bp3-intent-primary > .bp3-icon{
      color:#48aff0; }
  .bp3-input-group.bp3-intent-success .bp3-input{
    -webkit-box-shadow:0 0 0 0 rgba(15, 153, 96, 0), 0 0 0 0 rgba(15, 153, 96, 0), inset 0 0 0 1px #0f9960, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 0 rgba(15, 153, 96, 0), 0 0 0 0 rgba(15, 153, 96, 0), inset 0 0 0 1px #0f9960, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input-group.bp3-intent-success .bp3-input:focus{
      -webkit-box-shadow:0 0 0 1px #0f9960, 0 0 0 3px rgba(15, 153, 96, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #0f9960, 0 0 0 3px rgba(15, 153, 96, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input-group.bp3-intent-success .bp3-input[readonly]{
      -webkit-box-shadow:inset 0 0 0 1px #0f9960;
              box-shadow:inset 0 0 0 1px #0f9960; }
    .bp3-input-group.bp3-intent-success .bp3-input:disabled, .bp3-input-group.bp3-intent-success .bp3-input.bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none; }
  .bp3-input-group.bp3-intent-success > .bp3-icon{
    color:#0d8050; }
    .bp3-dark .bp3-input-group.bp3-intent-success > .bp3-icon{
      color:#3dcc91; }
  .bp3-input-group.bp3-intent-warning .bp3-input{
    -webkit-box-shadow:0 0 0 0 rgba(217, 130, 43, 0), 0 0 0 0 rgba(217, 130, 43, 0), inset 0 0 0 1px #d9822b, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 0 rgba(217, 130, 43, 0), 0 0 0 0 rgba(217, 130, 43, 0), inset 0 0 0 1px #d9822b, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input-group.bp3-intent-warning .bp3-input:focus{
      -webkit-box-shadow:0 0 0 1px #d9822b, 0 0 0 3px rgba(217, 130, 43, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #d9822b, 0 0 0 3px rgba(217, 130, 43, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input-group.bp3-intent-warning .bp3-input[readonly]{
      -webkit-box-shadow:inset 0 0 0 1px #d9822b;
              box-shadow:inset 0 0 0 1px #d9822b; }
    .bp3-input-group.bp3-intent-warning .bp3-input:disabled, .bp3-input-group.bp3-intent-warning .bp3-input.bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none; }
  .bp3-input-group.bp3-intent-warning > .bp3-icon{
    color:#bf7326; }
    .bp3-dark .bp3-input-group.bp3-intent-warning > .bp3-icon{
      color:#ffb366; }
  .bp3-input-group.bp3-intent-danger .bp3-input{
    -webkit-box-shadow:0 0 0 0 rgba(219, 55, 55, 0), 0 0 0 0 rgba(219, 55, 55, 0), inset 0 0 0 1px #db3737, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 0 rgba(219, 55, 55, 0), 0 0 0 0 rgba(219, 55, 55, 0), inset 0 0 0 1px #db3737, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input-group.bp3-intent-danger .bp3-input:focus{
      -webkit-box-shadow:0 0 0 1px #db3737, 0 0 0 3px rgba(219, 55, 55, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #db3737, 0 0 0 3px rgba(219, 55, 55, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input-group.bp3-intent-danger .bp3-input[readonly]{
      -webkit-box-shadow:inset 0 0 0 1px #db3737;
              box-shadow:inset 0 0 0 1px #db3737; }
    .bp3-input-group.bp3-intent-danger .bp3-input:disabled, .bp3-input-group.bp3-intent-danger .bp3-input.bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none; }
  .bp3-input-group.bp3-intent-danger > .bp3-icon{
    color:#c23030; }
    .bp3-dark .bp3-input-group.bp3-intent-danger > .bp3-icon{
      color:#ff7373; }
.bp3-input{
  -webkit-appearance:none;
     -moz-appearance:none;
          appearance:none;
  background:#ffffff;
  border:none;
  border-radius:3px;
  -webkit-box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
  color:#182026;
  font-size:14px;
  font-weight:400;
  height:30px;
  line-height:30px;
  outline:none;
  padding:0 10px;
  -webkit-transition:-webkit-box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:-webkit-box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9), -webkit-box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
  vertical-align:middle; }
  .bp3-input::-webkit-input-placeholder{
    color:rgba(92, 112, 128, 0.6);
    opacity:1; }
  .bp3-input::-moz-placeholder{
    color:rgba(92, 112, 128, 0.6);
    opacity:1; }
  .bp3-input:-ms-input-placeholder{
    color:rgba(92, 112, 128, 0.6);
    opacity:1; }
  .bp3-input::-ms-input-placeholder{
    color:rgba(92, 112, 128, 0.6);
    opacity:1; }
  .bp3-input::placeholder{
    color:rgba(92, 112, 128, 0.6);
    opacity:1; }
  .bp3-input:focus, .bp3-input.bp3-active{
    -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
  .bp3-input[type="search"], .bp3-input.bp3-round{
    border-radius:30px;
    -webkit-box-sizing:border-box;
            box-sizing:border-box;
    padding-left:10px; }
  .bp3-input[readonly]{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.15);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.15); }
  .bp3-input:disabled, .bp3-input.bp3-disabled{
    background:rgba(206, 217, 224, 0.5);
    -webkit-box-shadow:none;
            box-shadow:none;
    color:rgba(92, 112, 128, 0.6);
    cursor:not-allowed;
    resize:none; }
  .bp3-input.bp3-large{
    font-size:16px;
    height:40px;
    line-height:40px; }
    .bp3-input.bp3-large[type="search"], .bp3-input.bp3-large.bp3-round{
      padding:0 15px; }
  .bp3-input.bp3-small{
    font-size:12px;
    height:24px;
    line-height:24px;
    padding-left:8px;
    padding-right:8px; }
    .bp3-input.bp3-small[type="search"], .bp3-input.bp3-small.bp3-round{
      padding:0 12px; }
  .bp3-input.bp3-fill{
    -webkit-box-flex:1;
        -ms-flex:1 1 auto;
            flex:1 1 auto;
    width:100%; }
  .bp3-dark .bp3-input{
    background:rgba(16, 22, 26, 0.3);
    -webkit-box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
    color:#f5f8fa; }
    .bp3-dark .bp3-input::-webkit-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-input::-moz-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-input:-ms-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-input::-ms-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-input::placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-input:focus{
      -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px #137cbd, 0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-input[readonly]{
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-input:disabled, .bp3-dark .bp3-input.bp3-disabled{
      background:rgba(57, 75, 89, 0.5);
      -webkit-box-shadow:none;
              box-shadow:none;
      color:rgba(167, 182, 194, 0.6); }
  .bp3-input.bp3-intent-primary{
    -webkit-box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px #137cbd, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px #137cbd, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input.bp3-intent-primary:focus{
      -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input.bp3-intent-primary[readonly]{
      -webkit-box-shadow:inset 0 0 0 1px #137cbd;
              box-shadow:inset 0 0 0 1px #137cbd; }
    .bp3-input.bp3-intent-primary:disabled, .bp3-input.bp3-intent-primary.bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none; }
    .bp3-dark .bp3-input.bp3-intent-primary{
      -webkit-box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px #137cbd, inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px #137cbd, inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
      .bp3-dark .bp3-input.bp3-intent-primary:focus{
        -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
                box-shadow:0 0 0 1px #137cbd, 0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
      .bp3-dark .bp3-input.bp3-intent-primary[readonly]{
        -webkit-box-shadow:inset 0 0 0 1px #137cbd;
                box-shadow:inset 0 0 0 1px #137cbd; }
      .bp3-dark .bp3-input.bp3-intent-primary:disabled, .bp3-dark .bp3-input.bp3-intent-primary.bp3-disabled{
        -webkit-box-shadow:none;
                box-shadow:none; }
  .bp3-input.bp3-intent-success{
    -webkit-box-shadow:0 0 0 0 rgba(15, 153, 96, 0), 0 0 0 0 rgba(15, 153, 96, 0), inset 0 0 0 1px #0f9960, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 0 rgba(15, 153, 96, 0), 0 0 0 0 rgba(15, 153, 96, 0), inset 0 0 0 1px #0f9960, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input.bp3-intent-success:focus{
      -webkit-box-shadow:0 0 0 1px #0f9960, 0 0 0 3px rgba(15, 153, 96, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #0f9960, 0 0 0 3px rgba(15, 153, 96, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input.bp3-intent-success[readonly]{
      -webkit-box-shadow:inset 0 0 0 1px #0f9960;
              box-shadow:inset 0 0 0 1px #0f9960; }
    .bp3-input.bp3-intent-success:disabled, .bp3-input.bp3-intent-success.bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none; }
    .bp3-dark .bp3-input.bp3-intent-success{
      -webkit-box-shadow:0 0 0 0 rgba(15, 153, 96, 0), 0 0 0 0 rgba(15, 153, 96, 0), 0 0 0 0 rgba(15, 153, 96, 0), inset 0 0 0 1px #0f9960, inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 0 rgba(15, 153, 96, 0), 0 0 0 0 rgba(15, 153, 96, 0), 0 0 0 0 rgba(15, 153, 96, 0), inset 0 0 0 1px #0f9960, inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
      .bp3-dark .bp3-input.bp3-intent-success:focus{
        -webkit-box-shadow:0 0 0 1px #0f9960, 0 0 0 1px #0f9960, 0 0 0 3px rgba(15, 153, 96, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
                box-shadow:0 0 0 1px #0f9960, 0 0 0 1px #0f9960, 0 0 0 3px rgba(15, 153, 96, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
      .bp3-dark .bp3-input.bp3-intent-success[readonly]{
        -webkit-box-shadow:inset 0 0 0 1px #0f9960;
                box-shadow:inset 0 0 0 1px #0f9960; }
      .bp3-dark .bp3-input.bp3-intent-success:disabled, .bp3-dark .bp3-input.bp3-intent-success.bp3-disabled{
        -webkit-box-shadow:none;
                box-shadow:none; }
  .bp3-input.bp3-intent-warning{
    -webkit-box-shadow:0 0 0 0 rgba(217, 130, 43, 0), 0 0 0 0 rgba(217, 130, 43, 0), inset 0 0 0 1px #d9822b, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 0 rgba(217, 130, 43, 0), 0 0 0 0 rgba(217, 130, 43, 0), inset 0 0 0 1px #d9822b, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input.bp3-intent-warning:focus{
      -webkit-box-shadow:0 0 0 1px #d9822b, 0 0 0 3px rgba(217, 130, 43, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #d9822b, 0 0 0 3px rgba(217, 130, 43, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input.bp3-intent-warning[readonly]{
      -webkit-box-shadow:inset 0 0 0 1px #d9822b;
              box-shadow:inset 0 0 0 1px #d9822b; }
    .bp3-input.bp3-intent-warning:disabled, .bp3-input.bp3-intent-warning.bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none; }
    .bp3-dark .bp3-input.bp3-intent-warning{
      -webkit-box-shadow:0 0 0 0 rgba(217, 130, 43, 0), 0 0 0 0 rgba(217, 130, 43, 0), 0 0 0 0 rgba(217, 130, 43, 0), inset 0 0 0 1px #d9822b, inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 0 rgba(217, 130, 43, 0), 0 0 0 0 rgba(217, 130, 43, 0), 0 0 0 0 rgba(217, 130, 43, 0), inset 0 0 0 1px #d9822b, inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
      .bp3-dark .bp3-input.bp3-intent-warning:focus{
        -webkit-box-shadow:0 0 0 1px #d9822b, 0 0 0 1px #d9822b, 0 0 0 3px rgba(217, 130, 43, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
                box-shadow:0 0 0 1px #d9822b, 0 0 0 1px #d9822b, 0 0 0 3px rgba(217, 130, 43, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
      .bp3-dark .bp3-input.bp3-intent-warning[readonly]{
        -webkit-box-shadow:inset 0 0 0 1px #d9822b;
                box-shadow:inset 0 0 0 1px #d9822b; }
      .bp3-dark .bp3-input.bp3-intent-warning:disabled, .bp3-dark .bp3-input.bp3-intent-warning.bp3-disabled{
        -webkit-box-shadow:none;
                box-shadow:none; }
  .bp3-input.bp3-intent-danger{
    -webkit-box-shadow:0 0 0 0 rgba(219, 55, 55, 0), 0 0 0 0 rgba(219, 55, 55, 0), inset 0 0 0 1px #db3737, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 0 rgba(219, 55, 55, 0), 0 0 0 0 rgba(219, 55, 55, 0), inset 0 0 0 1px #db3737, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input.bp3-intent-danger:focus{
      -webkit-box-shadow:0 0 0 1px #db3737, 0 0 0 3px rgba(219, 55, 55, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #db3737, 0 0 0 3px rgba(219, 55, 55, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input.bp3-intent-danger[readonly]{
      -webkit-box-shadow:inset 0 0 0 1px #db3737;
              box-shadow:inset 0 0 0 1px #db3737; }
    .bp3-input.bp3-intent-danger:disabled, .bp3-input.bp3-intent-danger.bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none; }
    .bp3-dark .bp3-input.bp3-intent-danger{
      -webkit-box-shadow:0 0 0 0 rgba(219, 55, 55, 0), 0 0 0 0 rgba(219, 55, 55, 0), 0 0 0 0 rgba(219, 55, 55, 0), inset 0 0 0 1px #db3737, inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 0 rgba(219, 55, 55, 0), 0 0 0 0 rgba(219, 55, 55, 0), 0 0 0 0 rgba(219, 55, 55, 0), inset 0 0 0 1px #db3737, inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
      .bp3-dark .bp3-input.bp3-intent-danger:focus{
        -webkit-box-shadow:0 0 0 1px #db3737, 0 0 0 1px #db3737, 0 0 0 3px rgba(219, 55, 55, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
                box-shadow:0 0 0 1px #db3737, 0 0 0 1px #db3737, 0 0 0 3px rgba(219, 55, 55, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
      .bp3-dark .bp3-input.bp3-intent-danger[readonly]{
        -webkit-box-shadow:inset 0 0 0 1px #db3737;
                box-shadow:inset 0 0 0 1px #db3737; }
      .bp3-dark .bp3-input.bp3-intent-danger:disabled, .bp3-dark .bp3-input.bp3-intent-danger.bp3-disabled{
        -webkit-box-shadow:none;
                box-shadow:none; }
  .bp3-input::-ms-clear{
    display:none; }
textarea.bp3-input{
  max-width:100%;
  padding:10px; }
  textarea.bp3-input, textarea.bp3-input.bp3-large, textarea.bp3-input.bp3-small{
    height:auto;
    line-height:inherit; }
  textarea.bp3-input.bp3-small{
    padding:8px; }
  .bp3-dark textarea.bp3-input{
    background:rgba(16, 22, 26, 0.3);
    -webkit-box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
    color:#f5f8fa; }
    .bp3-dark textarea.bp3-input::-webkit-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark textarea.bp3-input::-moz-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark textarea.bp3-input:-ms-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark textarea.bp3-input::-ms-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark textarea.bp3-input::placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark textarea.bp3-input:focus{
      -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px #137cbd, 0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark textarea.bp3-input[readonly]{
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark textarea.bp3-input:disabled, .bp3-dark textarea.bp3-input.bp3-disabled{
      background:rgba(57, 75, 89, 0.5);
      -webkit-box-shadow:none;
              box-shadow:none;
      color:rgba(167, 182, 194, 0.6); }
label.bp3-label{
  display:block;
  margin-bottom:15px;
  margin-top:0; }
  label.bp3-label .bp3-html-select,
  label.bp3-label .bp3-input,
  label.bp3-label .bp3-select,
  label.bp3-label .bp3-slider,
  label.bp3-label .bp3-popover-wrapper{
    display:block;
    margin-top:5px;
    text-transform:none; }
  label.bp3-label .bp3-button-group{
    margin-top:5px; }
  label.bp3-label .bp3-select select,
  label.bp3-label .bp3-html-select select{
    font-weight:400;
    vertical-align:top;
    width:100%; }
  label.bp3-label.bp3-disabled,
  label.bp3-label.bp3-disabled .bp3-text-muted{
    color:rgba(92, 112, 128, 0.6); }
  label.bp3-label.bp3-inline{
    line-height:30px; }
    label.bp3-label.bp3-inline .bp3-html-select,
    label.bp3-label.bp3-inline .bp3-input,
    label.bp3-label.bp3-inline .bp3-input-group,
    label.bp3-label.bp3-inline .bp3-select,
    label.bp3-label.bp3-inline .bp3-popover-wrapper{
      display:inline-block;
      margin:0 0 0 5px;
      vertical-align:top; }
    label.bp3-label.bp3-inline .bp3-button-group{
      margin:0 0 0 5px; }
    label.bp3-label.bp3-inline .bp3-input-group .bp3-input{
      margin-left:0; }
    label.bp3-label.bp3-inline.bp3-large{
      line-height:40px; }
  label.bp3-label:not(.bp3-inline) .bp3-popover-target{
    display:block; }
  .bp3-dark label.bp3-label{
    color:#f5f8fa; }
    .bp3-dark label.bp3-label.bp3-disabled,
    .bp3-dark label.bp3-label.bp3-disabled .bp3-text-muted{
      color:rgba(167, 182, 194, 0.6); }
.bp3-numeric-input .bp3-button-group.bp3-vertical > .bp3-button{
  -webkit-box-flex:1;
      -ms-flex:1 1 14px;
          flex:1 1 14px;
  min-height:0;
  padding:0;
  width:30px; }
  .bp3-numeric-input .bp3-button-group.bp3-vertical > .bp3-button:first-child{
    border-radius:0 3px 0 0; }
  .bp3-numeric-input .bp3-button-group.bp3-vertical > .bp3-button:last-child{
    border-radius:0 0 3px 0; }

.bp3-numeric-input .bp3-button-group.bp3-vertical:first-child > .bp3-button:first-child{
  border-radius:3px 0 0 0; }

.bp3-numeric-input .bp3-button-group.bp3-vertical:first-child > .bp3-button:last-child{
  border-radius:0 0 0 3px; }

.bp3-numeric-input.bp3-large .bp3-button-group.bp3-vertical > .bp3-button{
  width:40px; }

form{
  display:block; }
.bp3-html-select select,
.bp3-select select{
  display:-webkit-inline-box;
  display:-ms-inline-flexbox;
  display:inline-flex;
  -webkit-box-orient:horizontal;
  -webkit-box-direction:normal;
      -ms-flex-direction:row;
          flex-direction:row;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  border:none;
  border-radius:3px;
  cursor:pointer;
  font-size:14px;
  -webkit-box-pack:center;
      -ms-flex-pack:center;
          justify-content:center;
  padding:5px 10px;
  text-align:left;
  vertical-align:middle;
  background-color:#f5f8fa;
  background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.8)), to(rgba(255, 255, 255, 0)));
  background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.8), rgba(255, 255, 255, 0));
  -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
          box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
  color:#182026;
  -moz-appearance:none;
  -webkit-appearance:none;
  border-radius:3px;
  height:30px;
  padding:0 25px 0 10px;
  width:100%; }
  .bp3-html-select select > *, .bp3-select select > *{
    -webkit-box-flex:0;
        -ms-flex-positive:0;
            flex-grow:0;
    -ms-flex-negative:0;
        flex-shrink:0; }
  .bp3-html-select select > .bp3-fill, .bp3-select select > .bp3-fill{
    -webkit-box-flex:1;
        -ms-flex-positive:1;
            flex-grow:1;
    -ms-flex-negative:1;
        flex-shrink:1; }
  .bp3-html-select select::before,
  .bp3-select select::before, .bp3-html-select select > *, .bp3-select select > *{
    margin-right:7px; }
  .bp3-html-select select:empty::before,
  .bp3-select select:empty::before,
  .bp3-html-select select > :last-child,
  .bp3-select select > :last-child{
    margin-right:0; }
  .bp3-html-select select:hover,
  .bp3-select select:hover{
    background-clip:padding-box;
    background-color:#ebf1f5;
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1); }
  .bp3-html-select select:active,
  .bp3-select select:active, .bp3-html-select select.bp3-active,
  .bp3-select select.bp3-active{
    background-color:#d8e1e8;
    background-image:none;
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2); }
  .bp3-html-select select:disabled,
  .bp3-select select:disabled, .bp3-html-select select.bp3-disabled,
  .bp3-select select.bp3-disabled{
    background-color:rgba(206, 217, 224, 0.5);
    background-image:none;
    -webkit-box-shadow:none;
            box-shadow:none;
    color:rgba(92, 112, 128, 0.6);
    cursor:not-allowed;
    outline:none; }
    .bp3-html-select select:disabled.bp3-active,
    .bp3-select select:disabled.bp3-active, .bp3-html-select select:disabled.bp3-active:hover,
    .bp3-select select:disabled.bp3-active:hover, .bp3-html-select select.bp3-disabled.bp3-active,
    .bp3-select select.bp3-disabled.bp3-active, .bp3-html-select select.bp3-disabled.bp3-active:hover,
    .bp3-select select.bp3-disabled.bp3-active:hover{
      background:rgba(206, 217, 224, 0.7); }

.bp3-html-select.bp3-minimal select,
.bp3-select.bp3-minimal select{
  background:none;
  -webkit-box-shadow:none;
          box-shadow:none; }
  .bp3-html-select.bp3-minimal select:hover,
  .bp3-select.bp3-minimal select:hover{
    background:rgba(167, 182, 194, 0.3);
    -webkit-box-shadow:none;
            box-shadow:none;
    color:#182026;
    text-decoration:none; }
  .bp3-html-select.bp3-minimal select:active,
  .bp3-select.bp3-minimal select:active, .bp3-html-select.bp3-minimal select.bp3-active,
  .bp3-select.bp3-minimal select.bp3-active{
    background:rgba(115, 134, 148, 0.3);
    -webkit-box-shadow:none;
            box-shadow:none;
    color:#182026; }
  .bp3-html-select.bp3-minimal select:disabled,
  .bp3-select.bp3-minimal select:disabled, .bp3-html-select.bp3-minimal select:disabled:hover,
  .bp3-select.bp3-minimal select:disabled:hover, .bp3-html-select.bp3-minimal select.bp3-disabled,
  .bp3-select.bp3-minimal select.bp3-disabled, .bp3-html-select.bp3-minimal select.bp3-disabled:hover,
  .bp3-select.bp3-minimal select.bp3-disabled:hover{
    background:none;
    color:rgba(92, 112, 128, 0.6);
    cursor:not-allowed; }
    .bp3-html-select.bp3-minimal select:disabled.bp3-active,
    .bp3-select.bp3-minimal select:disabled.bp3-active, .bp3-html-select.bp3-minimal select:disabled:hover.bp3-active,
    .bp3-select.bp3-minimal select:disabled:hover.bp3-active, .bp3-html-select.bp3-minimal select.bp3-disabled.bp3-active,
    .bp3-select.bp3-minimal select.bp3-disabled.bp3-active, .bp3-html-select.bp3-minimal select.bp3-disabled:hover.bp3-active,
    .bp3-select.bp3-minimal select.bp3-disabled:hover.bp3-active{
      background:rgba(115, 134, 148, 0.3); }
  .bp3-dark .bp3-html-select.bp3-minimal select, .bp3-html-select.bp3-minimal .bp3-dark select,
  .bp3-dark .bp3-select.bp3-minimal select, .bp3-select.bp3-minimal .bp3-dark select{
    background:none;
    -webkit-box-shadow:none;
            box-shadow:none;
    color:inherit; }
    .bp3-dark .bp3-html-select.bp3-minimal select:hover, .bp3-html-select.bp3-minimal .bp3-dark select:hover,
    .bp3-dark .bp3-select.bp3-minimal select:hover, .bp3-select.bp3-minimal .bp3-dark select:hover, .bp3-dark .bp3-html-select.bp3-minimal select:active, .bp3-html-select.bp3-minimal .bp3-dark select:active,
    .bp3-dark .bp3-select.bp3-minimal select:active, .bp3-select.bp3-minimal .bp3-dark select:active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-active,
    .bp3-dark .bp3-select.bp3-minimal select.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-active{
      background:none;
      -webkit-box-shadow:none;
              box-shadow:none; }
    .bp3-dark .bp3-html-select.bp3-minimal select:hover, .bp3-html-select.bp3-minimal .bp3-dark select:hover,
    .bp3-dark .bp3-select.bp3-minimal select:hover, .bp3-select.bp3-minimal .bp3-dark select:hover{
      background:rgba(138, 155, 168, 0.15); }
    .bp3-dark .bp3-html-select.bp3-minimal select:active, .bp3-html-select.bp3-minimal .bp3-dark select:active,
    .bp3-dark .bp3-select.bp3-minimal select:active, .bp3-select.bp3-minimal .bp3-dark select:active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-active,
    .bp3-dark .bp3-select.bp3-minimal select.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-active{
      background:rgba(138, 155, 168, 0.3);
      color:#f5f8fa; }
    .bp3-dark .bp3-html-select.bp3-minimal select:disabled, .bp3-html-select.bp3-minimal .bp3-dark select:disabled,
    .bp3-dark .bp3-select.bp3-minimal select:disabled, .bp3-select.bp3-minimal .bp3-dark select:disabled, .bp3-dark .bp3-html-select.bp3-minimal select:disabled:hover, .bp3-html-select.bp3-minimal .bp3-dark select:disabled:hover,
    .bp3-dark .bp3-select.bp3-minimal select:disabled:hover, .bp3-select.bp3-minimal .bp3-dark select:disabled:hover, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-disabled, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-disabled,
    .bp3-dark .bp3-select.bp3-minimal select.bp3-disabled, .bp3-select.bp3-minimal .bp3-dark select.bp3-disabled, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-disabled:hover, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-disabled:hover,
    .bp3-dark .bp3-select.bp3-minimal select.bp3-disabled:hover, .bp3-select.bp3-minimal .bp3-dark select.bp3-disabled:hover{
      background:none;
      color:rgba(167, 182, 194, 0.6);
      cursor:not-allowed; }
      .bp3-dark .bp3-html-select.bp3-minimal select:disabled.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select:disabled.bp3-active,
      .bp3-dark .bp3-select.bp3-minimal select:disabled.bp3-active, .bp3-select.bp3-minimal .bp3-dark select:disabled.bp3-active, .bp3-dark .bp3-html-select.bp3-minimal select:disabled:hover.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select:disabled:hover.bp3-active,
      .bp3-dark .bp3-select.bp3-minimal select:disabled:hover.bp3-active, .bp3-select.bp3-minimal .bp3-dark select:disabled:hover.bp3-active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-disabled.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-disabled.bp3-active,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-disabled.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-disabled.bp3-active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-disabled:hover.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-disabled:hover.bp3-active,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-disabled:hover.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-disabled:hover.bp3-active{
        background:rgba(138, 155, 168, 0.3); }
  .bp3-html-select.bp3-minimal select.bp3-intent-primary,
  .bp3-select.bp3-minimal select.bp3-intent-primary{
    color:#106ba3; }
    .bp3-html-select.bp3-minimal select.bp3-intent-primary:hover,
    .bp3-select.bp3-minimal select.bp3-intent-primary:hover, .bp3-html-select.bp3-minimal select.bp3-intent-primary:active,
    .bp3-select.bp3-minimal select.bp3-intent-primary:active, .bp3-html-select.bp3-minimal select.bp3-intent-primary.bp3-active,
    .bp3-select.bp3-minimal select.bp3-intent-primary.bp3-active{
      background:none;
      -webkit-box-shadow:none;
              box-shadow:none;
      color:#106ba3; }
    .bp3-html-select.bp3-minimal select.bp3-intent-primary:hover,
    .bp3-select.bp3-minimal select.bp3-intent-primary:hover{
      background:rgba(19, 124, 189, 0.15);
      color:#106ba3; }
    .bp3-html-select.bp3-minimal select.bp3-intent-primary:active,
    .bp3-select.bp3-minimal select.bp3-intent-primary:active, .bp3-html-select.bp3-minimal select.bp3-intent-primary.bp3-active,
    .bp3-select.bp3-minimal select.bp3-intent-primary.bp3-active{
      background:rgba(19, 124, 189, 0.3);
      color:#106ba3; }
    .bp3-html-select.bp3-minimal select.bp3-intent-primary:disabled,
    .bp3-select.bp3-minimal select.bp3-intent-primary:disabled, .bp3-html-select.bp3-minimal select.bp3-intent-primary.bp3-disabled,
    .bp3-select.bp3-minimal select.bp3-intent-primary.bp3-disabled{
      background:none;
      color:rgba(16, 107, 163, 0.5); }
      .bp3-html-select.bp3-minimal select.bp3-intent-primary:disabled.bp3-active,
      .bp3-select.bp3-minimal select.bp3-intent-primary:disabled.bp3-active, .bp3-html-select.bp3-minimal select.bp3-intent-primary.bp3-disabled.bp3-active,
      .bp3-select.bp3-minimal select.bp3-intent-primary.bp3-disabled.bp3-active{
        background:rgba(19, 124, 189, 0.3); }
    .bp3-html-select.bp3-minimal select.bp3-intent-primary .bp3-button-spinner .bp3-spinner-head, .bp3-select.bp3-minimal select.bp3-intent-primary .bp3-button-spinner .bp3-spinner-head{
      stroke:#106ba3; }
    .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-primary, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-primary,
    .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-primary, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-primary{
      color:#48aff0; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-primary:hover, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-primary:hover,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-primary:hover, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-primary:hover{
        background:rgba(19, 124, 189, 0.2);
        color:#48aff0; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-primary:active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-primary:active,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-primary:active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-primary:active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-primary.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-primary.bp3-active,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-primary.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-primary.bp3-active{
        background:rgba(19, 124, 189, 0.3);
        color:#48aff0; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-primary:disabled, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-primary:disabled,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-primary:disabled, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-primary:disabled, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-primary.bp3-disabled, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-primary.bp3-disabled,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-primary.bp3-disabled, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-primary.bp3-disabled{
        background:none;
        color:rgba(72, 175, 240, 0.5); }
        .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-primary:disabled.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-primary:disabled.bp3-active,
        .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-primary:disabled.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-primary:disabled.bp3-active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-primary.bp3-disabled.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-primary.bp3-disabled.bp3-active,
        .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-primary.bp3-disabled.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-primary.bp3-disabled.bp3-active{
          background:rgba(19, 124, 189, 0.3); }
  .bp3-html-select.bp3-minimal select.bp3-intent-success,
  .bp3-select.bp3-minimal select.bp3-intent-success{
    color:#0d8050; }
    .bp3-html-select.bp3-minimal select.bp3-intent-success:hover,
    .bp3-select.bp3-minimal select.bp3-intent-success:hover, .bp3-html-select.bp3-minimal select.bp3-intent-success:active,
    .bp3-select.bp3-minimal select.bp3-intent-success:active, .bp3-html-select.bp3-minimal select.bp3-intent-success.bp3-active,
    .bp3-select.bp3-minimal select.bp3-intent-success.bp3-active{
      background:none;
      -webkit-box-shadow:none;
              box-shadow:none;
      color:#0d8050; }
    .bp3-html-select.bp3-minimal select.bp3-intent-success:hover,
    .bp3-select.bp3-minimal select.bp3-intent-success:hover{
      background:rgba(15, 153, 96, 0.15);
      color:#0d8050; }
    .bp3-html-select.bp3-minimal select.bp3-intent-success:active,
    .bp3-select.bp3-minimal select.bp3-intent-success:active, .bp3-html-select.bp3-minimal select.bp3-intent-success.bp3-active,
    .bp3-select.bp3-minimal select.bp3-intent-success.bp3-active{
      background:rgba(15, 153, 96, 0.3);
      color:#0d8050; }
    .bp3-html-select.bp3-minimal select.bp3-intent-success:disabled,
    .bp3-select.bp3-minimal select.bp3-intent-success:disabled, .bp3-html-select.bp3-minimal select.bp3-intent-success.bp3-disabled,
    .bp3-select.bp3-minimal select.bp3-intent-success.bp3-disabled{
      background:none;
      color:rgba(13, 128, 80, 0.5); }
      .bp3-html-select.bp3-minimal select.bp3-intent-success:disabled.bp3-active,
      .bp3-select.bp3-minimal select.bp3-intent-success:disabled.bp3-active, .bp3-html-select.bp3-minimal select.bp3-intent-success.bp3-disabled.bp3-active,
      .bp3-select.bp3-minimal select.bp3-intent-success.bp3-disabled.bp3-active{
        background:rgba(15, 153, 96, 0.3); }
    .bp3-html-select.bp3-minimal select.bp3-intent-success .bp3-button-spinner .bp3-spinner-head, .bp3-select.bp3-minimal select.bp3-intent-success .bp3-button-spinner .bp3-spinner-head{
      stroke:#0d8050; }
    .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-success, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-success,
    .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-success, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-success{
      color:#3dcc91; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-success:hover, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-success:hover,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-success:hover, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-success:hover{
        background:rgba(15, 153, 96, 0.2);
        color:#3dcc91; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-success:active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-success:active,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-success:active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-success:active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-success.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-success.bp3-active,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-success.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-success.bp3-active{
        background:rgba(15, 153, 96, 0.3);
        color:#3dcc91; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-success:disabled, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-success:disabled,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-success:disabled, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-success:disabled, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-success.bp3-disabled, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-success.bp3-disabled,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-success.bp3-disabled, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-success.bp3-disabled{
        background:none;
        color:rgba(61, 204, 145, 0.5); }
        .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-success:disabled.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-success:disabled.bp3-active,
        .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-success:disabled.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-success:disabled.bp3-active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-success.bp3-disabled.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-success.bp3-disabled.bp3-active,
        .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-success.bp3-disabled.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-success.bp3-disabled.bp3-active{
          background:rgba(15, 153, 96, 0.3); }
  .bp3-html-select.bp3-minimal select.bp3-intent-warning,
  .bp3-select.bp3-minimal select.bp3-intent-warning{
    color:#bf7326; }
    .bp3-html-select.bp3-minimal select.bp3-intent-warning:hover,
    .bp3-select.bp3-minimal select.bp3-intent-warning:hover, .bp3-html-select.bp3-minimal select.bp3-intent-warning:active,
    .bp3-select.bp3-minimal select.bp3-intent-warning:active, .bp3-html-select.bp3-minimal select.bp3-intent-warning.bp3-active,
    .bp3-select.bp3-minimal select.bp3-intent-warning.bp3-active{
      background:none;
      -webkit-box-shadow:none;
              box-shadow:none;
      color:#bf7326; }
    .bp3-html-select.bp3-minimal select.bp3-intent-warning:hover,
    .bp3-select.bp3-minimal select.bp3-intent-warning:hover{
      background:rgba(217, 130, 43, 0.15);
      color:#bf7326; }
    .bp3-html-select.bp3-minimal select.bp3-intent-warning:active,
    .bp3-select.bp3-minimal select.bp3-intent-warning:active, .bp3-html-select.bp3-minimal select.bp3-intent-warning.bp3-active,
    .bp3-select.bp3-minimal select.bp3-intent-warning.bp3-active{
      background:rgba(217, 130, 43, 0.3);
      color:#bf7326; }
    .bp3-html-select.bp3-minimal select.bp3-intent-warning:disabled,
    .bp3-select.bp3-minimal select.bp3-intent-warning:disabled, .bp3-html-select.bp3-minimal select.bp3-intent-warning.bp3-disabled,
    .bp3-select.bp3-minimal select.bp3-intent-warning.bp3-disabled{
      background:none;
      color:rgba(191, 115, 38, 0.5); }
      .bp3-html-select.bp3-minimal select.bp3-intent-warning:disabled.bp3-active,
      .bp3-select.bp3-minimal select.bp3-intent-warning:disabled.bp3-active, .bp3-html-select.bp3-minimal select.bp3-intent-warning.bp3-disabled.bp3-active,
      .bp3-select.bp3-minimal select.bp3-intent-warning.bp3-disabled.bp3-active{
        background:rgba(217, 130, 43, 0.3); }
    .bp3-html-select.bp3-minimal select.bp3-intent-warning .bp3-button-spinner .bp3-spinner-head, .bp3-select.bp3-minimal select.bp3-intent-warning .bp3-button-spinner .bp3-spinner-head{
      stroke:#bf7326; }
    .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-warning, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-warning,
    .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-warning, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-warning{
      color:#ffb366; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-warning:hover, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-warning:hover,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-warning:hover, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-warning:hover{
        background:rgba(217, 130, 43, 0.2);
        color:#ffb366; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-warning:active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-warning:active,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-warning:active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-warning:active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-warning.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-warning.bp3-active,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-warning.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-warning.bp3-active{
        background:rgba(217, 130, 43, 0.3);
        color:#ffb366; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-warning:disabled, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-warning:disabled,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-warning:disabled, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-warning:disabled, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-warning.bp3-disabled, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-warning.bp3-disabled,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-warning.bp3-disabled, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-warning.bp3-disabled{
        background:none;
        color:rgba(255, 179, 102, 0.5); }
        .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-warning:disabled.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-warning:disabled.bp3-active,
        .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-warning:disabled.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-warning:disabled.bp3-active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-warning.bp3-disabled.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-warning.bp3-disabled.bp3-active,
        .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-warning.bp3-disabled.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-warning.bp3-disabled.bp3-active{
          background:rgba(217, 130, 43, 0.3); }
  .bp3-html-select.bp3-minimal select.bp3-intent-danger,
  .bp3-select.bp3-minimal select.bp3-intent-danger{
    color:#c23030; }
    .bp3-html-select.bp3-minimal select.bp3-intent-danger:hover,
    .bp3-select.bp3-minimal select.bp3-intent-danger:hover, .bp3-html-select.bp3-minimal select.bp3-intent-danger:active,
    .bp3-select.bp3-minimal select.bp3-intent-danger:active, .bp3-html-select.bp3-minimal select.bp3-intent-danger.bp3-active,
    .bp3-select.bp3-minimal select.bp3-intent-danger.bp3-active{
      background:none;
      -webkit-box-shadow:none;
              box-shadow:none;
      color:#c23030; }
    .bp3-html-select.bp3-minimal select.bp3-intent-danger:hover,
    .bp3-select.bp3-minimal select.bp3-intent-danger:hover{
      background:rgba(219, 55, 55, 0.15);
      color:#c23030; }
    .bp3-html-select.bp3-minimal select.bp3-intent-danger:active,
    .bp3-select.bp3-minimal select.bp3-intent-danger:active, .bp3-html-select.bp3-minimal select.bp3-intent-danger.bp3-active,
    .bp3-select.bp3-minimal select.bp3-intent-danger.bp3-active{
      background:rgba(219, 55, 55, 0.3);
      color:#c23030; }
    .bp3-html-select.bp3-minimal select.bp3-intent-danger:disabled,
    .bp3-select.bp3-minimal select.bp3-intent-danger:disabled, .bp3-html-select.bp3-minimal select.bp3-intent-danger.bp3-disabled,
    .bp3-select.bp3-minimal select.bp3-intent-danger.bp3-disabled{
      background:none;
      color:rgba(194, 48, 48, 0.5); }
      .bp3-html-select.bp3-minimal select.bp3-intent-danger:disabled.bp3-active,
      .bp3-select.bp3-minimal select.bp3-intent-danger:disabled.bp3-active, .bp3-html-select.bp3-minimal select.bp3-intent-danger.bp3-disabled.bp3-active,
      .bp3-select.bp3-minimal select.bp3-intent-danger.bp3-disabled.bp3-active{
        background:rgba(219, 55, 55, 0.3); }
    .bp3-html-select.bp3-minimal select.bp3-intent-danger .bp3-button-spinner .bp3-spinner-head, .bp3-select.bp3-minimal select.bp3-intent-danger .bp3-button-spinner .bp3-spinner-head{
      stroke:#c23030; }
    .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-danger, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-danger,
    .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-danger, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-danger{
      color:#ff7373; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-danger:hover, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-danger:hover,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-danger:hover, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-danger:hover{
        background:rgba(219, 55, 55, 0.2);
        color:#ff7373; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-danger:active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-danger:active,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-danger:active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-danger:active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-danger.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-danger.bp3-active,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-danger.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-danger.bp3-active{
        background:rgba(219, 55, 55, 0.3);
        color:#ff7373; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-danger:disabled, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-danger:disabled,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-danger:disabled, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-danger:disabled, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-danger.bp3-disabled, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-danger.bp3-disabled,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-danger.bp3-disabled, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-danger.bp3-disabled{
        background:none;
        color:rgba(255, 115, 115, 0.5); }
        .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-danger:disabled.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-danger:disabled.bp3-active,
        .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-danger:disabled.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-danger:disabled.bp3-active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-danger.bp3-disabled.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-danger.bp3-disabled.bp3-active,
        .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-danger.bp3-disabled.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-danger.bp3-disabled.bp3-active{
          background:rgba(219, 55, 55, 0.3); }

.bp3-html-select.bp3-large select,
.bp3-select.bp3-large select{
  font-size:16px;
  height:40px;
  padding-right:35px; }

.bp3-dark .bp3-html-select select, .bp3-dark .bp3-select select{
  background-color:#394b59;
  background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.05)), to(rgba(255, 255, 255, 0)));
  background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.05), rgba(255, 255, 255, 0));
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
  color:#f5f8fa; }
  .bp3-dark .bp3-html-select select:hover, .bp3-dark .bp3-select select:hover, .bp3-dark .bp3-html-select select:active, .bp3-dark .bp3-select select:active, .bp3-dark .bp3-html-select select.bp3-active, .bp3-dark .bp3-select select.bp3-active{
    color:#f5f8fa; }
  .bp3-dark .bp3-html-select select:hover, .bp3-dark .bp3-select select:hover{
    background-color:#30404d;
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4); }
  .bp3-dark .bp3-html-select select:active, .bp3-dark .bp3-select select:active, .bp3-dark .bp3-html-select select.bp3-active, .bp3-dark .bp3-select select.bp3-active{
    background-color:#202b33;
    background-image:none;
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2); }
  .bp3-dark .bp3-html-select select:disabled, .bp3-dark .bp3-select select:disabled, .bp3-dark .bp3-html-select select.bp3-disabled, .bp3-dark .bp3-select select.bp3-disabled{
    background-color:rgba(57, 75, 89, 0.5);
    background-image:none;
    -webkit-box-shadow:none;
            box-shadow:none;
    color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-html-select select:disabled.bp3-active, .bp3-dark .bp3-select select:disabled.bp3-active, .bp3-dark .bp3-html-select select.bp3-disabled.bp3-active, .bp3-dark .bp3-select select.bp3-disabled.bp3-active{
      background:rgba(57, 75, 89, 0.7); }
  .bp3-dark .bp3-html-select select .bp3-button-spinner .bp3-spinner-head, .bp3-dark .bp3-select select .bp3-button-spinner .bp3-spinner-head{
    background:rgba(16, 22, 26, 0.5);
    stroke:#8a9ba8; }

.bp3-html-select select:disabled,
.bp3-select select:disabled{
  background-color:rgba(206, 217, 224, 0.5);
  -webkit-box-shadow:none;
          box-shadow:none;
  color:rgba(92, 112, 128, 0.6);
  cursor:not-allowed; }

.bp3-html-select .bp3-icon,
.bp3-select .bp3-icon, .bp3-select::after{
  color:#5c7080;
  pointer-events:none;
  position:absolute;
  right:7px;
  top:7px; }
  .bp3-html-select .bp3-disabled.bp3-icon,
  .bp3-select .bp3-disabled.bp3-icon, .bp3-disabled.bp3-select::after{
    color:rgba(92, 112, 128, 0.6); }
.bp3-html-select,
.bp3-select{
  display:inline-block;
  letter-spacing:normal;
  position:relative;
  vertical-align:middle; }
  .bp3-html-select select::-ms-expand,
  .bp3-select select::-ms-expand{
    display:none; }
  .bp3-html-select .bp3-icon,
  .bp3-select .bp3-icon{
    color:#5c7080; }
    .bp3-html-select .bp3-icon:hover,
    .bp3-select .bp3-icon:hover{
      color:#182026; }
    .bp3-dark .bp3-html-select .bp3-icon, .bp3-dark
    .bp3-select .bp3-icon{
      color:#a7b6c2; }
      .bp3-dark .bp3-html-select .bp3-icon:hover, .bp3-dark
      .bp3-select .bp3-icon:hover{
        color:#f5f8fa; }
  .bp3-html-select.bp3-large::after,
  .bp3-html-select.bp3-large .bp3-icon,
  .bp3-select.bp3-large::after,
  .bp3-select.bp3-large .bp3-icon{
    right:12px;
    top:12px; }
  .bp3-html-select.bp3-fill,
  .bp3-html-select.bp3-fill select,
  .bp3-select.bp3-fill,
  .bp3-select.bp3-fill select{
    width:100%; }
  .bp3-dark .bp3-html-select option, .bp3-dark
  .bp3-select option{
    background-color:#30404d;
    color:#f5f8fa; }
  .bp3-dark .bp3-html-select option:disabled, .bp3-dark
  .bp3-select option:disabled{
    color:rgba(167, 182, 194, 0.6); }
  .bp3-dark .bp3-html-select::after, .bp3-dark
  .bp3-select::after{
    color:#a7b6c2; }

.bp3-select::after{
  font-family:"Icons16", sans-serif;
  font-size:16px;
  font-style:normal;
  font-weight:400;
  line-height:1;
  -moz-osx-font-smoothing:grayscale;
  -webkit-font-smoothing:antialiased;
  content:""; }
.bp3-running-text table, table.bp3-html-table{
  border-spacing:0;
  font-size:14px; }
  .bp3-running-text table th, table.bp3-html-table th,
  .bp3-running-text table td,
  table.bp3-html-table td{
    padding:11px;
    text-align:left;
    vertical-align:top; }
  .bp3-running-text table th, table.bp3-html-table th{
    color:#182026;
    font-weight:600; }
  
  .bp3-running-text table td,
  table.bp3-html-table td{
    color:#182026; }
  .bp3-running-text table tbody tr:first-child th, table.bp3-html-table tbody tr:first-child th,
  .bp3-running-text table tbody tr:first-child td,
  table.bp3-html-table tbody tr:first-child td{
    -webkit-box-shadow:inset 0 1px 0 0 rgba(16, 22, 26, 0.15);
            box-shadow:inset 0 1px 0 0 rgba(16, 22, 26, 0.15); }
  .bp3-dark .bp3-running-text table th, .bp3-running-text .bp3-dark table th, .bp3-dark table.bp3-html-table th{
    color:#f5f8fa; }
  .bp3-dark .bp3-running-text table td, .bp3-running-text .bp3-dark table td, .bp3-dark table.bp3-html-table td{
    color:#f5f8fa; }
  .bp3-dark .bp3-running-text table tbody tr:first-child th, .bp3-running-text .bp3-dark table tbody tr:first-child th, .bp3-dark table.bp3-html-table tbody tr:first-child th,
  .bp3-dark .bp3-running-text table tbody tr:first-child td,
  .bp3-running-text .bp3-dark table tbody tr:first-child td,
  .bp3-dark table.bp3-html-table tbody tr:first-child td{
    -webkit-box-shadow:inset 0 1px 0 0 rgba(255, 255, 255, 0.15);
            box-shadow:inset 0 1px 0 0 rgba(255, 255, 255, 0.15); }

table.bp3-html-table.bp3-html-table-condensed th,
table.bp3-html-table.bp3-html-table-condensed td, table.bp3-html-table.bp3-small th,
table.bp3-html-table.bp3-small td{
  padding-bottom:6px;
  padding-top:6px; }

table.bp3-html-table.bp3-html-table-striped tbody tr:nth-child(odd) td{
  background:rgba(191, 204, 214, 0.15); }

table.bp3-html-table.bp3-html-table-bordered th:not(:first-child){
  -webkit-box-shadow:inset 1px 0 0 0 rgba(16, 22, 26, 0.15);
          box-shadow:inset 1px 0 0 0 rgba(16, 22, 26, 0.15); }

table.bp3-html-table.bp3-html-table-bordered tbody tr td{
  -webkit-box-shadow:inset 0 1px 0 0 rgba(16, 22, 26, 0.15);
          box-shadow:inset 0 1px 0 0 rgba(16, 22, 26, 0.15); }
  table.bp3-html-table.bp3-html-table-bordered tbody tr td:not(:first-child){
    -webkit-box-shadow:inset 1px 1px 0 0 rgba(16, 22, 26, 0.15);
            box-shadow:inset 1px 1px 0 0 rgba(16, 22, 26, 0.15); }

table.bp3-html-table.bp3-html-table-bordered.bp3-html-table-striped tbody tr:not(:first-child) td{
  -webkit-box-shadow:none;
          box-shadow:none; }
  table.bp3-html-table.bp3-html-table-bordered.bp3-html-table-striped tbody tr:not(:first-child) td:not(:first-child){
    -webkit-box-shadow:inset 1px 0 0 0 rgba(16, 22, 26, 0.15);
            box-shadow:inset 1px 0 0 0 rgba(16, 22, 26, 0.15); }

table.bp3-html-table.bp3-interactive tbody tr:hover td{
  background-color:rgba(191, 204, 214, 0.3);
  cursor:pointer; }

table.bp3-html-table.bp3-interactive tbody tr:active td{
  background-color:rgba(191, 204, 214, 0.4); }

.bp3-dark table.bp3-html-table{ }
  .bp3-dark table.bp3-html-table.bp3-html-table-striped tbody tr:nth-child(odd) td{
    background:rgba(92, 112, 128, 0.15); }
  .bp3-dark table.bp3-html-table.bp3-html-table-bordered th:not(:first-child){
    -webkit-box-shadow:inset 1px 0 0 0 rgba(255, 255, 255, 0.15);
            box-shadow:inset 1px 0 0 0 rgba(255, 255, 255, 0.15); }
  .bp3-dark table.bp3-html-table.bp3-html-table-bordered tbody tr td{
    -webkit-box-shadow:inset 0 1px 0 0 rgba(255, 255, 255, 0.15);
            box-shadow:inset 0 1px 0 0 rgba(255, 255, 255, 0.15); }
    .bp3-dark table.bp3-html-table.bp3-html-table-bordered tbody tr td:not(:first-child){
      -webkit-box-shadow:inset 1px 1px 0 0 rgba(255, 255, 255, 0.15);
              box-shadow:inset 1px 1px 0 0 rgba(255, 255, 255, 0.15); }
  .bp3-dark table.bp3-html-table.bp3-html-table-bordered.bp3-html-table-striped tbody tr:not(:first-child) td{
    -webkit-box-shadow:inset 1px 0 0 0 rgba(255, 255, 255, 0.15);
            box-shadow:inset 1px 0 0 0 rgba(255, 255, 255, 0.15); }
    .bp3-dark table.bp3-html-table.bp3-html-table-bordered.bp3-html-table-striped tbody tr:not(:first-child) td:first-child{
      -webkit-box-shadow:none;
              box-shadow:none; }
  .bp3-dark table.bp3-html-table.bp3-interactive tbody tr:hover td{
    background-color:rgba(92, 112, 128, 0.3);
    cursor:pointer; }
  .bp3-dark table.bp3-html-table.bp3-interactive tbody tr:active td{
    background-color:rgba(92, 112, 128, 0.4); }

.bp3-key-combo{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-orient:horizontal;
  -webkit-box-direction:normal;
      -ms-flex-direction:row;
          flex-direction:row;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center; }
  .bp3-key-combo > *{
    -webkit-box-flex:0;
        -ms-flex-positive:0;
            flex-grow:0;
    -ms-flex-negative:0;
        flex-shrink:0; }
  .bp3-key-combo > .bp3-fill{
    -webkit-box-flex:1;
        -ms-flex-positive:1;
            flex-grow:1;
    -ms-flex-negative:1;
        flex-shrink:1; }
  .bp3-key-combo::before,
  .bp3-key-combo > *{
    margin-right:5px; }
  .bp3-key-combo:empty::before,
  .bp3-key-combo > :last-child{
    margin-right:0; }

.bp3-hotkey-dialog{
  padding-bottom:0;
  top:40px; }
  .bp3-hotkey-dialog .bp3-dialog-body{
    margin:0;
    padding:0; }
  .bp3-hotkey-dialog .bp3-hotkey-label{
    -webkit-box-flex:1;
        -ms-flex-positive:1;
            flex-grow:1; }

.bp3-hotkey-column{
  margin:auto;
  max-height:80vh;
  overflow-y:auto;
  padding:30px; }
  .bp3-hotkey-column .bp3-heading{
    margin-bottom:20px; }
    .bp3-hotkey-column .bp3-heading:not(:first-child){
      margin-top:40px; }

.bp3-hotkey{
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-pack:justify;
      -ms-flex-pack:justify;
          justify-content:space-between;
  margin-left:0;
  margin-right:0; }
  .bp3-hotkey:not(:last-child){
    margin-bottom:10px; }
.bp3-icon{
  display:inline-block;
  -webkit-box-flex:0;
      -ms-flex:0 0 auto;
          flex:0 0 auto;
  vertical-align:text-bottom; }
  .bp3-icon:not(:empty)::before{
    content:"" !important;
    content:unset !important; }
  .bp3-icon > svg{
    display:block; }
    .bp3-icon > svg:not([fill]){
      fill:currentColor; }

.bp3-icon.bp3-intent-primary, .bp3-icon-standard.bp3-intent-primary, .bp3-icon-large.bp3-intent-primary{
  color:#106ba3; }
  .bp3-dark .bp3-icon.bp3-intent-primary, .bp3-dark .bp3-icon-standard.bp3-intent-primary, .bp3-dark .bp3-icon-large.bp3-intent-primary{
    color:#48aff0; }

.bp3-icon.bp3-intent-success, .bp3-icon-standard.bp3-intent-success, .bp3-icon-large.bp3-intent-success{
  color:#0d8050; }
  .bp3-dark .bp3-icon.bp3-intent-success, .bp3-dark .bp3-icon-standard.bp3-intent-success, .bp3-dark .bp3-icon-large.bp3-intent-success{
    color:#3dcc91; }

.bp3-icon.bp3-intent-warning, .bp3-icon-standard.bp3-intent-warning, .bp3-icon-large.bp3-intent-warning{
  color:#bf7326; }
  .bp3-dark .bp3-icon.bp3-intent-warning, .bp3-dark .bp3-icon-standard.bp3-intent-warning, .bp3-dark .bp3-icon-large.bp3-intent-warning{
    color:#ffb366; }

.bp3-icon.bp3-intent-danger, .bp3-icon-standard.bp3-intent-danger, .bp3-icon-large.bp3-intent-danger{
  color:#c23030; }
  .bp3-dark .bp3-icon.bp3-intent-danger, .bp3-dark .bp3-icon-standard.bp3-intent-danger, .bp3-dark .bp3-icon-large.bp3-intent-danger{
    color:#ff7373; }

span.bp3-icon-standard{
  font-family:"Icons16", sans-serif;
  font-size:16px;
  font-style:normal;
  font-weight:400;
  line-height:1;
  -moz-osx-font-smoothing:grayscale;
  -webkit-font-smoothing:antialiased;
  display:inline-block; }

span.bp3-icon-large{
  font-family:"Icons20", sans-serif;
  font-size:20px;
  font-style:normal;
  font-weight:400;
  line-height:1;
  -moz-osx-font-smoothing:grayscale;
  -webkit-font-smoothing:antialiased;
  display:inline-block; }

span.bp3-icon:empty{
  font-family:"Icons20";
  font-size:inherit;
  font-style:normal;
  font-weight:400;
  line-height:1; }
  span.bp3-icon:empty::before{
    -moz-osx-font-smoothing:grayscale;
    -webkit-font-smoothing:antialiased; }

.bp3-icon-add::before{
  content:""; }

.bp3-icon-add-column-left::before{
  content:""; }

.bp3-icon-add-column-right::before{
  content:""; }

.bp3-icon-add-row-bottom::before{
  content:""; }

.bp3-icon-add-row-top::before{
  content:""; }

.bp3-icon-add-to-artifact::before{
  content:""; }

.bp3-icon-add-to-folder::before{
  content:""; }

.bp3-icon-airplane::before{
  content:""; }

.bp3-icon-align-center::before{
  content:""; }

.bp3-icon-align-justify::before{
  content:""; }

.bp3-icon-align-left::before{
  content:""; }

.bp3-icon-align-right::before{
  content:""; }

.bp3-icon-alignment-bottom::before{
  content:""; }

.bp3-icon-alignment-horizontal-center::before{
  content:""; }

.bp3-icon-alignment-left::before{
  content:""; }

.bp3-icon-alignment-right::before{
  content:""; }

.bp3-icon-alignment-top::before{
  content:""; }

.bp3-icon-alignment-vertical-center::before{
  content:""; }

.bp3-icon-annotation::before{
  content:""; }

.bp3-icon-application::before{
  content:""; }

.bp3-icon-applications::before{
  content:""; }

.bp3-icon-archive::before{
  content:""; }

.bp3-icon-arrow-bottom-left::before{
  content:""; }

.bp3-icon-arrow-bottom-right::before{
  content:""; }

.bp3-icon-arrow-down::before{
  content:""; }

.bp3-icon-arrow-left::before{
  content:""; }

.bp3-icon-arrow-right::before{
  content:""; }

.bp3-icon-arrow-top-left::before{
  content:""; }

.bp3-icon-arrow-top-right::before{
  content:""; }

.bp3-icon-arrow-up::before{
  content:""; }

.bp3-icon-arrows-horizontal::before{
  content:""; }

.bp3-icon-arrows-vertical::before{
  content:""; }

.bp3-icon-asterisk::before{
  content:"*"; }

.bp3-icon-automatic-updates::before{
  content:""; }

.bp3-icon-badge::before{
  content:""; }

.bp3-icon-ban-circle::before{
  content:""; }

.bp3-icon-bank-account::before{
  content:""; }

.bp3-icon-barcode::before{
  content:""; }

.bp3-icon-blank::before{
  content:""; }

.bp3-icon-blocked-person::before{
  content:""; }

.bp3-icon-bold::before{
  content:""; }

.bp3-icon-book::before{
  content:""; }

.bp3-icon-bookmark::before{
  content:""; }

.bp3-icon-box::before{
  content:""; }

.bp3-icon-briefcase::before{
  content:""; }

.bp3-icon-bring-data::before{
  content:""; }

.bp3-icon-build::before{
  content:""; }

.bp3-icon-calculator::before{
  content:""; }

.bp3-icon-calendar::before{
  content:""; }

.bp3-icon-camera::before{
  content:""; }

.bp3-icon-caret-down::before{
  content:""; }

.bp3-icon-caret-left::before{
  content:""; }

.bp3-icon-caret-right::before{
  content:""; }

.bp3-icon-caret-up::before{
  content:""; }

.bp3-icon-cell-tower::before{
  content:""; }

.bp3-icon-changes::before{
  content:""; }

.bp3-icon-chart::before{
  content:""; }

.bp3-icon-chat::before{
  content:""; }

.bp3-icon-chevron-backward::before{
  content:""; }

.bp3-icon-chevron-down::before{
  content:""; }

.bp3-icon-chevron-forward::before{
  content:""; }

.bp3-icon-chevron-left::before{
  content:""; }

.bp3-icon-chevron-right::before{
  content:""; }

.bp3-icon-chevron-up::before{
  content:""; }

.bp3-icon-circle::before{
  content:""; }

.bp3-icon-circle-arrow-down::before{
  content:""; }

.bp3-icon-circle-arrow-left::before{
  content:""; }

.bp3-icon-circle-arrow-right::before{
  content:""; }

.bp3-icon-circle-arrow-up::before{
  content:""; }

.bp3-icon-citation::before{
  content:""; }

.bp3-icon-clean::before{
  content:""; }

.bp3-icon-clipboard::before{
  content:""; }

.bp3-icon-cloud::before{
  content:""; }

.bp3-icon-cloud-download::before{
  content:""; }

.bp3-icon-cloud-upload::before{
  content:""; }

.bp3-icon-code::before{
  content:""; }

.bp3-icon-code-block::before{
  content:""; }

.bp3-icon-cog::before{
  content:""; }

.bp3-icon-collapse-all::before{
  content:""; }

.bp3-icon-column-layout::before{
  content:""; }

.bp3-icon-comment::before{
  content:""; }

.bp3-icon-comparison::before{
  content:""; }

.bp3-icon-compass::before{
  content:""; }

.bp3-icon-compressed::before{
  content:""; }

.bp3-icon-confirm::before{
  content:""; }

.bp3-icon-console::before{
  content:""; }

.bp3-icon-contrast::before{
  content:""; }

.bp3-icon-control::before{
  content:""; }

.bp3-icon-credit-card::before{
  content:""; }

.bp3-icon-cross::before{
  content:""; }

.bp3-icon-crown::before{
  content:""; }

.bp3-icon-cube::before{
  content:""; }

.bp3-icon-cube-add::before{
  content:""; }

.bp3-icon-cube-remove::before{
  content:""; }

.bp3-icon-curved-range-chart::before{
  content:""; }

.bp3-icon-cut::before{
  content:""; }

.bp3-icon-dashboard::before{
  content:""; }

.bp3-icon-data-lineage::before{
  content:""; }

.bp3-icon-database::before{
  content:""; }

.bp3-icon-delete::before{
  content:""; }

.bp3-icon-delta::before{
  content:""; }

.bp3-icon-derive-column::before{
  content:""; }

.bp3-icon-desktop::before{
  content:""; }

.bp3-icon-diagnosis::before{
  content:""; }

.bp3-icon-diagram-tree::before{
  content:""; }

.bp3-icon-direction-left::before{
  content:""; }

.bp3-icon-direction-right::before{
  content:""; }

.bp3-icon-disable::before{
  content:""; }

.bp3-icon-document::before{
  content:""; }

.bp3-icon-document-open::before{
  content:""; }

.bp3-icon-document-share::before{
  content:""; }

.bp3-icon-dollar::before{
  content:"$"; }

.bp3-icon-dot::before{
  content:""; }

.bp3-icon-double-caret-horizontal::before{
  content:""; }

.bp3-icon-double-caret-vertical::before{
  content:""; }

.bp3-icon-double-chevron-down::before{
  content:""; }

.bp3-icon-double-chevron-left::before{
  content:""; }

.bp3-icon-double-chevron-right::before{
  content:""; }

.bp3-icon-double-chevron-up::before{
  content:""; }

.bp3-icon-doughnut-chart::before{
  content:""; }

.bp3-icon-download::before{
  content:""; }

.bp3-icon-drag-handle-horizontal::before{
  content:""; }

.bp3-icon-drag-handle-vertical::before{
  content:""; }

.bp3-icon-draw::before{
  content:""; }

.bp3-icon-drive-time::before{
  content:""; }

.bp3-icon-duplicate::before{
  content:""; }

.bp3-icon-edit::before{
  content:""; }

.bp3-icon-eject::before{
  content:""; }

.bp3-icon-endorsed::before{
  content:""; }

.bp3-icon-envelope::before{
  content:""; }

.bp3-icon-equals::before{
  content:""; }

.bp3-icon-eraser::before{
  content:""; }

.bp3-icon-error::before{
  content:""; }

.bp3-icon-euro::before{
  content:""; }

.bp3-icon-exchange::before{
  content:""; }

.bp3-icon-exclude-row::before{
  content:""; }

.bp3-icon-expand-all::before{
  content:""; }

.bp3-icon-export::before{
  content:""; }

.bp3-icon-eye-off::before{
  content:""; }

.bp3-icon-eye-on::before{
  content:""; }

.bp3-icon-eye-open::before{
  content:""; }

.bp3-icon-fast-backward::before{
  content:""; }

.bp3-icon-fast-forward::before{
  content:""; }

.bp3-icon-feed::before{
  content:""; }

.bp3-icon-feed-subscribed::before{
  content:""; }

.bp3-icon-film::before{
  content:""; }

.bp3-icon-filter::before{
  content:""; }

.bp3-icon-filter-keep::before{
  content:""; }

.bp3-icon-filter-list::before{
  content:""; }

.bp3-icon-filter-open::before{
  content:""; }

.bp3-icon-filter-remove::before{
  content:""; }

.bp3-icon-flag::before{
  content:""; }

.bp3-icon-flame::before{
  content:""; }

.bp3-icon-flash::before{
  content:""; }

.bp3-icon-floppy-disk::before{
  content:""; }

.bp3-icon-flow-branch::before{
  content:""; }

.bp3-icon-flow-end::before{
  content:""; }

.bp3-icon-flow-linear::before{
  content:""; }

.bp3-icon-flow-review::before{
  content:""; }

.bp3-icon-flow-review-branch::before{
  content:""; }

.bp3-icon-flows::before{
  content:""; }

.bp3-icon-folder-close::before{
  content:""; }

.bp3-icon-folder-new::before{
  content:""; }

.bp3-icon-folder-open::before{
  content:""; }

.bp3-icon-folder-shared::before{
  content:""; }

.bp3-icon-folder-shared-open::before{
  content:""; }

.bp3-icon-follower::before{
  content:""; }

.bp3-icon-following::before{
  content:""; }

.bp3-icon-font::before{
  content:""; }

.bp3-icon-fork::before{
  content:""; }

.bp3-icon-form::before{
  content:""; }

.bp3-icon-full-circle::before{
  content:""; }

.bp3-icon-full-stacked-chart::before{
  content:""; }

.bp3-icon-fullscreen::before{
  content:""; }

.bp3-icon-function::before{
  content:""; }

.bp3-icon-gantt-chart::before{
  content:""; }

.bp3-icon-geolocation::before{
  content:""; }

.bp3-icon-geosearch::before{
  content:""; }

.bp3-icon-git-branch::before{
  content:""; }

.bp3-icon-git-commit::before{
  content:""; }

.bp3-icon-git-merge::before{
  content:""; }

.bp3-icon-git-new-branch::before{
  content:""; }

.bp3-icon-git-pull::before{
  content:""; }

.bp3-icon-git-push::before{
  content:""; }

.bp3-icon-git-repo::before{
  content:""; }

.bp3-icon-glass::before{
  content:""; }

.bp3-icon-globe::before{
  content:""; }

.bp3-icon-globe-network::before{
  content:""; }

.bp3-icon-graph::before{
  content:""; }

.bp3-icon-graph-remove::before{
  content:""; }

.bp3-icon-greater-than::before{
  content:""; }

.bp3-icon-greater-than-or-equal-to::before{
  content:""; }

.bp3-icon-grid::before{
  content:""; }

.bp3-icon-grid-view::before{
  content:""; }

.bp3-icon-group-objects::before{
  content:""; }

.bp3-icon-grouped-bar-chart::before{
  content:""; }

.bp3-icon-hand::before{
  content:""; }

.bp3-icon-hand-down::before{
  content:""; }

.bp3-icon-hand-left::before{
  content:""; }

.bp3-icon-hand-right::before{
  content:""; }

.bp3-icon-hand-up::before{
  content:""; }

.bp3-icon-header::before{
  content:""; }

.bp3-icon-header-one::before{
  content:""; }

.bp3-icon-header-two::before{
  content:""; }

.bp3-icon-headset::before{
  content:""; }

.bp3-icon-heart::before{
  content:""; }

.bp3-icon-heart-broken::before{
  content:""; }

.bp3-icon-heat-grid::before{
  content:""; }

.bp3-icon-heatmap::before{
  content:""; }

.bp3-icon-help::before{
  content:"?"; }

.bp3-icon-helper-management::before{
  content:""; }

.bp3-icon-highlight::before{
  content:""; }

.bp3-icon-history::before{
  content:""; }

.bp3-icon-home::before{
  content:""; }

.bp3-icon-horizontal-bar-chart::before{
  content:""; }

.bp3-icon-horizontal-bar-chart-asc::before{
  content:""; }

.bp3-icon-horizontal-bar-chart-desc::before{
  content:""; }

.bp3-icon-horizontal-distribution::before{
  content:""; }

.bp3-icon-id-number::before{
  content:""; }

.bp3-icon-image-rotate-left::before{
  content:""; }

.bp3-icon-image-rotate-right::before{
  content:""; }

.bp3-icon-import::before{
  content:""; }

.bp3-icon-inbox::before{
  content:""; }

.bp3-icon-inbox-filtered::before{
  content:""; }

.bp3-icon-inbox-geo::before{
  content:""; }

.bp3-icon-inbox-search::before{
  content:""; }

.bp3-icon-inbox-update::before{
  content:""; }

.bp3-icon-info-sign::before{
  content:""; }

.bp3-icon-inheritance::before{
  content:""; }

.bp3-icon-inner-join::before{
  content:""; }

.bp3-icon-insert::before{
  content:""; }

.bp3-icon-intersection::before{
  content:""; }

.bp3-icon-ip-address::before{
  content:""; }

.bp3-icon-issue::before{
  content:""; }

.bp3-icon-issue-closed::before{
  content:""; }

.bp3-icon-issue-new::before{
  content:""; }

.bp3-icon-italic::before{
  content:""; }

.bp3-icon-join-table::before{
  content:""; }

.bp3-icon-key::before{
  content:""; }

.bp3-icon-key-backspace::before{
  content:""; }

.bp3-icon-key-command::before{
  content:""; }

.bp3-icon-key-control::before{
  content:""; }

.bp3-icon-key-delete::before{
  content:""; }

.bp3-icon-key-enter::before{
  content:""; }

.bp3-icon-key-escape::before{
  content:""; }

.bp3-icon-key-option::before{
  content:""; }

.bp3-icon-key-shift::before{
  content:""; }

.bp3-icon-key-tab::before{
  content:""; }

.bp3-icon-known-vehicle::before{
  content:""; }

.bp3-icon-lab-test::before{
  content:""; }

.bp3-icon-label::before{
  content:""; }

.bp3-icon-layer::before{
  content:""; }

.bp3-icon-layers::before{
  content:""; }

.bp3-icon-layout::before{
  content:""; }

.bp3-icon-layout-auto::before{
  content:""; }

.bp3-icon-layout-balloon::before{
  content:""; }

.bp3-icon-layout-circle::before{
  content:""; }

.bp3-icon-layout-grid::before{
  content:""; }

.bp3-icon-layout-group-by::before{
  content:""; }

.bp3-icon-layout-hierarchy::before{
  content:""; }

.bp3-icon-layout-linear::before{
  content:""; }

.bp3-icon-layout-skew-grid::before{
  content:""; }

.bp3-icon-layout-sorted-clusters::before{
  content:""; }

.bp3-icon-learning::before{
  content:""; }

.bp3-icon-left-join::before{
  content:""; }

.bp3-icon-less-than::before{
  content:""; }

.bp3-icon-less-than-or-equal-to::before{
  content:""; }

.bp3-icon-lifesaver::before{
  content:""; }

.bp3-icon-lightbulb::before{
  content:""; }

.bp3-icon-link::before{
  content:""; }

.bp3-icon-list::before{
  content:""; }

.bp3-icon-list-columns::before{
  content:""; }

.bp3-icon-list-detail-view::before{
  content:""; }

.bp3-icon-locate::before{
  content:""; }

.bp3-icon-lock::before{
  content:""; }

.bp3-icon-log-in::before{
  content:""; }

.bp3-icon-log-out::before{
  content:""; }

.bp3-icon-manual::before{
  content:""; }

.bp3-icon-manually-entered-data::before{
  content:""; }

.bp3-icon-map::before{
  content:""; }

.bp3-icon-map-create::before{
  content:""; }

.bp3-icon-map-marker::before{
  content:""; }

.bp3-icon-maximize::before{
  content:""; }

.bp3-icon-media::before{
  content:""; }

.bp3-icon-menu::before{
  content:""; }

.bp3-icon-menu-closed::before{
  content:""; }

.bp3-icon-menu-open::before{
  content:""; }

.bp3-icon-merge-columns::before{
  content:""; }

.bp3-icon-merge-links::before{
  content:""; }

.bp3-icon-minimize::before{
  content:""; }

.bp3-icon-minus::before{
  content:""; }

.bp3-icon-mobile-phone::before{
  content:""; }

.bp3-icon-mobile-video::before{
  content:""; }

.bp3-icon-moon::before{
  content:""; }

.bp3-icon-more::before{
  content:""; }

.bp3-icon-mountain::before{
  content:""; }

.bp3-icon-move::before{
  content:""; }

.bp3-icon-mugshot::before{
  content:""; }

.bp3-icon-multi-select::before{
  content:""; }

.bp3-icon-music::before{
  content:""; }

.bp3-icon-new-drawing::before{
  content:""; }

.bp3-icon-new-grid-item::before{
  content:""; }

.bp3-icon-new-layer::before{
  content:""; }

.bp3-icon-new-layers::before{
  content:""; }

.bp3-icon-new-link::before{
  content:""; }

.bp3-icon-new-object::before{
  content:""; }

.bp3-icon-new-person::before{
  content:""; }

.bp3-icon-new-prescription::before{
  content:""; }

.bp3-icon-new-text-box::before{
  content:""; }

.bp3-icon-ninja::before{
  content:""; }

.bp3-icon-not-equal-to::before{
  content:""; }

.bp3-icon-notifications::before{
  content:""; }

.bp3-icon-notifications-updated::before{
  content:""; }

.bp3-icon-numbered-list::before{
  content:""; }

.bp3-icon-numerical::before{
  content:""; }

.bp3-icon-office::before{
  content:""; }

.bp3-icon-offline::before{
  content:""; }

.bp3-icon-oil-field::before{
  content:""; }

.bp3-icon-one-column::before{
  content:""; }

.bp3-icon-outdated::before{
  content:""; }

.bp3-icon-page-layout::before{
  content:""; }

.bp3-icon-panel-stats::before{
  content:""; }

.bp3-icon-panel-table::before{
  content:""; }

.bp3-icon-paperclip::before{
  content:""; }

.bp3-icon-paragraph::before{
  content:""; }

.bp3-icon-path::before{
  content:""; }

.bp3-icon-path-search::before{
  content:""; }

.bp3-icon-pause::before{
  content:""; }

.bp3-icon-people::before{
  content:""; }

.bp3-icon-percentage::before{
  content:""; }

.bp3-icon-person::before{
  content:""; }

.bp3-icon-phone::before{
  content:""; }

.bp3-icon-pie-chart::before{
  content:""; }

.bp3-icon-pin::before{
  content:""; }

.bp3-icon-pivot::before{
  content:""; }

.bp3-icon-pivot-table::before{
  content:""; }

.bp3-icon-play::before{
  content:""; }

.bp3-icon-plus::before{
  content:"+"; }

.bp3-icon-polygon-filter::before{
  content:""; }

.bp3-icon-power::before{
  content:""; }

.bp3-icon-predictive-analysis::before{
  content:""; }

.bp3-icon-prescription::before{
  content:""; }

.bp3-icon-presentation::before{
  content:""; }

.bp3-icon-print::before{
  content:""; }

.bp3-icon-projects::before{
  content:""; }

.bp3-icon-properties::before{
  content:""; }

.bp3-icon-property::before{
  content:""; }

.bp3-icon-publish-function::before{
  content:""; }

.bp3-icon-pulse::before{
  content:""; }

.bp3-icon-random::before{
  content:""; }

.bp3-icon-record::before{
  content:""; }

.bp3-icon-redo::before{
  content:""; }

.bp3-icon-refresh::before{
  content:""; }

.bp3-icon-regression-chart::before{
  content:""; }

.bp3-icon-remove::before{
  content:""; }

.bp3-icon-remove-column::before{
  content:""; }

.bp3-icon-remove-column-left::before{
  content:""; }

.bp3-icon-remove-column-right::before{
  content:""; }

.bp3-icon-remove-row-bottom::before{
  content:""; }

.bp3-icon-remove-row-top::before{
  content:""; }

.bp3-icon-repeat::before{
  content:""; }

.bp3-icon-reset::before{
  content:""; }

.bp3-icon-resolve::before{
  content:""; }

.bp3-icon-rig::before{
  content:""; }

.bp3-icon-right-join::before{
  content:""; }

.bp3-icon-ring::before{
  content:""; }

.bp3-icon-rotate-document::before{
  content:""; }

.bp3-icon-rotate-page::before{
  content:""; }

.bp3-icon-satellite::before{
  content:""; }

.bp3-icon-saved::before{
  content:""; }

.bp3-icon-scatter-plot::before{
  content:""; }

.bp3-icon-search::before{
  content:""; }

.bp3-icon-search-around::before{
  content:""; }

.bp3-icon-search-template::before{
  content:""; }

.bp3-icon-search-text::before{
  content:""; }

.bp3-icon-segmented-control::before{
  content:""; }

.bp3-icon-select::before{
  content:""; }

.bp3-icon-selection::before{
  content:""; }

.bp3-icon-send-to::before{
  content:""; }

.bp3-icon-send-to-graph::before{
  content:""; }

.bp3-icon-send-to-map::before{
  content:""; }

.bp3-icon-series-add::before{
  content:""; }

.bp3-icon-series-configuration::before{
  content:""; }

.bp3-icon-series-derived::before{
  content:""; }

.bp3-icon-series-filtered::before{
  content:""; }

.bp3-icon-series-search::before{
  content:""; }

.bp3-icon-settings::before{
  content:""; }

.bp3-icon-share::before{
  content:""; }

.bp3-icon-shield::before{
  content:""; }

.bp3-icon-shop::before{
  content:""; }

.bp3-icon-shopping-cart::before{
  content:""; }

.bp3-icon-signal-search::before{
  content:""; }

.bp3-icon-sim-card::before{
  content:""; }

.bp3-icon-slash::before{
  content:""; }

.bp3-icon-small-cross::before{
  content:""; }

.bp3-icon-small-minus::before{
  content:""; }

.bp3-icon-small-plus::before{
  content:""; }

.bp3-icon-small-tick::before{
  content:""; }

.bp3-icon-snowflake::before{
  content:""; }

.bp3-icon-social-media::before{
  content:""; }

.bp3-icon-sort::before{
  content:""; }

.bp3-icon-sort-alphabetical::before{
  content:""; }

.bp3-icon-sort-alphabetical-desc::before{
  content:""; }

.bp3-icon-sort-asc::before{
  content:""; }

.bp3-icon-sort-desc::before{
  content:""; }

.bp3-icon-sort-numerical::before{
  content:""; }

.bp3-icon-sort-numerical-desc::before{
  content:""; }

.bp3-icon-split-columns::before{
  content:""; }

.bp3-icon-square::before{
  content:""; }

.bp3-icon-stacked-chart::before{
  content:""; }

.bp3-icon-star::before{
  content:""; }

.bp3-icon-star-empty::before{
  content:""; }

.bp3-icon-step-backward::before{
  content:""; }

.bp3-icon-step-chart::before{
  content:""; }

.bp3-icon-step-forward::before{
  content:""; }

.bp3-icon-stop::before{
  content:""; }

.bp3-icon-stopwatch::before{
  content:""; }

.bp3-icon-strikethrough::before{
  content:""; }

.bp3-icon-style::before{
  content:""; }

.bp3-icon-swap-horizontal::before{
  content:""; }

.bp3-icon-swap-vertical::before{
  content:""; }

.bp3-icon-symbol-circle::before{
  content:""; }

.bp3-icon-symbol-cross::before{
  content:""; }

.bp3-icon-symbol-diamond::before{
  content:""; }

.bp3-icon-symbol-square::before{
  content:""; }

.bp3-icon-symbol-triangle-down::before{
  content:""; }

.bp3-icon-symbol-triangle-up::before{
  content:""; }

.bp3-icon-tag::before{
  content:""; }

.bp3-icon-take-action::before{
  content:""; }

.bp3-icon-taxi::before{
  content:""; }

.bp3-icon-text-highlight::before{
  content:""; }

.bp3-icon-th::before{
  content:""; }

.bp3-icon-th-derived::before{
  content:""; }

.bp3-icon-th-disconnect::before{
  content:""; }

.bp3-icon-th-filtered::before{
  content:""; }

.bp3-icon-th-list::before{
  content:""; }

.bp3-icon-thumbs-down::before{
  content:""; }

.bp3-icon-thumbs-up::before{
  content:""; }

.bp3-icon-tick::before{
  content:""; }

.bp3-icon-tick-circle::before{
  content:""; }

.bp3-icon-time::before{
  content:""; }

.bp3-icon-timeline-area-chart::before{
  content:""; }

.bp3-icon-timeline-bar-chart::before{
  content:""; }

.bp3-icon-timeline-events::before{
  content:""; }

.bp3-icon-timeline-line-chart::before{
  content:""; }

.bp3-icon-tint::before{
  content:""; }

.bp3-icon-torch::before{
  content:""; }

.bp3-icon-tractor::before{
  content:""; }

.bp3-icon-train::before{
  content:""; }

.bp3-icon-translate::before{
  content:""; }

.bp3-icon-trash::before{
  content:""; }

.bp3-icon-tree::before{
  content:""; }

.bp3-icon-trending-down::before{
  content:""; }

.bp3-icon-trending-up::before{
  content:""; }

.bp3-icon-truck::before{
  content:""; }

.bp3-icon-two-columns::before{
  content:""; }

.bp3-icon-unarchive::before{
  content:""; }

.bp3-icon-underline::before{
  content:""; }

.bp3-icon-undo::before{
  content:""; }

.bp3-icon-ungroup-objects::before{
  content:""; }

.bp3-icon-unknown-vehicle::before{
  content:""; }

.bp3-icon-unlock::before{
  content:""; }

.bp3-icon-unpin::before{
  content:""; }

.bp3-icon-unresolve::before{
  content:""; }

.bp3-icon-updated::before{
  content:""; }

.bp3-icon-upload::before{
  content:""; }

.bp3-icon-user::before{
  content:""; }

.bp3-icon-variable::before{
  content:""; }

.bp3-icon-vertical-bar-chart-asc::before{
  content:""; }

.bp3-icon-vertical-bar-chart-desc::before{
  content:""; }

.bp3-icon-vertical-distribution::before{
  content:""; }

.bp3-icon-video::before{
  content:""; }

.bp3-icon-volume-down::before{
  content:""; }

.bp3-icon-volume-off::before{
  content:""; }

.bp3-icon-volume-up::before{
  content:""; }

.bp3-icon-walk::before{
  content:""; }

.bp3-icon-warning-sign::before{
  content:""; }

.bp3-icon-waterfall-chart::before{
  content:""; }

.bp3-icon-widget::before{
  content:""; }

.bp3-icon-widget-button::before{
  content:""; }

.bp3-icon-widget-footer::before{
  content:""; }

.bp3-icon-widget-header::before{
  content:""; }

.bp3-icon-wrench::before{
  content:""; }

.bp3-icon-zoom-in::before{
  content:""; }

.bp3-icon-zoom-out::before{
  content:""; }

.bp3-icon-zoom-to-fit::before{
  content:""; }
.bp3-submenu > .bp3-popover-wrapper{
  display:block; }

.bp3-submenu .bp3-popover-target{
  display:block; }
  .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-menu-item{ }

.bp3-submenu.bp3-popover{
  -webkit-box-shadow:none;
          box-shadow:none;
  padding:0 5px; }
  .bp3-submenu.bp3-popover > .bp3-popover-content{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2); }
  .bp3-dark .bp3-submenu.bp3-popover, .bp3-submenu.bp3-popover.bp3-dark{
    -webkit-box-shadow:none;
            box-shadow:none; }
    .bp3-dark .bp3-submenu.bp3-popover > .bp3-popover-content, .bp3-submenu.bp3-popover.bp3-dark > .bp3-popover-content{
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4); }
.bp3-menu{
  background:#ffffff;
  border-radius:3px;
  color:#182026;
  list-style:none;
  margin:0;
  min-width:180px;
  padding:5px;
  text-align:left; }

.bp3-menu-divider{
  border-top:1px solid rgba(16, 22, 26, 0.15);
  display:block;
  margin:5px; }
  .bp3-dark .bp3-menu-divider{
    border-top-color:rgba(255, 255, 255, 0.15); }

.bp3-menu-item{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-orient:horizontal;
  -webkit-box-direction:normal;
      -ms-flex-direction:row;
          flex-direction:row;
  -webkit-box-align:start;
      -ms-flex-align:start;
          align-items:flex-start;
  border-radius:2px;
  color:inherit;
  line-height:20px;
  padding:5px 7px;
  text-decoration:none;
  -webkit-user-select:none;
     -moz-user-select:none;
      -ms-user-select:none;
          user-select:none; }
  .bp3-menu-item > *{
    -webkit-box-flex:0;
        -ms-flex-positive:0;
            flex-grow:0;
    -ms-flex-negative:0;
        flex-shrink:0; }
  .bp3-menu-item > .bp3-fill{
    -webkit-box-flex:1;
        -ms-flex-positive:1;
            flex-grow:1;
    -ms-flex-negative:1;
        flex-shrink:1; }
  .bp3-menu-item::before,
  .bp3-menu-item > *{
    margin-right:7px; }
  .bp3-menu-item:empty::before,
  .bp3-menu-item > :last-child{
    margin-right:0; }
  .bp3-menu-item > .bp3-fill{
    word-break:break-word; }
  .bp3-menu-item:hover, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-menu-item{
    background-color:rgba(167, 182, 194, 0.3);
    cursor:pointer;
    text-decoration:none; }
  .bp3-menu-item.bp3-disabled{
    background-color:inherit;
    color:rgba(92, 112, 128, 0.6);
    cursor:not-allowed; }
  .bp3-dark .bp3-menu-item{
    color:inherit; }
    .bp3-dark .bp3-menu-item:hover, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-menu-item, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-menu-item{
      background-color:rgba(138, 155, 168, 0.15);
      color:inherit; }
    .bp3-dark .bp3-menu-item.bp3-disabled{
      background-color:inherit;
      color:rgba(167, 182, 194, 0.6); }
  .bp3-menu-item.bp3-intent-primary{
    color:#106ba3; }
    .bp3-menu-item.bp3-intent-primary .bp3-icon{
      color:inherit; }
    .bp3-menu-item.bp3-intent-primary::before, .bp3-menu-item.bp3-intent-primary::after,
    .bp3-menu-item.bp3-intent-primary .bp3-menu-item-label{
      color:#106ba3; }
    .bp3-menu-item.bp3-intent-primary:hover, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item, .bp3-menu-item.bp3-intent-primary.bp3-active{
      background-color:#137cbd; }
    .bp3-menu-item.bp3-intent-primary:active{
      background-color:#106ba3; }
    .bp3-menu-item.bp3-intent-primary:hover, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item, .bp3-menu-item.bp3-intent-primary:hover::before, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item::before, .bp3-menu-item.bp3-intent-primary:hover::after, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item::after,
    .bp3-menu-item.bp3-intent-primary:hover .bp3-menu-item-label,
    .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item .bp3-menu-item-label, .bp3-menu-item.bp3-intent-primary:active, .bp3-menu-item.bp3-intent-primary:active::before, .bp3-menu-item.bp3-intent-primary:active::after,
    .bp3-menu-item.bp3-intent-primary:active .bp3-menu-item-label, .bp3-menu-item.bp3-intent-primary.bp3-active, .bp3-menu-item.bp3-intent-primary.bp3-active::before, .bp3-menu-item.bp3-intent-primary.bp3-active::after,
    .bp3-menu-item.bp3-intent-primary.bp3-active .bp3-menu-item-label{
      color:#ffffff; }
  .bp3-menu-item.bp3-intent-success{
    color:#0d8050; }
    .bp3-menu-item.bp3-intent-success .bp3-icon{
      color:inherit; }
    .bp3-menu-item.bp3-intent-success::before, .bp3-menu-item.bp3-intent-success::after,
    .bp3-menu-item.bp3-intent-success .bp3-menu-item-label{
      color:#0d8050; }
    .bp3-menu-item.bp3-intent-success:hover, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item, .bp3-menu-item.bp3-intent-success.bp3-active{
      background-color:#0f9960; }
    .bp3-menu-item.bp3-intent-success:active{
      background-color:#0d8050; }
    .bp3-menu-item.bp3-intent-success:hover, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item, .bp3-menu-item.bp3-intent-success:hover::before, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item::before, .bp3-menu-item.bp3-intent-success:hover::after, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item::after,
    .bp3-menu-item.bp3-intent-success:hover .bp3-menu-item-label,
    .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item .bp3-menu-item-label, .bp3-menu-item.bp3-intent-success:active, .bp3-menu-item.bp3-intent-success:active::before, .bp3-menu-item.bp3-intent-success:active::after,
    .bp3-menu-item.bp3-intent-success:active .bp3-menu-item-label, .bp3-menu-item.bp3-intent-success.bp3-active, .bp3-menu-item.bp3-intent-success.bp3-active::before, .bp3-menu-item.bp3-intent-success.bp3-active::after,
    .bp3-menu-item.bp3-intent-success.bp3-active .bp3-menu-item-label{
      color:#ffffff; }
  .bp3-menu-item.bp3-intent-warning{
    color:#bf7326; }
    .bp3-menu-item.bp3-intent-warning .bp3-icon{
      color:inherit; }
    .bp3-menu-item.bp3-intent-warning::before, .bp3-menu-item.bp3-intent-warning::after,
    .bp3-menu-item.bp3-intent-warning .bp3-menu-item-label{
      color:#bf7326; }
    .bp3-menu-item.bp3-intent-warning:hover, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item, .bp3-menu-item.bp3-intent-warning.bp3-active{
      background-color:#d9822b; }
    .bp3-menu-item.bp3-intent-warning:active{
      background-color:#bf7326; }
    .bp3-menu-item.bp3-intent-warning:hover, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item, .bp3-menu-item.bp3-intent-warning:hover::before, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item::before, .bp3-menu-item.bp3-intent-warning:hover::after, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item::after,
    .bp3-menu-item.bp3-intent-warning:hover .bp3-menu-item-label,
    .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item .bp3-menu-item-label, .bp3-menu-item.bp3-intent-warning:active, .bp3-menu-item.bp3-intent-warning:active::before, .bp3-menu-item.bp3-intent-warning:active::after,
    .bp3-menu-item.bp3-intent-warning:active .bp3-menu-item-label, .bp3-menu-item.bp3-intent-warning.bp3-active, .bp3-menu-item.bp3-intent-warning.bp3-active::before, .bp3-menu-item.bp3-intent-warning.bp3-active::after,
    .bp3-menu-item.bp3-intent-warning.bp3-active .bp3-menu-item-label{
      color:#ffffff; }
  .bp3-menu-item.bp3-intent-danger{
    color:#c23030; }
    .bp3-menu-item.bp3-intent-danger .bp3-icon{
      color:inherit; }
    .bp3-menu-item.bp3-intent-danger::before, .bp3-menu-item.bp3-intent-danger::after,
    .bp3-menu-item.bp3-intent-danger .bp3-menu-item-label{
      color:#c23030; }
    .bp3-menu-item.bp3-intent-danger:hover, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item, .bp3-menu-item.bp3-intent-danger.bp3-active{
      background-color:#db3737; }
    .bp3-menu-item.bp3-intent-danger:active{
      background-color:#c23030; }
    .bp3-menu-item.bp3-intent-danger:hover, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item, .bp3-menu-item.bp3-intent-danger:hover::before, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item::before, .bp3-menu-item.bp3-intent-danger:hover::after, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item::after,
    .bp3-menu-item.bp3-intent-danger:hover .bp3-menu-item-label,
    .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item .bp3-menu-item-label, .bp3-menu-item.bp3-intent-danger:active, .bp3-menu-item.bp3-intent-danger:active::before, .bp3-menu-item.bp3-intent-danger:active::after,
    .bp3-menu-item.bp3-intent-danger:active .bp3-menu-item-label, .bp3-menu-item.bp3-intent-danger.bp3-active, .bp3-menu-item.bp3-intent-danger.bp3-active::before, .bp3-menu-item.bp3-intent-danger.bp3-active::after,
    .bp3-menu-item.bp3-intent-danger.bp3-active .bp3-menu-item-label{
      color:#ffffff; }
  .bp3-menu-item::before{
    font-family:"Icons16", sans-serif;
    font-size:16px;
    font-style:normal;
    font-weight:400;
    line-height:1;
    -moz-osx-font-smoothing:grayscale;
    -webkit-font-smoothing:antialiased;
    margin-right:7px; }
  .bp3-menu-item::before,
  .bp3-menu-item > .bp3-icon{
    color:#5c7080;
    margin-top:2px; }
  .bp3-menu-item .bp3-menu-item-label{
    color:#5c7080; }
  .bp3-menu-item:hover, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-menu-item{
    color:inherit; }
  .bp3-menu-item.bp3-active, .bp3-menu-item:active{
    background-color:rgba(115, 134, 148, 0.3); }
  .bp3-menu-item.bp3-disabled{
    background-color:inherit !important;
    color:rgba(92, 112, 128, 0.6) !important;
    cursor:not-allowed !important;
    outline:none !important; }
    .bp3-menu-item.bp3-disabled::before,
    .bp3-menu-item.bp3-disabled > .bp3-icon,
    .bp3-menu-item.bp3-disabled .bp3-menu-item-label{
      color:rgba(92, 112, 128, 0.6) !important; }
  .bp3-large .bp3-menu-item{
    font-size:16px;
    line-height:22px;
    padding:9px 7px; }
    .bp3-large .bp3-menu-item .bp3-icon{
      margin-top:3px; }
    .bp3-large .bp3-menu-item::before{
      font-family:"Icons20", sans-serif;
      font-size:20px;
      font-style:normal;
      font-weight:400;
      line-height:1;
      -moz-osx-font-smoothing:grayscale;
      -webkit-font-smoothing:antialiased;
      margin-right:10px;
      margin-top:1px; }

button.bp3-menu-item{
  background:none;
  border:none;
  text-align:left;
  width:100%; }
.bp3-menu-header{
  border-top:1px solid rgba(16, 22, 26, 0.15);
  display:block;
  margin:5px;
  cursor:default;
  padding-left:2px; }
  .bp3-dark .bp3-menu-header{
    border-top-color:rgba(255, 255, 255, 0.15); }
  .bp3-menu-header:first-of-type{
    border-top:none; }
  .bp3-menu-header > h6{
    color:#182026;
    font-weight:600;
    overflow:hidden;
    text-overflow:ellipsis;
    white-space:nowrap;
    word-wrap:normal;
    line-height:17px;
    margin:0;
    padding:10px 7px 0 1px; }
    .bp3-dark .bp3-menu-header > h6{
      color:#f5f8fa; }
  .bp3-menu-header:first-of-type > h6{
    padding-top:0; }
  .bp3-large .bp3-menu-header > h6{
    font-size:18px;
    padding-bottom:5px;
    padding-top:15px; }
  .bp3-large .bp3-menu-header:first-of-type > h6{
    padding-top:0; }

.bp3-dark .bp3-menu{
  background:#30404d;
  color:#f5f8fa; }

.bp3-dark .bp3-menu-item{ }
  .bp3-dark .bp3-menu-item.bp3-intent-primary{
    color:#48aff0; }
    .bp3-dark .bp3-menu-item.bp3-intent-primary .bp3-icon{
      color:inherit; }
    .bp3-dark .bp3-menu-item.bp3-intent-primary::before, .bp3-dark .bp3-menu-item.bp3-intent-primary::after,
    .bp3-dark .bp3-menu-item.bp3-intent-primary .bp3-menu-item-label{
      color:#48aff0; }
    .bp3-dark .bp3-menu-item.bp3-intent-primary:hover, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item, .bp3-dark .bp3-menu-item.bp3-intent-primary.bp3-active{
      background-color:#137cbd; }
    .bp3-dark .bp3-menu-item.bp3-intent-primary:active{
      background-color:#106ba3; }
    .bp3-dark .bp3-menu-item.bp3-intent-primary:hover, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item, .bp3-dark .bp3-menu-item.bp3-intent-primary:hover::before, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item::before, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item::before, .bp3-dark .bp3-menu-item.bp3-intent-primary:hover::after, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item::after, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item::after,
    .bp3-dark .bp3-menu-item.bp3-intent-primary:hover .bp3-menu-item-label,
    .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item .bp3-menu-item-label,
    .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item .bp3-menu-item-label, .bp3-dark .bp3-menu-item.bp3-intent-primary:active, .bp3-dark .bp3-menu-item.bp3-intent-primary:active::before, .bp3-dark .bp3-menu-item.bp3-intent-primary:active::after,
    .bp3-dark .bp3-menu-item.bp3-intent-primary:active .bp3-menu-item-label, .bp3-dark .bp3-menu-item.bp3-intent-primary.bp3-active, .bp3-dark .bp3-menu-item.bp3-intent-primary.bp3-active::before, .bp3-dark .bp3-menu-item.bp3-intent-primary.bp3-active::after,
    .bp3-dark .bp3-menu-item.bp3-intent-primary.bp3-active .bp3-menu-item-label{
      color:#ffffff; }
  .bp3-dark .bp3-menu-item.bp3-intent-success{
    color:#3dcc91; }
    .bp3-dark .bp3-menu-item.bp3-intent-success .bp3-icon{
      color:inherit; }
    .bp3-dark .bp3-menu-item.bp3-intent-success::before, .bp3-dark .bp3-menu-item.bp3-intent-success::after,
    .bp3-dark .bp3-menu-item.bp3-intent-success .bp3-menu-item-label{
      color:#3dcc91; }
    .bp3-dark .bp3-menu-item.bp3-intent-success:hover, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item, .bp3-dark .bp3-menu-item.bp3-intent-success.bp3-active{
      background-color:#0f9960; }
    .bp3-dark .bp3-menu-item.bp3-intent-success:active{
      background-color:#0d8050; }
    .bp3-dark .bp3-menu-item.bp3-intent-success:hover, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item, .bp3-dark .bp3-menu-item.bp3-intent-success:hover::before, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item::before, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item::before, .bp3-dark .bp3-menu-item.bp3-intent-success:hover::after, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item::after, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item::after,
    .bp3-dark .bp3-menu-item.bp3-intent-success:hover .bp3-menu-item-label,
    .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item .bp3-menu-item-label,
    .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item .bp3-menu-item-label, .bp3-dark .bp3-menu-item.bp3-intent-success:active, .bp3-dark .bp3-menu-item.bp3-intent-success:active::before, .bp3-dark .bp3-menu-item.bp3-intent-success:active::after,
    .bp3-dark .bp3-menu-item.bp3-intent-success:active .bp3-menu-item-label, .bp3-dark .bp3-menu-item.bp3-intent-success.bp3-active, .bp3-dark .bp3-menu-item.bp3-intent-success.bp3-active::before, .bp3-dark .bp3-menu-item.bp3-intent-success.bp3-active::after,
    .bp3-dark .bp3-menu-item.bp3-intent-success.bp3-active .bp3-menu-item-label{
      color:#ffffff; }
  .bp3-dark .bp3-menu-item.bp3-intent-warning{
    color:#ffb366; }
    .bp3-dark .bp3-menu-item.bp3-intent-warning .bp3-icon{
      color:inherit; }
    .bp3-dark .bp3-menu-item.bp3-intent-warning::before, .bp3-dark .bp3-menu-item.bp3-intent-warning::after,
    .bp3-dark .bp3-menu-item.bp3-intent-warning .bp3-menu-item-label{
      color:#ffb366; }
    .bp3-dark .bp3-menu-item.bp3-intent-warning:hover, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item, .bp3-dark .bp3-menu-item.bp3-intent-warning.bp3-active{
      background-color:#d9822b; }
    .bp3-dark .bp3-menu-item.bp3-intent-warning:active{
      background-color:#bf7326; }
    .bp3-dark .bp3-menu-item.bp3-intent-warning:hover, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item, .bp3-dark .bp3-menu-item.bp3-intent-warning:hover::before, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item::before, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item::before, .bp3-dark .bp3-menu-item.bp3-intent-warning:hover::after, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item::after, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item::after,
    .bp3-dark .bp3-menu-item.bp3-intent-warning:hover .bp3-menu-item-label,
    .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item .bp3-menu-item-label,
    .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item .bp3-menu-item-label, .bp3-dark .bp3-menu-item.bp3-intent-warning:active, .bp3-dark .bp3-menu-item.bp3-intent-warning:active::before, .bp3-dark .bp3-menu-item.bp3-intent-warning:active::after,
    .bp3-dark .bp3-menu-item.bp3-intent-warning:active .bp3-menu-item-label, .bp3-dark .bp3-menu-item.bp3-intent-warning.bp3-active, .bp3-dark .bp3-menu-item.bp3-intent-warning.bp3-active::before, .bp3-dark .bp3-menu-item.bp3-intent-warning.bp3-active::after,
    .bp3-dark .bp3-menu-item.bp3-intent-warning.bp3-active .bp3-menu-item-label{
      color:#ffffff; }
  .bp3-dark .bp3-menu-item.bp3-intent-danger{
    color:#ff7373; }
    .bp3-dark .bp3-menu-item.bp3-intent-danger .bp3-icon{
      color:inherit; }
    .bp3-dark .bp3-menu-item.bp3-intent-danger::before, .bp3-dark .bp3-menu-item.bp3-intent-danger::after,
    .bp3-dark .bp3-menu-item.bp3-intent-danger .bp3-menu-item-label{
      color:#ff7373; }
    .bp3-dark .bp3-menu-item.bp3-intent-danger:hover, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item, .bp3-dark .bp3-menu-item.bp3-intent-danger.bp3-active{
      background-color:#db3737; }
    .bp3-dark .bp3-menu-item.bp3-intent-danger:active{
      background-color:#c23030; }
    .bp3-dark .bp3-menu-item.bp3-intent-danger:hover, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item, .bp3-dark .bp3-menu-item.bp3-intent-danger:hover::before, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item::before, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item::before, .bp3-dark .bp3-menu-item.bp3-intent-danger:hover::after, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item::after, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item::after,
    .bp3-dark .bp3-menu-item.bp3-intent-danger:hover .bp3-menu-item-label,
    .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item .bp3-menu-item-label,
    .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item .bp3-menu-item-label, .bp3-dark .bp3-menu-item.bp3-intent-danger:active, .bp3-dark .bp3-menu-item.bp3-intent-danger:active::before, .bp3-dark .bp3-menu-item.bp3-intent-danger:active::after,
    .bp3-dark .bp3-menu-item.bp3-intent-danger:active .bp3-menu-item-label, .bp3-dark .bp3-menu-item.bp3-intent-danger.bp3-active, .bp3-dark .bp3-menu-item.bp3-intent-danger.bp3-active::before, .bp3-dark .bp3-menu-item.bp3-intent-danger.bp3-active::after,
    .bp3-dark .bp3-menu-item.bp3-intent-danger.bp3-active .bp3-menu-item-label{
      color:#ffffff; }
  .bp3-dark .bp3-menu-item::before,
  .bp3-dark .bp3-menu-item > .bp3-icon{
    color:#a7b6c2; }
  .bp3-dark .bp3-menu-item .bp3-menu-item-label{
    color:#a7b6c2; }
  .bp3-dark .bp3-menu-item.bp3-active, .bp3-dark .bp3-menu-item:active{
    background-color:rgba(138, 155, 168, 0.3); }
  .bp3-dark .bp3-menu-item.bp3-disabled{
    color:rgba(167, 182, 194, 0.6) !important; }
    .bp3-dark .bp3-menu-item.bp3-disabled::before,
    .bp3-dark .bp3-menu-item.bp3-disabled > .bp3-icon,
    .bp3-dark .bp3-menu-item.bp3-disabled .bp3-menu-item-label{
      color:rgba(167, 182, 194, 0.6) !important; }

.bp3-dark .bp3-menu-divider,
.bp3-dark .bp3-menu-header{
  border-color:rgba(255, 255, 255, 0.15); }

.bp3-dark .bp3-menu-header > h6{
  color:#f5f8fa; }

.bp3-label .bp3-menu{
  margin-top:5px; }
.bp3-navbar{
  background-color:#ffffff;
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.2);
  height:50px;
  padding:0 15px;
  position:relative;
  width:100%;
  z-index:10; }
  .bp3-navbar.bp3-dark,
  .bp3-dark .bp3-navbar{
    background-color:#394b59; }
  .bp3-navbar.bp3-dark{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.4); }
  .bp3-dark .bp3-navbar{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.4); }
  .bp3-navbar.bp3-fixed-top{
    left:0;
    position:fixed;
    right:0;
    top:0; }

.bp3-navbar-heading{
  font-size:16px;
  margin-right:15px; }

.bp3-navbar-group{
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  height:50px; }
  .bp3-navbar-group.bp3-align-left{
    float:left; }
  .bp3-navbar-group.bp3-align-right{
    float:right; }

.bp3-navbar-divider{
  border-left:1px solid rgba(16, 22, 26, 0.15);
  height:20px;
  margin:0 10px; }
  .bp3-dark .bp3-navbar-divider{
    border-left-color:rgba(255, 255, 255, 0.15); }
.bp3-non-ideal-state{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-orient:vertical;
  -webkit-box-direction:normal;
      -ms-flex-direction:column;
          flex-direction:column;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  height:100%;
  -webkit-box-pack:center;
      -ms-flex-pack:center;
          justify-content:center;
  text-align:center;
  width:100%; }
  .bp3-non-ideal-state > *{
    -webkit-box-flex:0;
        -ms-flex-positive:0;
            flex-grow:0;
    -ms-flex-negative:0;
        flex-shrink:0; }
  .bp3-non-ideal-state > .bp3-fill{
    -webkit-box-flex:1;
        -ms-flex-positive:1;
            flex-grow:1;
    -ms-flex-negative:1;
        flex-shrink:1; }
  .bp3-non-ideal-state::before,
  .bp3-non-ideal-state > *{
    margin-bottom:20px; }
  .bp3-non-ideal-state:empty::before,
  .bp3-non-ideal-state > :last-child{
    margin-bottom:0; }
  .bp3-non-ideal-state > *{
    max-width:400px; }

.bp3-non-ideal-state-visual{
  color:rgba(92, 112, 128, 0.6);
  font-size:60px; }
  .bp3-dark .bp3-non-ideal-state-visual{
    color:rgba(167, 182, 194, 0.6); }

.bp3-overflow-list{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -ms-flex-wrap:nowrap;
      flex-wrap:nowrap;
  min-width:0; }

.bp3-overflow-list-spacer{
  -ms-flex-negative:1;
      flex-shrink:1;
  width:1px; }

body.bp3-overlay-open{
  overflow:hidden; }

.bp3-overlay{
  bottom:0;
  left:0;
  position:static;
  right:0;
  top:0;
  z-index:20; }
  .bp3-overlay:not(.bp3-overlay-open){
    pointer-events:none; }
  .bp3-overlay.bp3-overlay-container{
    overflow:hidden;
    position:fixed; }
    .bp3-overlay.bp3-overlay-container.bp3-overlay-inline{
      position:absolute; }
  .bp3-overlay.bp3-overlay-scroll-container{
    overflow:auto;
    position:fixed; }
    .bp3-overlay.bp3-overlay-scroll-container.bp3-overlay-inline{
      position:absolute; }
  .bp3-overlay.bp3-overlay-inline{
    display:inline;
    overflow:visible; }

.bp3-overlay-content{
  position:fixed;
  z-index:20; }
  .bp3-overlay-inline .bp3-overlay-content,
  .bp3-overlay-scroll-container .bp3-overlay-content{
    position:absolute; }

.bp3-overlay-backdrop{
  bottom:0;
  left:0;
  position:fixed;
  right:0;
  top:0;
  opacity:1;
  background-color:rgba(16, 22, 26, 0.7);
  overflow:auto;
  -webkit-user-select:none;
     -moz-user-select:none;
      -ms-user-select:none;
          user-select:none;
  z-index:20; }
  .bp3-overlay-backdrop.bp3-overlay-enter, .bp3-overlay-backdrop.bp3-overlay-appear{
    opacity:0; }
  .bp3-overlay-backdrop.bp3-overlay-enter-active, .bp3-overlay-backdrop.bp3-overlay-appear-active{
    opacity:1;
    -webkit-transition-delay:0;
            transition-delay:0;
    -webkit-transition-duration:200ms;
            transition-duration:200ms;
    -webkit-transition-property:opacity;
    transition-property:opacity;
    -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
            transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-overlay-backdrop.bp3-overlay-exit{
    opacity:1; }
  .bp3-overlay-backdrop.bp3-overlay-exit-active{
    opacity:0;
    -webkit-transition-delay:0;
            transition-delay:0;
    -webkit-transition-duration:200ms;
            transition-duration:200ms;
    -webkit-transition-property:opacity;
    transition-property:opacity;
    -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
            transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-overlay-backdrop:focus{
    outline:none; }
  .bp3-overlay-inline .bp3-overlay-backdrop{
    position:absolute; }
.bp3-panel-stack{
  overflow:hidden;
  position:relative; }

.bp3-panel-stack-header{
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  -webkit-box-shadow:0 1px rgba(16, 22, 26, 0.15);
          box-shadow:0 1px rgba(16, 22, 26, 0.15);
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -ms-flex-negative:0;
      flex-shrink:0;
  height:30px;
  z-index:1; }
  .bp3-dark .bp3-panel-stack-header{
    -webkit-box-shadow:0 1px rgba(255, 255, 255, 0.15);
            box-shadow:0 1px rgba(255, 255, 255, 0.15); }
  .bp3-panel-stack-header > span{
    -webkit-box-align:stretch;
        -ms-flex-align:stretch;
            align-items:stretch;
    display:-webkit-box;
    display:-ms-flexbox;
    display:flex;
    -webkit-box-flex:1;
        -ms-flex:1;
            flex:1; }
  .bp3-panel-stack-header .bp3-heading{
    margin:0 5px; }

.bp3-button.bp3-panel-stack-header-back{
  margin-left:5px;
  padding-left:0;
  white-space:nowrap; }
  .bp3-button.bp3-panel-stack-header-back .bp3-icon{
    margin:0 2px; }

.bp3-panel-stack-view{
  bottom:0;
  left:0;
  position:absolute;
  right:0;
  top:0;
  background-color:#ffffff;
  border-right:1px solid rgba(16, 22, 26, 0.15);
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-orient:vertical;
  -webkit-box-direction:normal;
      -ms-flex-direction:column;
          flex-direction:column;
  margin-right:-1px;
  overflow-y:auto;
  z-index:1; }
  .bp3-dark .bp3-panel-stack-view{
    background-color:#30404d; }
  .bp3-panel-stack-view:nth-last-child(n + 4){
    display:none; }

.bp3-panel-stack-push .bp3-panel-stack-enter, .bp3-panel-stack-push .bp3-panel-stack-appear{
  -webkit-transform:translateX(100%);
          transform:translateX(100%);
  opacity:0; }

.bp3-panel-stack-push .bp3-panel-stack-enter-active, .bp3-panel-stack-push .bp3-panel-stack-appear-active{
  -webkit-transform:translate(0%);
          transform:translate(0%);
  opacity:1;
  -webkit-transition-delay:0;
          transition-delay:0;
  -webkit-transition-duration:400ms;
          transition-duration:400ms;
  -webkit-transition-property:opacity, -webkit-transform;
  transition-property:opacity, -webkit-transform;
  transition-property:transform, opacity;
  transition-property:transform, opacity, -webkit-transform;
  -webkit-transition-timing-function:ease;
          transition-timing-function:ease; }

.bp3-panel-stack-push .bp3-panel-stack-exit{
  -webkit-transform:translate(0%);
          transform:translate(0%);
  opacity:1; }

.bp3-panel-stack-push .bp3-panel-stack-exit-active{
  -webkit-transform:translateX(-50%);
          transform:translateX(-50%);
  opacity:0;
  -webkit-transition-delay:0;
          transition-delay:0;
  -webkit-transition-duration:400ms;
          transition-duration:400ms;
  -webkit-transition-property:opacity, -webkit-transform;
  transition-property:opacity, -webkit-transform;
  transition-property:transform, opacity;
  transition-property:transform, opacity, -webkit-transform;
  -webkit-transition-timing-function:ease;
          transition-timing-function:ease; }

.bp3-panel-stack-pop .bp3-panel-stack-enter, .bp3-panel-stack-pop .bp3-panel-stack-appear{
  -webkit-transform:translateX(-50%);
          transform:translateX(-50%);
  opacity:0; }

.bp3-panel-stack-pop .bp3-panel-stack-enter-active, .bp3-panel-stack-pop .bp3-panel-stack-appear-active{
  -webkit-transform:translate(0%);
          transform:translate(0%);
  opacity:1;
  -webkit-transition-delay:0;
          transition-delay:0;
  -webkit-transition-duration:400ms;
          transition-duration:400ms;
  -webkit-transition-property:opacity, -webkit-transform;
  transition-property:opacity, -webkit-transform;
  transition-property:transform, opacity;
  transition-property:transform, opacity, -webkit-transform;
  -webkit-transition-timing-function:ease;
          transition-timing-function:ease; }

.bp3-panel-stack-pop .bp3-panel-stack-exit{
  -webkit-transform:translate(0%);
          transform:translate(0%);
  opacity:1; }

.bp3-panel-stack-pop .bp3-panel-stack-exit-active{
  -webkit-transform:translateX(100%);
          transform:translateX(100%);
  opacity:0;
  -webkit-transition-delay:0;
          transition-delay:0;
  -webkit-transition-duration:400ms;
          transition-duration:400ms;
  -webkit-transition-property:opacity, -webkit-transform;
  transition-property:opacity, -webkit-transform;
  transition-property:transform, opacity;
  transition-property:transform, opacity, -webkit-transform;
  -webkit-transition-timing-function:ease;
          transition-timing-function:ease; }
.bp3-popover{
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
  -webkit-transform:scale(1);
          transform:scale(1);
  border-radius:3px;
  display:inline-block;
  z-index:20; }
  .bp3-popover .bp3-popover-arrow{
    height:30px;
    position:absolute;
    width:30px; }
    .bp3-popover .bp3-popover-arrow::before{
      height:20px;
      margin:5px;
      width:20px; }
  .bp3-tether-element-attached-bottom.bp3-tether-target-attached-top > .bp3-popover{
    margin-bottom:17px;
    margin-top:-17px; }
    .bp3-tether-element-attached-bottom.bp3-tether-target-attached-top > .bp3-popover > .bp3-popover-arrow{
      bottom:-11px; }
      .bp3-tether-element-attached-bottom.bp3-tether-target-attached-top > .bp3-popover > .bp3-popover-arrow svg{
        -webkit-transform:rotate(-90deg);
                transform:rotate(-90deg); }
  .bp3-tether-element-attached-left.bp3-tether-target-attached-right > .bp3-popover{
    margin-left:17px; }
    .bp3-tether-element-attached-left.bp3-tether-target-attached-right > .bp3-popover > .bp3-popover-arrow{
      left:-11px; }
      .bp3-tether-element-attached-left.bp3-tether-target-attached-right > .bp3-popover > .bp3-popover-arrow svg{
        -webkit-transform:rotate(0);
                transform:rotate(0); }
  .bp3-tether-element-attached-top.bp3-tether-target-attached-bottom > .bp3-popover{
    margin-top:17px; }
    .bp3-tether-element-attached-top.bp3-tether-target-attached-bottom > .bp3-popover > .bp3-popover-arrow{
      top:-11px; }
      .bp3-tether-element-attached-top.bp3-tether-target-attached-bottom > .bp3-popover > .bp3-popover-arrow svg{
        -webkit-transform:rotate(90deg);
                transform:rotate(90deg); }
  .bp3-tether-element-attached-right.bp3-tether-target-attached-left > .bp3-popover{
    margin-left:-17px;
    margin-right:17px; }
    .bp3-tether-element-attached-right.bp3-tether-target-attached-left > .bp3-popover > .bp3-popover-arrow{
      right:-11px; }
      .bp3-tether-element-attached-right.bp3-tether-target-attached-left > .bp3-popover > .bp3-popover-arrow svg{
        -webkit-transform:rotate(180deg);
                transform:rotate(180deg); }
  .bp3-tether-element-attached-middle > .bp3-popover > .bp3-popover-arrow{
    top:50%;
    -webkit-transform:translateY(-50%);
            transform:translateY(-50%); }
  .bp3-tether-element-attached-center > .bp3-popover > .bp3-popover-arrow{
    right:50%;
    -webkit-transform:translateX(50%);
            transform:translateX(50%); }
  .bp3-tether-element-attached-top.bp3-tether-target-attached-top > .bp3-popover > .bp3-popover-arrow{
    top:-0.3934px; }
  .bp3-tether-element-attached-right.bp3-tether-target-attached-right > .bp3-popover > .bp3-popover-arrow{
    right:-0.3934px; }
  .bp3-tether-element-attached-left.bp3-tether-target-attached-left > .bp3-popover > .bp3-popover-arrow{
    left:-0.3934px; }
  .bp3-tether-element-attached-bottom.bp3-tether-target-attached-bottom > .bp3-popover > .bp3-popover-arrow{
    bottom:-0.3934px; }
  .bp3-tether-element-attached-top.bp3-tether-element-attached-left > .bp3-popover{
    -webkit-transform-origin:top left;
            transform-origin:top left; }
  .bp3-tether-element-attached-top.bp3-tether-element-attached-center > .bp3-popover{
    -webkit-transform-origin:top center;
            transform-origin:top center; }
  .bp3-tether-element-attached-top.bp3-tether-element-attached-right > .bp3-popover{
    -webkit-transform-origin:top right;
            transform-origin:top right; }
  .bp3-tether-element-attached-middle.bp3-tether-element-attached-left > .bp3-popover{
    -webkit-transform-origin:center left;
            transform-origin:center left; }
  .bp3-tether-element-attached-middle.bp3-tether-element-attached-center > .bp3-popover{
    -webkit-transform-origin:center center;
            transform-origin:center center; }
  .bp3-tether-element-attached-middle.bp3-tether-element-attached-right > .bp3-popover{
    -webkit-transform-origin:center right;
            transform-origin:center right; }
  .bp3-tether-element-attached-bottom.bp3-tether-element-attached-left > .bp3-popover{
    -webkit-transform-origin:bottom left;
            transform-origin:bottom left; }
  .bp3-tether-element-attached-bottom.bp3-tether-element-attached-center > .bp3-popover{
    -webkit-transform-origin:bottom center;
            transform-origin:bottom center; }
  .bp3-tether-element-attached-bottom.bp3-tether-element-attached-right > .bp3-popover{
    -webkit-transform-origin:bottom right;
            transform-origin:bottom right; }
  .bp3-popover .bp3-popover-content{
    background:#ffffff;
    color:inherit; }
  .bp3-popover .bp3-popover-arrow::before{
    -webkit-box-shadow:1px 1px 6px rgba(16, 22, 26, 0.2);
            box-shadow:1px 1px 6px rgba(16, 22, 26, 0.2); }
  .bp3-popover .bp3-popover-arrow-border{
    fill:#10161a;
    fill-opacity:0.1; }
  .bp3-popover .bp3-popover-arrow-fill{
    fill:#ffffff; }
  .bp3-popover-enter > .bp3-popover, .bp3-popover-appear > .bp3-popover{
    -webkit-transform:scale(0.3);
            transform:scale(0.3); }
  .bp3-popover-enter-active > .bp3-popover, .bp3-popover-appear-active > .bp3-popover{
    -webkit-transform:scale(1);
            transform:scale(1);
    -webkit-transition-delay:0;
            transition-delay:0;
    -webkit-transition-duration:300ms;
            transition-duration:300ms;
    -webkit-transition-property:-webkit-transform;
    transition-property:-webkit-transform;
    transition-property:transform;
    transition-property:transform, -webkit-transform;
    -webkit-transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11);
            transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11); }
  .bp3-popover-exit > .bp3-popover{
    -webkit-transform:scale(1);
            transform:scale(1); }
  .bp3-popover-exit-active > .bp3-popover{
    -webkit-transform:scale(0.3);
            transform:scale(0.3);
    -webkit-transition-delay:0;
            transition-delay:0;
    -webkit-transition-duration:300ms;
            transition-duration:300ms;
    -webkit-transition-property:-webkit-transform;
    transition-property:-webkit-transform;
    transition-property:transform;
    transition-property:transform, -webkit-transform;
    -webkit-transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11);
            transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11); }
  .bp3-popover .bp3-popover-content{
    border-radius:3px;
    position:relative; }
  .bp3-popover.bp3-popover-content-sizing .bp3-popover-content{
    max-width:350px;
    padding:20px; }
  .bp3-popover-target + .bp3-overlay .bp3-popover.bp3-popover-content-sizing{
    width:350px; }
  .bp3-popover.bp3-minimal{
    margin:0 !important; }
    .bp3-popover.bp3-minimal .bp3-popover-arrow{
      display:none; }
    .bp3-popover.bp3-minimal.bp3-popover{
      -webkit-transform:scale(1);
              transform:scale(1); }
      .bp3-popover-enter > .bp3-popover.bp3-minimal.bp3-popover, .bp3-popover-appear > .bp3-popover.bp3-minimal.bp3-popover{
        -webkit-transform:scale(1);
                transform:scale(1); }
      .bp3-popover-enter-active > .bp3-popover.bp3-minimal.bp3-popover, .bp3-popover-appear-active > .bp3-popover.bp3-minimal.bp3-popover{
        -webkit-transform:scale(1);
                transform:scale(1);
        -webkit-transition-delay:0;
                transition-delay:0;
        -webkit-transition-duration:100ms;
                transition-duration:100ms;
        -webkit-transition-property:-webkit-transform;
        transition-property:-webkit-transform;
        transition-property:transform;
        transition-property:transform, -webkit-transform;
        -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
                transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9); }
      .bp3-popover-exit > .bp3-popover.bp3-minimal.bp3-popover{
        -webkit-transform:scale(1);
                transform:scale(1); }
      .bp3-popover-exit-active > .bp3-popover.bp3-minimal.bp3-popover{
        -webkit-transform:scale(1);
                transform:scale(1);
        -webkit-transition-delay:0;
                transition-delay:0;
        -webkit-transition-duration:100ms;
                transition-duration:100ms;
        -webkit-transition-property:-webkit-transform;
        transition-property:-webkit-transform;
        transition-property:transform;
        transition-property:transform, -webkit-transform;
        -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
                transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-popover.bp3-dark,
  .bp3-dark .bp3-popover{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4); }
    .bp3-popover.bp3-dark .bp3-popover-content,
    .bp3-dark .bp3-popover .bp3-popover-content{
      background:#30404d;
      color:inherit; }
    .bp3-popover.bp3-dark .bp3-popover-arrow::before,
    .bp3-dark .bp3-popover .bp3-popover-arrow::before{
      -webkit-box-shadow:1px 1px 6px rgba(16, 22, 26, 0.4);
              box-shadow:1px 1px 6px rgba(16, 22, 26, 0.4); }
    .bp3-popover.bp3-dark .bp3-popover-arrow-border,
    .bp3-dark .bp3-popover .bp3-popover-arrow-border{
      fill:#10161a;
      fill-opacity:0.2; }
    .bp3-popover.bp3-dark .bp3-popover-arrow-fill,
    .bp3-dark .bp3-popover .bp3-popover-arrow-fill{
      fill:#30404d; }

.bp3-popover-arrow::before{
  border-radius:2px;
  content:"";
  display:block;
  position:absolute;
  -webkit-transform:rotate(45deg);
          transform:rotate(45deg); }

.bp3-tether-pinned .bp3-popover-arrow{
  display:none; }

.bp3-popover-backdrop{
  background:rgba(255, 255, 255, 0); }

.bp3-transition-container{
  opacity:1;
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  z-index:20; }
  .bp3-transition-container.bp3-popover-enter, .bp3-transition-container.bp3-popover-appear{
    opacity:0; }
  .bp3-transition-container.bp3-popover-enter-active, .bp3-transition-container.bp3-popover-appear-active{
    opacity:1;
    -webkit-transition-delay:0;
            transition-delay:0;
    -webkit-transition-duration:100ms;
            transition-duration:100ms;
    -webkit-transition-property:opacity;
    transition-property:opacity;
    -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
            transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-transition-container.bp3-popover-exit{
    opacity:1; }
  .bp3-transition-container.bp3-popover-exit-active{
    opacity:0;
    -webkit-transition-delay:0;
            transition-delay:0;
    -webkit-transition-duration:100ms;
            transition-duration:100ms;
    -webkit-transition-property:opacity;
    transition-property:opacity;
    -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
            transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-transition-container:focus{
    outline:none; }
  .bp3-transition-container.bp3-popover-leave .bp3-popover-content{
    pointer-events:none; }
  .bp3-transition-container[data-x-out-of-boundaries]{
    display:none; }

span.bp3-popover-target{
  display:inline-block; }

.bp3-popover-wrapper.bp3-fill{
  width:100%; }

.bp3-portal{
  left:0;
  position:absolute;
  right:0;
  top:0; }
@-webkit-keyframes linear-progress-bar-stripes{
  from{
    background-position:0 0; }
  to{
    background-position:30px 0; } }
@keyframes linear-progress-bar-stripes{
  from{
    background-position:0 0; }
  to{
    background-position:30px 0; } }

.bp3-progress-bar{
  background:rgba(92, 112, 128, 0.2);
  border-radius:40px;
  display:block;
  height:8px;
  overflow:hidden;
  position:relative;
  width:100%; }
  .bp3-progress-bar .bp3-progress-meter{
    background:linear-gradient(-45deg, rgba(255, 255, 255, 0.2) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.2) 50%, rgba(255, 255, 255, 0.2) 75%, transparent 75%);
    background-color:rgba(92, 112, 128, 0.8);
    background-size:30px 30px;
    border-radius:40px;
    height:100%;
    position:absolute;
    -webkit-transition:width 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
    transition:width 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
    width:100%; }
  .bp3-progress-bar:not(.bp3-no-animation):not(.bp3-no-stripes) .bp3-progress-meter{
    animation:linear-progress-bar-stripes 300ms linear infinite reverse; }
  .bp3-progress-bar.bp3-no-stripes .bp3-progress-meter{
    background-image:none; }

.bp3-dark .bp3-progress-bar{
  background:rgba(16, 22, 26, 0.5); }
  .bp3-dark .bp3-progress-bar .bp3-progress-meter{
    background-color:#8a9ba8; }

.bp3-progress-bar.bp3-intent-primary .bp3-progress-meter{
  background-color:#137cbd; }

.bp3-progress-bar.bp3-intent-success .bp3-progress-meter{
  background-color:#0f9960; }

.bp3-progress-bar.bp3-intent-warning .bp3-progress-meter{
  background-color:#d9822b; }

.bp3-progress-bar.bp3-intent-danger .bp3-progress-meter{
  background-color:#db3737; }
@-webkit-keyframes skeleton-glow{
  from{
    background:rgba(206, 217, 224, 0.2);
    border-color:rgba(206, 217, 224, 0.2); }
  to{
    background:rgba(92, 112, 128, 0.2);
    border-color:rgba(92, 112, 128, 0.2); } }
@keyframes skeleton-glow{
  from{
    background:rgba(206, 217, 224, 0.2);
    border-color:rgba(206, 217, 224, 0.2); }
  to{
    background:rgba(92, 112, 128, 0.2);
    border-color:rgba(92, 112, 128, 0.2); } }
.bp3-skeleton{
  -webkit-animation:1000ms linear infinite alternate skeleton-glow;
          animation:1000ms linear infinite alternate skeleton-glow;
  background:rgba(206, 217, 224, 0.2);
  background-clip:padding-box !important;
  border-color:rgba(206, 217, 224, 0.2) !important;
  border-radius:2px;
  -webkit-box-shadow:none !important;
          box-shadow:none !important;
  color:transparent !important;
  cursor:default;
  pointer-events:none;
  -webkit-user-select:none;
     -moz-user-select:none;
      -ms-user-select:none;
          user-select:none; }
  .bp3-skeleton::before, .bp3-skeleton::after,
  .bp3-skeleton *{
    visibility:hidden !important; }
.bp3-slider{
  height:40px;
  min-width:150px;
  width:100%;
  cursor:default;
  outline:none;
  position:relative;
  -webkit-user-select:none;
     -moz-user-select:none;
      -ms-user-select:none;
          user-select:none; }
  .bp3-slider:hover{
    cursor:pointer; }
  .bp3-slider:active{
    cursor:-webkit-grabbing;
    cursor:grabbing; }
  .bp3-slider.bp3-disabled{
    cursor:not-allowed;
    opacity:0.5; }
  .bp3-slider.bp3-slider-unlabeled{
    height:16px; }

.bp3-slider-track,
.bp3-slider-progress{
  height:6px;
  left:0;
  right:0;
  top:5px;
  position:absolute; }

.bp3-slider-track{
  border-radius:3px;
  overflow:hidden; }

.bp3-slider-progress{
  background:rgba(92, 112, 128, 0.2); }
  .bp3-dark .bp3-slider-progress{
    background:rgba(16, 22, 26, 0.5); }
  .bp3-slider-progress.bp3-intent-primary{
    background-color:#137cbd; }
  .bp3-slider-progress.bp3-intent-success{
    background-color:#0f9960; }
  .bp3-slider-progress.bp3-intent-warning{
    background-color:#d9822b; }
  .bp3-slider-progress.bp3-intent-danger{
    background-color:#db3737; }

.bp3-slider-handle{
  background-color:#f5f8fa;
  background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.8)), to(rgba(255, 255, 255, 0)));
  background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.8), rgba(255, 255, 255, 0));
  -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
          box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
  color:#182026;
  border-radius:3px;
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 1px 1px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 1px 1px rgba(16, 22, 26, 0.2);
  cursor:pointer;
  height:16px;
  left:0;
  position:absolute;
  top:0;
  width:16px; }
  .bp3-slider-handle:hover{
    background-clip:padding-box;
    background-color:#ebf1f5;
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1); }
  .bp3-slider-handle:active, .bp3-slider-handle.bp3-active{
    background-color:#d8e1e8;
    background-image:none;
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2); }
  .bp3-slider-handle:disabled, .bp3-slider-handle.bp3-disabled{
    background-color:rgba(206, 217, 224, 0.5);
    background-image:none;
    -webkit-box-shadow:none;
            box-shadow:none;
    color:rgba(92, 112, 128, 0.6);
    cursor:not-allowed;
    outline:none; }
    .bp3-slider-handle:disabled.bp3-active, .bp3-slider-handle:disabled.bp3-active:hover, .bp3-slider-handle.bp3-disabled.bp3-active, .bp3-slider-handle.bp3-disabled.bp3-active:hover{
      background:rgba(206, 217, 224, 0.7); }
  .bp3-slider-handle:focus{
    z-index:1; }
  .bp3-slider-handle:hover{
    background-clip:padding-box;
    background-color:#ebf1f5;
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 1px 1px rgba(16, 22, 26, 0.2);
    cursor:-webkit-grab;
    cursor:grab;
    z-index:2; }
  .bp3-slider-handle.bp3-active{
    background-color:#d8e1e8;
    background-image:none;
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 1px rgba(16, 22, 26, 0.1);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 1px rgba(16, 22, 26, 0.1);
    cursor:-webkit-grabbing;
    cursor:grabbing; }
  .bp3-disabled .bp3-slider-handle{
    background:#bfccd6;
    -webkit-box-shadow:none;
            box-shadow:none;
    pointer-events:none; }
  .bp3-dark .bp3-slider-handle{
    background-color:#394b59;
    background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.05)), to(rgba(255, 255, 255, 0)));
    background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.05), rgba(255, 255, 255, 0));
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
    color:#f5f8fa; }
    .bp3-dark .bp3-slider-handle:hover, .bp3-dark .bp3-slider-handle:active, .bp3-dark .bp3-slider-handle.bp3-active{
      color:#f5f8fa; }
    .bp3-dark .bp3-slider-handle:hover{
      background-color:#30404d;
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-slider-handle:active, .bp3-dark .bp3-slider-handle.bp3-active{
      background-color:#202b33;
      background-image:none;
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2); }
    .bp3-dark .bp3-slider-handle:disabled, .bp3-dark .bp3-slider-handle.bp3-disabled{
      background-color:rgba(57, 75, 89, 0.5);
      background-image:none;
      -webkit-box-shadow:none;
              box-shadow:none;
      color:rgba(167, 182, 194, 0.6); }
      .bp3-dark .bp3-slider-handle:disabled.bp3-active, .bp3-dark .bp3-slider-handle.bp3-disabled.bp3-active{
        background:rgba(57, 75, 89, 0.7); }
    .bp3-dark .bp3-slider-handle .bp3-button-spinner .bp3-spinner-head{
      background:rgba(16, 22, 26, 0.5);
      stroke:#8a9ba8; }
    .bp3-dark .bp3-slider-handle, .bp3-dark .bp3-slider-handle:hover{
      background-color:#394b59; }
    .bp3-dark .bp3-slider-handle.bp3-active{
      background-color:#293742; }
  .bp3-dark .bp3-disabled .bp3-slider-handle{
    background:#5c7080;
    border-color:#5c7080;
    -webkit-box-shadow:none;
            box-shadow:none; }
  .bp3-slider-handle .bp3-slider-label{
    background:#394b59;
    border-radius:3px;
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
    color:#f5f8fa;
    margin-left:8px; }
    .bp3-dark .bp3-slider-handle .bp3-slider-label{
      background:#e1e8ed;
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4);
      color:#394b59; }
    .bp3-disabled .bp3-slider-handle .bp3-slider-label{
      -webkit-box-shadow:none;
              box-shadow:none; }
  .bp3-slider-handle.bp3-start, .bp3-slider-handle.bp3-end{
    width:8px; }
  .bp3-slider-handle.bp3-start{
    border-bottom-right-radius:0;
    border-top-right-radius:0; }
  .bp3-slider-handle.bp3-end{
    border-bottom-left-radius:0;
    border-top-left-radius:0;
    margin-left:8px; }
    .bp3-slider-handle.bp3-end .bp3-slider-label{
      margin-left:0; }

.bp3-slider-label{
  -webkit-transform:translate(-50%, 20px);
          transform:translate(-50%, 20px);
  display:inline-block;
  font-size:12px;
  line-height:1;
  padding:2px 5px;
  position:absolute;
  vertical-align:top; }

.bp3-slider.bp3-vertical{
  height:150px;
  min-width:40px;
  width:40px; }
  .bp3-slider.bp3-vertical .bp3-slider-track,
  .bp3-slider.bp3-vertical .bp3-slider-progress{
    bottom:0;
    height:auto;
    left:5px;
    top:0;
    width:6px; }
  .bp3-slider.bp3-vertical .bp3-slider-progress{
    top:auto; }
  .bp3-slider.bp3-vertical .bp3-slider-label{
    -webkit-transform:translate(20px, 50%);
            transform:translate(20px, 50%); }
  .bp3-slider.bp3-vertical .bp3-slider-handle{
    top:auto; }
    .bp3-slider.bp3-vertical .bp3-slider-handle .bp3-slider-label{
      margin-left:0;
      margin-top:-8px; }
    .bp3-slider.bp3-vertical .bp3-slider-handle.bp3-end, .bp3-slider.bp3-vertical .bp3-slider-handle.bp3-start{
      height:8px;
      margin-left:0;
      width:16px; }
    .bp3-slider.bp3-vertical .bp3-slider-handle.bp3-start{
      border-bottom-right-radius:3px;
      border-top-left-radius:0; }
      .bp3-slider.bp3-vertical .bp3-slider-handle.bp3-start .bp3-slider-label{
        -webkit-transform:translate(20px);
                transform:translate(20px); }
    .bp3-slider.bp3-vertical .bp3-slider-handle.bp3-end{
      border-bottom-left-radius:0;
      border-bottom-right-radius:0;
      border-top-left-radius:3px;
      margin-bottom:8px; }

@-webkit-keyframes pt-spinner-animation{
  from{
    -webkit-transform:rotate(0deg);
            transform:rotate(0deg); }
  to{
    -webkit-transform:rotate(360deg);
            transform:rotate(360deg); } }

@keyframes pt-spinner-animation{
  from{
    -webkit-transform:rotate(0deg);
            transform:rotate(0deg); }
  to{
    -webkit-transform:rotate(360deg);
            transform:rotate(360deg); } }

.bp3-spinner{
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-pack:center;
      -ms-flex-pack:center;
          justify-content:center;
  overflow:visible;
  vertical-align:middle; }
  .bp3-spinner svg{
    display:block; }
  .bp3-spinner path{
    fill-opacity:0; }
  .bp3-spinner .bp3-spinner-head{
    stroke:rgba(92, 112, 128, 0.8);
    stroke-linecap:round;
    -webkit-transform-origin:center;
            transform-origin:center;
    -webkit-transition:stroke-dashoffset 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
    transition:stroke-dashoffset 200ms cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-spinner .bp3-spinner-track{
    stroke:rgba(92, 112, 128, 0.2); }

.bp3-spinner-animation{
  -webkit-animation:pt-spinner-animation 500ms linear infinite;
          animation:pt-spinner-animation 500ms linear infinite; }
  .bp3-no-spin > .bp3-spinner-animation{
    -webkit-animation:none;
            animation:none; }

.bp3-dark .bp3-spinner .bp3-spinner-head{
  stroke:#8a9ba8; }

.bp3-dark .bp3-spinner .bp3-spinner-track{
  stroke:rgba(16, 22, 26, 0.5); }

.bp3-spinner.bp3-intent-primary .bp3-spinner-head{
  stroke:#137cbd; }

.bp3-spinner.bp3-intent-success .bp3-spinner-head{
  stroke:#0f9960; }

.bp3-spinner.bp3-intent-warning .bp3-spinner-head{
  stroke:#d9822b; }

.bp3-spinner.bp3-intent-danger .bp3-spinner-head{
  stroke:#db3737; }
.bp3-tabs.bp3-vertical{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex; }
  .bp3-tabs.bp3-vertical > .bp3-tab-list{
    -webkit-box-align:start;
        -ms-flex-align:start;
            align-items:flex-start;
    -webkit-box-orient:vertical;
    -webkit-box-direction:normal;
        -ms-flex-direction:column;
            flex-direction:column; }
    .bp3-tabs.bp3-vertical > .bp3-tab-list .bp3-tab{
      border-radius:3px;
      padding:0 10px;
      width:100%; }
      .bp3-tabs.bp3-vertical > .bp3-tab-list .bp3-tab[aria-selected="true"]{
        background-color:rgba(19, 124, 189, 0.2);
        -webkit-box-shadow:none;
                box-shadow:none; }
    .bp3-tabs.bp3-vertical > .bp3-tab-list .bp3-tab-indicator-wrapper .bp3-tab-indicator{
      background-color:rgba(19, 124, 189, 0.2);
      border-radius:3px;
      bottom:0;
      height:auto;
      left:0;
      right:0;
      top:0; }
  .bp3-tabs.bp3-vertical > .bp3-tab-panel{
    margin-top:0;
    padding-left:20px; }

.bp3-tab-list{
  -webkit-box-align:end;
      -ms-flex-align:end;
          align-items:flex-end;
  border:none;
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-flex:0;
      -ms-flex:0 0 auto;
          flex:0 0 auto;
  list-style:none;
  margin:0;
  padding:0;
  position:relative; }
  .bp3-tab-list > *:not(:last-child){
    margin-right:20px; }

.bp3-tab{
  overflow:hidden;
  text-overflow:ellipsis;
  white-space:nowrap;
  word-wrap:normal;
  color:#182026;
  cursor:pointer;
  -webkit-box-flex:0;
      -ms-flex:0 0 auto;
          flex:0 0 auto;
  font-size:14px;
  line-height:30px;
  max-width:100%;
  position:relative;
  vertical-align:top; }
  .bp3-tab a{
    color:inherit;
    display:block;
    text-decoration:none; }
  .bp3-tab-indicator-wrapper ~ .bp3-tab{
    background-color:transparent !important;
    -webkit-box-shadow:none !important;
            box-shadow:none !important; }
  .bp3-tab[aria-disabled="true"]{
    color:rgba(92, 112, 128, 0.6);
    cursor:not-allowed; }
  .bp3-tab[aria-selected="true"]{
    border-radius:0;
    -webkit-box-shadow:inset 0 -3px 0 #106ba3;
            box-shadow:inset 0 -3px 0 #106ba3; }
  .bp3-tab[aria-selected="true"], .bp3-tab:not([aria-disabled="true"]):hover{
    color:#106ba3; }
  .bp3-tab:focus{
    -moz-outline-radius:0; }
  .bp3-large > .bp3-tab{
    font-size:16px;
    line-height:40px; }

.bp3-tab-panel{
  margin-top:20px; }
  .bp3-tab-panel[aria-hidden="true"]{
    display:none; }

.bp3-tab-indicator-wrapper{
  left:0;
  pointer-events:none;
  position:absolute;
  top:0;
  -webkit-transform:translateX(0), translateY(0);
          transform:translateX(0), translateY(0);
  -webkit-transition:height, width, -webkit-transform;
  transition:height, width, -webkit-transform;
  transition:height, transform, width;
  transition:height, transform, width, -webkit-transform;
  -webkit-transition-duration:200ms;
          transition-duration:200ms;
  -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
          transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-tab-indicator-wrapper .bp3-tab-indicator{
    background-color:#106ba3;
    bottom:0;
    height:3px;
    left:0;
    position:absolute;
    right:0; }
  .bp3-tab-indicator-wrapper.bp3-no-animation{
    -webkit-transition:none;
    transition:none; }

.bp3-dark .bp3-tab{
  color:#f5f8fa; }
  .bp3-dark .bp3-tab[aria-disabled="true"]{
    color:rgba(167, 182, 194, 0.6); }
  .bp3-dark .bp3-tab[aria-selected="true"]{
    -webkit-box-shadow:inset 0 -3px 0 #48aff0;
            box-shadow:inset 0 -3px 0 #48aff0; }
  .bp3-dark .bp3-tab[aria-selected="true"], .bp3-dark .bp3-tab:not([aria-disabled="true"]):hover{
    color:#48aff0; }

.bp3-dark .bp3-tab-indicator{
  background-color:#48aff0; }

.bp3-flex-expander{
  -webkit-box-flex:1;
      -ms-flex:1 1;
          flex:1 1; }
.bp3-tag{
  display:-webkit-inline-box;
  display:-ms-inline-flexbox;
  display:inline-flex;
  -webkit-box-orient:horizontal;
  -webkit-box-direction:normal;
      -ms-flex-direction:row;
          flex-direction:row;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  background-color:#5c7080;
  border:none;
  border-radius:3px;
  -webkit-box-shadow:none;
          box-shadow:none;
  color:#f5f8fa;
  font-size:12px;
  line-height:16px;
  max-width:100%;
  min-height:20px;
  min-width:20px;
  padding:2px 6px;
  position:relative; }
  .bp3-tag.bp3-interactive{
    cursor:pointer; }
    .bp3-tag.bp3-interactive:hover{
      background-color:rgba(92, 112, 128, 0.85); }
    .bp3-tag.bp3-interactive.bp3-active, .bp3-tag.bp3-interactive:active{
      background-color:rgba(92, 112, 128, 0.7); }
  .bp3-tag > *{
    -webkit-box-flex:0;
        -ms-flex-positive:0;
            flex-grow:0;
    -ms-flex-negative:0;
        flex-shrink:0; }
  .bp3-tag > .bp3-fill{
    -webkit-box-flex:1;
        -ms-flex-positive:1;
            flex-grow:1;
    -ms-flex-negative:1;
        flex-shrink:1; }
  .bp3-tag::before,
  .bp3-tag > *{
    margin-right:4px; }
  .bp3-tag:empty::before,
  .bp3-tag > :last-child{
    margin-right:0; }
  .bp3-tag:focus{
    outline:rgba(19, 124, 189, 0.6) auto 2px;
    outline-offset:0;
    -moz-outline-radius:6px; }
  .bp3-tag.bp3-round{
    border-radius:30px;
    padding-left:8px;
    padding-right:8px; }
  .bp3-dark .bp3-tag{
    background-color:#bfccd6;
    color:#182026; }
    .bp3-dark .bp3-tag.bp3-interactive{
      cursor:pointer; }
      .bp3-dark .bp3-tag.bp3-interactive:hover{
        background-color:rgba(191, 204, 214, 0.85); }
      .bp3-dark .bp3-tag.bp3-interactive.bp3-active, .bp3-dark .bp3-tag.bp3-interactive:active{
        background-color:rgba(191, 204, 214, 0.7); }
    .bp3-dark .bp3-tag > .bp3-icon, .bp3-dark .bp3-tag .bp3-icon-standard, .bp3-dark .bp3-tag .bp3-icon-large{
      fill:currentColor; }
  .bp3-tag > .bp3-icon, .bp3-tag .bp3-icon-standard, .bp3-tag .bp3-icon-large{
    fill:#ffffff; }
  .bp3-tag.bp3-large,
  .bp3-large .bp3-tag{
    font-size:14px;
    line-height:20px;
    min-height:30px;
    min-width:30px;
    padding:5px 10px; }
    .bp3-tag.bp3-large::before,
    .bp3-tag.bp3-large > *,
    .bp3-large .bp3-tag::before,
    .bp3-large .bp3-tag > *{
      margin-right:7px; }
    .bp3-tag.bp3-large:empty::before,
    .bp3-tag.bp3-large > :last-child,
    .bp3-large .bp3-tag:empty::before,
    .bp3-large .bp3-tag > :last-child{
      margin-right:0; }
    .bp3-tag.bp3-large.bp3-round,
    .bp3-large .bp3-tag.bp3-round{
      padding-left:12px;
      padding-right:12px; }
  .bp3-tag.bp3-intent-primary{
    background:#137cbd;
    color:#ffffff; }
    .bp3-tag.bp3-intent-primary.bp3-interactive{
      cursor:pointer; }
      .bp3-tag.bp3-intent-primary.bp3-interactive:hover{
        background-color:rgba(19, 124, 189, 0.85); }
      .bp3-tag.bp3-intent-primary.bp3-interactive.bp3-active, .bp3-tag.bp3-intent-primary.bp3-interactive:active{
        background-color:rgba(19, 124, 189, 0.7); }
  .bp3-tag.bp3-intent-success{
    background:#0f9960;
    color:#ffffff; }
    .bp3-tag.bp3-intent-success.bp3-interactive{
      cursor:pointer; }
      .bp3-tag.bp3-intent-success.bp3-interactive:hover{
        background-color:rgba(15, 153, 96, 0.85); }
      .bp3-tag.bp3-intent-success.bp3-interactive.bp3-active, .bp3-tag.bp3-intent-success.bp3-interactive:active{
        background-color:rgba(15, 153, 96, 0.7); }
  .bp3-tag.bp3-intent-warning{
    background:#d9822b;
    color:#ffffff; }
    .bp3-tag.bp3-intent-warning.bp3-interactive{
      cursor:pointer; }
      .bp3-tag.bp3-intent-warning.bp3-interactive:hover{
        background-color:rgba(217, 130, 43, 0.85); }
      .bp3-tag.bp3-intent-warning.bp3-interactive.bp3-active, .bp3-tag.bp3-intent-warning.bp3-interactive:active{
        background-color:rgba(217, 130, 43, 0.7); }
  .bp3-tag.bp3-intent-danger{
    background:#db3737;
    color:#ffffff; }
    .bp3-tag.bp3-intent-danger.bp3-interactive{
      cursor:pointer; }
      .bp3-tag.bp3-intent-danger.bp3-interactive:hover{
        background-color:rgba(219, 55, 55, 0.85); }
      .bp3-tag.bp3-intent-danger.bp3-interactive.bp3-active, .bp3-tag.bp3-intent-danger.bp3-interactive:active{
        background-color:rgba(219, 55, 55, 0.7); }
  .bp3-tag.bp3-fill{
    display:-webkit-box;
    display:-ms-flexbox;
    display:flex;
    width:100%; }
  .bp3-tag.bp3-minimal > .bp3-icon, .bp3-tag.bp3-minimal .bp3-icon-standard, .bp3-tag.bp3-minimal .bp3-icon-large{
    fill:#5c7080; }
  .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]){
    background-color:rgba(138, 155, 168, 0.2);
    color:#182026; }
    .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]).bp3-interactive{
      cursor:pointer; }
      .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]).bp3-interactive:hover{
        background-color:rgba(92, 112, 128, 0.3); }
      .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]).bp3-interactive.bp3-active, .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]).bp3-interactive:active{
        background-color:rgba(92, 112, 128, 0.4); }
    .bp3-dark .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]){
      color:#f5f8fa; }
      .bp3-dark .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]).bp3-interactive{
        cursor:pointer; }
        .bp3-dark .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]).bp3-interactive:hover{
          background-color:rgba(191, 204, 214, 0.3); }
        .bp3-dark .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]).bp3-interactive.bp3-active, .bp3-dark .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]).bp3-interactive:active{
          background-color:rgba(191, 204, 214, 0.4); }
      .bp3-dark .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]) > .bp3-icon, .bp3-dark .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]) .bp3-icon-standard, .bp3-dark .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]) .bp3-icon-large{
        fill:#a7b6c2; }
  .bp3-tag.bp3-minimal.bp3-intent-primary{
    background-color:rgba(19, 124, 189, 0.15);
    color:#106ba3; }
    .bp3-tag.bp3-minimal.bp3-intent-primary.bp3-interactive{
      cursor:pointer; }
      .bp3-tag.bp3-minimal.bp3-intent-primary.bp3-interactive:hover{
        background-color:rgba(19, 124, 189, 0.25); }
      .bp3-tag.bp3-minimal.bp3-intent-primary.bp3-interactive.bp3-active, .bp3-tag.bp3-minimal.bp3-intent-primary.bp3-interactive:active{
        background-color:rgba(19, 124, 189, 0.35); }
    .bp3-tag.bp3-minimal.bp3-intent-primary > .bp3-icon, .bp3-tag.bp3-minimal.bp3-intent-primary .bp3-icon-standard, .bp3-tag.bp3-minimal.bp3-intent-primary .bp3-icon-large{
      fill:#137cbd; }
    .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-primary{
      background-color:rgba(19, 124, 189, 0.25);
      color:#48aff0; }
      .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-primary.bp3-interactive{
        cursor:pointer; }
        .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-primary.bp3-interactive:hover{
          background-color:rgba(19, 124, 189, 0.35); }
        .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-primary.bp3-interactive.bp3-active, .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-primary.bp3-interactive:active{
          background-color:rgba(19, 124, 189, 0.45); }
  .bp3-tag.bp3-minimal.bp3-intent-success{
    background-color:rgba(15, 153, 96, 0.15);
    color:#0d8050; }
    .bp3-tag.bp3-minimal.bp3-intent-success.bp3-interactive{
      cursor:pointer; }
      .bp3-tag.bp3-minimal.bp3-intent-success.bp3-interactive:hover{
        background-color:rgba(15, 153, 96, 0.25); }
      .bp3-tag.bp3-minimal.bp3-intent-success.bp3-interactive.bp3-active, .bp3-tag.bp3-minimal.bp3-intent-success.bp3-interactive:active{
        background-color:rgba(15, 153, 96, 0.35); }
    .bp3-tag.bp3-minimal.bp3-intent-success > .bp3-icon, .bp3-tag.bp3-minimal.bp3-intent-success .bp3-icon-standard, .bp3-tag.bp3-minimal.bp3-intent-success .bp3-icon-large{
      fill:#0f9960; }
    .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-success{
      background-color:rgba(15, 153, 96, 0.25);
      color:#3dcc91; }
      .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-success.bp3-interactive{
        cursor:pointer; }
        .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-success.bp3-interactive:hover{
          background-color:rgba(15, 153, 96, 0.35); }
        .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-success.bp3-interactive.bp3-active, .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-success.bp3-interactive:active{
          background-color:rgba(15, 153, 96, 0.45); }
  .bp3-tag.bp3-minimal.bp3-intent-warning{
    background-color:rgba(217, 130, 43, 0.15);
    color:#bf7326; }
    .bp3-tag.bp3-minimal.bp3-intent-warning.bp3-interactive{
      cursor:pointer; }
      .bp3-tag.bp3-minimal.bp3-intent-warning.bp3-interactive:hover{
        background-color:rgba(217, 130, 43, 0.25); }
      .bp3-tag.bp3-minimal.bp3-intent-warning.bp3-interactive.bp3-active, .bp3-tag.bp3-minimal.bp3-intent-warning.bp3-interactive:active{
        background-color:rgba(217, 130, 43, 0.35); }
    .bp3-tag.bp3-minimal.bp3-intent-warning > .bp3-icon, .bp3-tag.bp3-minimal.bp3-intent-warning .bp3-icon-standard, .bp3-tag.bp3-minimal.bp3-intent-warning .bp3-icon-large{
      fill:#d9822b; }
    .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-warning{
      background-color:rgba(217, 130, 43, 0.25);
      color:#ffb366; }
      .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-warning.bp3-interactive{
        cursor:pointer; }
        .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-warning.bp3-interactive:hover{
          background-color:rgba(217, 130, 43, 0.35); }
        .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-warning.bp3-interactive.bp3-active, .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-warning.bp3-interactive:active{
          background-color:rgba(217, 130, 43, 0.45); }
  .bp3-tag.bp3-minimal.bp3-intent-danger{
    background-color:rgba(219, 55, 55, 0.15);
    color:#c23030; }
    .bp3-tag.bp3-minimal.bp3-intent-danger.bp3-interactive{
      cursor:pointer; }
      .bp3-tag.bp3-minimal.bp3-intent-danger.bp3-interactive:hover{
        background-color:rgba(219, 55, 55, 0.25); }
      .bp3-tag.bp3-minimal.bp3-intent-danger.bp3-interactive.bp3-active, .bp3-tag.bp3-minimal.bp3-intent-danger.bp3-interactive:active{
        background-color:rgba(219, 55, 55, 0.35); }
    .bp3-tag.bp3-minimal.bp3-intent-danger > .bp3-icon, .bp3-tag.bp3-minimal.bp3-intent-danger .bp3-icon-standard, .bp3-tag.bp3-minimal.bp3-intent-danger .bp3-icon-large{
      fill:#db3737; }
    .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-danger{
      background-color:rgba(219, 55, 55, 0.25);
      color:#ff7373; }
      .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-danger.bp3-interactive{
        cursor:pointer; }
        .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-danger.bp3-interactive:hover{
          background-color:rgba(219, 55, 55, 0.35); }
        .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-danger.bp3-interactive.bp3-active, .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-danger.bp3-interactive:active{
          background-color:rgba(219, 55, 55, 0.45); }

.bp3-tag-remove{
  background:none;
  border:none;
  color:inherit;
  cursor:pointer;
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  margin-bottom:-2px;
  margin-right:-6px !important;
  margin-top:-2px;
  opacity:0.5;
  padding:2px;
  padding-left:0; }
  .bp3-tag-remove:hover{
    background:none;
    opacity:0.8;
    text-decoration:none; }
  .bp3-tag-remove:active{
    opacity:1; }
  .bp3-tag-remove:empty::before{
    font-family:"Icons16", sans-serif;
    font-size:16px;
    font-style:normal;
    font-weight:400;
    line-height:1;
    -moz-osx-font-smoothing:grayscale;
    -webkit-font-smoothing:antialiased;
    content:""; }
  .bp3-large .bp3-tag-remove{
    margin-right:-10px !important;
    padding:0 5px 0 0; }
    .bp3-large .bp3-tag-remove:empty::before{
      font-family:"Icons20", sans-serif;
      font-size:20px;
      font-style:normal;
      font-weight:400;
      line-height:1; }
.bp3-tag-input{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-orient:horizontal;
  -webkit-box-direction:normal;
      -ms-flex-direction:row;
          flex-direction:row;
  -webkit-box-align:start;
      -ms-flex-align:start;
          align-items:flex-start;
  cursor:text;
  height:auto;
  line-height:inherit;
  min-height:30px;
  padding-left:5px;
  padding-right:0; }
  .bp3-tag-input > *{
    -webkit-box-flex:0;
        -ms-flex-positive:0;
            flex-grow:0;
    -ms-flex-negative:0;
        flex-shrink:0; }
  .bp3-tag-input > .bp3-tag-input-values{
    -webkit-box-flex:1;
        -ms-flex-positive:1;
            flex-grow:1;
    -ms-flex-negative:1;
        flex-shrink:1; }
  .bp3-tag-input .bp3-tag-input-icon{
    color:#5c7080;
    margin-left:2px;
    margin-right:7px;
    margin-top:7px; }
  .bp3-tag-input .bp3-tag-input-values{
    display:-webkit-box;
    display:-ms-flexbox;
    display:flex;
    -webkit-box-orient:horizontal;
    -webkit-box-direction:normal;
        -ms-flex-direction:row;
            flex-direction:row;
    -webkit-box-align:center;
        -ms-flex-align:center;
            align-items:center;
    -ms-flex-item-align:stretch;
        align-self:stretch;
    -ms-flex-wrap:wrap;
        flex-wrap:wrap;
    margin-right:7px;
    margin-top:5px;
    min-width:0; }
    .bp3-tag-input .bp3-tag-input-values > *{
      -webkit-box-flex:0;
          -ms-flex-positive:0;
              flex-grow:0;
      -ms-flex-negative:0;
          flex-shrink:0; }
    .bp3-tag-input .bp3-tag-input-values > .bp3-fill{
      -webkit-box-flex:1;
          -ms-flex-positive:1;
              flex-grow:1;
      -ms-flex-negative:1;
          flex-shrink:1; }
    .bp3-tag-input .bp3-tag-input-values::before,
    .bp3-tag-input .bp3-tag-input-values > *{
      margin-right:5px; }
    .bp3-tag-input .bp3-tag-input-values:empty::before,
    .bp3-tag-input .bp3-tag-input-values > :last-child{
      margin-right:0; }
    .bp3-tag-input .bp3-tag-input-values:first-child .bp3-input-ghost:first-child{
      padding-left:5px; }
    .bp3-tag-input .bp3-tag-input-values > *{
      margin-bottom:5px; }
  .bp3-tag-input .bp3-tag{
    overflow-wrap:break-word; }
    .bp3-tag-input .bp3-tag.bp3-active{
      outline:rgba(19, 124, 189, 0.6) auto 2px;
      outline-offset:0;
      -moz-outline-radius:6px; }
  .bp3-tag-input .bp3-input-ghost{
    -webkit-box-flex:1;
        -ms-flex:1 1 auto;
            flex:1 1 auto;
    line-height:20px;
    width:80px; }
    .bp3-tag-input .bp3-input-ghost:disabled, .bp3-tag-input .bp3-input-ghost.bp3-disabled{
      cursor:not-allowed; }
  .bp3-tag-input .bp3-button,
  .bp3-tag-input .bp3-spinner{
    margin:3px;
    margin-left:0; }
  .bp3-tag-input .bp3-button{
    min-height:24px;
    min-width:24px;
    padding:0 7px; }
  .bp3-tag-input.bp3-large{
    height:auto;
    min-height:40px; }
    .bp3-tag-input.bp3-large::before,
    .bp3-tag-input.bp3-large > *{
      margin-right:10px; }
    .bp3-tag-input.bp3-large:empty::before,
    .bp3-tag-input.bp3-large > :last-child{
      margin-right:0; }
    .bp3-tag-input.bp3-large .bp3-tag-input-icon{
      margin-left:5px;
      margin-top:10px; }
    .bp3-tag-input.bp3-large .bp3-input-ghost{
      line-height:30px; }
    .bp3-tag-input.bp3-large .bp3-button{
      min-height:30px;
      min-width:30px;
      padding:5px 10px;
      margin:5px;
      margin-left:0; }
    .bp3-tag-input.bp3-large .bp3-spinner{
      margin:8px;
      margin-left:0; }
  .bp3-tag-input.bp3-active{
    background-color:#ffffff;
    -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-tag-input.bp3-active.bp3-intent-primary{
      -webkit-box-shadow:0 0 0 1px #106ba3, 0 0 0 3px rgba(16, 107, 163, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #106ba3, 0 0 0 3px rgba(16, 107, 163, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-tag-input.bp3-active.bp3-intent-success{
      -webkit-box-shadow:0 0 0 1px #0d8050, 0 0 0 3px rgba(13, 128, 80, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #0d8050, 0 0 0 3px rgba(13, 128, 80, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-tag-input.bp3-active.bp3-intent-warning{
      -webkit-box-shadow:0 0 0 1px #bf7326, 0 0 0 3px rgba(191, 115, 38, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #bf7326, 0 0 0 3px rgba(191, 115, 38, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-tag-input.bp3-active.bp3-intent-danger{
      -webkit-box-shadow:0 0 0 1px #c23030, 0 0 0 3px rgba(194, 48, 48, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #c23030, 0 0 0 3px rgba(194, 48, 48, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
  .bp3-dark .bp3-tag-input .bp3-tag-input-icon, .bp3-tag-input.bp3-dark .bp3-tag-input-icon{
    color:#a7b6c2; }
  .bp3-dark .bp3-tag-input .bp3-input-ghost, .bp3-tag-input.bp3-dark .bp3-input-ghost{
    color:#f5f8fa; }
    .bp3-dark .bp3-tag-input .bp3-input-ghost::-webkit-input-placeholder, .bp3-tag-input.bp3-dark .bp3-input-ghost::-webkit-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-tag-input .bp3-input-ghost::-moz-placeholder, .bp3-tag-input.bp3-dark .bp3-input-ghost::-moz-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-tag-input .bp3-input-ghost:-ms-input-placeholder, .bp3-tag-input.bp3-dark .bp3-input-ghost:-ms-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-tag-input .bp3-input-ghost::-ms-input-placeholder, .bp3-tag-input.bp3-dark .bp3-input-ghost::-ms-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-tag-input .bp3-input-ghost::placeholder, .bp3-tag-input.bp3-dark .bp3-input-ghost::placeholder{
      color:rgba(167, 182, 194, 0.6); }
  .bp3-dark .bp3-tag-input.bp3-active, .bp3-tag-input.bp3-dark.bp3-active{
    background-color:rgba(16, 22, 26, 0.3);
    -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px #137cbd, 0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-tag-input.bp3-active.bp3-intent-primary, .bp3-tag-input.bp3-dark.bp3-active.bp3-intent-primary{
      -webkit-box-shadow:0 0 0 1px #106ba3, 0 0 0 3px rgba(16, 107, 163, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px #106ba3, 0 0 0 3px rgba(16, 107, 163, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-tag-input.bp3-active.bp3-intent-success, .bp3-tag-input.bp3-dark.bp3-active.bp3-intent-success{
      -webkit-box-shadow:0 0 0 1px #0d8050, 0 0 0 3px rgba(13, 128, 80, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px #0d8050, 0 0 0 3px rgba(13, 128, 80, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-tag-input.bp3-active.bp3-intent-warning, .bp3-tag-input.bp3-dark.bp3-active.bp3-intent-warning{
      -webkit-box-shadow:0 0 0 1px #bf7326, 0 0 0 3px rgba(191, 115, 38, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px #bf7326, 0 0 0 3px rgba(191, 115, 38, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-tag-input.bp3-active.bp3-intent-danger, .bp3-tag-input.bp3-dark.bp3-active.bp3-intent-danger{
      -webkit-box-shadow:0 0 0 1px #c23030, 0 0 0 3px rgba(194, 48, 48, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px #c23030, 0 0 0 3px rgba(194, 48, 48, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }

.bp3-input-ghost{
  background:none;
  border:none;
  -webkit-box-shadow:none;
          box-shadow:none;
  padding:0; }
  .bp3-input-ghost::-webkit-input-placeholder{
    color:rgba(92, 112, 128, 0.6);
    opacity:1; }
  .bp3-input-ghost::-moz-placeholder{
    color:rgba(92, 112, 128, 0.6);
    opacity:1; }
  .bp3-input-ghost:-ms-input-placeholder{
    color:rgba(92, 112, 128, 0.6);
    opacity:1; }
  .bp3-input-ghost::-ms-input-placeholder{
    color:rgba(92, 112, 128, 0.6);
    opacity:1; }
  .bp3-input-ghost::placeholder{
    color:rgba(92, 112, 128, 0.6);
    opacity:1; }
  .bp3-input-ghost:focus{
    outline:none !important; }
.bp3-toast{
  -webkit-box-align:start;
      -ms-flex-align:start;
          align-items:flex-start;
  background-color:#ffffff;
  border-radius:3px;
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  margin:20px 0 0;
  max-width:500px;
  min-width:300px;
  pointer-events:all;
  position:relative !important; }
  .bp3-toast.bp3-toast-enter, .bp3-toast.bp3-toast-appear{
    -webkit-transform:translateY(-40px);
            transform:translateY(-40px); }
  .bp3-toast.bp3-toast-enter-active, .bp3-toast.bp3-toast-appear-active{
    -webkit-transform:translateY(0);
            transform:translateY(0);
    -webkit-transition-delay:0;
            transition-delay:0;
    -webkit-transition-duration:300ms;
            transition-duration:300ms;
    -webkit-transition-property:-webkit-transform;
    transition-property:-webkit-transform;
    transition-property:transform;
    transition-property:transform, -webkit-transform;
    -webkit-transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11);
            transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11); }
  .bp3-toast.bp3-toast-enter ~ .bp3-toast, .bp3-toast.bp3-toast-appear ~ .bp3-toast{
    -webkit-transform:translateY(-40px);
            transform:translateY(-40px); }
  .bp3-toast.bp3-toast-enter-active ~ .bp3-toast, .bp3-toast.bp3-toast-appear-active ~ .bp3-toast{
    -webkit-transform:translateY(0);
            transform:translateY(0);
    -webkit-transition-delay:0;
            transition-delay:0;
    -webkit-transition-duration:300ms;
            transition-duration:300ms;
    -webkit-transition-property:-webkit-transform;
    transition-property:-webkit-transform;
    transition-property:transform;
    transition-property:transform, -webkit-transform;
    -webkit-transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11);
            transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11); }
  .bp3-toast.bp3-toast-exit{
    opacity:1;
    -webkit-filter:blur(0);
            filter:blur(0); }
  .bp3-toast.bp3-toast-exit-active{
    opacity:0;
    -webkit-filter:blur(10px);
            filter:blur(10px);
    -webkit-transition-delay:0;
            transition-delay:0;
    -webkit-transition-duration:300ms;
            transition-duration:300ms;
    -webkit-transition-property:opacity, -webkit-filter;
    transition-property:opacity, -webkit-filter;
    transition-property:opacity, filter;
    transition-property:opacity, filter, -webkit-filter;
    -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
            transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-toast.bp3-toast-exit ~ .bp3-toast{
    -webkit-transform:translateY(0);
            transform:translateY(0); }
  .bp3-toast.bp3-toast-exit-active ~ .bp3-toast{
    -webkit-transform:translateY(-40px);
            transform:translateY(-40px);
    -webkit-transition-delay:50ms;
            transition-delay:50ms;
    -webkit-transition-duration:100ms;
            transition-duration:100ms;
    -webkit-transition-property:-webkit-transform;
    transition-property:-webkit-transform;
    transition-property:transform;
    transition-property:transform, -webkit-transform;
    -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
            transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-toast .bp3-button-group{
    -webkit-box-flex:0;
        -ms-flex:0 0 auto;
            flex:0 0 auto;
    padding:5px;
    padding-left:0; }
  .bp3-toast > .bp3-icon{
    color:#5c7080;
    margin:12px;
    margin-right:0; }
  .bp3-toast.bp3-dark,
  .bp3-dark .bp3-toast{
    background-color:#394b59;
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4); }
    .bp3-toast.bp3-dark > .bp3-icon,
    .bp3-dark .bp3-toast > .bp3-icon{
      color:#a7b6c2; }
  .bp3-toast[class*="bp3-intent-"] a{
    color:rgba(255, 255, 255, 0.7); }
    .bp3-toast[class*="bp3-intent-"] a:hover{
      color:#ffffff; }
  .bp3-toast[class*="bp3-intent-"] > .bp3-icon{
    color:#ffffff; }
  .bp3-toast[class*="bp3-intent-"] .bp3-button, .bp3-toast[class*="bp3-intent-"] .bp3-button::before,
  .bp3-toast[class*="bp3-intent-"] .bp3-button .bp3-icon, .bp3-toast[class*="bp3-intent-"] .bp3-button:active{
    color:rgba(255, 255, 255, 0.7) !important; }
  .bp3-toast[class*="bp3-intent-"] .bp3-button:focus{
    outline-color:rgba(255, 255, 255, 0.5); }
  .bp3-toast[class*="bp3-intent-"] .bp3-button:hover{
    background-color:rgba(255, 255, 255, 0.15) !important;
    color:#ffffff !important; }
  .bp3-toast[class*="bp3-intent-"] .bp3-button:active{
    background-color:rgba(255, 255, 255, 0.3) !important;
    color:#ffffff !important; }
  .bp3-toast[class*="bp3-intent-"] .bp3-button::after{
    background:rgba(255, 255, 255, 0.3) !important; }
  .bp3-toast.bp3-intent-primary{
    background-color:#137cbd;
    color:#ffffff; }
  .bp3-toast.bp3-intent-success{
    background-color:#0f9960;
    color:#ffffff; }
  .bp3-toast.bp3-intent-warning{
    background-color:#d9822b;
    color:#ffffff; }
  .bp3-toast.bp3-intent-danger{
    background-color:#db3737;
    color:#ffffff; }

.bp3-toast-message{
  -webkit-box-flex:1;
      -ms-flex:1 1 auto;
          flex:1 1 auto;
  padding:11px;
  word-break:break-word; }

.bp3-toast-container{
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  display:-webkit-box !important;
  display:-ms-flexbox !important;
  display:flex !important;
  -webkit-box-orient:vertical;
  -webkit-box-direction:normal;
      -ms-flex-direction:column;
          flex-direction:column;
  left:0;
  overflow:hidden;
  padding:0 20px 20px;
  pointer-events:none;
  position:fixed;
  right:0;
  z-index:40; }
  .bp3-toast-container.bp3-toast-container-top{
    top:0; }
  .bp3-toast-container.bp3-toast-container-bottom{
    bottom:0;
    -webkit-box-orient:vertical;
    -webkit-box-direction:reverse;
        -ms-flex-direction:column-reverse;
            flex-direction:column-reverse;
    top:auto; }
  .bp3-toast-container.bp3-toast-container-left{
    -webkit-box-align:start;
        -ms-flex-align:start;
            align-items:flex-start; }
  .bp3-toast-container.bp3-toast-container-right{
    -webkit-box-align:end;
        -ms-flex-align:end;
            align-items:flex-end; }

.bp3-toast-container-bottom .bp3-toast.bp3-toast-enter:not(.bp3-toast-enter-active),
.bp3-toast-container-bottom .bp3-toast.bp3-toast-enter:not(.bp3-toast-enter-active) ~ .bp3-toast, .bp3-toast-container-bottom .bp3-toast.bp3-toast-appear:not(.bp3-toast-appear-active),
.bp3-toast-container-bottom .bp3-toast.bp3-toast-appear:not(.bp3-toast-appear-active) ~ .bp3-toast,
.bp3-toast-container-bottom .bp3-toast.bp3-toast-exit-active ~ .bp3-toast,
.bp3-toast-container-bottom .bp3-toast.bp3-toast-leave-active ~ .bp3-toast{
  -webkit-transform:translateY(60px);
          transform:translateY(60px); }
.bp3-tooltip{
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
  -webkit-transform:scale(1);
          transform:scale(1); }
  .bp3-tooltip .bp3-popover-arrow{
    height:22px;
    position:absolute;
    width:22px; }
    .bp3-tooltip .bp3-popover-arrow::before{
      height:14px;
      margin:4px;
      width:14px; }
  .bp3-tether-element-attached-bottom.bp3-tether-target-attached-top > .bp3-tooltip{
    margin-bottom:11px;
    margin-top:-11px; }
    .bp3-tether-element-attached-bottom.bp3-tether-target-attached-top > .bp3-tooltip > .bp3-popover-arrow{
      bottom:-8px; }
      .bp3-tether-element-attached-bottom.bp3-tether-target-attached-top > .bp3-tooltip > .bp3-popover-arrow svg{
        -webkit-transform:rotate(-90deg);
                transform:rotate(-90deg); }
  .bp3-tether-element-attached-left.bp3-tether-target-attached-right > .bp3-tooltip{
    margin-left:11px; }
    .bp3-tether-element-attached-left.bp3-tether-target-attached-right > .bp3-tooltip > .bp3-popover-arrow{
      left:-8px; }
      .bp3-tether-element-attached-left.bp3-tether-target-attached-right > .bp3-tooltip > .bp3-popover-arrow svg{
        -webkit-transform:rotate(0);
                transform:rotate(0); }
  .bp3-tether-element-attached-top.bp3-tether-target-attached-bottom > .bp3-tooltip{
    margin-top:11px; }
    .bp3-tether-element-attached-top.bp3-tether-target-attached-bottom > .bp3-tooltip > .bp3-popover-arrow{
      top:-8px; }
      .bp3-tether-element-attached-top.bp3-tether-target-attached-bottom > .bp3-tooltip > .bp3-popover-arrow svg{
        -webkit-transform:rotate(90deg);
                transform:rotate(90deg); }
  .bp3-tether-element-attached-right.bp3-tether-target-attached-left > .bp3-tooltip{
    margin-left:-11px;
    margin-right:11px; }
    .bp3-tether-element-attached-right.bp3-tether-target-attached-left > .bp3-tooltip > .bp3-popover-arrow{
      right:-8px; }
      .bp3-tether-element-attached-right.bp3-tether-target-attached-left > .bp3-tooltip > .bp3-popover-arrow svg{
        -webkit-transform:rotate(180deg);
                transform:rotate(180deg); }
  .bp3-tether-element-attached-middle > .bp3-tooltip > .bp3-popover-arrow{
    top:50%;
    -webkit-transform:translateY(-50%);
            transform:translateY(-50%); }
  .bp3-tether-element-attached-center > .bp3-tooltip > .bp3-popover-arrow{
    right:50%;
    -webkit-transform:translateX(50%);
            transform:translateX(50%); }
  .bp3-tether-element-attached-top.bp3-tether-target-attached-top > .bp3-tooltip > .bp3-popover-arrow{
    top:-0.22183px; }
  .bp3-tether-element-attached-right.bp3-tether-target-attached-right > .bp3-tooltip > .bp3-popover-arrow{
    right:-0.22183px; }
  .bp3-tether-element-attached-left.bp3-tether-target-attached-left > .bp3-tooltip > .bp3-popover-arrow{
    left:-0.22183px; }
  .bp3-tether-element-attached-bottom.bp3-tether-target-attached-bottom > .bp3-tooltip > .bp3-popover-arrow{
    bottom:-0.22183px; }
  .bp3-tether-element-attached-top.bp3-tether-element-attached-left > .bp3-tooltip{
    -webkit-transform-origin:top left;
            transform-origin:top left; }
  .bp3-tether-element-attached-top.bp3-tether-element-attached-center > .bp3-tooltip{
    -webkit-transform-origin:top center;
            transform-origin:top center; }
  .bp3-tether-element-attached-top.bp3-tether-element-attached-right > .bp3-tooltip{
    -webkit-transform-origin:top right;
            transform-origin:top right; }
  .bp3-tether-element-attached-middle.bp3-tether-element-attached-left > .bp3-tooltip{
    -webkit-transform-origin:center left;
            transform-origin:center left; }
  .bp3-tether-element-attached-middle.bp3-tether-element-attached-center > .bp3-tooltip{
    -webkit-transform-origin:center center;
            transform-origin:center center; }
  .bp3-tether-element-attached-middle.bp3-tether-element-attached-right > .bp3-tooltip{
    -webkit-transform-origin:center right;
            transform-origin:center right; }
  .bp3-tether-element-attached-bottom.bp3-tether-element-attached-left > .bp3-tooltip{
    -webkit-transform-origin:bottom left;
            transform-origin:bottom left; }
  .bp3-tether-element-attached-bottom.bp3-tether-element-attached-center > .bp3-tooltip{
    -webkit-transform-origin:bottom center;
            transform-origin:bottom center; }
  .bp3-tether-element-attached-bottom.bp3-tether-element-attached-right > .bp3-tooltip{
    -webkit-transform-origin:bottom right;
            transform-origin:bottom right; }
  .bp3-tooltip .bp3-popover-content{
    background:#394b59;
    color:#f5f8fa; }
  .bp3-tooltip .bp3-popover-arrow::before{
    -webkit-box-shadow:1px 1px 6px rgba(16, 22, 26, 0.2);
            box-shadow:1px 1px 6px rgba(16, 22, 26, 0.2); }
  .bp3-tooltip .bp3-popover-arrow-border{
    fill:#10161a;
    fill-opacity:0.1; }
  .bp3-tooltip .bp3-popover-arrow-fill{
    fill:#394b59; }
  .bp3-popover-enter > .bp3-tooltip, .bp3-popover-appear > .bp3-tooltip{
    -webkit-transform:scale(0.8);
            transform:scale(0.8); }
  .bp3-popover-enter-active > .bp3-tooltip, .bp3-popover-appear-active > .bp3-tooltip{
    -webkit-transform:scale(1);
            transform:scale(1);
    -webkit-transition-delay:0;
            transition-delay:0;
    -webkit-transition-duration:100ms;
            transition-duration:100ms;
    -webkit-transition-property:-webkit-transform;
    transition-property:-webkit-transform;
    transition-property:transform;
    transition-property:transform, -webkit-transform;
    -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
            transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-popover-exit > .bp3-tooltip{
    -webkit-transform:scale(1);
            transform:scale(1); }
  .bp3-popover-exit-active > .bp3-tooltip{
    -webkit-transform:scale(0.8);
            transform:scale(0.8);
    -webkit-transition-delay:0;
            transition-delay:0;
    -webkit-transition-duration:100ms;
            transition-duration:100ms;
    -webkit-transition-property:-webkit-transform;
    transition-property:-webkit-transform;
    transition-property:transform;
    transition-property:transform, -webkit-transform;
    -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
            transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-tooltip .bp3-popover-content{
    padding:10px 12px; }
  .bp3-tooltip.bp3-dark,
  .bp3-dark .bp3-tooltip{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4); }
    .bp3-tooltip.bp3-dark .bp3-popover-content,
    .bp3-dark .bp3-tooltip .bp3-popover-content{
      background:#e1e8ed;
      color:#394b59; }
    .bp3-tooltip.bp3-dark .bp3-popover-arrow::before,
    .bp3-dark .bp3-tooltip .bp3-popover-arrow::before{
      -webkit-box-shadow:1px 1px 6px rgba(16, 22, 26, 0.4);
              box-shadow:1px 1px 6px rgba(16, 22, 26, 0.4); }
    .bp3-tooltip.bp3-dark .bp3-popover-arrow-border,
    .bp3-dark .bp3-tooltip .bp3-popover-arrow-border{
      fill:#10161a;
      fill-opacity:0.2; }
    .bp3-tooltip.bp3-dark .bp3-popover-arrow-fill,
    .bp3-dark .bp3-tooltip .bp3-popover-arrow-fill{
      fill:#e1e8ed; }
  .bp3-tooltip.bp3-intent-primary .bp3-popover-content{
    background:#137cbd;
    color:#ffffff; }
  .bp3-tooltip.bp3-intent-primary .bp3-popover-arrow-fill{
    fill:#137cbd; }
  .bp3-tooltip.bp3-intent-success .bp3-popover-content{
    background:#0f9960;
    color:#ffffff; }
  .bp3-tooltip.bp3-intent-success .bp3-popover-arrow-fill{
    fill:#0f9960; }
  .bp3-tooltip.bp3-intent-warning .bp3-popover-content{
    background:#d9822b;
    color:#ffffff; }
  .bp3-tooltip.bp3-intent-warning .bp3-popover-arrow-fill{
    fill:#d9822b; }
  .bp3-tooltip.bp3-intent-danger .bp3-popover-content{
    background:#db3737;
    color:#ffffff; }
  .bp3-tooltip.bp3-intent-danger .bp3-popover-arrow-fill{
    fill:#db3737; }

.bp3-tooltip-indicator{
  border-bottom:dotted 1px;
  cursor:help; }
.bp3-tree .bp3-icon, .bp3-tree .bp3-icon-standard, .bp3-tree .bp3-icon-large{
  color:#5c7080; }
  .bp3-tree .bp3-icon.bp3-intent-primary, .bp3-tree .bp3-icon-standard.bp3-intent-primary, .bp3-tree .bp3-icon-large.bp3-intent-primary{
    color:#137cbd; }
  .bp3-tree .bp3-icon.bp3-intent-success, .bp3-tree .bp3-icon-standard.bp3-intent-success, .bp3-tree .bp3-icon-large.bp3-intent-success{
    color:#0f9960; }
  .bp3-tree .bp3-icon.bp3-intent-warning, .bp3-tree .bp3-icon-standard.bp3-intent-warning, .bp3-tree .bp3-icon-large.bp3-intent-warning{
    color:#d9822b; }
  .bp3-tree .bp3-icon.bp3-intent-danger, .bp3-tree .bp3-icon-standard.bp3-intent-danger, .bp3-tree .bp3-icon-large.bp3-intent-danger{
    color:#db3737; }

.bp3-tree-node-list{
  list-style:none;
  margin:0;
  padding-left:0; }

.bp3-tree-root{
  background-color:transparent;
  cursor:default;
  padding-left:0;
  position:relative; }

.bp3-tree-node-content-0{
  padding-left:0px; }

.bp3-tree-node-content-1{
  padding-left:23px; }

.bp3-tree-node-content-2{
  padding-left:46px; }

.bp3-tree-node-content-3{
  padding-left:69px; }

.bp3-tree-node-content-4{
  padding-left:92px; }

.bp3-tree-node-content-5{
  padding-left:115px; }

.bp3-tree-node-content-6{
  padding-left:138px; }

.bp3-tree-node-content-7{
  padding-left:161px; }

.bp3-tree-node-content-8{
  padding-left:184px; }

.bp3-tree-node-content-9{
  padding-left:207px; }

.bp3-tree-node-content-10{
  padding-left:230px; }

.bp3-tree-node-content-11{
  padding-left:253px; }

.bp3-tree-node-content-12{
  padding-left:276px; }

.bp3-tree-node-content-13{
  padding-left:299px; }

.bp3-tree-node-content-14{
  padding-left:322px; }

.bp3-tree-node-content-15{
  padding-left:345px; }

.bp3-tree-node-content-16{
  padding-left:368px; }

.bp3-tree-node-content-17{
  padding-left:391px; }

.bp3-tree-node-content-18{
  padding-left:414px; }

.bp3-tree-node-content-19{
  padding-left:437px; }

.bp3-tree-node-content-20{
  padding-left:460px; }

.bp3-tree-node-content{
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  height:30px;
  padding-right:5px;
  width:100%; }
  .bp3-tree-node-content:hover{
    background-color:rgba(191, 204, 214, 0.4); }

.bp3-tree-node-caret,
.bp3-tree-node-caret-none{
  min-width:30px; }

.bp3-tree-node-caret{
  color:#5c7080;
  cursor:pointer;
  padding:7px;
  -webkit-transform:rotate(0deg);
          transform:rotate(0deg);
  -webkit-transition:-webkit-transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:-webkit-transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9), -webkit-transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-tree-node-caret:hover{
    color:#182026; }
  .bp3-dark .bp3-tree-node-caret{
    color:#a7b6c2; }
    .bp3-dark .bp3-tree-node-caret:hover{
      color:#f5f8fa; }
  .bp3-tree-node-caret.bp3-tree-node-caret-open{
    -webkit-transform:rotate(90deg);
            transform:rotate(90deg); }
  .bp3-tree-node-caret.bp3-icon-standard::before{
    content:""; }

.bp3-tree-node-icon{
  margin-right:7px;
  position:relative; }

.bp3-tree-node-label{
  overflow:hidden;
  text-overflow:ellipsis;
  white-space:nowrap;
  word-wrap:normal;
  -webkit-box-flex:1;
      -ms-flex:1 1 auto;
          flex:1 1 auto;
  position:relative;
  -webkit-user-select:none;
     -moz-user-select:none;
      -ms-user-select:none;
          user-select:none; }
  .bp3-tree-node-label span{
    display:inline; }

.bp3-tree-node-secondary-label{
  padding:0 5px;
  -webkit-user-select:none;
     -moz-user-select:none;
      -ms-user-select:none;
          user-select:none; }
  .bp3-tree-node-secondary-label .bp3-popover-wrapper,
  .bp3-tree-node-secondary-label .bp3-popover-target{
    -webkit-box-align:center;
        -ms-flex-align:center;
            align-items:center;
    display:-webkit-box;
    display:-ms-flexbox;
    display:flex; }

.bp3-tree-node.bp3-disabled .bp3-tree-node-content{
  background-color:inherit;
  color:rgba(92, 112, 128, 0.6);
  cursor:not-allowed; }

.bp3-tree-node.bp3-disabled .bp3-tree-node-caret,
.bp3-tree-node.bp3-disabled .bp3-tree-node-icon{
  color:rgba(92, 112, 128, 0.6);
  cursor:not-allowed; }

.bp3-tree-node.bp3-tree-node-selected > .bp3-tree-node-content{
  background-color:#137cbd; }
  .bp3-tree-node.bp3-tree-node-selected > .bp3-tree-node-content,
  .bp3-tree-node.bp3-tree-node-selected > .bp3-tree-node-content .bp3-icon, .bp3-tree-node.bp3-tree-node-selected > .bp3-tree-node-content .bp3-icon-standard, .bp3-tree-node.bp3-tree-node-selected > .bp3-tree-node-content .bp3-icon-large{
    color:#ffffff; }
  .bp3-tree-node.bp3-tree-node-selected > .bp3-tree-node-content .bp3-tree-node-caret::before{
    color:rgba(255, 255, 255, 0.7); }
  .bp3-tree-node.bp3-tree-node-selected > .bp3-tree-node-content .bp3-tree-node-caret:hover::before{
    color:#ffffff; }

.bp3-dark .bp3-tree-node-content:hover{
  background-color:rgba(92, 112, 128, 0.3); }

.bp3-dark .bp3-tree .bp3-icon, .bp3-dark .bp3-tree .bp3-icon-standard, .bp3-dark .bp3-tree .bp3-icon-large{
  color:#a7b6c2; }
  .bp3-dark .bp3-tree .bp3-icon.bp3-intent-primary, .bp3-dark .bp3-tree .bp3-icon-standard.bp3-intent-primary, .bp3-dark .bp3-tree .bp3-icon-large.bp3-intent-primary{
    color:#137cbd; }
  .bp3-dark .bp3-tree .bp3-icon.bp3-intent-success, .bp3-dark .bp3-tree .bp3-icon-standard.bp3-intent-success, .bp3-dark .bp3-tree .bp3-icon-large.bp3-intent-success{
    color:#0f9960; }
  .bp3-dark .bp3-tree .bp3-icon.bp3-intent-warning, .bp3-dark .bp3-tree .bp3-icon-standard.bp3-intent-warning, .bp3-dark .bp3-tree .bp3-icon-large.bp3-intent-warning{
    color:#d9822b; }
  .bp3-dark .bp3-tree .bp3-icon.bp3-intent-danger, .bp3-dark .bp3-tree .bp3-icon-standard.bp3-intent-danger, .bp3-dark .bp3-tree .bp3-icon-large.bp3-intent-danger{
    color:#db3737; }

.bp3-dark .bp3-tree-node.bp3-tree-node-selected > .bp3-tree-node-content{
  background-color:#137cbd; }
.bp3-omnibar{
  -webkit-filter:blur(0);
          filter:blur(0);
  opacity:1;
  background-color:#ffffff;
  border-radius:3px;
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 4px 8px rgba(16, 22, 26, 0.2), 0 18px 46px 6px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 4px 8px rgba(16, 22, 26, 0.2), 0 18px 46px 6px rgba(16, 22, 26, 0.2);
  left:calc(50% - 250px);
  top:20vh;
  width:500px;
  z-index:21; }
  .bp3-omnibar.bp3-overlay-enter, .bp3-omnibar.bp3-overlay-appear{
    -webkit-filter:blur(20px);
            filter:blur(20px);
    opacity:0.2; }
  .bp3-omnibar.bp3-overlay-enter-active, .bp3-omnibar.bp3-overlay-appear-active{
    -webkit-filter:blur(0);
            filter:blur(0);
    opacity:1;
    -webkit-transition-delay:0;
            transition-delay:0;
    -webkit-transition-duration:200ms;
            transition-duration:200ms;
    -webkit-transition-property:opacity, -webkit-filter;
    transition-property:opacity, -webkit-filter;
    transition-property:filter, opacity;
    transition-property:filter, opacity, -webkit-filter;
    -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
            transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-omnibar.bp3-overlay-exit{
    -webkit-filter:blur(0);
            filter:blur(0);
    opacity:1; }
  .bp3-omnibar.bp3-overlay-exit-active{
    -webkit-filter:blur(20px);
            filter:blur(20px);
    opacity:0.2;
    -webkit-transition-delay:0;
            transition-delay:0;
    -webkit-transition-duration:200ms;
            transition-duration:200ms;
    -webkit-transition-property:opacity, -webkit-filter;
    transition-property:opacity, -webkit-filter;
    transition-property:filter, opacity;
    transition-property:filter, opacity, -webkit-filter;
    -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
            transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-omnibar .bp3-input{
    background-color:transparent;
    border-radius:0; }
    .bp3-omnibar .bp3-input, .bp3-omnibar .bp3-input:focus{
      -webkit-box-shadow:none;
              box-shadow:none; }
  .bp3-omnibar .bp3-menu{
    background-color:transparent;
    border-radius:0;
    -webkit-box-shadow:inset 0 1px 0 rgba(16, 22, 26, 0.15);
            box-shadow:inset 0 1px 0 rgba(16, 22, 26, 0.15);
    max-height:calc(60vh - 40px);
    overflow:auto; }
    .bp3-omnibar .bp3-menu:empty{
      display:none; }
  .bp3-dark .bp3-omnibar, .bp3-omnibar.bp3-dark{
    background-color:#30404d;
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 4px 8px rgba(16, 22, 26, 0.4), 0 18px 46px 6px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 4px 8px rgba(16, 22, 26, 0.4), 0 18px 46px 6px rgba(16, 22, 26, 0.4); }

.bp3-omnibar-overlay .bp3-overlay-backdrop{
  background-color:rgba(16, 22, 26, 0.2); }

.bp3-select-popover .bp3-popover-content{
  padding:5px; }

.bp3-select-popover .bp3-input-group{
  margin-bottom:0; }

.bp3-select-popover .bp3-menu{
  max-height:300px;
  max-width:400px;
  overflow:auto;
  padding:0; }
  .bp3-select-popover .bp3-menu:not(:first-child){
    padding-top:5px; }

.bp3-multi-select{
  min-width:150px; }

.bp3-multi-select-popover .bp3-menu{
  max-height:300px;
  max-width:400px;
  overflow:auto; }

.bp3-select-popover .bp3-popover-content{
  padding:5px; }

.bp3-select-popover .bp3-input-group{
  margin-bottom:0; }

.bp3-select-popover .bp3-menu{
  max-height:300px;
  max-width:400px;
  overflow:auto;
  padding:0; }
  .bp3-select-popover .bp3-menu:not(:first-child){
    padding-top:5px; }
/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* This file was auto-generated by ensureUiComponents() in @jupyterlab/buildutils */

/**
 * (DEPRECATED) Support for consuming icons as CSS background images
 */

/* Icons urls */

:root {
  --jp-icon-add: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE5IDEzaC02djZoLTJ2LTZINXYtMmg2VjVoMnY2aDZ2MnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-bug: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTIwIDhoLTIuODFjLS40NS0uNzgtMS4wNy0xLjQ1LTEuODItMS45NkwxNyA0LjQxIDE1LjU5IDNsLTIuMTcgMi4xN0MxMi45NiA1LjA2IDEyLjQ5IDUgMTIgNWMtLjQ5IDAtLjk2LjA2LTEuNDEuMTdMOC40MSAzIDcgNC40MWwxLjYyIDEuNjNDNy44OCA2LjU1IDcuMjYgNy4yMiA2LjgxIDhINHYyaDIuMDljLS4wNS4zMy0uMDkuNjYtLjA5IDF2MUg0djJoMnYxYzAgLjM0LjA0LjY3LjA5IDFINHYyaDIuODFjMS4wNCAxLjc5IDIuOTcgMyA1LjE5IDNzNC4xNS0xLjIxIDUuMTktM0gyMHYtMmgtMi4wOWMuMDUtLjMzLjA5LS42Ni4wOS0xdi0xaDJ2LTJoLTJ2LTFjMC0uMzQtLjA0LS42Ny0uMDktMUgyMFY4em0tNiA4aC00di0yaDR2MnptMC00aC00di0yaDR2MnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-build: url(data:image/svg+xml;base64,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);
  --jp-icon-caret-down-empty-thin: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwb2x5Z29uIGNsYXNzPSJzdDEiIHBvaW50cz0iOS45LDEzLjYgMy42LDcuNCA0LjQsNi42IDkuOSwxMi4yIDE1LjQsNi43IDE2LjEsNy40ICIvPgoJPC9nPgo8L3N2Zz4K);
  --jp-icon-caret-down-empty: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiIHNoYXBlLXJlbmRlcmluZz0iZ2VvbWV0cmljUHJlY2lzaW9uIj4KICAgIDxwYXRoIGQ9Ik01LjIsNS45TDksOS43bDMuOC0zLjhsMS4yLDEuMmwtNC45LDVsLTQuOS01TDUuMiw1Ljl6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-caret-down: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiIHNoYXBlLXJlbmRlcmluZz0iZ2VvbWV0cmljUHJlY2lzaW9uIj4KICAgIDxwYXRoIGQ9Ik01LjIsNy41TDksMTEuMmwzLjgtMy44SDUuMnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-caret-left: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwYXRoIGQ9Ik0xMC44LDEyLjhMNy4xLDlsMy44LTMuOGwwLDcuNkgxMC44eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-caret-right: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiIHNoYXBlLXJlbmRlcmluZz0iZ2VvbWV0cmljUHJlY2lzaW9uIj4KICAgIDxwYXRoIGQ9Ik03LjIsNS4yTDEwLjksOWwtMy44LDMuOFY1LjJINy4yeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-caret-up-empty-thin: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwb2x5Z29uIGNsYXNzPSJzdDEiIHBvaW50cz0iMTUuNCwxMy4zIDkuOSw3LjcgNC40LDEzLjIgMy42LDEyLjUgOS45LDYuMyAxNi4xLDEyLjYgIi8+Cgk8L2c+Cjwvc3ZnPgo=);
  --jp-icon-caret-up: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwYXRoIGQ9Ik01LjIsMTAuNUw5LDYuOGwzLjgsMy44SDUuMnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-case-sensitive: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KICA8ZyBjbGFzcz0ianAtaWNvbjIiIGZpbGw9IiM0MTQxNDEiPgogICAgPHJlY3QgeD0iMiIgeT0iMiIgd2lkdGg9IjE2IiBoZWlnaHQ9IjE2Ii8+CiAgPC9nPgogIDxnIGNsYXNzPSJqcC1pY29uLWFjY2VudDIiIGZpbGw9IiNGRkYiPgogICAgPHBhdGggZD0iTTcuNiw4aDAuOWwzLjUsOGgtMS4xTDEwLDE0SDZsLTAuOSwySDRMNy42LDh6IE04LDkuMUw2LjQsMTNoMy4yTDgsOS4xeiIvPgogICAgPHBhdGggZD0iTTE2LjYsOS44Yy0wLjIsMC4xLTAuNCwwLjEtMC43LDAuMWMtMC4yLDAtMC40LTAuMS0wLjYtMC4yYy0wLjEtMC4xLTAuMi0wLjQtMC4yLTAuNyBjLTAuMywwLjMtMC42LDAuNS0wLjksMC43Yy0wLjMsMC4xLTAuNywwLjItMS4xLDAuMmMtMC4zLDAtMC41LDAtMC43LTAuMWMtMC4yLTAuMS0wLjQtMC4yLTAuNi0wLjNjLTAuMi0wLjEtMC4zLTAuMy0wLjQtMC41IGMtMC4xLTAuMi0wLjEtMC40LTAuMS0wLjdjMC0wLjMsMC4xLTAuNiwwLjItMC44YzAuMS0wLjIsMC4zLTAuNCwwLjQtMC41QzEyLDcsMTIuMiw2LjksMTIuNSw2LjhjMC4yLTAuMSwwLjUtMC4xLDAuNy0wLjIgYzAuMy0wLjEsMC41LTAuMSwwLjctMC4xYzAuMiwwLDAuNC0wLjEsMC42LTAuMWMwLjIsMCwwLjMtMC4xLDAuNC0wLjJjMC4xLTAuMSwwLjItMC4yLDAuMi0wLjRjMC0xLTEuMS0xLTEuMy0xIGMtMC40LDAtMS40LDAtMS40LDEuMmgtMC45YzAtMC40LDAuMS0wLjcsMC4yLTFjMC4xLTAuMiwwLjMtMC40LDAuNS0wLjZjMC4yLTAuMiwwLjUtMC4zLDAuOC0wLjNDMTMuMyw0LDEzLjYsNCwxMy45LDQgYzAuMywwLDAuNSwwLDAuOCwwLjFjMC4zLDAsMC41LDAuMSwwLjcsMC4yYzAuMiwwLjEsMC40LDAuMywwLjUsMC41QzE2LDUsMTYsNS4yLDE2LDUuNnYyLjljMCwwLjIsMCwwLjQsMCwwLjUgYzAsMC4xLDAuMSwwLjIsMC4zLDAuMmMwLjEsMCwwLjIsMCwwLjMsMFY5Ljh6IE0xNS4yLDYuOWMtMS4yLDAuNi0zLjEsMC4yLTMuMSwxLjRjMCwxLjQsMy4xLDEsMy4xLTAuNVY2Ljl6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-check: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTkgMTYuMTdMNC44MyAxMmwtMS40MiAxLjQxTDkgMTkgMjEgN2wtMS40MS0xLjQxeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-circle-empty: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyIDJDNi40NyAyIDIgNi40NyAyIDEyczQuNDcgMTAgMTAgMTAgMTAtNC40NyAxMC0xMFMxNy41MyAyIDEyIDJ6bTAgMThjLTQuNDEgMC04LTMuNTktOC04czMuNTktOCA4LTggOCAzLjU5IDggOC0zLjU5IDgtOCA4eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-circle: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMTggMTgiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPGNpcmNsZSBjeD0iOSIgY3k9IjkiIHI9IjgiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-clear: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8bWFzayBpZD0iZG9udXRIb2xlIj4KICAgIDxyZWN0IHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgZmlsbD0id2hpdGUiIC8+CiAgICA8Y2lyY2xlIGN4PSIxMiIgY3k9IjEyIiByPSI4IiBmaWxsPSJibGFjayIvPgogIDwvbWFzaz4KCiAgPGcgY2xhc3M9ImpwLWljb24zIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxyZWN0IGhlaWdodD0iMTgiIHdpZHRoPSIyIiB4PSIxMSIgeT0iMyIgdHJhbnNmb3JtPSJyb3RhdGUoMzE1LCAxMiwgMTIpIi8+CiAgICA8Y2lyY2xlIGN4PSIxMiIgY3k9IjEyIiByPSIxMCIgbWFzaz0idXJsKCNkb251dEhvbGUpIi8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-close: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbi1ub25lIGpwLWljb24tc2VsZWN0YWJsZS1pbnZlcnNlIGpwLWljb24zLWhvdmVyIiBmaWxsPSJub25lIj4KICAgIDxjaXJjbGUgY3g9IjEyIiBjeT0iMTIiIHI9IjExIi8+CiAgPC9nPgoKICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIGpwLWljb24tYWNjZW50Mi1ob3ZlciIgZmlsbD0iIzYxNjE2MSI+CiAgICA8cGF0aCBkPSJNMTkgNi40MUwxNy41OSA1IDEyIDEwLjU5IDYuNDEgNSA1IDYuNDEgMTAuNTkgMTIgNSAxNy41OSA2LjQxIDE5IDEyIDEzLjQxIDE3LjU5IDE5IDE5IDE3LjU5IDEzLjQxIDEyeiIvPgogIDwvZz4KCiAgPGcgY2xhc3M9ImpwLWljb24tbm9uZSBqcC1pY29uLWJ1c3kiIGZpbGw9Im5vbmUiPgogICAgPGNpcmNsZSBjeD0iMTIiIGN5PSIxMiIgcj0iNyIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-code: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjIiIGhlaWdodD0iMjIiIHZpZXdCb3g9IjAgMCAyOCAyOCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CgkJPHBhdGggZD0iTTExLjQgMTguNkw2LjggMTRMMTEuNCA5LjRMMTAgOEw0IDE0TDEwIDIwTDExLjQgMTguNlpNMTYuNiAxOC42TDIxLjIgMTRMMTYuNiA5LjRMMTggOEwyNCAxNEwxOCAyMEwxNi42IDE4LjZWMTguNloiLz4KCTwvZz4KPC9zdmc+Cg==);
  --jp-icon-console: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwMCAyMDAiPgogIDxnIGNsYXNzPSJqcC1pY29uLWJyYW5kMSBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiMwMjg4RDEiPgogICAgPHBhdGggZD0iTTIwIDE5LjhoMTYwdjE1OS45SDIweiIvPgogIDwvZz4KICA8ZyBjbGFzcz0ianAtaWNvbi1zZWxlY3RhYmxlLWludmVyc2UiIGZpbGw9IiNmZmYiPgogICAgPHBhdGggZD0iTTEwNSAxMjcuM2g0MHYxMi44aC00MHpNNTEuMSA3N0w3NCA5OS45bC0yMy4zIDIzLjMgMTAuNSAxMC41IDIzLjMtMjMuM0w5NSA5OS45IDg0LjUgODkuNCA2MS42IDY2LjV6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-copy: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMTggMTgiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTExLjksMUgzLjJDMi40LDEsMS43LDEuNywxLjcsMi41djEwLjJoMS41VjIuNWg4LjdWMXogTTE0LjEsMy45aC04Yy0wLjgsMC0xLjUsMC43LTEuNSwxLjV2MTAuMmMwLDAuOCwwLjcsMS41LDEuNSwxLjVoOCBjMC44LDAsMS41LTAuNywxLjUtMS41VjUuNEMxNS41LDQuNiwxNC45LDMuOSwxNC4xLDMuOXogTTE0LjEsMTUuNWgtOFY1LjRoOFYxNS41eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-cut: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTkuNjQgNy42NGMuMjMtLjUuMzYtMS4wNS4zNi0xLjY0IDAtMi4yMS0xLjc5LTQtNC00UzIgMy43OSAyIDZzMS43OSA0IDQgNGMuNTkgMCAxLjE0LS4xMyAxLjY0LS4zNkwxMCAxMmwtMi4zNiAyLjM2QzcuMTQgMTQuMTMgNi41OSAxNCA2IDE0Yy0yLjIxIDAtNCAxLjc5LTQgNHMxLjc5IDQgNCA0IDQtMS43OSA0LTRjMC0uNTktLjEzLTEuMTQtLjM2LTEuNjRMMTIgMTRsNyA3aDN2LTFMOS42NCA3LjY0ek02IDhjLTEuMSAwLTItLjg5LTItMnMuOS0yIDItMiAyIC44OSAyIDItLjkgMi0yIDJ6bTAgMTJjLTEuMSAwLTItLjg5LTItMnMuOS0yIDItMiAyIC44OSAyIDItLjkgMi0yIDJ6bTYtNy41Yy0uMjggMC0uNS0uMjItLjUtLjVzLjIyLS41LjUtLjUuNS4yMi41LjUtLjIyLjUtLjUuNXpNMTkgM2wtNiA2IDIgMiA3LTdWM3oiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-download: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE5IDloLTRWM0g5djZINWw3IDcgNy03ek01IDE4djJoMTR2LTJINXoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-edit: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTMgMTcuMjVWMjFoMy43NUwxNy44MSA5Ljk0bC0zLjc1LTMuNzVMMyAxNy4yNXpNMjAuNzEgNy4wNGMuMzktLjM5LjM5LTEuMDIgMC0xLjQxbC0yLjM0LTIuMzRjLS4zOS0uMzktMS4wMi0uMzktMS40MSAwbC0xLjgzIDEuODMgMy43NSAzLjc1IDEuODMtMS44M3oiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-ellipses: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPGNpcmNsZSBjeD0iNSIgY3k9IjEyIiByPSIyIi8+CiAgICA8Y2lyY2xlIGN4PSIxMiIgY3k9IjEyIiByPSIyIi8+CiAgICA8Y2lyY2xlIGN4PSIxOSIgY3k9IjEyIiByPSIyIi8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-extension: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTIwLjUgMTFIMTlWN2MwLTEuMS0uOS0yLTItMmgtNFYzLjVDMTMgMi4xMiAxMS44OCAxIDEwLjUgMVM4IDIuMTIgOCAzLjVWNUg0Yy0xLjEgMC0xLjk5LjktMS45OSAydjMuOEgzLjVjMS40OSAwIDIuNyAxLjIxIDIuNyAyLjdzLTEuMjEgMi43LTIuNyAyLjdIMlYyMGMwIDEuMS45IDIgMiAyaDMuOHYtMS41YzAtMS40OSAxLjIxLTIuNyAyLjctMi43IDEuNDkgMCAyLjcgMS4yMSAyLjcgMi43VjIySDE3YzEuMSAwIDItLjkgMi0ydi00aDEuNWMxLjM4IDAgMi41LTEuMTIgMi41LTIuNVMyMS44OCAxMSAyMC41IDExeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-fast-forward: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTQgMThsOC41LTZMNCA2djEyem05LTEydjEybDguNS02TDEzIDZ6Ii8+CiAgICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-file-upload: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTkgMTZoNnYtNmg0bC03LTctNyA3aDR6bS00IDJoMTR2Mkg1eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-file: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTkuMyA4LjJsLTUuNS01LjVjLS4zLS4zLS43LS41LTEuMi0uNUgzLjljLS44LjEtMS42LjktMS42IDEuOHYxNC4xYzAgLjkuNyAxLjYgMS42IDEuNmgxNC4yYy45IDAgMS42LS43IDEuNi0xLjZWOS40Yy4xLS41LS4xLS45LS40LTEuMnptLTUuOC0zLjNsMy40IDMuNmgtMy40VjQuOXptMy45IDEyLjdINC43Yy0uMSAwLS4yIDAtLjItLjJWNC43YzAtLjIuMS0uMy4yLS4zaDcuMnY0LjRzMCAuOC4zIDEuMWMuMy4zIDEuMS4zIDEuMS4zaDQuM3Y3LjJzLS4xLjItLjIuMnoiLz4KPC9zdmc+Cg==);
  --jp-icon-filter-list: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEwIDE4aDR2LTJoLTR2MnpNMyA2djJoMThWNkgzem0zIDdoMTJ2LTJINnYyeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-folder: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTAgNEg0Yy0xLjEgMC0xLjk5LjktMS45OSAyTDIgMThjMCAxLjEuOSAyIDIgMmgxNmMxLjEgMCAyLS45IDItMlY4YzAtMS4xLS45LTItMi0yaC04bC0yLTJ6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-html5: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDUxMiA1MTIiPgogIDxwYXRoIGNsYXNzPSJqcC1pY29uMCBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiMwMDAiIGQ9Ik0xMDguNCAwaDIzdjIyLjhoMjEuMlYwaDIzdjY5aC0yM1Y0NmgtMjF2MjNoLTIzLjJNMjA2IDIzaC0yMC4zVjBoNjMuN3YyM0gyMjl2NDZoLTIzbTUzLjUtNjloMjQuMWwxNC44IDI0LjNMMzEzLjIgMGgyNC4xdjY5aC0yM1YzNC44bC0xNi4xIDI0LjgtMTYuMS0yNC44VjY5aC0yMi42bTg5LjItNjloMjN2NDYuMmgzMi42VjY5aC01NS42Ii8+CiAgPHBhdGggY2xhc3M9ImpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iI2U0NGQyNiIgZD0iTTEwNy42IDQ3MWwtMzMtMzcwLjRoMzYyLjhsLTMzIDM3MC4yTDI1NS43IDUxMiIvPgogIDxwYXRoIGNsYXNzPSJqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiNmMTY1MjkiIGQ9Ik0yNTYgNDgwLjVWMTMxaDE0OC4zTDM3NiA0NDciLz4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1zZWxlY3RhYmxlLWludmVyc2UiIGZpbGw9IiNlYmViZWIiIGQ9Ik0xNDIgMTc2LjNoMTE0djQ1LjRoLTY0LjJsNC4yIDQ2LjVoNjB2NDUuM0gxNTQuNG0yIDIyLjhIMjAybDMuMiAzNi4zIDUwLjggMTMuNnY0Ny40bC05My4yLTI2Ii8+CiAgPHBhdGggY2xhc3M9ImpwLWljb24tc2VsZWN0YWJsZS1pbnZlcnNlIiBmaWxsPSIjZmZmIiBkPSJNMzY5LjYgMTc2LjNIMjU1Ljh2NDUuNGgxMDkuNm0tNC4xIDQ2LjVIMjU1Ljh2NDUuNGg1NmwtNS4zIDU5LTUwLjcgMTMuNnY0Ny4ybDkzLTI1LjgiLz4KPC9zdmc+Cg==);
  --jp-icon-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1icmFuZDQganAtaWNvbi1zZWxlY3RhYmxlLWludmVyc2UiIGZpbGw9IiNGRkYiIGQ9Ik0yLjIgMi4yaDE3LjV2MTcuNUgyLjJ6Ii8+CiAgPHBhdGggY2xhc3M9ImpwLWljb24tYnJhbmQwIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iIzNGNTFCNSIgZD0iTTIuMiAyLjJ2MTcuNWgxNy41bC4xLTE3LjVIMi4yem0xMi4xIDIuMmMxLjIgMCAyLjIgMSAyLjIgMi4ycy0xIDIuMi0yLjIgMi4yLTIuMi0xLTIuMi0yLjIgMS0yLjIgMi4yLTIuMnpNNC40IDE3LjZsMy4zLTguOCAzLjMgNi42IDIuMi0zLjIgNC40IDUuNEg0LjR6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-inspector: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMjAgNEg0Yy0xLjEgMC0xLjk5LjktMS45OSAyTDIgMThjMCAxLjEuOSAyIDIgMmgxNmMxLjEgMCAyLS45IDItMlY2YzAtMS4xLS45LTItMi0yem0tNSAxNEg0di00aDExdjR6bTAtNUg0VjloMTF2NHptNSA1aC00VjloNHY5eiIvPgo8L3N2Zz4K);
  --jp-icon-json: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtaWNvbi13YXJuMSBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiNGOUE4MjUiPgogICAgPHBhdGggZD0iTTIwLjIgMTEuOGMtMS42IDAtMS43LjUtMS43IDEgMCAuNC4xLjkuMSAxLjMuMS41LjEuOS4xIDEuMyAwIDEuNy0xLjQgMi4zLTMuNSAyLjNoLS45di0xLjloLjVjMS4xIDAgMS40IDAgMS40LS44IDAtLjMgMC0uNi0uMS0xIDAtLjQtLjEtLjgtLjEtMS4yIDAtMS4zIDAtMS44IDEuMy0yLTEuMy0uMi0xLjMtLjctMS4zLTIgMC0uNC4xLS44LjEtMS4yLjEtLjQuMS0uNy4xLTEgMC0uOC0uNC0uNy0xLjQtLjhoLS41VjQuMWguOWMyLjIgMCAzLjUuNyAzLjUgMi4zIDAgLjQtLjEuOS0uMSAxLjMtLjEuNS0uMS45LS4xIDEuMyAwIC41LjIgMSAxLjcgMXYxLjh6TTEuOCAxMC4xYzEuNiAwIDEuNy0uNSAxLjctMSAwLS40LS4xLS45LS4xLTEuMy0uMS0uNS0uMS0uOS0uMS0xLjMgMC0xLjYgMS40LTIuMyAzLjUtMi4zaC45djEuOWgtLjVjLTEgMC0xLjQgMC0xLjQuOCAwIC4zIDAgLjYuMSAxIDAgLjIuMS42LjEgMSAwIDEuMyAwIDEuOC0xLjMgMkM2IDExLjIgNiAxMS43IDYgMTNjMCAuNC0uMS44LS4xIDEuMi0uMS4zLS4xLjctLjEgMSAwIC44LjMuOCAxLjQuOGguNXYxLjloLS45Yy0yLjEgMC0zLjUtLjYtMy41LTIuMyAwLS40LjEtLjkuMS0xLjMuMS0uNS4xLS45LjEtMS4zIDAtLjUtLjItMS0xLjctMXYtMS45eiIvPgogICAgPGNpcmNsZSBjeD0iMTEiIGN5PSIxMy44IiByPSIyLjEiLz4KICAgIDxjaXJjbGUgY3g9IjExIiBjeT0iOC4yIiByPSIyLjEiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-jupyter-favicon: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTUyIiBoZWlnaHQ9IjE2NSIgdmlld0JveD0iMCAwIDE1MiAxNjUiIHZlcnNpb249IjEuMSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbi13YXJuMCIgZmlsbD0iI0YzNzcyNiI+CiAgICA8cGF0aCB0cmFuc2Zvcm09InRyYW5zbGF0ZSgwLjA3ODk0NywgMTEwLjU4MjkyNykiIGQ9Ik03NS45NDIyODQyLDI5LjU4MDQ1NjEgQzQzLjMwMjM5NDcsMjkuNTgwNDU2MSAxNC43OTY3ODMyLDE3LjY1MzQ2MzQgMCwwIEM1LjUxMDgzMjExLDE1Ljg0MDY4MjkgMTUuNzgxNTM4OSwyOS41NjY3NzMyIDI5LjM5MDQ5NDcsMzkuMjc4NDE3MSBDNDIuOTk5Nyw0OC45ODk4NTM3IDU5LjI3MzcsNTQuMjA2NzgwNSA3NS45NjA1Nzg5LDU0LjIwNjc4MDUgQzkyLjY0NzQ1NzksNTQuMjA2NzgwNSAxMDguOTIxNDU4LDQ4Ljk4OTg1MzcgMTIyLjUzMDY2MywzOS4yNzg0MTcxIEMxMzYuMTM5NDUzLDI5LjU2Njc3MzIgMTQ2LjQxMDI4NCwxNS44NDA2ODI5IDE1MS45MjExNTgsMCBDMTM3LjA4Nzg2OCwxNy42NTM0NjM0IDEwOC41ODI1ODksMjkuNTgwNDU2MSA3NS45NDIyODQyLDI5LjU4MDQ1NjEgTDc1Ljk0MjI4NDIsMjkuNTgwNDU2MSBaIiAvPgogICAgPHBhdGggdHJhbnNmb3JtPSJ0cmFuc2xhdGUoMC4wMzczNjgsIDAuNzA0ODc4KSIgZD0iTTc1Ljk3ODQ1NzksMjQuNjI2NDA3MyBDMTA4LjYxODc2MywyNC42MjY0MDczIDEzNy4xMjQ0NTgsMzYuNTUzNDQxNSAxNTEuOTIxMTU4LDU0LjIwNjc4MDUgQzE0Ni40MTAyODQsMzguMzY2MjIyIDEzNi4xMzk0NTMsMjQuNjQwMTMxNyAxMjIuNTMwNjYzLDE0LjkyODQ4NzggQzEwOC45MjE0NTgsNS4yMTY4NDM5IDkyLjY0NzQ1NzksMCA3NS45NjA1Nzg5LDAgQzU5LjI3MzcsMCA0Mi45OTk3LDUuMjE2ODQzOSAyOS4zOTA0OTQ3LDE0LjkyODQ4NzggQzE1Ljc4MTUzODksMjQuNjQwMTMxNyA1LjUxMDgzMjExLDM4LjM2NjIyMiAwLDU0LjIwNjc4MDUgQzE0LjgzMzA4MTYsMzYuNTg5OTI5MyA0My4zMzg1Njg0LDI0LjYyNjQwNzMgNzUuOTc4NDU3OSwyNC42MjY0MDczIEw3NS45Nzg0NTc5LDI0LjYyNjQwNzMgWiIgLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-jupyter: url(data:image/svg+xml;base64,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);
  --jp-icon-jupyterlab-wordmark: url(data:image/svg+xml;base64,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);
  --jp-icon-kernel: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgZmlsbD0iIzYxNjE2MSIgZD0iTTE1IDlIOXY2aDZWOXptLTIgNGgtMnYtMmgydjJ6bTgtMlY5aC0yVjdjMC0xLjEtLjktMi0yLTJoLTJWM2gtMnYyaC0yVjNIOXYySDdjLTEuMSAwLTIgLjktMiAydjJIM3YyaDJ2MkgzdjJoMnYyYzAgMS4xLjkgMiAyIDJoMnYyaDJ2LTJoMnYyaDJ2LTJoMmMxLjEgMCAyLS45IDItMnYtMmgydi0yaC0ydi0yaDJ6bS00IDZIN1Y3aDEwdjEweiIvPgo8L3N2Zz4K);
  --jp-icon-keyboard: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMjAgNUg0Yy0xLjEgMC0xLjk5LjktMS45OSAyTDIgMTdjMCAxLjEuOSAyIDIgMmgxNmMxLjEgMCAyLS45IDItMlY3YzAtMS4xLS45LTItMi0yem0tOSAzaDJ2MmgtMlY4em0wIDNoMnYyaC0ydi0yek04IDhoMnYySDhWOHptMCAzaDJ2Mkg4di0yem0tMSAySDV2LTJoMnYyem0wLTNINVY4aDJ2MnptOSA3SDh2LTJoOHYyem0wLTRoLTJ2LTJoMnYyem0wLTNoLTJWOGgydjJ6bTMgM2gtMnYtMmgydjJ6bTAtM2gtMlY4aDJ2MnoiLz4KPC9zdmc+Cg==);
  --jp-icon-launcher: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTkgMTlINVY1aDdWM0g1YTIgMiAwIDAwLTIgMnYxNGEyIDIgMCAwMDIgMmgxNGMxLjEgMCAyLS45IDItMnYtN2gtMnY3ek0xNCAzdjJoMy41OWwtOS44MyA5LjgzIDEuNDEgMS40MUwxOSA2LjQxVjEwaDJWM2gtN3oiLz4KPC9zdmc+Cg==);
  --jp-icon-line-form: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxwYXRoIGZpbGw9IndoaXRlIiBkPSJNNS44OCA0LjEyTDEzLjc2IDEybC03Ljg4IDcuODhMOCAyMmwxMC0xMEw4IDJ6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-link: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTMuOSAxMmMwLTEuNzEgMS4zOS0zLjEgMy4xLTMuMWg0VjdIN2MtMi43NiAwLTUgMi4yNC01IDVzMi4yNCA1IDUgNWg0di0xLjlIN2MtMS43MSAwLTMuMS0xLjM5LTMuMS0zLjF6TTggMTNoOHYtMkg4djJ6bTktNmgtNHYxLjloNGMxLjcxIDAgMy4xIDEuMzkgMy4xIDMuMXMtMS4zOSAzLjEtMy4xIDMuMWgtNFYxN2g0YzIuNzYgMCA1LTIuMjQgNS01cy0yLjI0LTUtNS01eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-list: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiM2MTYxNjEiIGQ9Ik0xOSA1djE0SDVWNWgxNG0xLjEtMkgzLjljLS41IDAtLjkuNC0uOS45djE2LjJjMCAuNC40LjkuOS45aDE2LjJjLjQgMCAuOS0uNS45LS45VjMuOWMwLS41LS41LS45LS45LS45ek0xMSA3aDZ2MmgtNlY3em0wIDRoNnYyaC02di0yem0wIDRoNnYyaC02ek03IDdoMnYySDd6bTAgNGgydjJIN3ptMCA0aDJ2Mkg3eiIvPgo8L3N2Zz4=);
  --jp-icon-listings-info: url(data:image/svg+xml;base64,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);
  --jp-icon-markdown: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1jb250cmFzdDAganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjN0IxRkEyIiBkPSJNNSAxNC45aDEybC02LjEgNnptOS40LTYuOGMwLTEuMy0uMS0yLjktLjEtNC41LS40IDEuNC0uOSAyLjktMS4zIDQuM2wtMS4zIDQuM2gtMkw4LjUgNy45Yy0uNC0xLjMtLjctMi45LTEtNC4zLS4xIDEuNi0uMSAzLjItLjIgNC42TDcgMTIuNEg0LjhsLjctMTFoMy4zTDEwIDVjLjQgMS4yLjcgMi43IDEgMy45LjMtMS4yLjctMi42IDEtMy45bDEuMi0zLjdoMy4zbC42IDExaC0yLjRsLS4zLTQuMnoiLz4KPC9zdmc+Cg==);
  --jp-icon-new-folder: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTIwIDZoLThsLTItMkg0Yy0xLjExIDAtMS45OS44OS0xLjk5IDJMMiAxOGMwIDEuMTEuODkgMiAyIDJoMTZjMS4xMSAwIDItLjg5IDItMlY4YzAtMS4xMS0uODktMi0yLTJ6bS0xIDhoLTN2M2gtMnYtM2gtM3YtMmgzVjloMnYzaDN2MnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-not-trusted: url(data:image/svg+xml;base64,PHN2ZyBmaWxsPSJub25lIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI1IDI1Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgc3Ryb2tlPSIjMzMzMzMzIiBzdHJva2Utd2lkdGg9IjIiIHRyYW5zZm9ybT0idHJhbnNsYXRlKDMgMykiIGQ9Ik0xLjg2MDk0IDExLjQ0MDlDMC44MjY0NDggOC43NzAyNyAwLjg2Mzc3OSA2LjA1NzY0IDEuMjQ5MDcgNC4xOTkzMkMyLjQ4MjA2IDMuOTMzNDcgNC4wODA2OCAzLjQwMzQ3IDUuNjAxMDIgMi44NDQ5QzcuMjM1NDkgMi4yNDQ0IDguODU2NjYgMS41ODE1IDkuOTg3NiAxLjA5NTM5QzExLjA1OTcgMS41ODM0MSAxMi42MDk0IDIuMjQ0NCAxNC4yMTggMi44NDMzOUMxNS43NTAzIDMuNDEzOTQgMTcuMzk5NSAzLjk1MjU4IDE4Ljc1MzkgNC4yMTM4NUMxOS4xMzY0IDYuMDcxNzcgMTkuMTcwOSA4Ljc3NzIyIDE4LjEzOSAxMS40NDA5QzE3LjAzMDMgMTQuMzAzMiAxNC42NjY4IDE3LjE4NDQgOS45OTk5OSAxOC45MzU0QzUuMzMzMTkgMTcuMTg0NCAyLjk2OTY4IDE0LjMwMzIgMS44NjA5NCAxMS40NDA5WiIvPgogICAgPHBhdGggY2xhc3M9ImpwLWljb24yIiBzdHJva2U9IiMzMzMzMzMiIHN0cm9rZS13aWR0aD0iMiIgdHJhbnNmb3JtPSJ0cmFuc2xhdGUoOS4zMTU5MiA5LjMyMDMxKSIgZD0iTTcuMzY4NDIgMEwwIDcuMzY0NzkiLz4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgc3Ryb2tlPSIjMzMzMzMzIiBzdHJva2Utd2lkdGg9IjIiIHRyYW5zZm9ybT0idHJhbnNsYXRlKDkuMzE1OTIgMTYuNjgzNikgc2NhbGUoMSAtMSkiIGQ9Ik03LjM2ODQyIDBMMCA3LjM2NDc5Ii8+Cjwvc3ZnPgo=);
  --jp-icon-notebook: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtaWNvbi13YXJuMCBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiNFRjZDMDAiPgogICAgPHBhdGggZD0iTTE4LjcgMy4zdjE1LjRIMy4zVjMuM2gxNS40bTEuNS0xLjVIMS44djE4LjNoMTguM2wuMS0xOC4zeiIvPgogICAgPHBhdGggZD0iTTE2LjUgMTYuNWwtNS40LTQuMy01LjYgNC4zdi0xMWgxMXoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-numbering: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjIiIGhlaWdodD0iMjIiIHZpZXdCb3g9IjAgMCAyOCAyOCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CgkJPHBhdGggZD0iTTQgMTlINlYxOS41SDVWMjAuNUg2VjIxSDRWMjJIN1YxOEg0VjE5Wk01IDEwSDZWNkg0VjdINVYxMFpNNCAxM0g1LjhMNCAxNS4xVjE2SDdWMTVINS4yTDcgMTIuOVYxMkg0VjEzWk05IDdWOUgyM1Y3SDlaTTkgMjFIMjNWMTlIOVYyMVpNOSAxNUgyM1YxM0g5VjE1WiIvPgoJPC9nPgo8L3N2Zz4K);
  --jp-icon-offline-bolt: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAyNCAyNCIgd2lkdGg9IjE2Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyIDIuMDJjLTUuNTEgMC05Ljk4IDQuNDctOS45OCA5Ljk4czQuNDcgOS45OCA5Ljk4IDkuOTggOS45OC00LjQ3IDkuOTgtOS45OFMxNy41MSAyLjAyIDEyIDIuMDJ6TTExLjQ4IDIwdi02LjI2SDhMMTMgNHY2LjI2aDMuMzVMMTEuNDggMjB6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-palette: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE4IDEzVjIwSDRWNkg5LjAyQzkuMDcgNS4yOSA5LjI0IDQuNjIgOS41IDRINEMyLjkgNCAyIDQuOSAyIDZWMjBDMiAyMS4xIDIuOSAyMiA0IDIySDE4QzE5LjEgMjIgMjAgMjEuMSAyMCAyMFYxNUwxOCAxM1pNMTkuMyA4Ljg5QzE5Ljc0IDguMTkgMjAgNy4zOCAyMCA2LjVDMjAgNC4wMSAxNy45OSAyIDE1LjUgMkMxMy4wMSAyIDExIDQuMDEgMTEgNi41QzExIDguOTkgMTMuMDEgMTEgMTUuNDkgMTFDMTYuMzcgMTEgMTcuMTkgMTAuNzQgMTcuODggMTAuM0wyMSAxMy40MkwyMi40MiAxMkwxOS4zIDguODlaTTE1LjUgOUMxNC4xMiA5IDEzIDcuODggMTMgNi41QzEzIDUuMTIgMTQuMTIgNCAxNS41IDRDMTYuODggNCAxOCA1LjEyIDE4IDYuNUMxOCA3Ljg4IDE2Ljg4IDkgMTUuNSA5WiIvPgogICAgPHBhdGggZmlsbC1ydWxlPSJldmVub2RkIiBjbGlwLXJ1bGU9ImV2ZW5vZGQiIGQ9Ik00IDZIOS4wMTg5NEM5LjAwNjM5IDYuMTY1MDIgOSA2LjMzMTc2IDkgNi41QzkgOC44MTU3NyAxMC4yMTEgMTAuODQ4NyAxMi4wMzQzIDEySDlWMTRIMTZWMTIuOTgxMUMxNi41NzAzIDEyLjkzNzcgMTcuMTIgMTIuODIwNyAxNy42Mzk2IDEyLjYzOTZMMTggMTNWMjBINFY2Wk04IDhINlYxMEg4VjhaTTYgMTJIOFYxNEg2VjEyWk04IDE2SDZWMThIOFYxNlpNOSAxNkgxNlYxOEg5VjE2WiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-paste: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTE5IDJoLTQuMThDMTQuNC44NCAxMy4zIDAgMTIgMGMtMS4zIDAtMi40Ljg0LTIuODIgMkg1Yy0xLjEgMC0yIC45LTIgMnYxNmMwIDEuMS45IDIgMiAyaDE0YzEuMSAwIDItLjkgMi0yVjRjMC0xLjEtLjktMi0yLTJ6bS03IDBjLjU1IDAgMSAuNDUgMSAxcy0uNDUgMS0xIDEtMS0uNDUtMS0xIC40NS0xIDEtMXptNyAxOEg1VjRoMnYzaDEwVjRoMnYxNnoiLz4KICAgIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-pdf: url(data:image/svg+xml;base64,PHN2ZwogICB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAyMiAyMiIgd2lkdGg9IjE2Ij4KICAgIDxwYXRoIHRyYW5zZm9ybT0icm90YXRlKDQ1KSIgY2xhc3M9ImpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iI0ZGMkEyQSIKICAgICAgIGQ9Im0gMjIuMzQ0MzY5LC0zLjAxNjM2NDIgaCA1LjYzODYwNCB2IDEuNTc5MjQzMyBoIC0zLjU0OTIyNyB2IDEuNTA4NjkyOTkgaCAzLjMzNzU3NiBWIDEuNjUwODE1NCBoIC0zLjMzNzU3NiB2IDMuNDM1MjYxMyBoIC0yLjA4OTM3NyB6IG0gLTcuMTM2NDQ0LDEuNTc5MjQzMyB2IDQuOTQzOTU0MyBoIDAuNzQ4OTIgcSAxLjI4MDc2MSwwIDEuOTUzNzAzLC0wLjYzNDk1MzUgMC42NzgzNjksLTAuNjM0OTUzNSAwLjY3ODM2OSwtMS44NDUxNjQxIDAsLTEuMjA0NzgzNTUgLTAuNjcyOTQyLC0xLjgzNDMxMDExIC0wLjY3Mjk0MiwtMC42Mjk1MjY1OSAtMS45NTkxMywtMC42Mjk1MjY1OSB6IG0gLTIuMDg5Mzc3LC0xLjU3OTI0MzMgaCAyLjIwMzM0MyBxIDEuODQ1MTY0LDAgMi43NDYwMzksMC4yNjU5MjA3IDAuOTA2MzAxLDAuMjYwNDkzNyAxLjU1MjEwOCwwLjg5MDAyMDMgMC41Njk4MywwLjU0ODEyMjMgMC44NDY2MDUsMS4yNjQ0ODAwNiAwLjI3Njc3NCwwLjcxNjM1NzgxIDAuMjc2Nzc0LDEuNjIyNjU4OTQgMCwwLjkxNzE1NTEgLTAuMjc2Nzc0LDEuNjM4OTM5OSAtMC4yNzY3NzUsMC43MTYzNTc4IC0wLjg0NjYwNSwxLjI2NDQ4IC0wLjY1MTIzNCwwLjYyOTUyNjYgLTEuNTYyOTYyLDAuODk1NDQ3MyAtMC45MTE3MjgsMC4yNjA0OTM3IC0yLjczNTE4NSwwLjI2MDQ5MzcgaCAtMi4yMDMzNDMgeiBtIC04LjE0NTg1NjUsMCBoIDMuNDY3ODIzIHEgMS41NDY2ODE2LDAgMi4zNzE1Nzg1LDAuNjg5MjIzIDAuODMwMzI0LDAuNjgzNzk2MSAwLjgzMDMyNCwxLjk1MzcwMzE0IDAsMS4yNzUzMzM5NyAtMC44MzAzMjQsMS45NjQ1NTcwNiBRIDkuOTg3MTk2MSwyLjI3NDkxNSA4LjQ0MDUxNDUsMi4yNzQ5MTUgSCA3LjA2MjA2ODQgViA1LjA4NjA3NjcgSCA0Ljk3MjY5MTUgWiBtIDIuMDg5Mzc2OSwxLjUxNDExOTkgdiAyLjI2MzAzOTQzIGggMS4xNTU5NDEgcSAwLjYwNzgxODgsMCAwLjkzODg2MjksLTAuMjkzMDU1NDcgMC4zMzEwNDQxLC0wLjI5ODQ4MjQxIDAuMzMxMDQ0MSwtMC44NDExNzc3MiAwLC0wLjU0MjY5NTMxIC0wLjMzMTA0NDEsLTAuODM1NzUwNzQgLTAuMzMxMDQ0MSwtMC4yOTMwNTU1IC0wLjkzODg2MjksLTAuMjkzMDU1NSB6IgovPgo8L3N2Zz4K);
  --jp-icon-python: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtaWNvbi1icmFuZDAganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjMEQ0N0ExIj4KICAgIDxwYXRoIGQ9Ik0xMS4xIDYuOVY1LjhINi45YzAtLjUgMC0xLjMuMi0xLjYuNC0uNy44LTEuMSAxLjctMS40IDEuNy0uMyAyLjUtLjMgMy45LS4xIDEgLjEgMS45LjkgMS45IDEuOXY0LjJjMCAuNS0uOSAxLjYtMiAxLjZIOC44Yy0xLjUgMC0yLjQgMS40LTIuNCAyLjh2Mi4ySDQuN0MzLjUgMTUuMSAzIDE0IDMgMTMuMVY5Yy0uMS0xIC42LTIgMS44LTIgMS41LS4xIDYuMy0uMSA2LjMtLjF6Ii8+CiAgICA8cGF0aCBkPSJNMTAuOSAxNS4xdjEuMWg0LjJjMCAuNSAwIDEuMy0uMiAxLjYtLjQuNy0uOCAxLjEtMS43IDEuNC0xLjcuMy0yLjUuMy0zLjkuMS0xLS4xLTEuOS0uOS0xLjktMS45di00LjJjMC0uNS45LTEuNiAyLTEuNmgzLjhjMS41IDAgMi40LTEuNCAyLjQtMi44VjYuNmgxLjdDMTguNSA2LjkgMTkgOCAxOSA4LjlWMTNjMCAxLS43IDIuMS0xLjkgMi4xaC02LjJ6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-r-kernel: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1jb250cmFzdDMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjMjE5NkYzIiBkPSJNNC40IDIuNWMxLjItLjEgMi45LS4zIDQuOS0uMyAyLjUgMCA0LjEuNCA1LjIgMS4zIDEgLjcgMS41IDEuOSAxLjUgMy41IDAgMi0xLjQgMy41LTIuOSA0LjEgMS4yLjQgMS43IDEuNiAyLjIgMyAuNiAxLjkgMSAzLjkgMS4zIDQuNmgtMy44Yy0uMy0uNC0uOC0xLjctMS4yLTMuN3MtMS4yLTIuNi0yLjYtMi42aC0uOXY2LjRINC40VjIuNXptMy43IDYuOWgxLjRjMS45IDAgMi45LS45IDIuOS0yLjNzLTEtMi4zLTIuOC0yLjNjLS43IDAtMS4zIDAtMS42LjJ2NC41aC4xdi0uMXoiLz4KPC9zdmc+Cg==);
  --jp-icon-react: url(data:image/svg+xml;base64,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);
  --jp-icon-redo: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGhlaWdodD0iMjQiIHZpZXdCb3g9IjAgMCAyNCAyNCIgd2lkdGg9IjE2Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgICA8cGF0aCBkPSJNMCAwaDI0djI0SDB6IiBmaWxsPSJub25lIi8+PHBhdGggZD0iTTE4LjQgMTAuNkMxNi41NSA4Ljk5IDE0LjE1IDggMTEuNSA4Yy00LjY1IDAtOC41OCAzLjAzLTkuOTYgNy4yMkwzLjkgMTZjMS4wNS0zLjE5IDQuMDUtNS41IDcuNi01LjUgMS45NSAwIDMuNzMuNzIgNS4xMiAxLjg4TDEzIDE2aDlWN2wtMy42IDMuNnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-refresh: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTkgMTMuNWMtMi40OSAwLTQuNS0yLjAxLTQuNS00LjVTNi41MSA0LjUgOSA0LjVjMS4yNCAwIDIuMzYuNTIgMy4xNyAxLjMzTDEwIDhoNVYzbC0xLjc2IDEuNzZDMTIuMTUgMy42OCAxMC42NiAzIDkgMyA1LjY5IDMgMy4wMSA1LjY5IDMuMDEgOVM1LjY5IDE1IDkgMTVjMi45NyAwIDUuNDMtMi4xNiA1LjktNWgtMS41MmMtLjQ2IDItMi4yNCAzLjUtNC4zOCAzLjV6Ii8+CiAgICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-regex: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KICA8ZyBjbGFzcz0ianAtaWNvbjIiIGZpbGw9IiM0MTQxNDEiPgogICAgPHJlY3QgeD0iMiIgeT0iMiIgd2lkdGg9IjE2IiBoZWlnaHQ9IjE2Ii8+CiAgPC9nPgoKICA8ZyBjbGFzcz0ianAtaWNvbi1hY2NlbnQyIiBmaWxsPSIjRkZGIj4KICAgIDxjaXJjbGUgY2xhc3M9InN0MiIgY3g9IjUuNSIgY3k9IjE0LjUiIHI9IjEuNSIvPgogICAgPHJlY3QgeD0iMTIiIHk9IjQiIGNsYXNzPSJzdDIiIHdpZHRoPSIxIiBoZWlnaHQ9IjgiLz4KICAgIDxyZWN0IHg9IjguNSIgeT0iNy41IiB0cmFuc2Zvcm09Im1hdHJpeCgwLjg2NiAtMC41IDAuNSAwLjg2NiAtMi4zMjU1IDcuMzIxOSkiIGNsYXNzPSJzdDIiIHdpZHRoPSI4IiBoZWlnaHQ9IjEiLz4KICAgIDxyZWN0IHg9IjEyIiB5PSI0IiB0cmFuc2Zvcm09Im1hdHJpeCgwLjUgLTAuODY2IDAuODY2IDAuNSAtMC42Nzc5IDE0LjgyNTIpIiBjbGFzcz0ic3QyIiB3aWR0aD0iMSIgaGVpZ2h0PSI4Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-run: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTggNXYxNGwxMS03eiIvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-running: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDUxMiA1MTIiPgogIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICA8cGF0aCBkPSJNMjU2IDhDMTE5IDggOCAxMTkgOCAyNTZzMTExIDI0OCAyNDggMjQ4IDI0OC0xMTEgMjQ4LTI0OFMzOTMgOCAyNTYgOHptOTYgMzI4YzAgOC44LTcuMiAxNi0xNiAxNkgxNzZjLTguOCAwLTE2LTcuMi0xNi0xNlYxNzZjMC04LjggNy4yLTE2IDE2LTE2aDE2MGM4LjggMCAxNiA3LjIgMTYgMTZ2MTYweiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-save: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTE3IDNINWMtMS4xMSAwLTIgLjktMiAydjE0YzAgMS4xLjg5IDIgMiAyaDE0YzEuMSAwIDItLjkgMi0yVjdsLTQtNHptLTUgMTZjLTEuNjYgMC0zLTEuMzQtMy0zczEuMzQtMyAzLTMgMyAxLjM0IDMgMy0xLjM0IDMtMyAzem0zLTEwSDVWNWgxMHY0eiIvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-search: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMTggMTgiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyLjEsMTAuOWgtMC43bC0wLjItMC4yYzAuOC0wLjksMS4zLTIuMiwxLjMtMy41YzAtMy0yLjQtNS40LTUuNC01LjRTMS44LDQuMiwxLjgsNy4xczIuNCw1LjQsNS40LDUuNCBjMS4zLDAsMi41LTAuNSwzLjUtMS4zbDAuMiwwLjJ2MC43bDQuMSw0LjFsMS4yLTEuMkwxMi4xLDEwLjl6IE03LjEsMTAuOWMtMi4xLDAtMy43LTEuNy0zLjctMy43czEuNy0zLjcsMy43LTMuN3MzLjcsMS43LDMuNywzLjcgUzkuMiwxMC45LDcuMSwxMC45eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-settings: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTkuNDMgMTIuOThjLjA0LS4zMi4wNy0uNjQuMDctLjk4cy0uMDMtLjY2LS4wNy0uOThsMi4xMS0xLjY1Yy4xOS0uMTUuMjQtLjQyLjEyLS42NGwtMi0zLjQ2Yy0uMTItLjIyLS4zOS0uMy0uNjEtLjIybC0yLjQ5IDFjLS41Mi0uNC0xLjA4LS43My0xLjY5LS45OGwtLjM4LTIuNjVBLjQ4OC40ODggMCAwMDE0IDJoLTRjLS4yNSAwLS40Ni4xOC0uNDkuNDJsLS4zOCAyLjY1Yy0uNjEuMjUtMS4xNy41OS0xLjY5Ljk4bC0yLjQ5LTFjLS4yMy0uMDktLjQ5IDAtLjYxLjIybC0yIDMuNDZjLS4xMy4yMi0uMDcuNDkuMTIuNjRsMi4xMSAxLjY1Yy0uMDQuMzItLjA3LjY1LS4wNy45OHMuMDMuNjYuMDcuOThsLTIuMTEgMS42NWMtLjE5LjE1LS4yNC40Mi0uMTIuNjRsMiAzLjQ2Yy4xMi4yMi4zOS4zLjYxLjIybDIuNDktMWMuNTIuNCAxLjA4LjczIDEuNjkuOThsLjM4IDIuNjVjLjAzLjI0LjI0LjQyLjQ5LjQyaDRjLjI1IDAgLjQ2LS4xOC40OS0uNDJsLjM4LTIuNjVjLjYxLS4yNSAxLjE3LS41OSAxLjY5LS45OGwyLjQ5IDFjLjIzLjA5LjQ5IDAgLjYxLS4yMmwyLTMuNDZjLjEyLS4yMi4wNy0uNDktLjEyLS42NGwtMi4xMS0xLjY1ek0xMiAxNS41Yy0xLjkzIDAtMy41LTEuNTctMy41LTMuNXMxLjU3LTMuNSAzLjUtMy41IDMuNSAxLjU3IDMuNSAzLjUtMS41NyAzLjUtMy41IDMuNXoiLz4KPC9zdmc+Cg==);
  --jp-icon-spreadsheet: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1jb250cmFzdDEganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNENBRjUwIiBkPSJNMi4yIDIuMnYxNy42aDE3LjZWMi4ySDIuMnptMTUuNCA3LjdoLTUuNVY0LjRoNS41djUuNXpNOS45IDQuNHY1LjVINC40VjQuNGg1LjV6bS01LjUgNy43aDUuNXY1LjVINC40di01LjV6bTcuNyA1LjV2LTUuNWg1LjV2NS41aC01LjV6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-stop: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTAgMGgyNHYyNEgweiIgZmlsbD0ibm9uZSIvPgogICAgICAgIDxwYXRoIGQ9Ik02IDZoMTJ2MTJINnoiLz4KICAgIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-tab: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTIxIDNIM2MtMS4xIDAtMiAuOS0yIDJ2MTRjMCAxLjEuOSAyIDIgMmgxOGMxLjEgMCAyLS45IDItMlY1YzAtMS4xLS45LTItMi0yem0wIDE2SDNWNWgxMHY0aDh2MTB6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-table-rows: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTAgMGgyNHYyNEgweiIgZmlsbD0ibm9uZSIvPgogICAgICAgIDxwYXRoIGQ9Ik0yMSw4SDNWNGgxOFY4eiBNMjEsMTBIM3Y0aDE4VjEweiBNMjEsMTZIM3Y0aDE4VjE2eiIvPgogICAgPC9nPgo8L3N2Zz4=);
  --jp-icon-tag: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjgiIGhlaWdodD0iMjgiIHZpZXdCb3g9IjAgMCA0MyAyOCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CgkJPHBhdGggZD0iTTI4LjgzMzIgMTIuMzM0TDMyLjk5OTggMTYuNTAwN0wzNy4xNjY1IDEyLjMzNEgyOC44MzMyWiIvPgoJCTxwYXRoIGQ9Ik0xNi4yMDk1IDIxLjYxMDRDMTUuNjg3MyAyMi4xMjk5IDE0Ljg0NDMgMjIuMTI5OSAxNC4zMjQ4IDIxLjYxMDRMNi45ODI5IDE0LjcyNDVDNi41NzI0IDE0LjMzOTQgNi4wODMxMyAxMy42MDk4IDYuMDQ3ODYgMTMuMDQ4MkM1Ljk1MzQ3IDExLjUyODggNi4wMjAwMiA4LjYxOTQ0IDYuMDY2MjEgNy4wNzY5NUM2LjA4MjgxIDYuNTE0NzcgNi41NTU0OCA2LjA0MzQ3IDcuMTE4MDQgNi4wMzA1NUM5LjA4ODYzIDUuOTg0NzMgMTMuMjYzOCA1LjkzNTc5IDEzLjY1MTggNi4zMjQyNUwyMS43MzY5IDEzLjYzOUMyMi4yNTYgMTQuMTU4NSAyMS43ODUxIDE1LjQ3MjQgMjEuMjYyIDE1Ljk5NDZMMTYuMjA5NSAyMS42MTA0Wk05Ljc3NTg1IDguMjY1QzkuMzM1NTEgNy44MjU2NiA4LjYyMzUxIDcuODI1NjYgOC4xODI4IDguMjY1QzcuNzQzNDYgOC43MDU3MSA3Ljc0MzQ2IDkuNDE3MzMgOC4xODI4IDkuODU2NjdDOC42MjM4MiAxMC4yOTY0IDkuMzM1ODIgMTAuMjk2NCA5Ljc3NTg1IDkuODU2NjdDMTAuMjE1NiA5LjQxNzMzIDEwLjIxNTYgOC43MDUzMyA5Ljc3NTg1IDguMjY1WiIvPgoJPC9nPgo8L3N2Zz4K);
  --jp-icon-terminal: url(data:image/svg+xml;base64,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);
  --jp-icon-text-editor: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTUgMTVIM3YyaDEydi0yem0wLThIM3YyaDEyVjd6TTMgMTNoMTh2LTJIM3Yyem0wIDhoMTh2LTJIM3Yyek0zIDN2MmgxOFYzSDN6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-toc: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHhtbG5zOnhsaW5rPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5L3hsaW5rIiB2ZXJzaW9uPSIxLjEiIHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgdmlld0JveD0iMCAwIDI0IDI0IiBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgoJPHBhdGggZD0iTTcsNUgyMVY3SDdWNU03LDEzVjExSDIxVjEzSDdNNCw0LjVBMS41LDEuNSAwIDAsMSA1LjUsNkExLjUsMS41IDAgMCwxIDQsNy41QTEuNSwxLjUgMCAwLDEgMi41LDZBMS41LDEuNSAwIDAsMSA0LDQuNU00LDEwLjVBMS41LDEuNSAwIDAsMSA1LjUsMTJBMS41LDEuNSAwIDAsMSA0LDEzLjVBMS41LDEuNSAwIDAsMSAyLjUsMTJBMS41LDEuNSAwIDAsMSA0LDEwLjVNNywxOVYxN0gyMVYxOUg3TTQsMTYuNUExLjUsMS41IDAgMCwxIDUuNSwxOEExLjUsMS41IDAgMCwxIDQsMTkuNUExLjUsMS41IDAgMCwxIDIuNSwxOEExLjUsMS41IDAgMCwxIDQsMTYuNVoiIC8+Cjwvc3ZnPgo=);
  --jp-icon-tree-view: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTAgMGgyNHYyNEgweiIgZmlsbD0ibm9uZSIvPgogICAgICAgIDxwYXRoIGQ9Ik0yMiAxMVYzaC03djNIOVYzSDJ2OGg3VjhoMnYxMGg0djNoN3YtOGgtN3YzaC0yVjhoMnYzeiIvPgogICAgPC9nPgo8L3N2Zz4=);
  --jp-icon-trusted: url(data:image/svg+xml;base64,PHN2ZyBmaWxsPSJub25lIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI1Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgc3Ryb2tlPSIjMzMzMzMzIiBzdHJva2Utd2lkdGg9IjIiIHRyYW5zZm9ybT0idHJhbnNsYXRlKDIgMykiIGQ9Ik0xLjg2MDk0IDExLjQ0MDlDMC44MjY0NDggOC43NzAyNyAwLjg2Mzc3OSA2LjA1NzY0IDEuMjQ5MDcgNC4xOTkzMkMyLjQ4MjA2IDMuOTMzNDcgNC4wODA2OCAzLjQwMzQ3IDUuNjAxMDIgMi44NDQ5QzcuMjM1NDkgMi4yNDQ0IDguODU2NjYgMS41ODE1IDkuOTg3NiAxLjA5NTM5QzExLjA1OTcgMS41ODM0MSAxMi42MDk0IDIuMjQ0NCAxNC4yMTggMi44NDMzOUMxNS43NTAzIDMuNDEzOTQgMTcuMzk5NSAzLjk1MjU4IDE4Ljc1MzkgNC4yMTM4NUMxOS4xMzY0IDYuMDcxNzcgMTkuMTcwOSA4Ljc3NzIyIDE4LjEzOSAxMS40NDA5QzE3LjAzMDMgMTQuMzAzMiAxNC42NjY4IDE3LjE4NDQgOS45OTk5OSAxOC45MzU0QzUuMzMzMiAxNy4xODQ0IDIuOTY5NjggMTQuMzAzMiAxLjg2MDk0IDExLjQ0MDlaIi8+CiAgICA8cGF0aCBjbGFzcz0ianAtaWNvbjIiIGZpbGw9IiMzMzMzMzMiIHN0cm9rZT0iIzMzMzMzMyIgdHJhbnNmb3JtPSJ0cmFuc2xhdGUoOCA5Ljg2NzE5KSIgZD0iTTIuODYwMTUgNC44NjUzNUwwLjcyNjU0OSAyLjk5OTU5TDAgMy42MzA0NUwyLjg2MDE1IDYuMTMxNTdMOCAwLjYzMDg3Mkw3LjI3ODU3IDBMMi44NjAxNSA0Ljg2NTM1WiIvPgo8L3N2Zz4K);
  --jp-icon-undo: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyLjUgOGMtMi42NSAwLTUuMDUuOTktNi45IDIuNkwyIDd2OWg5bC0zLjYyLTMuNjJjMS4zOS0xLjE2IDMuMTYtMS44OCA1LjEyLTEuODggMy41NCAwIDYuNTUgMi4zMSA3LjYgNS41bDIuMzctLjc4QzIxLjA4IDExLjAzIDE3LjE1IDggMTIuNSA4eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-vega: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtaWNvbjEganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjMjEyMTIxIj4KICAgIDxwYXRoIGQ9Ik0xMC42IDUuNGwyLjItMy4ySDIuMnY3LjNsNC02LjZ6Ii8+CiAgICA8cGF0aCBkPSJNMTUuOCAyLjJsLTQuNCA2LjZMNyA2LjNsLTQuOCA4djUuNWgxNy42VjIuMmgtNHptLTcgMTUuNEg1LjV2LTQuNGgzLjN2NC40em00LjQgMEg5LjhWOS44aDMuNHY3Ljh6bTQuNCAwaC0zLjRWNi41aDMuNHYxMS4xeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-yaml: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtaWNvbi1jb250cmFzdDIganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjRDgxQjYwIj4KICAgIDxwYXRoIGQ9Ik03LjIgMTguNnYtNS40TDMgNS42aDMuM2wxLjQgMy4xYy4zLjkuNiAxLjYgMSAyLjUuMy0uOC42LTEuNiAxLTIuNWwxLjQtMy4xaDMuNGwtNC40IDcuNnY1LjVsLTIuOS0uMXoiLz4KICAgIDxjaXJjbGUgY2xhc3M9InN0MCIgY3g9IjE3LjYiIGN5PSIxNi41IiByPSIyLjEiLz4KICAgIDxjaXJjbGUgY2xhc3M9InN0MCIgY3g9IjE3LjYiIGN5PSIxMSIgcj0iMi4xIi8+CiAgPC9nPgo8L3N2Zz4K);
}

/* Icon CSS class declarations */

.jp-AddIcon {
  background-image: var(--jp-icon-add);
}
.jp-BugIcon {
  background-image: var(--jp-icon-bug);
}
.jp-BuildIcon {
  background-image: var(--jp-icon-build);
}
.jp-CaretDownEmptyIcon {
  background-image: var(--jp-icon-caret-down-empty);
}
.jp-CaretDownEmptyThinIcon {
  background-image: var(--jp-icon-caret-down-empty-thin);
}
.jp-CaretDownIcon {
  background-image: var(--jp-icon-caret-down);
}
.jp-CaretLeftIcon {
  background-image: var(--jp-icon-caret-left);
}
.jp-CaretRightIcon {
  background-image: var(--jp-icon-caret-right);
}
.jp-CaretUpEmptyThinIcon {
  background-image: var(--jp-icon-caret-up-empty-thin);
}
.jp-CaretUpIcon {
  background-image: var(--jp-icon-caret-up);
}
.jp-CaseSensitiveIcon {
  background-image: var(--jp-icon-case-sensitive);
}
.jp-CheckIcon {
  background-image: var(--jp-icon-check);
}
.jp-CircleEmptyIcon {
  background-image: var(--jp-icon-circle-empty);
}
.jp-CircleIcon {
  background-image: var(--jp-icon-circle);
}
.jp-ClearIcon {
  background-image: var(--jp-icon-clear);
}
.jp-CloseIcon {
  background-image: var(--jp-icon-close);
}
.jp-CodeIcon {
  background-image: var(--jp-icon-code);
}
.jp-ConsoleIcon {
  background-image: var(--jp-icon-console);
}
.jp-CopyIcon {
  background-image: var(--jp-icon-copy);
}
.jp-CutIcon {
  background-image: var(--jp-icon-cut);
}
.jp-DownloadIcon {
  background-image: var(--jp-icon-download);
}
.jp-EditIcon {
  background-image: var(--jp-icon-edit);
}
.jp-EllipsesIcon {
  background-image: var(--jp-icon-ellipses);
}
.jp-ExtensionIcon {
  background-image: var(--jp-icon-extension);
}
.jp-FastForwardIcon {
  background-image: var(--jp-icon-fast-forward);
}
.jp-FileIcon {
  background-image: var(--jp-icon-file);
}
.jp-FileUploadIcon {
  background-image: var(--jp-icon-file-upload);
}
.jp-FilterListIcon {
  background-image: var(--jp-icon-filter-list);
}
.jp-FolderIcon {
  background-image: var(--jp-icon-folder);
}
.jp-Html5Icon {
  background-image: var(--jp-icon-html5);
}
.jp-ImageIcon {
  background-image: var(--jp-icon-image);
}
.jp-InspectorIcon {
  background-image: var(--jp-icon-inspector);
}
.jp-JsonIcon {
  background-image: var(--jp-icon-json);
}
.jp-JupyterFaviconIcon {
  background-image: var(--jp-icon-jupyter-favicon);
}
.jp-JupyterIcon {
  background-image: var(--jp-icon-jupyter);
}
.jp-JupyterlabWordmarkIcon {
  background-image: var(--jp-icon-jupyterlab-wordmark);
}
.jp-KernelIcon {
  background-image: var(--jp-icon-kernel);
}
.jp-KeyboardIcon {
  background-image: var(--jp-icon-keyboard);
}
.jp-LauncherIcon {
  background-image: var(--jp-icon-launcher);
}
.jp-LineFormIcon {
  background-image: var(--jp-icon-line-form);
}
.jp-LinkIcon {
  background-image: var(--jp-icon-link);
}
.jp-ListIcon {
  background-image: var(--jp-icon-list);
}
.jp-ListingsInfoIcon {
  background-image: var(--jp-icon-listings-info);
}
.jp-MarkdownIcon {
  background-image: var(--jp-icon-markdown);
}
.jp-NewFolderIcon {
  background-image: var(--jp-icon-new-folder);
}
.jp-NotTrustedIcon {
  background-image: var(--jp-icon-not-trusted);
}
.jp-NotebookIcon {
  background-image: var(--jp-icon-notebook);
}
.jp-NumberingIcon {
  background-image: var(--jp-icon-numbering);
}
.jp-OfflineBoltIcon {
  background-image: var(--jp-icon-offline-bolt);
}
.jp-PaletteIcon {
  background-image: var(--jp-icon-palette);
}
.jp-PasteIcon {
  background-image: var(--jp-icon-paste);
}
.jp-PdfIcon {
  background-image: var(--jp-icon-pdf);
}
.jp-PythonIcon {
  background-image: var(--jp-icon-python);
}
.jp-RKernelIcon {
  background-image: var(--jp-icon-r-kernel);
}
.jp-ReactIcon {
  background-image: var(--jp-icon-react);
}
.jp-RedoIcon {
  background-image: var(--jp-icon-redo);
}
.jp-RefreshIcon {
  background-image: var(--jp-icon-refresh);
}
.jp-RegexIcon {
  background-image: var(--jp-icon-regex);
}
.jp-RunIcon {
  background-image: var(--jp-icon-run);
}
.jp-RunningIcon {
  background-image: var(--jp-icon-running);
}
.jp-SaveIcon {
  background-image: var(--jp-icon-save);
}
.jp-SearchIcon {
  background-image: var(--jp-icon-search);
}
.jp-SettingsIcon {
  background-image: var(--jp-icon-settings);
}
.jp-SpreadsheetIcon {
  background-image: var(--jp-icon-spreadsheet);
}
.jp-StopIcon {
  background-image: var(--jp-icon-stop);
}
.jp-TabIcon {
  background-image: var(--jp-icon-tab);
}
.jp-TableRowsIcon {
  background-image: var(--jp-icon-table-rows);
}
.jp-TagIcon {
  background-image: var(--jp-icon-tag);
}
.jp-TerminalIcon {
  background-image: var(--jp-icon-terminal);
}
.jp-TextEditorIcon {
  background-image: var(--jp-icon-text-editor);
}
.jp-TocIcon {
  background-image: var(--jp-icon-toc);
}
.jp-TreeViewIcon {
  background-image: var(--jp-icon-tree-view);
}
.jp-TrustedIcon {
  background-image: var(--jp-icon-trusted);
}
.jp-UndoIcon {
  background-image: var(--jp-icon-undo);
}
.jp-VegaIcon {
  background-image: var(--jp-icon-vega);
}
.jp-YamlIcon {
  background-image: var(--jp-icon-yaml);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/**
 * (DEPRECATED) Support for consuming icons as CSS background images
 */

:root {
  --jp-icon-search-white: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMTggMTgiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyLjEsMTAuOWgtMC43bC0wLjItMC4yYzAuOC0wLjksMS4zLTIuMiwxLjMtMy41YzAtMy0yLjQtNS40LTUuNC01LjRTMS44LDQuMiwxLjgsNy4xczIuNCw1LjQsNS40LDUuNCBjMS4zLDAsMi41LTAuNSwzLjUtMS4zbDAuMiwwLjJ2MC43bDQuMSw0LjFsMS4yLTEuMkwxMi4xLDEwLjl6IE03LjEsMTAuOWMtMi4xLDAtMy43LTEuNy0zLjctMy43czEuNy0zLjcsMy43LTMuN3MzLjcsMS43LDMuNywzLjcgUzkuMiwxMC45LDcuMSwxMC45eiIvPgogIDwvZz4KPC9zdmc+Cg==);
}

.jp-Icon,
.jp-MaterialIcon {
  background-position: center;
  background-repeat: no-repeat;
  background-size: 16px;
  min-width: 16px;
  min-height: 16px;
}

.jp-Icon-cover {
  background-position: center;
  background-repeat: no-repeat;
  background-size: cover;
}

/**
 * (DEPRECATED) Support for specific CSS icon sizes
 */

.jp-Icon-16 {
  background-size: 16px;
  min-width: 16px;
  min-height: 16px;
}

.jp-Icon-18 {
  background-size: 18px;
  min-width: 18px;
  min-height: 18px;
}

.jp-Icon-20 {
  background-size: 20px;
  min-width: 20px;
  min-height: 20px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/**
 * Support for icons as inline SVG HTMLElements
 */

/* recolor the primary elements of an icon */
.jp-icon0[fill] {
  fill: var(--jp-inverse-layout-color0);
}
.jp-icon1[fill] {
  fill: var(--jp-inverse-layout-color1);
}
.jp-icon2[fill] {
  fill: var(--jp-inverse-layout-color2);
}
.jp-icon3[fill] {
  fill: var(--jp-inverse-layout-color3);
}
.jp-icon4[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon0[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}
.jp-icon1[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}
.jp-icon2[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}
.jp-icon3[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}
.jp-icon4[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}
/* recolor the accent elements of an icon */
.jp-icon-accent0[fill] {
  fill: var(--jp-layout-color0);
}
.jp-icon-accent1[fill] {
  fill: var(--jp-layout-color1);
}
.jp-icon-accent2[fill] {
  fill: var(--jp-layout-color2);
}
.jp-icon-accent3[fill] {
  fill: var(--jp-layout-color3);
}
.jp-icon-accent4[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-accent0[stroke] {
  stroke: var(--jp-layout-color0);
}
.jp-icon-accent1[stroke] {
  stroke: var(--jp-layout-color1);
}
.jp-icon-accent2[stroke] {
  stroke: var(--jp-layout-color2);
}
.jp-icon-accent3[stroke] {
  stroke: var(--jp-layout-color3);
}
.jp-icon-accent4[stroke] {
  stroke: var(--jp-layout-color4);
}
/* set the color of an icon to transparent */
.jp-icon-none[fill] {
  fill: none;
}

.jp-icon-none[stroke] {
  stroke: none;
}
/* brand icon colors. Same for light and dark */
.jp-icon-brand0[fill] {
  fill: var(--jp-brand-color0);
}
.jp-icon-brand1[fill] {
  fill: var(--jp-brand-color1);
}
.jp-icon-brand2[fill] {
  fill: var(--jp-brand-color2);
}
.jp-icon-brand3[fill] {
  fill: var(--jp-brand-color3);
}
.jp-icon-brand4[fill] {
  fill: var(--jp-brand-color4);
}

.jp-icon-brand0[stroke] {
  stroke: var(--jp-brand-color0);
}
.jp-icon-brand1[stroke] {
  stroke: var(--jp-brand-color1);
}
.jp-icon-brand2[stroke] {
  stroke: var(--jp-brand-color2);
}
.jp-icon-brand3[stroke] {
  stroke: var(--jp-brand-color3);
}
.jp-icon-brand4[stroke] {
  stroke: var(--jp-brand-color4);
}
/* warn icon colors. Same for light and dark */
.jp-icon-warn0[fill] {
  fill: var(--jp-warn-color0);
}
.jp-icon-warn1[fill] {
  fill: var(--jp-warn-color1);
}
.jp-icon-warn2[fill] {
  fill: var(--jp-warn-color2);
}
.jp-icon-warn3[fill] {
  fill: var(--jp-warn-color3);
}

.jp-icon-warn0[stroke] {
  stroke: var(--jp-warn-color0);
}
.jp-icon-warn1[stroke] {
  stroke: var(--jp-warn-color1);
}
.jp-icon-warn2[stroke] {
  stroke: var(--jp-warn-color2);
}
.jp-icon-warn3[stroke] {
  stroke: var(--jp-warn-color3);
}
/* icon colors that contrast well with each other and most backgrounds */
.jp-icon-contrast0[fill] {
  fill: var(--jp-icon-contrast-color0);
}
.jp-icon-contrast1[fill] {
  fill: var(--jp-icon-contrast-color1);
}
.jp-icon-contrast2[fill] {
  fill: var(--jp-icon-contrast-color2);
}
.jp-icon-contrast3[fill] {
  fill: var(--jp-icon-contrast-color3);
}

.jp-icon-contrast0[stroke] {
  stroke: var(--jp-icon-contrast-color0);
}
.jp-icon-contrast1[stroke] {
  stroke: var(--jp-icon-contrast-color1);
}
.jp-icon-contrast2[stroke] {
  stroke: var(--jp-icon-contrast-color2);
}
.jp-icon-contrast3[stroke] {
  stroke: var(--jp-icon-contrast-color3);
}

/* CSS for icons in selected items in the settings editor */
#setting-editor .jp-PluginList .jp-mod-selected .jp-icon-selectable[fill] {
  fill: #fff;
}
#setting-editor
  .jp-PluginList
  .jp-mod-selected
  .jp-icon-selectable-inverse[fill] {
  fill: var(--jp-brand-color1);
}

/* CSS for icons in selected filebrowser listing items */
.jp-DirListing-item.jp-mod-selected .jp-icon-selectable[fill] {
  fill: #fff;
}
.jp-DirListing-item.jp-mod-selected .jp-icon-selectable-inverse[fill] {
  fill: var(--jp-brand-color1);
}

/* CSS for icons in selected tabs in the sidebar tab manager */
#tab-manager .lm-TabBar-tab.jp-mod-active .jp-icon-selectable[fill] {
  fill: #fff;
}

#tab-manager .lm-TabBar-tab.jp-mod-active .jp-icon-selectable-inverse[fill] {
  fill: var(--jp-brand-color1);
}
#tab-manager
  .lm-TabBar-tab.jp-mod-active
  .jp-icon-hover
  :hover
  .jp-icon-selectable[fill] {
  fill: var(--jp-brand-color1);
}

#tab-manager
  .lm-TabBar-tab.jp-mod-active
  .jp-icon-hover
  :hover
  .jp-icon-selectable-inverse[fill] {
  fill: #fff;
}

/**
 * TODO: come up with non css-hack solution for showing the busy icon on top
 *  of the close icon
 * CSS for complex behavior of close icon of tabs in the sidebar tab manager
 */
#tab-manager
  .lm-TabBar-tab.jp-mod-dirty
  > .lm-TabBar-tabCloseIcon
  > :not(:hover)
  > .jp-icon3[fill] {
  fill: none;
}
#tab-manager
  .lm-TabBar-tab.jp-mod-dirty
  > .lm-TabBar-tabCloseIcon
  > :not(:hover)
  > .jp-icon-busy[fill] {
  fill: var(--jp-inverse-layout-color3);
}

#tab-manager
  .lm-TabBar-tab.jp-mod-dirty.jp-mod-active
  > .lm-TabBar-tabCloseIcon
  > :not(:hover)
  > .jp-icon-busy[fill] {
  fill: #fff;
}

/**
* TODO: come up with non css-hack solution for showing the busy icon on top
*  of the close icon
* CSS for complex behavior of close icon of tabs in the main area tabbar
*/
.lm-DockPanel-tabBar
  .lm-TabBar-tab.lm-mod-closable.jp-mod-dirty
  > .lm-TabBar-tabCloseIcon
  > :not(:hover)
  > .jp-icon3[fill] {
  fill: none;
}
.lm-DockPanel-tabBar
  .lm-TabBar-tab.lm-mod-closable.jp-mod-dirty
  > .lm-TabBar-tabCloseIcon
  > :not(:hover)
  > .jp-icon-busy[fill] {
  fill: var(--jp-inverse-layout-color3);
}

/* CSS for icons in status bar */
#jp-main-statusbar .jp-mod-selected .jp-icon-selectable[fill] {
  fill: #fff;
}

#jp-main-statusbar .jp-mod-selected .jp-icon-selectable-inverse[fill] {
  fill: var(--jp-brand-color1);
}
/* special handling for splash icon CSS. While the theme CSS reloads during
   splash, the splash icon can loose theming. To prevent that, we set a
   default for its color variable */
:root {
  --jp-warn-color0: var(--md-orange-700);
}

/* not sure what to do with this one, used in filebrowser listing */
.jp-DragIcon {
  margin-right: 4px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/**
 * Support for alt colors for icons as inline SVG HTMLElements
 */

/* alt recolor the primary elements of an icon */
.jp-icon-alt .jp-icon0[fill] {
  fill: var(--jp-layout-color0);
}
.jp-icon-alt .jp-icon1[fill] {
  fill: var(--jp-layout-color1);
}
.jp-icon-alt .jp-icon2[fill] {
  fill: var(--jp-layout-color2);
}
.jp-icon-alt .jp-icon3[fill] {
  fill: var(--jp-layout-color3);
}
.jp-icon-alt .jp-icon4[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-alt .jp-icon0[stroke] {
  stroke: var(--jp-layout-color0);
}
.jp-icon-alt .jp-icon1[stroke] {
  stroke: var(--jp-layout-color1);
}
.jp-icon-alt .jp-icon2[stroke] {
  stroke: var(--jp-layout-color2);
}
.jp-icon-alt .jp-icon3[stroke] {
  stroke: var(--jp-layout-color3);
}
.jp-icon-alt .jp-icon4[stroke] {
  stroke: var(--jp-layout-color4);
}

/* alt recolor the accent elements of an icon */
.jp-icon-alt .jp-icon-accent0[fill] {
  fill: var(--jp-inverse-layout-color0);
}
.jp-icon-alt .jp-icon-accent1[fill] {
  fill: var(--jp-inverse-layout-color1);
}
.jp-icon-alt .jp-icon-accent2[fill] {
  fill: var(--jp-inverse-layout-color2);
}
.jp-icon-alt .jp-icon-accent3[fill] {
  fill: var(--jp-inverse-layout-color3);
}
.jp-icon-alt .jp-icon-accent4[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon-alt .jp-icon-accent0[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}
.jp-icon-alt .jp-icon-accent1[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}
.jp-icon-alt .jp-icon-accent2[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}
.jp-icon-alt .jp-icon-accent3[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}
.jp-icon-alt .jp-icon-accent4[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-icon-hoverShow:not(:hover) svg {
  display: none !important;
}

/**
 * Support for hover colors for icons as inline SVG HTMLElements
 */

/**
 * regular colors
 */

/* recolor the primary elements of an icon */
.jp-icon-hover :hover .jp-icon0-hover[fill] {
  fill: var(--jp-inverse-layout-color0);
}
.jp-icon-hover :hover .jp-icon1-hover[fill] {
  fill: var(--jp-inverse-layout-color1);
}
.jp-icon-hover :hover .jp-icon2-hover[fill] {
  fill: var(--jp-inverse-layout-color2);
}
.jp-icon-hover :hover .jp-icon3-hover[fill] {
  fill: var(--jp-inverse-layout-color3);
}
.jp-icon-hover :hover .jp-icon4-hover[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon-hover :hover .jp-icon0-hover[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}
.jp-icon-hover :hover .jp-icon1-hover[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}
.jp-icon-hover :hover .jp-icon2-hover[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}
.jp-icon-hover :hover .jp-icon3-hover[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}
.jp-icon-hover :hover .jp-icon4-hover[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}

/* recolor the accent elements of an icon */
.jp-icon-hover :hover .jp-icon-accent0-hover[fill] {
  fill: var(--jp-layout-color0);
}
.jp-icon-hover :hover .jp-icon-accent1-hover[fill] {
  fill: var(--jp-layout-color1);
}
.jp-icon-hover :hover .jp-icon-accent2-hover[fill] {
  fill: var(--jp-layout-color2);
}
.jp-icon-hover :hover .jp-icon-accent3-hover[fill] {
  fill: var(--jp-layout-color3);
}
.jp-icon-hover :hover .jp-icon-accent4-hover[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-hover :hover .jp-icon-accent0-hover[stroke] {
  stroke: var(--jp-layout-color0);
}
.jp-icon-hover :hover .jp-icon-accent1-hover[stroke] {
  stroke: var(--jp-layout-color1);
}
.jp-icon-hover :hover .jp-icon-accent2-hover[stroke] {
  stroke: var(--jp-layout-color2);
}
.jp-icon-hover :hover .jp-icon-accent3-hover[stroke] {
  stroke: var(--jp-layout-color3);
}
.jp-icon-hover :hover .jp-icon-accent4-hover[stroke] {
  stroke: var(--jp-layout-color4);
}

/* set the color of an icon to transparent */
.jp-icon-hover :hover .jp-icon-none-hover[fill] {
  fill: none;
}

.jp-icon-hover :hover .jp-icon-none-hover[stroke] {
  stroke: none;
}

/**
 * inverse colors
 */

/* inverse recolor the primary elements of an icon */
.jp-icon-hover.jp-icon-alt :hover .jp-icon0-hover[fill] {
  fill: var(--jp-layout-color0);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon1-hover[fill] {
  fill: var(--jp-layout-color1);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon2-hover[fill] {
  fill: var(--jp-layout-color2);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon3-hover[fill] {
  fill: var(--jp-layout-color3);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon4-hover[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon0-hover[stroke] {
  stroke: var(--jp-layout-color0);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon1-hover[stroke] {
  stroke: var(--jp-layout-color1);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon2-hover[stroke] {
  stroke: var(--jp-layout-color2);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon3-hover[stroke] {
  stroke: var(--jp-layout-color3);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon4-hover[stroke] {
  stroke: var(--jp-layout-color4);
}

/* inverse recolor the accent elements of an icon */
.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent0-hover[fill] {
  fill: var(--jp-inverse-layout-color0);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent1-hover[fill] {
  fill: var(--jp-inverse-layout-color1);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent2-hover[fill] {
  fill: var(--jp-inverse-layout-color2);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent3-hover[fill] {
  fill: var(--jp-inverse-layout-color3);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent4-hover[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent0-hover[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent1-hover[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent2-hover[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent3-hover[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent4-hover[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-switch {
  display: flex;
  align-items: center;
  padding-left: 4px;
  padding-right: 4px;
  font-size: var(--jp-ui-font-size1);
  background-color: transparent;
  color: var(--jp-ui-font-color1);
  border: none;
  height: 20px;
}

.jp-switch:hover {
  background-color: var(--jp-layout-color2);
}

.jp-switch-label {
  margin-right: 5px;
}

.jp-switch-track {
  cursor: pointer;
  background-color: var(--jp-border-color1);
  -webkit-transition: 0.4s;
  transition: 0.4s;
  border-radius: 34px;
  height: 16px;
  width: 35px;
  position: relative;
}

.jp-switch-track::before {
  content: '';
  position: absolute;
  height: 10px;
  width: 10px;
  margin: 3px;
  left: 0px;
  background-color: var(--jp-ui-inverse-font-color1);
  -webkit-transition: 0.4s;
  transition: 0.4s;
  border-radius: 50%;
}

.jp-switch[aria-checked='true'] .jp-switch-track {
  background-color: var(--jp-warn-color0);
}

.jp-switch[aria-checked='true'] .jp-switch-track::before {
  /* track width (35) - margins (3 + 3) - thumb width (10) */
  left: 19px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* Sibling imports */

/* Override Blueprint's _reset.scss styles */
html {
  box-sizing: unset;
}

*,
*::before,
*::after {
  box-sizing: unset;
}

body {
  color: unset;
  font-family: var(--jp-ui-font-family);
}

p {
  margin-top: unset;
  margin-bottom: unset;
}

small {
  font-size: unset;
}

strong {
  font-weight: unset;
}

/* Override Blueprint's _typography.scss styles */
a {
  text-decoration: unset;
  color: unset;
}
a:hover {
  text-decoration: unset;
  color: unset;
}

/* Override Blueprint's _accessibility.scss styles */
:focus {
  outline: unset;
  outline-offset: unset;
  -moz-outline-radius: unset;
}

/* Styles for ui-components */
.jp-Button {
  border-radius: var(--jp-border-radius);
  padding: 0px 12px;
  font-size: var(--jp-ui-font-size1);
}

/* Use our own theme for hover styles */
button.jp-Button.bp3-button.bp3-minimal:hover {
  background-color: var(--jp-layout-color2);
}
.jp-Button.minimal {
  color: unset !important;
}

.jp-Button.jp-ToolbarButtonComponent {
  text-transform: none;
}

.jp-InputGroup input {
  box-sizing: border-box;
  border-radius: 0;
  background-color: transparent;
  color: var(--jp-ui-font-color0);
  box-shadow: inset 0 0 0 var(--jp-border-width) var(--jp-input-border-color);
}

.jp-InputGroup input:focus {
  box-shadow: inset 0 0 0 var(--jp-border-width)
      var(--jp-input-active-box-shadow-color),
    inset 0 0 0 3px var(--jp-input-active-box-shadow-color);
}

.jp-InputGroup input::placeholder,
input::placeholder {
  color: var(--jp-ui-font-color3);
}

.jp-BPIcon {
  display: inline-block;
  vertical-align: middle;
  margin: auto;
}

/* Stop blueprint futzing with our icon fills */
.bp3-icon.jp-BPIcon > svg:not([fill]) {
  fill: var(--jp-inverse-layout-color3);
}

.jp-InputGroupAction {
  padding: 6px;
}

.jp-HTMLSelect.jp-DefaultStyle select {
  background-color: initial;
  border: none;
  border-radius: 0;
  box-shadow: none;
  color: var(--jp-ui-font-color0);
  display: block;
  font-size: var(--jp-ui-font-size1);
  height: 24px;
  line-height: 14px;
  padding: 0 25px 0 10px;
  text-align: left;
  -moz-appearance: none;
  -webkit-appearance: none;
}

/* Use our own theme for hover and option styles */
.jp-HTMLSelect.jp-DefaultStyle select:hover,
.jp-HTMLSelect.jp-DefaultStyle select > option {
  background-color: var(--jp-layout-color2);
  color: var(--jp-ui-font-color0);
}
select {
  box-sizing: border-box;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Collapse {
  display: flex;
  flex-direction: column;
  align-items: stretch;
  border-top: 1px solid var(--jp-border-color2);
  border-bottom: 1px solid var(--jp-border-color2);
}

.jp-Collapse-header {
  padding: 1px 12px;
  color: var(--jp-ui-font-color1);
  background-color: var(--jp-layout-color1);
  font-size: var(--jp-ui-font-size2);
}

.jp-Collapse-header:hover {
  background-color: var(--jp-layout-color2);
}

.jp-Collapse-contents {
  padding: 0px 12px 0px 12px;
  background-color: var(--jp-layout-color1);
  color: var(--jp-ui-font-color1);
  overflow: auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Variables
|----------------------------------------------------------------------------*/

:root {
  --jp-private-commandpalette-search-height: 28px;
}

/*-----------------------------------------------------------------------------
| Overall styles
|----------------------------------------------------------------------------*/

.lm-CommandPalette {
  padding-bottom: 0px;
  color: var(--jp-ui-font-color1);
  background: var(--jp-layout-color1);
  /* This is needed so that all font sizing of children done in ems is
   * relative to this base size */
  font-size: var(--jp-ui-font-size1);
}

/*-----------------------------------------------------------------------------
| Modal variant
|----------------------------------------------------------------------------*/

.jp-ModalCommandPalette {
  position: absolute;
  z-index: 10000;
  top: 38px;
  left: 30%;
  margin: 0;
  padding: 4px;
  width: 40%;
  box-shadow: var(--jp-elevation-z4);
  border-radius: 4px;
  background: var(--jp-layout-color0);
}

.jp-ModalCommandPalette .lm-CommandPalette {
  max-height: 40vh;
}

.jp-ModalCommandPalette .lm-CommandPalette .lm-close-icon::after {
  display: none;
}

.jp-ModalCommandPalette .lm-CommandPalette .lm-CommandPalette-header {
  display: none;
}

.jp-ModalCommandPalette .lm-CommandPalette .lm-CommandPalette-item {
  margin-left: 4px;
  margin-right: 4px;
}

.jp-ModalCommandPalette
  .lm-CommandPalette
  .lm-CommandPalette-item.lm-mod-disabled {
  display: none;
}

/*-----------------------------------------------------------------------------
| Search
|----------------------------------------------------------------------------*/

.lm-CommandPalette-search {
  padding: 4px;
  background-color: var(--jp-layout-color1);
  z-index: 2;
}

.lm-CommandPalette-wrapper {
  overflow: overlay;
  padding: 0px 9px;
  background-color: var(--jp-input-active-background);
  height: 30px;
  box-shadow: inset 0 0 0 var(--jp-border-width) var(--jp-input-border-color);
}

.lm-CommandPalette.lm-mod-focused .lm-CommandPalette-wrapper {
  box-shadow: inset 0 0 0 1px var(--jp-input-active-box-shadow-color),
    inset 0 0 0 3px var(--jp-input-active-box-shadow-color);
}

.lm-CommandPalette-wrapper::after {
  content: ' ';
  color: white;
  background-color: var(--jp-brand-color1);
  position: absolute;
  top: 4px;
  right: 4px;
  height: 30px;
  width: 10px;
  padding: 0px 10px;
  background-image: var(--jp-icon-search-white);
  background-size: 20px;
  background-repeat: no-repeat;
  background-position: center;
}

.lm-CommandPalette-input {
  background: transparent;
  width: calc(100% - 18px);
  float: left;
  border: none;
  outline: none;
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color0);
  line-height: var(--jp-private-commandpalette-search-height);
}

.lm-CommandPalette-input::-webkit-input-placeholder,
.lm-CommandPalette-input::-moz-placeholder,
.lm-CommandPalette-input:-ms-input-placeholder {
  color: var(--jp-ui-font-color3);
  font-size: var(--jp-ui-font-size1);
}

/*-----------------------------------------------------------------------------
| Results
|----------------------------------------------------------------------------*/

.lm-CommandPalette-header:first-child {
  margin-top: 0px;
}

.lm-CommandPalette-header {
  border-bottom: solid var(--jp-border-width) var(--jp-border-color2);
  color: var(--jp-ui-font-color1);
  cursor: pointer;
  display: flex;
  font-size: var(--jp-ui-font-size0);
  font-weight: 600;
  letter-spacing: 1px;
  margin-top: 8px;
  padding: 8px 0 8px 12px;
  text-transform: uppercase;
}

.lm-CommandPalette-header.lm-mod-active {
  background: var(--jp-layout-color2);
}

.lm-CommandPalette-header > mark {
  background-color: transparent;
  font-weight: bold;
  color: var(--jp-ui-font-color1);
}

.lm-CommandPalette-item {
  padding: 4px 12px 4px 4px;
  color: var(--jp-ui-font-color1);
  font-size: var(--jp-ui-font-size1);
  font-weight: 400;
  display: flex;
}

.lm-CommandPalette-item.lm-mod-disabled {
  color: var(--jp-ui-font-color3);
}

.lm-CommandPalette-item.lm-mod-active {
  background: var(--jp-layout-color3);
}

.lm-CommandPalette-item.lm-mod-active:hover:not(.lm-mod-disabled) {
  background: var(--jp-layout-color4);
}

.lm-CommandPalette-item:hover:not(.lm-mod-active):not(.lm-mod-disabled) {
  background: var(--jp-layout-color2);
}

.lm-CommandPalette-itemContent {
  overflow: hidden;
}

.lm-CommandPalette-itemLabel > mark {
  color: var(--jp-ui-font-color0);
  background-color: transparent;
  font-weight: bold;
}

.lm-CommandPalette-item.lm-mod-disabled mark {
  color: var(--jp-ui-font-color3);
}

.lm-CommandPalette-item .lm-CommandPalette-itemIcon {
  margin: 0 4px 0 0;
  position: relative;
  width: 16px;
  top: 2px;
  flex: 0 0 auto;
}

.lm-CommandPalette-item.lm-mod-disabled .lm-CommandPalette-itemIcon {
  opacity: 0.4;
}

.lm-CommandPalette-item .lm-CommandPalette-itemShortcut {
  flex: 0 0 auto;
}

.lm-CommandPalette-itemCaption {
  display: none;
}

.lm-CommandPalette-content {
  background-color: var(--jp-layout-color1);
}

.lm-CommandPalette-content:empty:after {
  content: 'No results';
  margin: auto;
  margin-top: 20px;
  width: 100px;
  display: block;
  font-size: var(--jp-ui-font-size2);
  font-family: var(--jp-ui-font-family);
  font-weight: lighter;
}

.lm-CommandPalette-emptyMessage {
  text-align: center;
  margin-top: 24px;
  line-height: 1.32;
  padding: 0px 8px;
  color: var(--jp-content-font-color3);
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Dialog {
  position: absolute;
  z-index: 10000;
  display: flex;
  flex-direction: column;
  align-items: center;
  justify-content: center;
  top: 0px;
  left: 0px;
  margin: 0;
  padding: 0;
  width: 100%;
  height: 100%;
  background: var(--jp-dialog-background);
}

.jp-Dialog-content {
  display: flex;
  flex-direction: column;
  margin-left: auto;
  margin-right: auto;
  background: var(--jp-layout-color1);
  padding: 24px;
  padding-bottom: 12px;
  min-width: 300px;
  min-height: 150px;
  max-width: 1000px;
  max-height: 500px;
  box-sizing: border-box;
  box-shadow: var(--jp-elevation-z20);
  word-wrap: break-word;
  border-radius: var(--jp-border-radius);
  /* This is needed so that all font sizing of children done in ems is
   * relative to this base size */
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color1);
  resize: both;
}

.jp-Dialog-button {
  overflow: visible;
}

button.jp-Dialog-button:focus {
  outline: 1px solid var(--jp-brand-color1);
  outline-offset: 4px;
  -moz-outline-radius: 0px;
}

button.jp-Dialog-button:focus::-moz-focus-inner {
  border: 0;
}

button.jp-Dialog-close-button {
  padding: 0;
  height: 100%;
  min-width: unset;
  min-height: unset;
}

.jp-Dialog-header {
  display: flex;
  justify-content: space-between;
  flex: 0 0 auto;
  padding-bottom: 12px;
  font-size: var(--jp-ui-font-size3);
  font-weight: 400;
  color: var(--jp-ui-font-color0);
}

.jp-Dialog-body {
  display: flex;
  flex-direction: column;
  flex: 1 1 auto;
  font-size: var(--jp-ui-font-size1);
  background: var(--jp-layout-color1);
  overflow: auto;
}

.jp-Dialog-footer {
  display: flex;
  flex-direction: row;
  justify-content: flex-end;
  flex: 0 0 auto;
  margin-left: -12px;
  margin-right: -12px;
  padding: 12px;
}

.jp-Dialog-title {
  overflow: hidden;
  white-space: nowrap;
  text-overflow: ellipsis;
}

.jp-Dialog-body > .jp-select-wrapper {
  width: 100%;
}

.jp-Dialog-body > button {
  padding: 0px 16px;
}

.jp-Dialog-body > label {
  line-height: 1.4;
  color: var(--jp-ui-font-color0);
}

.jp-Dialog-button.jp-mod-styled:not(:last-child) {
  margin-right: 12px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-HoverBox {
  position: fixed;
}

.jp-HoverBox.jp-mod-outofview {
  display: none;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-IFrame {
  width: 100%;
  height: 100%;
}

.jp-IFrame > iframe {
  border: none;
}

/*
When drag events occur, `p-mod-override-cursor` is added to the body.
Because iframes steal all cursor events, the following two rules are necessary
to suppress pointer events while resize drags are occurring. There may be a
better solution to this problem.
*/
body.lm-mod-override-cursor .jp-IFrame {
  position: relative;
}

body.lm-mod-override-cursor .jp-IFrame:before {
  content: '';
  position: absolute;
  top: 0;
  left: 0;
  right: 0;
  bottom: 0;
  background: transparent;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-MainAreaWidget > :focus {
  outline: none;
}

/**
 * google-material-color v1.2.6
 * https://github.com/danlevan/google-material-color
 */
:root {
  --md-red-50: #ffebee;
  --md-red-100: #ffcdd2;
  --md-red-200: #ef9a9a;
  --md-red-300: #e57373;
  --md-red-400: #ef5350;
  --md-red-500: #f44336;
  --md-red-600: #e53935;
  --md-red-700: #d32f2f;
  --md-red-800: #c62828;
  --md-red-900: #b71c1c;
  --md-red-A100: #ff8a80;
  --md-red-A200: #ff5252;
  --md-red-A400: #ff1744;
  --md-red-A700: #d50000;

  --md-pink-50: #fce4ec;
  --md-pink-100: #f8bbd0;
  --md-pink-200: #f48fb1;
  --md-pink-300: #f06292;
  --md-pink-400: #ec407a;
  --md-pink-500: #e91e63;
  --md-pink-600: #d81b60;
  --md-pink-700: #c2185b;
  --md-pink-800: #ad1457;
  --md-pink-900: #880e4f;
  --md-pink-A100: #ff80ab;
  --md-pink-A200: #ff4081;
  --md-pink-A400: #f50057;
  --md-pink-A700: #c51162;

  --md-purple-50: #f3e5f5;
  --md-purple-100: #e1bee7;
  --md-purple-200: #ce93d8;
  --md-purple-300: #ba68c8;
  --md-purple-400: #ab47bc;
  --md-purple-500: #9c27b0;
  --md-purple-600: #8e24aa;
  --md-purple-700: #7b1fa2;
  --md-purple-800: #6a1b9a;
  --md-purple-900: #4a148c;
  --md-purple-A100: #ea80fc;
  --md-purple-A200: #e040fb;
  --md-purple-A400: #d500f9;
  --md-purple-A700: #aa00ff;

  --md-deep-purple-50: #ede7f6;
  --md-deep-purple-100: #d1c4e9;
  --md-deep-purple-200: #b39ddb;
  --md-deep-purple-300: #9575cd;
  --md-deep-purple-400: #7e57c2;
  --md-deep-purple-500: #673ab7;
  --md-deep-purple-600: #5e35b1;
  --md-deep-purple-700: #512da8;
  --md-deep-purple-800: #4527a0;
  --md-deep-purple-900: #311b92;
  --md-deep-purple-A100: #b388ff;
  --md-deep-purple-A200: #7c4dff;
  --md-deep-purple-A400: #651fff;
  --md-deep-purple-A700: #6200ea;

  --md-indigo-50: #e8eaf6;
  --md-indigo-100: #c5cae9;
  --md-indigo-200: #9fa8da;
  --md-indigo-300: #7986cb;
  --md-indigo-400: #5c6bc0;
  --md-indigo-500: #3f51b5;
  --md-indigo-600: #3949ab;
  --md-indigo-700: #303f9f;
  --md-indigo-800: #283593;
  --md-indigo-900: #1a237e;
  --md-indigo-A100: #8c9eff;
  --md-indigo-A200: #536dfe;
  --md-indigo-A400: #3d5afe;
  --md-indigo-A700: #304ffe;

  --md-blue-50: #e3f2fd;
  --md-blue-100: #bbdefb;
  --md-blue-200: #90caf9;
  --md-blue-300: #64b5f6;
  --md-blue-400: #42a5f5;
  --md-blue-500: #2196f3;
  --md-blue-600: #1e88e5;
  --md-blue-700: #1976d2;
  --md-blue-800: #1565c0;
  --md-blue-900: #0d47a1;
  --md-blue-A100: #82b1ff;
  --md-blue-A200: #448aff;
  --md-blue-A400: #2979ff;
  --md-blue-A700: #2962ff;

  --md-light-blue-50: #e1f5fe;
  --md-light-blue-100: #b3e5fc;
  --md-light-blue-200: #81d4fa;
  --md-light-blue-300: #4fc3f7;
  --md-light-blue-400: #29b6f6;
  --md-light-blue-500: #03a9f4;
  --md-light-blue-600: #039be5;
  --md-light-blue-700: #0288d1;
  --md-light-blue-800: #0277bd;
  --md-light-blue-900: #01579b;
  --md-light-blue-A100: #80d8ff;
  --md-light-blue-A200: #40c4ff;
  --md-light-blue-A400: #00b0ff;
  --md-light-blue-A700: #0091ea;

  --md-cyan-50: #e0f7fa;
  --md-cyan-100: #b2ebf2;
  --md-cyan-200: #80deea;
  --md-cyan-300: #4dd0e1;
  --md-cyan-400: #26c6da;
  --md-cyan-500: #00bcd4;
  --md-cyan-600: #00acc1;
  --md-cyan-700: #0097a7;
  --md-cyan-800: #00838f;
  --md-cyan-900: #006064;
  --md-cyan-A100: #84ffff;
  --md-cyan-A200: #18ffff;
  --md-cyan-A400: #00e5ff;
  --md-cyan-A700: #00b8d4;

  --md-teal-50: #e0f2f1;
  --md-teal-100: #b2dfdb;
  --md-teal-200: #80cbc4;
  --md-teal-300: #4db6ac;
  --md-teal-400: #26a69a;
  --md-teal-500: #009688;
  --md-teal-600: #00897b;
  --md-teal-700: #00796b;
  --md-teal-800: #00695c;
  --md-teal-900: #004d40;
  --md-teal-A100: #a7ffeb;
  --md-teal-A200: #64ffda;
  --md-teal-A400: #1de9b6;
  --md-teal-A700: #00bfa5;

  --md-green-50: #e8f5e9;
  --md-green-100: #c8e6c9;
  --md-green-200: #a5d6a7;
  --md-green-300: #81c784;
  --md-green-400: #66bb6a;
  --md-green-500: #4caf50;
  --md-green-600: #43a047;
  --md-green-700: #388e3c;
  --md-green-800: #2e7d32;
  --md-green-900: #1b5e20;
  --md-green-A100: #b9f6ca;
  --md-green-A200: #69f0ae;
  --md-green-A400: #00e676;
  --md-green-A700: #00c853;

  --md-light-green-50: #f1f8e9;
  --md-light-green-100: #dcedc8;
  --md-light-green-200: #c5e1a5;
  --md-light-green-300: #aed581;
  --md-light-green-400: #9ccc65;
  --md-light-green-500: #8bc34a;
  --md-light-green-600: #7cb342;
  --md-light-green-700: #689f38;
  --md-light-green-800: #558b2f;
  --md-light-green-900: #33691e;
  --md-light-green-A100: #ccff90;
  --md-light-green-A200: #b2ff59;
  --md-light-green-A400: #76ff03;
  --md-light-green-A700: #64dd17;

  --md-lime-50: #f9fbe7;
  --md-lime-100: #f0f4c3;
  --md-lime-200: #e6ee9c;
  --md-lime-300: #dce775;
  --md-lime-400: #d4e157;
  --md-lime-500: #cddc39;
  --md-lime-600: #c0ca33;
  --md-lime-700: #afb42b;
  --md-lime-800: #9e9d24;
  --md-lime-900: #827717;
  --md-lime-A100: #f4ff81;
  --md-lime-A200: #eeff41;
  --md-lime-A400: #c6ff00;
  --md-lime-A700: #aeea00;

  --md-yellow-50: #fffde7;
  --md-yellow-100: #fff9c4;
  --md-yellow-200: #fff59d;
  --md-yellow-300: #fff176;
  --md-yellow-400: #ffee58;
  --md-yellow-500: #ffeb3b;
  --md-yellow-600: #fdd835;
  --md-yellow-700: #fbc02d;
  --md-yellow-800: #f9a825;
  --md-yellow-900: #f57f17;
  --md-yellow-A100: #ffff8d;
  --md-yellow-A200: #ffff00;
  --md-yellow-A400: #ffea00;
  --md-yellow-A700: #ffd600;

  --md-amber-50: #fff8e1;
  --md-amber-100: #ffecb3;
  --md-amber-200: #ffe082;
  --md-amber-300: #ffd54f;
  --md-amber-400: #ffca28;
  --md-amber-500: #ffc107;
  --md-amber-600: #ffb300;
  --md-amber-700: #ffa000;
  --md-amber-800: #ff8f00;
  --md-amber-900: #ff6f00;
  --md-amber-A100: #ffe57f;
  --md-amber-A200: #ffd740;
  --md-amber-A400: #ffc400;
  --md-amber-A700: #ffab00;

  --md-orange-50: #fff3e0;
  --md-orange-100: #ffe0b2;
  --md-orange-200: #ffcc80;
  --md-orange-300: #ffb74d;
  --md-orange-400: #ffa726;
  --md-orange-500: #ff9800;
  --md-orange-600: #fb8c00;
  --md-orange-700: #f57c00;
  --md-orange-800: #ef6c00;
  --md-orange-900: #e65100;
  --md-orange-A100: #ffd180;
  --md-orange-A200: #ffab40;
  --md-orange-A400: #ff9100;
  --md-orange-A700: #ff6d00;

  --md-deep-orange-50: #fbe9e7;
  --md-deep-orange-100: #ffccbc;
  --md-deep-orange-200: #ffab91;
  --md-deep-orange-300: #ff8a65;
  --md-deep-orange-400: #ff7043;
  --md-deep-orange-500: #ff5722;
  --md-deep-orange-600: #f4511e;
  --md-deep-orange-700: #e64a19;
  --md-deep-orange-800: #d84315;
  --md-deep-orange-900: #bf360c;
  --md-deep-orange-A100: #ff9e80;
  --md-deep-orange-A200: #ff6e40;
  --md-deep-orange-A400: #ff3d00;
  --md-deep-orange-A700: #dd2c00;

  --md-brown-50: #efebe9;
  --md-brown-100: #d7ccc8;
  --md-brown-200: #bcaaa4;
  --md-brown-300: #a1887f;
  --md-brown-400: #8d6e63;
  --md-brown-500: #795548;
  --md-brown-600: #6d4c41;
  --md-brown-700: #5d4037;
  --md-brown-800: #4e342e;
  --md-brown-900: #3e2723;

  --md-grey-50: #fafafa;
  --md-grey-100: #f5f5f5;
  --md-grey-200: #eeeeee;
  --md-grey-300: #e0e0e0;
  --md-grey-400: #bdbdbd;
  --md-grey-500: #9e9e9e;
  --md-grey-600: #757575;
  --md-grey-700: #616161;
  --md-grey-800: #424242;
  --md-grey-900: #212121;

  --md-blue-grey-50: #eceff1;
  --md-blue-grey-100: #cfd8dc;
  --md-blue-grey-200: #b0bec5;
  --md-blue-grey-300: #90a4ae;
  --md-blue-grey-400: #78909c;
  --md-blue-grey-500: #607d8b;
  --md-blue-grey-600: #546e7a;
  --md-blue-grey-700: #455a64;
  --md-blue-grey-800: #37474f;
  --md-blue-grey-900: #263238;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Spinner {
  position: absolute;
  display: flex;
  justify-content: center;
  align-items: center;
  z-index: 10;
  left: 0;
  top: 0;
  width: 100%;
  height: 100%;
  background: var(--jp-layout-color0);
  outline: none;
}

.jp-SpinnerContent {
  font-size: 10px;
  margin: 50px auto;
  text-indent: -9999em;
  width: 3em;
  height: 3em;
  border-radius: 50%;
  background: var(--jp-brand-color3);
  background: linear-gradient(
    to right,
    #f37626 10%,
    rgba(255, 255, 255, 0) 42%
  );
  position: relative;
  animation: load3 1s infinite linear, fadeIn 1s;
}

.jp-SpinnerContent:before {
  width: 50%;
  height: 50%;
  background: #f37626;
  border-radius: 100% 0 0 0;
  position: absolute;
  top: 0;
  left: 0;
  content: '';
}

.jp-SpinnerContent:after {
  background: var(--jp-layout-color0);
  width: 75%;
  height: 75%;
  border-radius: 50%;
  content: '';
  margin: auto;
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  right: 0;
}

@keyframes fadeIn {
  0% {
    opacity: 0;
  }
  100% {
    opacity: 1;
  }
}

@keyframes load3 {
  0% {
    transform: rotate(0deg);
  }
  100% {
    transform: rotate(360deg);
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

button.jp-mod-styled {
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color0);
  border: none;
  box-sizing: border-box;
  text-align: center;
  line-height: 32px;
  height: 32px;
  padding: 0px 12px;
  letter-spacing: 0.8px;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
}

input.jp-mod-styled {
  background: var(--jp-input-background);
  height: 28px;
  box-sizing: border-box;
  border: var(--jp-border-width) solid var(--jp-border-color1);
  padding-left: 7px;
  padding-right: 7px;
  font-size: var(--jp-ui-font-size2);
  color: var(--jp-ui-font-color0);
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
}

input.jp-mod-styled:focus {
  border: var(--jp-border-width) solid var(--md-blue-500);
  box-shadow: inset 0 0 4px var(--md-blue-300);
}

.jp-select-wrapper {
  display: flex;
  position: relative;
  flex-direction: column;
  padding: 1px;
  background-color: var(--jp-layout-color1);
  height: 28px;
  box-sizing: border-box;
  margin-bottom: 12px;
}

.jp-select-wrapper.jp-mod-focused select.jp-mod-styled {
  border: var(--jp-border-width) solid var(--jp-input-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
  background-color: var(--jp-input-active-background);
}

select.jp-mod-styled:hover {
  background-color: var(--jp-layout-color1);
  cursor: pointer;
  color: var(--jp-ui-font-color0);
  background-color: var(--jp-input-hover-background);
  box-shadow: inset 0 0px 1px rgba(0, 0, 0, 0.5);
}

select.jp-mod-styled {
  flex: 1 1 auto;
  height: 32px;
  width: 100%;
  font-size: var(--jp-ui-font-size2);
  background: var(--jp-input-background);
  color: var(--jp-ui-font-color0);
  padding: 0 25px 0 8px;
  border: var(--jp-border-width) solid var(--jp-input-border-color);
  border-radius: 0px;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

:root {
  --jp-private-toolbar-height: calc(
    28px + var(--jp-border-width)
  ); /* leave 28px for content */
}

.jp-Toolbar {
  color: var(--jp-ui-font-color1);
  flex: 0 0 auto;
  display: flex;
  flex-direction: row;
  border-bottom: var(--jp-border-width) solid var(--jp-toolbar-border-color);
  box-shadow: var(--jp-toolbar-box-shadow);
  background: var(--jp-toolbar-background);
  min-height: var(--jp-toolbar-micro-height);
  padding: 2px;
  z-index: 1;
  overflow-x: hidden;
}

.jp-Toolbar:hover {
  overflow-x: auto;
}

/* Toolbar items */

.jp-Toolbar > .jp-Toolbar-item.jp-Toolbar-spacer {
  flex-grow: 1;
  flex-shrink: 1;
}

.jp-Toolbar-item.jp-Toolbar-kernelStatus {
  display: inline-block;
  width: 32px;
  background-repeat: no-repeat;
  background-position: center;
  background-size: 16px;
}

.jp-Toolbar > .jp-Toolbar-item {
  flex: 0 0 auto;
  display: flex;
  padding-left: 1px;
  padding-right: 1px;
  font-size: var(--jp-ui-font-size1);
  line-height: var(--jp-private-toolbar-height);
  height: 100%;
}

/* Toolbar buttons */

/* This is the div we use to wrap the react component into a Widget */
div.jp-ToolbarButton {
  color: transparent;
  border: none;
  box-sizing: border-box;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
  padding: 0px;
  margin: 0px;
}

button.jp-ToolbarButtonComponent {
  background: var(--jp-layout-color1);
  border: none;
  box-sizing: border-box;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
  padding: 0px 6px;
  margin: 0px;
  height: 24px;
  border-radius: var(--jp-border-radius);
  display: flex;
  align-items: center;
  text-align: center;
  font-size: 14px;
  min-width: unset;
  min-height: unset;
}

button.jp-ToolbarButtonComponent:disabled {
  opacity: 0.4;
}

button.jp-ToolbarButtonComponent span {
  padding: 0px;
  flex: 0 0 auto;
}

button.jp-ToolbarButtonComponent .jp-ToolbarButtonComponent-label {
  font-size: var(--jp-ui-font-size1);
  line-height: 100%;
  padding-left: 2px;
  color: var(--jp-ui-font-color1);
}

#jp-main-dock-panel[data-mode='single-document']
  .jp-MainAreaWidget
  > .jp-Toolbar.jp-Toolbar-micro {
  padding: 0;
  min-height: 0;
}

#jp-main-dock-panel[data-mode='single-document']
  .jp-MainAreaWidget
  > .jp-Toolbar {
  border: none;
  box-shadow: none;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/


/* <DEPRECATED> */ body.p-mod-override-cursor *, /* </DEPRECATED> */
body.lm-mod-override-cursor * {
  cursor: inherit !important;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-JSONEditor {
  display: flex;
  flex-direction: column;
  width: 100%;
}

.jp-JSONEditor-host {
  flex: 1 1 auto;
  border: var(--jp-border-width) solid var(--jp-input-border-color);
  border-radius: 0px;
  background: var(--jp-layout-color0);
  min-height: 50px;
  padding: 1px;
}

.jp-JSONEditor.jp-mod-error .jp-JSONEditor-host {
  border-color: red;
  outline-color: red;
}

.jp-JSONEditor-header {
  display: flex;
  flex: 1 0 auto;
  padding: 0 0 0 12px;
}

.jp-JSONEditor-header label {
  flex: 0 0 auto;
}

.jp-JSONEditor-commitButton {
  height: 16px;
  width: 16px;
  background-size: 18px;
  background-repeat: no-repeat;
  background-position: center;
}

.jp-JSONEditor-host.jp-mod-focused {
  background-color: var(--jp-input-active-background);
  border: 1px solid var(--jp-input-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
}

.jp-Editor.jp-mod-dropTarget {
  border: var(--jp-border-width) solid var(--jp-input-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
}

/* BASICS */

.CodeMirror {
  /* Set height, width, borders, and global font properties here */
  font-family: monospace;
  height: 300px;
  color: black;
  direction: ltr;
}

/* PADDING */

.CodeMirror-lines {
  padding: 4px 0; /* Vertical padding around content */
}
.CodeMirror pre.CodeMirror-line,
.CodeMirror pre.CodeMirror-line-like {
  padding: 0 4px; /* Horizontal padding of content */
}

.CodeMirror-scrollbar-filler, .CodeMirror-gutter-filler {
  background-color: white; /* The little square between H and V scrollbars */
}

/* GUTTER */

.CodeMirror-gutters {
  border-right: 1px solid #ddd;
  background-color: #f7f7f7;
  white-space: nowrap;
}
.CodeMirror-linenumbers {}
.CodeMirror-linenumber {
  padding: 0 3px 0 5px;
  min-width: 20px;
  text-align: right;
  color: #999;
  white-space: nowrap;
}

.CodeMirror-guttermarker { color: black; }
.CodeMirror-guttermarker-subtle { color: #999; }

/* CURSOR */

.CodeMirror-cursor {
  border-left: 1px solid black;
  border-right: none;
  width: 0;
}
/* Shown when moving in bi-directional text */
.CodeMirror div.CodeMirror-secondarycursor {
  border-left: 1px solid silver;
}
.cm-fat-cursor .CodeMirror-cursor {
  width: auto;
  border: 0 !important;
  background: #7e7;
}
.cm-fat-cursor div.CodeMirror-cursors {
  z-index: 1;
}
.cm-fat-cursor-mark {
  background-color: rgba(20, 255, 20, 0.5);
  -webkit-animation: blink 1.06s steps(1) infinite;
  -moz-animation: blink 1.06s steps(1) infinite;
  animation: blink 1.06s steps(1) infinite;
}
.cm-animate-fat-cursor {
  width: auto;
  border: 0;
  -webkit-animation: blink 1.06s steps(1) infinite;
  -moz-animation: blink 1.06s steps(1) infinite;
  animation: blink 1.06s steps(1) infinite;
  background-color: #7e7;
}
@-moz-keyframes blink {
  0% {}
  50% { background-color: transparent; }
  100% {}
}
@-webkit-keyframes blink {
  0% {}
  50% { background-color: transparent; }
  100% {}
}
@keyframes blink {
  0% {}
  50% { background-color: transparent; }
  100% {}
}

/* Can style cursor different in overwrite (non-insert) mode */
.CodeMirror-overwrite .CodeMirror-cursor {}

.cm-tab { display: inline-block; text-decoration: inherit; }

.CodeMirror-rulers {
  position: absolute;
  left: 0; right: 0; top: -50px; bottom: 0;
  overflow: hidden;
}
.CodeMirror-ruler {
  border-left: 1px solid #ccc;
  top: 0; bottom: 0;
  position: absolute;
}

/* DEFAULT THEME */

.cm-s-default .cm-header {color: blue;}
.cm-s-default .cm-quote {color: #090;}
.cm-negative {color: #d44;}
.cm-positive {color: #292;}
.cm-header, .cm-strong {font-weight: bold;}
.cm-em {font-style: italic;}
.cm-link {text-decoration: underline;}
.cm-strikethrough {text-decoration: line-through;}

.cm-s-default .cm-keyword {color: #708;}
.cm-s-default .cm-atom {color: #219;}
.cm-s-default .cm-number {color: #164;}
.cm-s-default .cm-def {color: #00f;}
.cm-s-default .cm-variable,
.cm-s-default .cm-punctuation,
.cm-s-default .cm-property,
.cm-s-default .cm-operator {}
.cm-s-default .cm-variable-2 {color: #05a;}
.cm-s-default .cm-variable-3, .cm-s-default .cm-type {color: #085;}
.cm-s-default .cm-comment {color: #a50;}
.cm-s-default .cm-string {color: #a11;}
.cm-s-default .cm-string-2 {color: #f50;}
.cm-s-default .cm-meta {color: #555;}
.cm-s-default .cm-qualifier {color: #555;}
.cm-s-default .cm-builtin {color: #30a;}
.cm-s-default .cm-bracket {color: #997;}
.cm-s-default .cm-tag {color: #170;}
.cm-s-default .cm-attribute {color: #00c;}
.cm-s-default .cm-hr {color: #999;}
.cm-s-default .cm-link {color: #00c;}

.cm-s-default .cm-error {color: #f00;}
.cm-invalidchar {color: #f00;}

.CodeMirror-composing { border-bottom: 2px solid; }

/* Default styles for common addons */

div.CodeMirror span.CodeMirror-matchingbracket {color: #0b0;}
div.CodeMirror span.CodeMirror-nonmatchingbracket {color: #a22;}
.CodeMirror-matchingtag { background: rgba(255, 150, 0, .3); }
.CodeMirror-activeline-background {background: #e8f2ff;}

/* STOP */

/* The rest of this file contains styles related to the mechanics of
   the editor. You probably shouldn't touch them. */

.CodeMirror {
  position: relative;
  overflow: hidden;
  background: white;
}

.CodeMirror-scroll {
  overflow: scroll !important; /* Things will break if this is overridden */
  /* 50px is the magic margin used to hide the element's real scrollbars */
  /* See overflow: hidden in .CodeMirror */
  margin-bottom: -50px; margin-right: -50px;
  padding-bottom: 50px;
  height: 100%;
  outline: none; /* Prevent dragging from highlighting the element */
  position: relative;
}
.CodeMirror-sizer {
  position: relative;
  border-right: 50px solid transparent;
}

/* The fake, visible scrollbars. Used to force redraw during scrolling
   before actual scrolling happens, thus preventing shaking and
   flickering artifacts. */
.CodeMirror-vscrollbar, .CodeMirror-hscrollbar, .CodeMirror-scrollbar-filler, .CodeMirror-gutter-filler {
  position: absolute;
  z-index: 6;
  display: none;
}
.CodeMirror-vscrollbar {
  right: 0; top: 0;
  overflow-x: hidden;
  overflow-y: scroll;
}
.CodeMirror-hscrollbar {
  bottom: 0; left: 0;
  overflow-y: hidden;
  overflow-x: scroll;
}
.CodeMirror-scrollbar-filler {
  right: 0; bottom: 0;
}
.CodeMirror-gutter-filler {
  left: 0; bottom: 0;
}

.CodeMirror-gutters {
  position: absolute; left: 0; top: 0;
  min-height: 100%;
  z-index: 3;
}
.CodeMirror-gutter {
  white-space: normal;
  height: 100%;
  display: inline-block;
  vertical-align: top;
  margin-bottom: -50px;
}
.CodeMirror-gutter-wrapper {
  position: absolute;
  z-index: 4;
  background: none !important;
  border: none !important;
}
.CodeMirror-gutter-background {
  position: absolute;
  top: 0; bottom: 0;
  z-index: 4;
}
.CodeMirror-gutter-elt {
  position: absolute;
  cursor: default;
  z-index: 4;
}
.CodeMirror-gutter-wrapper ::selection { background-color: transparent }
.CodeMirror-gutter-wrapper ::-moz-selection { background-color: transparent }

.CodeMirror-lines {
  cursor: text;
  min-height: 1px; /* prevents collapsing before first draw */
}
.CodeMirror pre.CodeMirror-line,
.CodeMirror pre.CodeMirror-line-like {
  /* Reset some styles that the rest of the page might have set */
  -moz-border-radius: 0; -webkit-border-radius: 0; border-radius: 0;
  border-width: 0;
  background: transparent;
  font-family: inherit;
  font-size: inherit;
  margin: 0;
  white-space: pre;
  word-wrap: normal;
  line-height: inherit;
  color: inherit;
  z-index: 2;
  position: relative;
  overflow: visible;
  -webkit-tap-highlight-color: transparent;
  -webkit-font-variant-ligatures: contextual;
  font-variant-ligatures: contextual;
}
.CodeMirror-wrap pre.CodeMirror-line,
.CodeMirror-wrap pre.CodeMirror-line-like {
  word-wrap: break-word;
  white-space: pre-wrap;
  word-break: normal;
}

.CodeMirror-linebackground {
  position: absolute;
  left: 0; right: 0; top: 0; bottom: 0;
  z-index: 0;
}

.CodeMirror-linewidget {
  position: relative;
  z-index: 2;
  padding: 0.1px; /* Force widget margins to stay inside of the container */
}

.CodeMirror-widget {}

.CodeMirror-rtl pre { direction: rtl; }

.CodeMirror-code {
  outline: none;
}

/* Force content-box sizing for the elements where we expect it */
.CodeMirror-scroll,
.CodeMirror-sizer,
.CodeMirror-gutter,
.CodeMirror-gutters,
.CodeMirror-linenumber {
  -moz-box-sizing: content-box;
  box-sizing: content-box;
}

.CodeMirror-measure {
  position: absolute;
  width: 100%;
  height: 0;
  overflow: hidden;
  visibility: hidden;
}

.CodeMirror-cursor {
  position: absolute;
  pointer-events: none;
}
.CodeMirror-measure pre { position: static; }

div.CodeMirror-cursors {
  visibility: hidden;
  position: relative;
  z-index: 3;
}
div.CodeMirror-dragcursors {
  visibility: visible;
}

.CodeMirror-focused div.CodeMirror-cursors {
  visibility: visible;
}

.CodeMirror-selected { background: #d9d9d9; }
.CodeMirror-focused .CodeMirror-selected { background: #d7d4f0; }
.CodeMirror-crosshair { cursor: crosshair; }
.CodeMirror-line::selection, .CodeMirror-line > span::selection, .CodeMirror-line > span > span::selection { background: #d7d4f0; }
.CodeMirror-line::-moz-selection, .CodeMirror-line > span::-moz-selection, .CodeMirror-line > span > span::-moz-selection { background: #d7d4f0; }

.cm-searching {
  background-color: #ffa;
  background-color: rgba(255, 255, 0, .4);
}

/* Used to force a border model for a node */
.cm-force-border { padding-right: .1px; }

@media print {
  /* Hide the cursor when printing */
  .CodeMirror div.CodeMirror-cursors {
    visibility: hidden;
  }
}

/* See issue #2901 */
.cm-tab-wrap-hack:after { content: ''; }

/* Help users use markselection to safely style text background */
span.CodeMirror-selectedtext { background: none; }

.CodeMirror-dialog {
  position: absolute;
  left: 0; right: 0;
  background: inherit;
  z-index: 15;
  padding: .1em .8em;
  overflow: hidden;
  color: inherit;
}

.CodeMirror-dialog-top {
  border-bottom: 1px solid #eee;
  top: 0;
}

.CodeMirror-dialog-bottom {
  border-top: 1px solid #eee;
  bottom: 0;
}

.CodeMirror-dialog input {
  border: none;
  outline: none;
  background: transparent;
  width: 20em;
  color: inherit;
  font-family: monospace;
}

.CodeMirror-dialog button {
  font-size: 70%;
}

.CodeMirror-foldmarker {
  color: blue;
  text-shadow: #b9f 1px 1px 2px, #b9f -1px -1px 2px, #b9f 1px -1px 2px, #b9f -1px 1px 2px;
  font-family: arial;
  line-height: .3;
  cursor: pointer;
}
.CodeMirror-foldgutter {
  width: .7em;
}
.CodeMirror-foldgutter-open,
.CodeMirror-foldgutter-folded {
  cursor: pointer;
}
.CodeMirror-foldgutter-open:after {
  content: "\25BE";
}
.CodeMirror-foldgutter-folded:after {
  content: "\25B8";
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.CodeMirror {
  line-height: var(--jp-code-line-height);
  font-size: var(--jp-code-font-size);
  font-family: var(--jp-code-font-family);
  border: 0;
  border-radius: 0;
  height: auto;
  /* Changed to auto to autogrow */
}

.CodeMirror pre {
  padding: 0 var(--jp-code-padding);
}

.jp-CodeMirrorEditor[data-type='inline'] .CodeMirror-dialog {
  background-color: var(--jp-layout-color0);
  color: var(--jp-content-font-color1);
}

/* This causes https://github.com/jupyter/jupyterlab/issues/522 */
/* May not cause it not because we changed it! */
.CodeMirror-lines {
  padding: var(--jp-code-padding) 0;
}

.CodeMirror-linenumber {
  padding: 0 8px;
}

.jp-CodeMirrorEditor {
  cursor: text;
}

.jp-CodeMirrorEditor[data-type='inline'] .CodeMirror-cursor {
  border-left: var(--jp-code-cursor-width0) solid var(--jp-editor-cursor-color);
}

/* When zoomed out 67% and 33% on a screen of 1440 width x 900 height */
@media screen and (min-width: 2138px) and (max-width: 4319px) {
  .jp-CodeMirrorEditor[data-type='inline'] .CodeMirror-cursor {
    border-left: var(--jp-code-cursor-width1) solid
      var(--jp-editor-cursor-color);
  }
}

/* When zoomed out less than 33% */
@media screen and (min-width: 4320px) {
  .jp-CodeMirrorEditor[data-type='inline'] .CodeMirror-cursor {
    border-left: var(--jp-code-cursor-width2) solid
      var(--jp-editor-cursor-color);
  }
}

.CodeMirror.jp-mod-readOnly .CodeMirror-cursor {
  display: none;
}

.CodeMirror-gutters {
  border-right: 1px solid var(--jp-border-color2);
  background-color: var(--jp-layout-color0);
}

.jp-CollaboratorCursor {
  border-left: 5px solid transparent;
  border-right: 5px solid transparent;
  border-top: none;
  border-bottom: 3px solid;
  background-clip: content-box;
  margin-left: -5px;
  margin-right: -5px;
}

.CodeMirror-selectedtext.cm-searching {
  background-color: var(--jp-search-selected-match-background-color) !important;
  color: var(--jp-search-selected-match-color) !important;
}

.cm-searching {
  background-color: var(
    --jp-search-unselected-match-background-color
  ) !important;
  color: var(--jp-search-unselected-match-color) !important;
}

.CodeMirror-focused .CodeMirror-selected {
  background-color: var(--jp-editor-selected-focused-background);
}

.CodeMirror-selected {
  background-color: var(--jp-editor-selected-background);
}

.jp-CollaboratorCursor-hover {
  position: absolute;
  z-index: 1;
  transform: translateX(-50%);
  color: white;
  border-radius: 3px;
  padding-left: 4px;
  padding-right: 4px;
  padding-top: 1px;
  padding-bottom: 1px;
  text-align: center;
  font-size: var(--jp-ui-font-size1);
  white-space: nowrap;
}

.jp-CodeMirror-ruler {
  border-left: 1px dashed var(--jp-border-color2);
}

/**
 * Here is our jupyter theme for CodeMirror syntax highlighting
 * This is used in our marked.js syntax highlighting and CodeMirror itself
 * The string "jupyter" is set in ../codemirror/widget.DEFAULT_CODEMIRROR_THEME
 * This came from the classic notebook, which came form highlight.js/GitHub
 */

/**
 * CodeMirror themes are handling the background/color in this way. This works
 * fine for CodeMirror editors outside the notebook, but the notebook styles
 * these things differently.
 */
.CodeMirror.cm-s-jupyter {
  background: var(--jp-layout-color0);
  color: var(--jp-content-font-color1);
}

/* In the notebook, we want this styling to be handled by its container */
.jp-CodeConsole .CodeMirror.cm-s-jupyter,
.jp-Notebook .CodeMirror.cm-s-jupyter {
  background: transparent;
}

.cm-s-jupyter .CodeMirror-cursor {
  border-left: var(--jp-code-cursor-width0) solid var(--jp-editor-cursor-color);
}
.cm-s-jupyter span.cm-keyword {
  color: var(--jp-mirror-editor-keyword-color);
  font-weight: bold;
}
.cm-s-jupyter span.cm-atom {
  color: var(--jp-mirror-editor-atom-color);
}
.cm-s-jupyter span.cm-number {
  color: var(--jp-mirror-editor-number-color);
}
.cm-s-jupyter span.cm-def {
  color: var(--jp-mirror-editor-def-color);
}
.cm-s-jupyter span.cm-variable {
  color: var(--jp-mirror-editor-variable-color);
}
.cm-s-jupyter span.cm-variable-2 {
  color: var(--jp-mirror-editor-variable-2-color);
}
.cm-s-jupyter span.cm-variable-3 {
  color: var(--jp-mirror-editor-variable-3-color);
}
.cm-s-jupyter span.cm-punctuation {
  color: var(--jp-mirror-editor-punctuation-color);
}
.cm-s-jupyter span.cm-property {
  color: var(--jp-mirror-editor-property-color);
}
.cm-s-jupyter span.cm-operator {
  color: var(--jp-mirror-editor-operator-color);
  font-weight: bold;
}
.cm-s-jupyter span.cm-comment {
  color: var(--jp-mirror-editor-comment-color);
  font-style: italic;
}
.cm-s-jupyter span.cm-string {
  color: var(--jp-mirror-editor-string-color);
}
.cm-s-jupyter span.cm-string-2 {
  color: var(--jp-mirror-editor-string-2-color);
}
.cm-s-jupyter span.cm-meta {
  color: var(--jp-mirror-editor-meta-color);
}
.cm-s-jupyter span.cm-qualifier {
  color: var(--jp-mirror-editor-qualifier-color);
}
.cm-s-jupyter span.cm-builtin {
  color: var(--jp-mirror-editor-builtin-color);
}
.cm-s-jupyter span.cm-bracket {
  color: var(--jp-mirror-editor-bracket-color);
}
.cm-s-jupyter span.cm-tag {
  color: var(--jp-mirror-editor-tag-color);
}
.cm-s-jupyter span.cm-attribute {
  color: var(--jp-mirror-editor-attribute-color);
}
.cm-s-jupyter span.cm-header {
  color: var(--jp-mirror-editor-header-color);
}
.cm-s-jupyter span.cm-quote {
  color: var(--jp-mirror-editor-quote-color);
}
.cm-s-jupyter span.cm-link {
  color: var(--jp-mirror-editor-link-color);
}
.cm-s-jupyter span.cm-error {
  color: var(--jp-mirror-editor-error-color);
}
.cm-s-jupyter span.cm-hr {
  color: #999;
}

.cm-s-jupyter span.cm-tab {
  background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=);
  background-position: right;
  background-repeat: no-repeat;
}

.cm-s-jupyter .CodeMirror-activeline-background,
.cm-s-jupyter .CodeMirror-gutter {
  background-color: var(--jp-layout-color2);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| RenderedText
|----------------------------------------------------------------------------*/

:root {
  /* This is the padding value to fill the gaps between lines containing spans with background color. */
  --jp-private-code-span-padding: calc(
    (var(--jp-code-line-height) - 1) * var(--jp-code-font-size) / 2
  );
}

.jp-RenderedText {
  text-align: left;
  padding-left: var(--jp-code-padding);
  line-height: var(--jp-code-line-height);
  font-family: var(--jp-code-font-family);
}

.jp-RenderedText pre,
.jp-RenderedJavaScript pre,
.jp-RenderedHTMLCommon pre {
  color: var(--jp-content-font-color1);
  font-size: var(--jp-code-font-size);
  border: none;
  margin: 0px;
  padding: 0px;
}

.jp-RenderedText pre a:link {
  text-decoration: none;
  color: var(--jp-content-link-color);
}
.jp-RenderedText pre a:hover {
  text-decoration: underline;
  color: var(--jp-content-link-color);
}
.jp-RenderedText pre a:visited {
  text-decoration: none;
  color: var(--jp-content-link-color);
}

/* console foregrounds and backgrounds */
.jp-RenderedText pre .ansi-black-fg {
  color: #3e424d;
}
.jp-RenderedText pre .ansi-red-fg {
  color: #e75c58;
}
.jp-RenderedText pre .ansi-green-fg {
  color: #00a250;
}
.jp-RenderedText pre .ansi-yellow-fg {
  color: #ddb62b;
}
.jp-RenderedText pre .ansi-blue-fg {
  color: #208ffb;
}
.jp-RenderedText pre .ansi-magenta-fg {
  color: #d160c4;
}
.jp-RenderedText pre .ansi-cyan-fg {
  color: #60c6c8;
}
.jp-RenderedText pre .ansi-white-fg {
  color: #c5c1b4;
}

.jp-RenderedText pre .ansi-black-bg {
  background-color: #3e424d;
  padding: var(--jp-private-code-span-padding) 0;
}
.jp-RenderedText pre .ansi-red-bg {
  background-color: #e75c58;
  padding: var(--jp-private-code-span-padding) 0;
}
.jp-RenderedText pre .ansi-green-bg {
  background-color: #00a250;
  padding: var(--jp-private-code-span-padding) 0;
}
.jp-RenderedText pre .ansi-yellow-bg {
  background-color: #ddb62b;
  padding: var(--jp-private-code-span-padding) 0;
}
.jp-RenderedText pre .ansi-blue-bg {
  background-color: #208ffb;
  padding: var(--jp-private-code-span-padding) 0;
}
.jp-RenderedText pre .ansi-magenta-bg {
  background-color: #d160c4;
  padding: var(--jp-private-code-span-padding) 0;
}
.jp-RenderedText pre .ansi-cyan-bg {
  background-color: #60c6c8;
  padding: var(--jp-private-code-span-padding) 0;
}
.jp-RenderedText pre .ansi-white-bg {
  background-color: #c5c1b4;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-black-intense-fg {
  color: #282c36;
}
.jp-RenderedText pre .ansi-red-intense-fg {
  color: #b22b31;
}
.jp-RenderedText pre .ansi-green-intense-fg {
  color: #007427;
}
.jp-RenderedText pre .ansi-yellow-intense-fg {
  color: #b27d12;
}
.jp-RenderedText pre .ansi-blue-intense-fg {
  color: #0065ca;
}
.jp-RenderedText pre .ansi-magenta-intense-fg {
  color: #a03196;
}
.jp-RenderedText pre .ansi-cyan-intense-fg {
  color: #258f8f;
}
.jp-RenderedText pre .ansi-white-intense-fg {
  color: #a1a6b2;
}

.jp-RenderedText pre .ansi-black-intense-bg {
  background-color: #282c36;
  padding: var(--jp-private-code-span-padding) 0;
}
.jp-RenderedText pre .ansi-red-intense-bg {
  background-color: #b22b31;
  padding: var(--jp-private-code-span-padding) 0;
}
.jp-RenderedText pre .ansi-green-intense-bg {
  background-color: #007427;
  padding: var(--jp-private-code-span-padding) 0;
}
.jp-RenderedText pre .ansi-yellow-intense-bg {
  background-color: #b27d12;
  padding: var(--jp-private-code-span-padding) 0;
}
.jp-RenderedText pre .ansi-blue-intense-bg {
  background-color: #0065ca;
  padding: var(--jp-private-code-span-padding) 0;
}
.jp-RenderedText pre .ansi-magenta-intense-bg {
  background-color: #a03196;
  padding: var(--jp-private-code-span-padding) 0;
}
.jp-RenderedText pre .ansi-cyan-intense-bg {
  background-color: #258f8f;
  padding: var(--jp-private-code-span-padding) 0;
}
.jp-RenderedText pre .ansi-white-intense-bg {
  background-color: #a1a6b2;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-default-inverse-fg {
  color: var(--jp-ui-inverse-font-color0);
}
.jp-RenderedText pre .ansi-default-inverse-bg {
  background-color: var(--jp-inverse-layout-color0);
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-bold {
  font-weight: bold;
}
.jp-RenderedText pre .ansi-underline {
  text-decoration: underline;
}

.jp-RenderedText[data-mime-type='application/vnd.jupyter.stderr'] {
  background: var(--jp-rendermime-error-background);
  padding-top: var(--jp-code-padding);
}

/*-----------------------------------------------------------------------------
| RenderedLatex
|----------------------------------------------------------------------------*/

.jp-RenderedLatex {
  color: var(--jp-content-font-color1);
  font-size: var(--jp-content-font-size1);
  line-height: var(--jp-content-line-height);
}

/* Left-justify outputs.*/
.jp-OutputArea-output.jp-RenderedLatex {
  padding: var(--jp-code-padding);
  text-align: left;
}

/*-----------------------------------------------------------------------------
| RenderedHTML
|----------------------------------------------------------------------------*/

.jp-RenderedHTMLCommon {
  color: var(--jp-content-font-color1);
  font-family: var(--jp-content-font-family);
  font-size: var(--jp-content-font-size1);
  line-height: var(--jp-content-line-height);
  /* Give a bit more R padding on Markdown text to keep line lengths reasonable */
  padding-right: 20px;
}

.jp-RenderedHTMLCommon em {
  font-style: italic;
}

.jp-RenderedHTMLCommon strong {
  font-weight: bold;
}

.jp-RenderedHTMLCommon u {
  text-decoration: underline;
}

.jp-RenderedHTMLCommon a:link {
  text-decoration: none;
  color: var(--jp-content-link-color);
}

.jp-RenderedHTMLCommon a:hover {
  text-decoration: underline;
  color: var(--jp-content-link-color);
}

.jp-RenderedHTMLCommon a:visited {
  text-decoration: none;
  color: var(--jp-content-link-color);
}

/* Headings */

.jp-RenderedHTMLCommon h1,
.jp-RenderedHTMLCommon h2,
.jp-RenderedHTMLCommon h3,
.jp-RenderedHTMLCommon h4,
.jp-RenderedHTMLCommon h5,
.jp-RenderedHTMLCommon h6 {
  line-height: var(--jp-content-heading-line-height);
  font-weight: var(--jp-content-heading-font-weight);
  font-style: normal;
  margin: var(--jp-content-heading-margin-top) 0
    var(--jp-content-heading-margin-bottom) 0;
}

.jp-RenderedHTMLCommon h1:first-child,
.jp-RenderedHTMLCommon h2:first-child,
.jp-RenderedHTMLCommon h3:first-child,
.jp-RenderedHTMLCommon h4:first-child,
.jp-RenderedHTMLCommon h5:first-child,
.jp-RenderedHTMLCommon h6:first-child {
  margin-top: calc(0.5 * var(--jp-content-heading-margin-top));
}

.jp-RenderedHTMLCommon h1:last-child,
.jp-RenderedHTMLCommon h2:last-child,
.jp-RenderedHTMLCommon h3:last-child,
.jp-RenderedHTMLCommon h4:last-child,
.jp-RenderedHTMLCommon h5:last-child,
.jp-RenderedHTMLCommon h6:last-child {
  margin-bottom: calc(0.5 * var(--jp-content-heading-margin-bottom));
}

.jp-RenderedHTMLCommon h1 {
  font-size: var(--jp-content-font-size5);
}

.jp-RenderedHTMLCommon h2 {
  font-size: var(--jp-content-font-size4);
}

.jp-RenderedHTMLCommon h3 {
  font-size: var(--jp-content-font-size3);
}

.jp-RenderedHTMLCommon h4 {
  font-size: var(--jp-content-font-size2);
}

.jp-RenderedHTMLCommon h5 {
  font-size: var(--jp-content-font-size1);
}

.jp-RenderedHTMLCommon h6 {
  font-size: var(--jp-content-font-size0);
}

/* Lists */

.jp-RenderedHTMLCommon ul:not(.list-inline),
.jp-RenderedHTMLCommon ol:not(.list-inline) {
  padding-left: 2em;
}

.jp-RenderedHTMLCommon ul {
  list-style: disc;
}

.jp-RenderedHTMLCommon ul ul {
  list-style: square;
}

.jp-RenderedHTMLCommon ul ul ul {
  list-style: circle;
}

.jp-RenderedHTMLCommon ol {
  list-style: decimal;
}

.jp-RenderedHTMLCommon ol ol {
  list-style: upper-alpha;
}

.jp-RenderedHTMLCommon ol ol ol {
  list-style: lower-alpha;
}

.jp-RenderedHTMLCommon ol ol ol ol {
  list-style: lower-roman;
}

.jp-RenderedHTMLCommon ol ol ol ol ol {
  list-style: decimal;
}

.jp-RenderedHTMLCommon ol,
.jp-RenderedHTMLCommon ul {
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon ul ul,
.jp-RenderedHTMLCommon ul ol,
.jp-RenderedHTMLCommon ol ul,
.jp-RenderedHTMLCommon ol ol {
  margin-bottom: 0em;
}

.jp-RenderedHTMLCommon hr {
  color: var(--jp-border-color2);
  background-color: var(--jp-border-color1);
  margin-top: 1em;
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon > pre {
  margin: 1.5em 2em;
}

.jp-RenderedHTMLCommon pre,
.jp-RenderedHTMLCommon code {
  border: 0;
  background-color: var(--jp-layout-color0);
  color: var(--jp-content-font-color1);
  font-family: var(--jp-code-font-family);
  font-size: inherit;
  line-height: var(--jp-code-line-height);
  padding: 0;
  white-space: pre-wrap;
}

.jp-RenderedHTMLCommon :not(pre) > code {
  background-color: var(--jp-layout-color2);
  padding: 1px 5px;
}

/* Tables */

.jp-RenderedHTMLCommon table {
  border-collapse: collapse;
  border-spacing: 0;
  border: none;
  color: var(--jp-ui-font-color1);
  font-size: 12px;
  table-layout: fixed;
  margin-left: auto;
  margin-right: auto;
}

.jp-RenderedHTMLCommon thead {
  border-bottom: var(--jp-border-width) solid var(--jp-border-color1);
  vertical-align: bottom;
}

.jp-RenderedHTMLCommon td,
.jp-RenderedHTMLCommon th,
.jp-RenderedHTMLCommon tr {
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}

.jp-RenderedMarkdown.jp-RenderedHTMLCommon td,
.jp-RenderedMarkdown.jp-RenderedHTMLCommon th {
  max-width: none;
}

:not(.jp-RenderedMarkdown).jp-RenderedHTMLCommon td,
:not(.jp-RenderedMarkdown).jp-RenderedHTMLCommon th,
:not(.jp-RenderedMarkdown).jp-RenderedHTMLCommon tr {
  text-align: right;
}

.jp-RenderedHTMLCommon th {
  font-weight: bold;
}

.jp-RenderedHTMLCommon tbody tr:nth-child(odd) {
  background: var(--jp-layout-color0);
}

.jp-RenderedHTMLCommon tbody tr:nth-child(even) {
  background: var(--jp-rendermime-table-row-background);
}

.jp-RenderedHTMLCommon tbody tr:hover {
  background: var(--jp-rendermime-table-row-hover-background);
}

.jp-RenderedHTMLCommon table {
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon p {
  text-align: left;
  margin: 0px;
}

.jp-RenderedHTMLCommon p {
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon img {
  -moz-force-broken-image-icon: 1;
}

/* Restrict to direct children as other images could be nested in other content. */
.jp-RenderedHTMLCommon > img {
  display: block;
  margin-left: 0;
  margin-right: 0;
  margin-bottom: 1em;
}

/* Change color behind transparent images if they need it... */
[data-jp-theme-light='false'] .jp-RenderedImage img.jp-needs-light-background {
  background-color: var(--jp-inverse-layout-color1);
}
[data-jp-theme-light='true'] .jp-RenderedImage img.jp-needs-dark-background {
  background-color: var(--jp-inverse-layout-color1);
}
/* ...or leave it untouched if they don't */
[data-jp-theme-light='false'] .jp-RenderedImage img.jp-needs-dark-background {
}
[data-jp-theme-light='true'] .jp-RenderedImage img.jp-needs-light-background {
}

.jp-RenderedHTMLCommon img,
.jp-RenderedImage img,
.jp-RenderedHTMLCommon svg,
.jp-RenderedSVG svg {
  max-width: 100%;
  height: auto;
}

.jp-RenderedHTMLCommon img.jp-mod-unconfined,
.jp-RenderedImage img.jp-mod-unconfined,
.jp-RenderedHTMLCommon svg.jp-mod-unconfined,
.jp-RenderedSVG svg.jp-mod-unconfined {
  max-width: none;
}

.jp-RenderedHTMLCommon .alert {
  padding: var(--jp-notebook-padding);
  border: var(--jp-border-width) solid transparent;
  border-radius: var(--jp-border-radius);
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon .alert-info {
  color: var(--jp-info-color0);
  background-color: var(--jp-info-color3);
  border-color: var(--jp-info-color2);
}
.jp-RenderedHTMLCommon .alert-info hr {
  border-color: var(--jp-info-color3);
}
.jp-RenderedHTMLCommon .alert-info > p:last-child,
.jp-RenderedHTMLCommon .alert-info > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon .alert-warning {
  color: var(--jp-warn-color0);
  background-color: var(--jp-warn-color3);
  border-color: var(--jp-warn-color2);
}
.jp-RenderedHTMLCommon .alert-warning hr {
  border-color: var(--jp-warn-color3);
}
.jp-RenderedHTMLCommon .alert-warning > p:last-child,
.jp-RenderedHTMLCommon .alert-warning > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon .alert-success {
  color: var(--jp-success-color0);
  background-color: var(--jp-success-color3);
  border-color: var(--jp-success-color2);
}
.jp-RenderedHTMLCommon .alert-success hr {
  border-color: var(--jp-success-color3);
}
.jp-RenderedHTMLCommon .alert-success > p:last-child,
.jp-RenderedHTMLCommon .alert-success > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon .alert-danger {
  color: var(--jp-error-color0);
  background-color: var(--jp-error-color3);
  border-color: var(--jp-error-color2);
}
.jp-RenderedHTMLCommon .alert-danger hr {
  border-color: var(--jp-error-color3);
}
.jp-RenderedHTMLCommon .alert-danger > p:last-child,
.jp-RenderedHTMLCommon .alert-danger > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon blockquote {
  margin: 1em 2em;
  padding: 0 1em;
  border-left: 5px solid var(--jp-border-color2);
}

a.jp-InternalAnchorLink {
  visibility: hidden;
  margin-left: 8px;
  color: var(--md-blue-800);
}

h1:hover .jp-InternalAnchorLink,
h2:hover .jp-InternalAnchorLink,
h3:hover .jp-InternalAnchorLink,
h4:hover .jp-InternalAnchorLink,
h5:hover .jp-InternalAnchorLink,
h6:hover .jp-InternalAnchorLink {
  visibility: visible;
}

.jp-RenderedHTMLCommon kbd {
  background-color: var(--jp-rendermime-table-row-background);
  border: 1px solid var(--jp-border-color0);
  border-bottom-color: var(--jp-border-color2);
  border-radius: 3px;
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.25);
  display: inline-block;
  font-size: 0.8em;
  line-height: 1em;
  padding: 0.2em 0.5em;
}

/* Most direct children of .jp-RenderedHTMLCommon have a margin-bottom of 1.0.
 * At the bottom of cells this is a bit too much as there is also spacing
 * between cells. Going all the way to 0 gets too tight between markdown and
 * code cells.
 */
.jp-RenderedHTMLCommon > *:last-child {
  margin-bottom: 0.5em;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-MimeDocument {
  outline: none;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Variables
|----------------------------------------------------------------------------*/

:root {
  --jp-private-filebrowser-button-height: 28px;
  --jp-private-filebrowser-button-width: 48px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-FileBrowser {
  display: flex;
  flex-direction: column;
  color: var(--jp-ui-font-color1);
  background: var(--jp-layout-color1);
  /* This is needed so that all font sizing of children done in ems is
   * relative to this base size */
  font-size: var(--jp-ui-font-size1);
}

.jp-FileBrowser-toolbar.jp-Toolbar {
  border-bottom: none;
  height: auto;
  margin: var(--jp-toolbar-header-margin);
  box-shadow: none;
}

.jp-BreadCrumbs {
  flex: 0 0 auto;
  margin: 8px 12px 8px 12px;
}

.jp-BreadCrumbs-item {
  margin: 0px 2px;
  padding: 0px 2px;
  border-radius: var(--jp-border-radius);
  cursor: pointer;
}

.jp-BreadCrumbs-item:hover {
  background-color: var(--jp-layout-color2);
}

.jp-BreadCrumbs-item:first-child {
  margin-left: 0px;
}

.jp-BreadCrumbs-item.jp-mod-dropTarget {
  background-color: var(--jp-brand-color2);
  opacity: 0.7;
}

/*-----------------------------------------------------------------------------
| Buttons
|----------------------------------------------------------------------------*/

.jp-FileBrowser-toolbar.jp-Toolbar {
  padding: 0px;
  margin: 8px 12px 0px 12px;
}

.jp-FileBrowser-toolbar.jp-Toolbar {
  justify-content: flex-start;
}

.jp-FileBrowser-toolbar.jp-Toolbar .jp-Toolbar-item {
  flex: 0 0 auto;
  padding-left: 0px;
  padding-right: 2px;
}

.jp-FileBrowser-toolbar.jp-Toolbar .jp-ToolbarButtonComponent {
  width: 40px;
}

.jp-FileBrowser-toolbar.jp-Toolbar
  .jp-Toolbar-item:first-child
  .jp-ToolbarButtonComponent {
  width: 72px;
  background: var(--jp-brand-color1);
}

.jp-FileBrowser-toolbar.jp-Toolbar
  .jp-Toolbar-item:first-child
  .jp-ToolbarButtonComponent
  .jp-icon3 {
  fill: white;
}

/*-----------------------------------------------------------------------------
| Other styles
|----------------------------------------------------------------------------*/

.jp-FileDialog.jp-mod-conflict input {
  color: red;
}

.jp-FileDialog .jp-new-name-title {
  margin-top: 12px;
}

.jp-LastModified-hidden {
  display: none;
}

.jp-FileBrowser-filterBox {
  padding: 0px;
  flex: 0 0 auto;
  margin: 8px 12px 0px 12px;
}

/*-----------------------------------------------------------------------------
| DirListing
|----------------------------------------------------------------------------*/

.jp-DirListing {
  flex: 1 1 auto;
  display: flex;
  flex-direction: column;
  outline: 0;
}

.jp-DirListing-header {
  flex: 0 0 auto;
  display: flex;
  flex-direction: row;
  overflow: hidden;
  border-top: var(--jp-border-width) solid var(--jp-border-color2);
  border-bottom: var(--jp-border-width) solid var(--jp-border-color1);
  box-shadow: var(--jp-toolbar-box-shadow);
  z-index: 2;
}

.jp-DirListing-headerItem {
  padding: 4px 12px 2px 12px;
  font-weight: 500;
}

.jp-DirListing-headerItem:hover {
  background: var(--jp-layout-color2);
}

.jp-DirListing-headerItem.jp-id-name {
  flex: 1 0 84px;
}

.jp-DirListing-headerItem.jp-id-modified {
  flex: 0 0 112px;
  border-left: var(--jp-border-width) solid var(--jp-border-color2);
  text-align: right;
}

.jp-id-narrow {
  display: none;
  flex: 0 0 5px;
  padding: 4px 4px;
  border-left: var(--jp-border-width) solid var(--jp-border-color2);
  text-align: right;
  color: var(--jp-border-color2);
}

.jp-DirListing-narrow .jp-id-narrow {
  display: block;
}

.jp-DirListing-narrow .jp-id-modified,
.jp-DirListing-narrow .jp-DirListing-itemModified {
  display: none;
}

.jp-DirListing-headerItem.jp-mod-selected {
  font-weight: 600;
}

/* increase specificity to override bundled default */
.jp-DirListing-content {
  flex: 1 1 auto;
  margin: 0;
  padding: 0;
  list-style-type: none;
  overflow: auto;
  background-color: var(--jp-layout-color1);
}

.jp-DirListing-content mark {
  color: var(--jp-ui-font-color0);
  background-color: transparent;
  font-weight: bold;
}

/* Style the directory listing content when a user drops a file to upload */
.jp-DirListing.jp-mod-native-drop .jp-DirListing-content {
  outline: 5px dashed rgba(128, 128, 128, 0.5);
  outline-offset: -10px;
  cursor: copy;
}

.jp-DirListing-item {
  display: flex;
  flex-direction: row;
  padding: 4px 12px;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.jp-DirListing-item[data-is-dot] {
  opacity: 75%;
}

.jp-DirListing-item.jp-mod-selected {
  color: white;
  background: var(--jp-brand-color1);
}

.jp-DirListing-item.jp-mod-dropTarget {
  background: var(--jp-brand-color3);
}

.jp-DirListing-item:hover:not(.jp-mod-selected) {
  background: var(--jp-layout-color2);
}

.jp-DirListing-itemIcon {
  flex: 0 0 20px;
  margin-right: 4px;
}

.jp-DirListing-itemText {
  flex: 1 0 64px;
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;
  user-select: none;
}

.jp-DirListing-itemModified {
  flex: 0 0 125px;
  text-align: right;
}

.jp-DirListing-editor {
  flex: 1 0 64px;
  outline: none;
  border: none;
}

.jp-DirListing-item.jp-mod-running .jp-DirListing-itemIcon:before {
  color: limegreen;
  content: '\25CF';
  font-size: 8px;
  position: absolute;
  left: -8px;
}

.jp-DirListing-item.lm-mod-drag-image,
.jp-DirListing-item.jp-mod-selected.lm-mod-drag-image {
  font-size: var(--jp-ui-font-size1);
  padding-left: 4px;
  margin-left: 4px;
  width: 160px;
  background-color: var(--jp-ui-inverse-font-color2);
  box-shadow: var(--jp-elevation-z2);
  border-radius: 0px;
  color: var(--jp-ui-font-color1);
  transform: translateX(-40%) translateY(-58%);
}

.jp-DirListing-deadSpace {
  flex: 1 1 auto;
  margin: 0;
  padding: 0;
  list-style-type: none;
  overflow: auto;
  background-color: var(--jp-layout-color1);
}

.jp-Document {
  min-width: 120px;
  min-height: 120px;
  outline: none;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Private CSS variables
|----------------------------------------------------------------------------*/

:root {
}

/*-----------------------------------------------------------------------------
| Main OutputArea
| OutputArea has a list of Outputs
|----------------------------------------------------------------------------*/

.jp-OutputArea {
  overflow-y: auto;
}

.jp-OutputArea-child {
  display: flex;
  flex-direction: row;
}

.jp-OutputPrompt {
  flex: 0 0 var(--jp-cell-prompt-width);
  color: var(--jp-cell-outprompt-font-color);
  font-family: var(--jp-cell-prompt-font-family);
  padding: var(--jp-code-padding);
  letter-spacing: var(--jp-cell-prompt-letter-spacing);
  line-height: var(--jp-code-line-height);
  font-size: var(--jp-code-font-size);
  border: var(--jp-border-width) solid transparent;
  opacity: var(--jp-cell-prompt-opacity);
  /* Right align prompt text, don't wrap to handle large prompt numbers */
  text-align: right;
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;
  /* Disable text selection */
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.jp-OutputArea-output {
  height: auto;
  overflow: auto;
  user-select: text;
  -moz-user-select: text;
  -webkit-user-select: text;
  -ms-user-select: text;
}

.jp-OutputArea-child .jp-OutputArea-output {
  flex-grow: 1;
  flex-shrink: 1;
}

/**
 * Isolated output.
 */
.jp-OutputArea-output.jp-mod-isolated {
  width: 100%;
  display: block;
}

/*
When drag events occur, `p-mod-override-cursor` is added to the body.
Because iframes steal all cursor events, the following two rules are necessary
to suppress pointer events while resize drags are occurring. There may be a
better solution to this problem.
*/
body.lm-mod-override-cursor .jp-OutputArea-output.jp-mod-isolated {
  position: relative;
}

body.lm-mod-override-cursor .jp-OutputArea-output.jp-mod-isolated:before {
  content: '';
  position: absolute;
  top: 0;
  left: 0;
  right: 0;
  bottom: 0;
  background: transparent;
}

/* pre */

.jp-OutputArea-output pre {
  border: none;
  margin: 0px;
  padding: 0px;
  overflow-x: auto;
  overflow-y: auto;
  word-break: break-all;
  word-wrap: break-word;
  white-space: pre-wrap;
}

/* tables */

.jp-OutputArea-output.jp-RenderedHTMLCommon table {
  margin-left: 0;
  margin-right: 0;
}

/* description lists */

.jp-OutputArea-output dl,
.jp-OutputArea-output dt,
.jp-OutputArea-output dd {
  display: block;
}

.jp-OutputArea-output dl {
  width: 100%;
  overflow: hidden;
  padding: 0;
  margin: 0;
}

.jp-OutputArea-output dt {
  font-weight: bold;
  float: left;
  width: 20%;
  padding: 0;
  margin: 0;
}

.jp-OutputArea-output dd {
  float: left;
  width: 80%;
  padding: 0;
  margin: 0;
}

/* Hide the gutter in case of
 *  - nested output areas (e.g. in the case of output widgets)
 *  - mirrored output areas
 */
.jp-OutputArea .jp-OutputArea .jp-OutputArea-prompt {
  display: none;
}

/*-----------------------------------------------------------------------------
| executeResult is added to any Output-result for the display of the object
| returned by a cell
|----------------------------------------------------------------------------*/

.jp-OutputArea-output.jp-OutputArea-executeResult {
  margin-left: 0px;
  flex: 1 1 auto;
}

/* Text output with the Out[] prompt needs a top padding to match the
 * alignment of the Out[] prompt itself.
 */
.jp-OutputArea-executeResult .jp-RenderedText.jp-OutputArea-output {
  padding-top: var(--jp-code-padding);
  border-top: var(--jp-border-width) solid transparent;
}

/*-----------------------------------------------------------------------------
| The Stdin output
|----------------------------------------------------------------------------*/

.jp-OutputArea-stdin {
  line-height: var(--jp-code-line-height);
  padding-top: var(--jp-code-padding);
  display: flex;
}

.jp-Stdin-prompt {
  color: var(--jp-content-font-color0);
  padding-right: var(--jp-code-padding);
  vertical-align: baseline;
  flex: 0 0 auto;
}

.jp-Stdin-input {
  font-family: var(--jp-code-font-family);
  font-size: inherit;
  color: inherit;
  background-color: inherit;
  width: 42%;
  min-width: 200px;
  /* make sure input baseline aligns with prompt */
  vertical-align: baseline;
  /* padding + margin = 0.5em between prompt and cursor */
  padding: 0em 0.25em;
  margin: 0em 0.25em;
  flex: 0 0 70%;
}

.jp-Stdin-input:focus {
  box-shadow: none;
}

/*-----------------------------------------------------------------------------
| Output Area View
|----------------------------------------------------------------------------*/

.jp-LinkedOutputView .jp-OutputArea {
  height: 100%;
  display: block;
}

.jp-LinkedOutputView .jp-OutputArea-output:only-child {
  height: 100%;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Collapser {
  flex: 0 0 var(--jp-cell-collapser-width);
  padding: 0px;
  margin: 0px;
  border: none;
  outline: none;
  background: transparent;
  border-radius: var(--jp-border-radius);
  opacity: 1;
}

.jp-Collapser-child {
  display: block;
  width: 100%;
  box-sizing: border-box;
  /* height: 100% doesn't work because the height of its parent is computed from content */
  position: absolute;
  top: 0px;
  bottom: 0px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Header/Footer
|----------------------------------------------------------------------------*/

/* Hidden by zero height by default */
.jp-CellHeader,
.jp-CellFooter {
  height: 0px;
  width: 100%;
  padding: 0px;
  margin: 0px;
  border: none;
  outline: none;
  background: transparent;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Input
|----------------------------------------------------------------------------*/

/* All input areas */
.jp-InputArea {
  display: flex;
  flex-direction: row;
  overflow: hidden;
}

.jp-InputArea-editor {
  flex: 1 1 auto;
  overflow: hidden;
}

.jp-InputArea-editor {
  /* This is the non-active, default styling */
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  border-radius: 0px;
  background: var(--jp-cell-editor-background);
}

.jp-InputPrompt {
  flex: 0 0 var(--jp-cell-prompt-width);
  color: var(--jp-cell-inprompt-font-color);
  font-family: var(--jp-cell-prompt-font-family);
  padding: var(--jp-code-padding);
  letter-spacing: var(--jp-cell-prompt-letter-spacing);
  opacity: var(--jp-cell-prompt-opacity);
  line-height: var(--jp-code-line-height);
  font-size: var(--jp-code-font-size);
  border: var(--jp-border-width) solid transparent;
  opacity: var(--jp-cell-prompt-opacity);
  /* Right align prompt text, don't wrap to handle large prompt numbers */
  text-align: right;
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;
  /* Disable text selection */
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Placeholder
|----------------------------------------------------------------------------*/

.jp-Placeholder {
  display: flex;
  flex-direction: row;
  flex: 1 1 auto;
}

.jp-Placeholder-prompt {
  box-sizing: border-box;
}

.jp-Placeholder-content {
  flex: 1 1 auto;
  border: none;
  background: transparent;
  height: 20px;
  box-sizing: border-box;
}

.jp-Placeholder-content .jp-MoreHorizIcon {
  width: 32px;
  height: 16px;
  border: 1px solid transparent;
  border-radius: var(--jp-border-radius);
}

.jp-Placeholder-content .jp-MoreHorizIcon:hover {
  border: 1px solid var(--jp-border-color1);
  box-shadow: 0px 0px 2px 0px rgba(0, 0, 0, 0.25);
  background-color: var(--jp-layout-color0);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Private CSS variables
|----------------------------------------------------------------------------*/

:root {
  --jp-private-cell-scrolling-output-offset: 5px;
}

/*-----------------------------------------------------------------------------
| Cell
|----------------------------------------------------------------------------*/

.jp-Cell {
  padding: var(--jp-cell-padding);
  margin: 0px;
  border: none;
  outline: none;
  background: transparent;
}

/*-----------------------------------------------------------------------------
| Common input/output
|----------------------------------------------------------------------------*/

.jp-Cell-inputWrapper,
.jp-Cell-outputWrapper {
  display: flex;
  flex-direction: row;
  padding: 0px;
  margin: 0px;
  /* Added to reveal the box-shadow on the input and output collapsers. */
  overflow: visible;
}

/* Only input/output areas inside cells */
.jp-Cell-inputArea,
.jp-Cell-outputArea {
  flex: 1 1 auto;
}

/*-----------------------------------------------------------------------------
| Collapser
|----------------------------------------------------------------------------*/

/* Make the output collapser disappear when there is not output, but do so
 * in a manner that leaves it in the layout and preserves its width.
 */
.jp-Cell.jp-mod-noOutputs .jp-Cell-outputCollapser {
  border: none !important;
  background: transparent !important;
}

.jp-Cell:not(.jp-mod-noOutputs) .jp-Cell-outputCollapser {
  min-height: var(--jp-cell-collapser-min-height);
}

/*-----------------------------------------------------------------------------
| Output
|----------------------------------------------------------------------------*/

/* Put a space between input and output when there IS output */
.jp-Cell:not(.jp-mod-noOutputs) .jp-Cell-outputWrapper {
  margin-top: 5px;
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-Cell-outputArea {
  overflow-y: auto;
  max-height: 200px;
  box-shadow: inset 0 0 6px 2px rgba(0, 0, 0, 0.3);
  margin-left: var(--jp-private-cell-scrolling-output-offset);
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-OutputArea-prompt {
  flex: 0 0
    calc(
      var(--jp-cell-prompt-width) -
        var(--jp-private-cell-scrolling-output-offset)
    );
}

/*-----------------------------------------------------------------------------
| CodeCell
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| MarkdownCell
|----------------------------------------------------------------------------*/

.jp-MarkdownOutput {
  flex: 1 1 auto;
  margin-top: 0;
  margin-bottom: 0;
  padding-left: var(--jp-code-padding);
}

.jp-MarkdownOutput.jp-RenderedHTMLCommon {
  overflow: auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Variables
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------

/*-----------------------------------------------------------------------------
| Styles
|----------------------------------------------------------------------------*/

.jp-NotebookPanel-toolbar {
  padding: 2px;
}

.jp-Toolbar-item.jp-Notebook-toolbarCellType .jp-select-wrapper.jp-mod-focused {
  border: none;
  box-shadow: none;
}

.jp-Notebook-toolbarCellTypeDropdown select {
  height: 24px;
  font-size: var(--jp-ui-font-size1);
  line-height: 14px;
  border-radius: 0;
  display: block;
}

.jp-Notebook-toolbarCellTypeDropdown span {
  top: 5px !important;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Private CSS variables
|----------------------------------------------------------------------------*/

:root {
  --jp-private-notebook-dragImage-width: 304px;
  --jp-private-notebook-dragImage-height: 36px;
  --jp-private-notebook-selected-color: var(--md-blue-400);
  --jp-private-notebook-active-color: var(--md-green-400);
}

/*-----------------------------------------------------------------------------
| Imports
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Notebook
|----------------------------------------------------------------------------*/

.jp-NotebookPanel {
  display: block;
  height: 100%;
}

.jp-NotebookPanel.jp-Document {
  min-width: 240px;
  min-height: 120px;
}

.jp-Notebook {
  padding: var(--jp-notebook-padding);
  outline: none;
  overflow: auto;
  background: var(--jp-layout-color0);
}

.jp-Notebook.jp-mod-scrollPastEnd::after {
  display: block;
  content: '';
  min-height: var(--jp-notebook-scroll-padding);
}

.jp-Notebook .jp-Cell {
  overflow: visible;
}

.jp-Notebook .jp-Cell .jp-InputPrompt {
  cursor: move;
}

/*-----------------------------------------------------------------------------
| Notebook state related styling
|
| The notebook and cells each have states, here are the possibilities:
|
| - Notebook
|   - Command
|   - Edit
| - Cell
|   - None
|   - Active (only one can be active)
|   - Selected (the cells actions are applied to)
|   - Multiselected (when multiple selected, the cursor)
|   - No outputs
|----------------------------------------------------------------------------*/

/* Command or edit modes */

.jp-Notebook .jp-Cell:not(.jp-mod-active) .jp-InputPrompt {
  opacity: var(--jp-cell-prompt-not-active-opacity);
  color: var(--jp-cell-prompt-not-active-font-color);
}

.jp-Notebook .jp-Cell:not(.jp-mod-active) .jp-OutputPrompt {
  opacity: var(--jp-cell-prompt-not-active-opacity);
  color: var(--jp-cell-prompt-not-active-font-color);
}

/* cell is active */
.jp-Notebook .jp-Cell.jp-mod-active .jp-Collapser {
  background: var(--jp-brand-color1);
}

/* collapser is hovered */
.jp-Notebook .jp-Cell .jp-Collapser:hover {
  box-shadow: var(--jp-elevation-z2);
  background: var(--jp-brand-color1);
  opacity: var(--jp-cell-collapser-not-active-hover-opacity);
}

/* cell is active and collapser is hovered */
.jp-Notebook .jp-Cell.jp-mod-active .jp-Collapser:hover {
  background: var(--jp-brand-color0);
  opacity: 1;
}

/* Command mode */

.jp-Notebook.jp-mod-commandMode .jp-Cell.jp-mod-selected {
  background: var(--jp-notebook-multiselected-color);
}

.jp-Notebook.jp-mod-commandMode
  .jp-Cell.jp-mod-active.jp-mod-selected:not(.jp-mod-multiSelected) {
  background: transparent;
}

/* Edit mode */

.jp-Notebook.jp-mod-editMode .jp-Cell.jp-mod-active .jp-InputArea-editor {
  border: var(--jp-border-width) solid var(--jp-cell-editor-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
  background-color: var(--jp-cell-editor-active-background);
}

/*-----------------------------------------------------------------------------
| Notebook drag and drop
|----------------------------------------------------------------------------*/

.jp-Notebook-cell.jp-mod-dropSource {
  opacity: 0.5;
}

.jp-Notebook-cell.jp-mod-dropTarget,
.jp-Notebook.jp-mod-commandMode
  .jp-Notebook-cell.jp-mod-active.jp-mod-selected.jp-mod-dropTarget {
  border-top-color: var(--jp-private-notebook-selected-color);
  border-top-style: solid;
  border-top-width: 2px;
}

.jp-dragImage {
  display: flex;
  flex-direction: row;
  width: var(--jp-private-notebook-dragImage-width);
  height: var(--jp-private-notebook-dragImage-height);
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  background: var(--jp-cell-editor-background);
  overflow: visible;
}

.jp-dragImage-singlePrompt {
  box-shadow: 2px 2px 4px 0px rgba(0, 0, 0, 0.12);
}

.jp-dragImage .jp-dragImage-content {
  flex: 1 1 auto;
  z-index: 2;
  font-size: var(--jp-code-font-size);
  font-family: var(--jp-code-font-family);
  line-height: var(--jp-code-line-height);
  padding: var(--jp-code-padding);
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  background: var(--jp-cell-editor-background-color);
  color: var(--jp-content-font-color3);
  text-align: left;
  margin: 4px 4px 4px 0px;
}

.jp-dragImage .jp-dragImage-prompt {
  flex: 0 0 auto;
  min-width: 36px;
  color: var(--jp-cell-inprompt-font-color);
  padding: var(--jp-code-padding);
  padding-left: 12px;
  font-family: var(--jp-cell-prompt-font-family);
  letter-spacing: var(--jp-cell-prompt-letter-spacing);
  line-height: 1.9;
  font-size: var(--jp-code-font-size);
  border: var(--jp-border-width) solid transparent;
}

.jp-dragImage-multipleBack {
  z-index: -1;
  position: absolute;
  height: 32px;
  width: 300px;
  top: 8px;
  left: 8px;
  background: var(--jp-layout-color2);
  border: var(--jp-border-width) solid var(--jp-input-border-color);
  box-shadow: 2px 2px 4px 0px rgba(0, 0, 0, 0.12);
}

/*-----------------------------------------------------------------------------
| Cell toolbar
|----------------------------------------------------------------------------*/

.jp-NotebookTools {
  display: block;
  min-width: var(--jp-sidebar-min-width);
  color: var(--jp-ui-font-color1);
  background: var(--jp-layout-color1);
  /* This is needed so that all font sizing of children done in ems is
    * relative to this base size */
  font-size: var(--jp-ui-font-size1);
  overflow: auto;
}

.jp-NotebookTools-tool {
  padding: 0px 12px 0 12px;
}

.jp-ActiveCellTool {
  padding: 12px;
  background-color: var(--jp-layout-color1);
  border-top: none !important;
}

.jp-ActiveCellTool .jp-InputArea-prompt {
  flex: 0 0 auto;
  padding-left: 0px;
}

.jp-ActiveCellTool .jp-InputArea-editor {
  flex: 1 1 auto;
  background: var(--jp-cell-editor-background);
  border-color: var(--jp-cell-editor-border-color);
}

.jp-ActiveCellTool .jp-InputArea-editor .CodeMirror {
  background: transparent;
}

.jp-MetadataEditorTool {
  flex-direction: column;
  padding: 12px 0px 12px 0px;
}

.jp-RankedPanel > :not(:first-child) {
  margin-top: 12px;
}

.jp-KeySelector select.jp-mod-styled {
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color0);
  border: var(--jp-border-width) solid var(--jp-border-color1);
}

.jp-KeySelector label,
.jp-MetadataEditorTool label {
  line-height: 1.4;
}

.jp-NotebookTools .jp-select-wrapper {
  margin-top: 4px;
  margin-bottom: 0px;
}

.jp-NotebookTools .jp-Collapse {
  margin-top: 16px;
}

/*-----------------------------------------------------------------------------
| Presentation Mode (.jp-mod-presentationMode)
|----------------------------------------------------------------------------*/

.jp-mod-presentationMode .jp-Notebook {
  --jp-content-font-size1: var(--jp-content-presentation-font-size1);
  --jp-code-font-size: var(--jp-code-presentation-font-size);
}

.jp-mod-presentationMode .jp-Notebook .jp-Cell .jp-InputPrompt,
.jp-mod-presentationMode .jp-Notebook .jp-Cell .jp-OutputPrompt {
  flex: 0 0 110px;
}

</style>

    <style type="text/css">
/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*
The following CSS variables define the main, public API for styling JupyterLab.
These variables should be used by all plugins wherever possible. In other
words, plugins should not define custom colors, sizes, etc unless absolutely
necessary. This enables users to change the visual theme of JupyterLab
by changing these variables.

Many variables appear in an ordered sequence (0,1,2,3). These sequences
are designed to work well together, so for example, `--jp-border-color1` should
be used with `--jp-layout-color1`. The numbers have the following meanings:

* 0: super-primary, reserved for special emphasis
* 1: primary, most important under normal situations
* 2: secondary, next most important under normal situations
* 3: tertiary, next most important under normal situations

Throughout JupyterLab, we are mostly following principles from Google's
Material Design when selecting colors. We are not, however, following
all of MD as it is not optimized for dense, information rich UIs.
*/

:root {
  /* Elevation
   *
   * We style box-shadows using Material Design's idea of elevation. These particular numbers are taken from here:
   *
   * https://github.com/material-components/material-components-web
   * https://material-components-web.appspot.com/elevation.html
   */

  --jp-shadow-base-lightness: 0;
  --jp-shadow-umbra-color: rgba(
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    0.2
  );
  --jp-shadow-penumbra-color: rgba(
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    0.14
  );
  --jp-shadow-ambient-color: rgba(
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    0.12
  );
  --jp-elevation-z0: none;
  --jp-elevation-z1: 0px 2px 1px -1px var(--jp-shadow-umbra-color),
    0px 1px 1px 0px var(--jp-shadow-penumbra-color),
    0px 1px 3px 0px var(--jp-shadow-ambient-color);
  --jp-elevation-z2: 0px 3px 1px -2px var(--jp-shadow-umbra-color),
    0px 2px 2px 0px var(--jp-shadow-penumbra-color),
    0px 1px 5px 0px var(--jp-shadow-ambient-color);
  --jp-elevation-z4: 0px 2px 4px -1px var(--jp-shadow-umbra-color),
    0px 4px 5px 0px var(--jp-shadow-penumbra-color),
    0px 1px 10px 0px var(--jp-shadow-ambient-color);
  --jp-elevation-z6: 0px 3px 5px -1px var(--jp-shadow-umbra-color),
    0px 6px 10px 0px var(--jp-shadow-penumbra-color),
    0px 1px 18px 0px var(--jp-shadow-ambient-color);
  --jp-elevation-z8: 0px 5px 5px -3px var(--jp-shadow-umbra-color),
    0px 8px 10px 1px var(--jp-shadow-penumbra-color),
    0px 3px 14px 2px var(--jp-shadow-ambient-color);
  --jp-elevation-z12: 0px 7px 8px -4px var(--jp-shadow-umbra-color),
    0px 12px 17px 2px var(--jp-shadow-penumbra-color),
    0px 5px 22px 4px var(--jp-shadow-ambient-color);
  --jp-elevation-z16: 0px 8px 10px -5px var(--jp-shadow-umbra-color),
    0px 16px 24px 2px var(--jp-shadow-penumbra-color),
    0px 6px 30px 5px var(--jp-shadow-ambient-color);
  --jp-elevation-z20: 0px 10px 13px -6px var(--jp-shadow-umbra-color),
    0px 20px 31px 3px var(--jp-shadow-penumbra-color),
    0px 8px 38px 7px var(--jp-shadow-ambient-color);
  --jp-elevation-z24: 0px 11px 15px -7px var(--jp-shadow-umbra-color),
    0px 24px 38px 3px var(--jp-shadow-penumbra-color),
    0px 9px 46px 8px var(--jp-shadow-ambient-color);

  /* Borders
   *
   * The following variables, specify the visual styling of borders in JupyterLab.
   */

  --jp-border-width: 1px;
  --jp-border-color0: var(--md-grey-400);
  --jp-border-color1: var(--md-grey-400);
  --jp-border-color2: var(--md-grey-300);
  --jp-border-color3: var(--md-grey-200);
  --jp-border-radius: 2px;

  /* UI Fonts
   *
   * The UI font CSS variables are used for the typography all of the JupyterLab
   * user interface elements that are not directly user generated content.
   *
   * The font sizing here is done assuming that the body font size of --jp-ui-font-size1
   * is applied to a parent element. When children elements, such as headings, are sized
   * in em all things will be computed relative to that body size.
   */

  --jp-ui-font-scale-factor: 1.2;
  --jp-ui-font-size0: 0.83333em;
  --jp-ui-font-size1: 13px; /* Base font size */
  --jp-ui-font-size2: 1.2em;
  --jp-ui-font-size3: 1.44em;

  --jp-ui-font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica,
    Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol';

  /*
   * Use these font colors against the corresponding main layout colors.
   * In a light theme, these go from dark to light.
   */

  /* Defaults use Material Design specification */
  --jp-ui-font-color0: rgba(0, 0, 0, 1);
  --jp-ui-font-color1: rgba(0, 0, 0, 0.87);
  --jp-ui-font-color2: rgba(0, 0, 0, 0.54);
  --jp-ui-font-color3: rgba(0, 0, 0, 0.38);

  /*
   * Use these against the brand/accent/warn/error colors.
   * These will typically go from light to darker, in both a dark and light theme.
   */

  --jp-ui-inverse-font-color0: rgba(255, 255, 255, 1);
  --jp-ui-inverse-font-color1: rgba(255, 255, 255, 1);
  --jp-ui-inverse-font-color2: rgba(255, 255, 255, 0.7);
  --jp-ui-inverse-font-color3: rgba(255, 255, 255, 0.5);

  /* Content Fonts
   *
   * Content font variables are used for typography of user generated content.
   *
   * The font sizing here is done assuming that the body font size of --jp-content-font-size1
   * is applied to a parent element. When children elements, such as headings, are sized
   * in em all things will be computed relative to that body size.
   */

  --jp-content-line-height: 1.6;
  --jp-content-font-scale-factor: 1.2;
  --jp-content-font-size0: 0.83333em;
  --jp-content-font-size1: 14px; /* Base font size */
  --jp-content-font-size2: 1.2em;
  --jp-content-font-size3: 1.44em;
  --jp-content-font-size4: 1.728em;
  --jp-content-font-size5: 2.0736em;

  /* This gives a magnification of about 125% in presentation mode over normal. */
  --jp-content-presentation-font-size1: 17px;

  --jp-content-heading-line-height: 1;
  --jp-content-heading-margin-top: 1.2em;
  --jp-content-heading-margin-bottom: 0.8em;
  --jp-content-heading-font-weight: 500;

  /* Defaults use Material Design specification */
  --jp-content-font-color0: rgba(0, 0, 0, 1);
  --jp-content-font-color1: rgba(0, 0, 0, 0.87);
  --jp-content-font-color2: rgba(0, 0, 0, 0.54);
  --jp-content-font-color3: rgba(0, 0, 0, 0.38);

  --jp-content-link-color: var(--md-blue-700);

  --jp-content-font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI',
    Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji',
    'Segoe UI Symbol';

  /*
   * Code Fonts
   *
   * Code font variables are used for typography of code and other monospaces content.
   */

  --jp-code-font-size: 13px;
  --jp-code-line-height: 1.3077; /* 17px for 13px base */
  --jp-code-padding: 5px; /* 5px for 13px base, codemirror highlighting needs integer px value */
  --jp-code-font-family-default: Menlo, Consolas, 'DejaVu Sans Mono', monospace;
  --jp-code-font-family: var(--jp-code-font-family-default);

  /* This gives a magnification of about 125% in presentation mode over normal. */
  --jp-code-presentation-font-size: 16px;

  /* may need to tweak cursor width if you change font size */
  --jp-code-cursor-width0: 1.4px;
  --jp-code-cursor-width1: 2px;
  --jp-code-cursor-width2: 4px;

  /* Layout
   *
   * The following are the main layout colors use in JupyterLab. In a light
   * theme these would go from light to dark.
   */

  --jp-layout-color0: white;
  --jp-layout-color1: white;
  --jp-layout-color2: var(--md-grey-200);
  --jp-layout-color3: var(--md-grey-400);
  --jp-layout-color4: var(--md-grey-600);

  /* Inverse Layout
   *
   * The following are the inverse layout colors use in JupyterLab. In a light
   * theme these would go from dark to light.
   */

  --jp-inverse-layout-color0: #111111;
  --jp-inverse-layout-color1: var(--md-grey-900);
  --jp-inverse-layout-color2: var(--md-grey-800);
  --jp-inverse-layout-color3: var(--md-grey-700);
  --jp-inverse-layout-color4: var(--md-grey-600);

  /* Brand/accent */

  --jp-brand-color0: var(--md-blue-700);
  --jp-brand-color1: var(--md-blue-500);
  --jp-brand-color2: var(--md-blue-300);
  --jp-brand-color3: var(--md-blue-100);
  --jp-brand-color4: var(--md-blue-50);

  --jp-accent-color0: var(--md-green-700);
  --jp-accent-color1: var(--md-green-500);
  --jp-accent-color2: var(--md-green-300);
  --jp-accent-color3: var(--md-green-100);

  /* State colors (warn, error, success, info) */

  --jp-warn-color0: var(--md-orange-700);
  --jp-warn-color1: var(--md-orange-500);
  --jp-warn-color2: var(--md-orange-300);
  --jp-warn-color3: var(--md-orange-100);

  --jp-error-color0: var(--md-red-700);
  --jp-error-color1: var(--md-red-500);
  --jp-error-color2: var(--md-red-300);
  --jp-error-color3: var(--md-red-100);

  --jp-success-color0: var(--md-green-700);
  --jp-success-color1: var(--md-green-500);
  --jp-success-color2: var(--md-green-300);
  --jp-success-color3: var(--md-green-100);

  --jp-info-color0: var(--md-cyan-700);
  --jp-info-color1: var(--md-cyan-500);
  --jp-info-color2: var(--md-cyan-300);
  --jp-info-color3: var(--md-cyan-100);

  /* Cell specific styles */

  --jp-cell-padding: 5px;

  --jp-cell-collapser-width: 8px;
  --jp-cell-collapser-min-height: 20px;
  --jp-cell-collapser-not-active-hover-opacity: 0.6;

  --jp-cell-editor-background: var(--md-grey-100);
  --jp-cell-editor-border-color: var(--md-grey-300);
  --jp-cell-editor-box-shadow: inset 0 0 2px var(--md-blue-300);
  --jp-cell-editor-active-background: var(--jp-layout-color0);
  --jp-cell-editor-active-border-color: var(--jp-brand-color1);

  --jp-cell-prompt-width: 64px;
  --jp-cell-prompt-font-family: var(--jp-code-font-family-default);
  --jp-cell-prompt-letter-spacing: 0px;
  --jp-cell-prompt-opacity: 1;
  --jp-cell-prompt-not-active-opacity: 0.5;
  --jp-cell-prompt-not-active-font-color: var(--md-grey-700);
  /* A custom blend of MD grey and blue 600
   * See https://meyerweb.com/eric/tools/color-blend/#546E7A:1E88E5:5:hex */
  --jp-cell-inprompt-font-color: #307fc1;
  /* A custom blend of MD grey and orange 600
   * https://meyerweb.com/eric/tools/color-blend/#546E7A:F4511E:5:hex */
  --jp-cell-outprompt-font-color: #bf5b3d;

  /* Notebook specific styles */

  --jp-notebook-padding: 10px;
  --jp-notebook-select-background: var(--jp-layout-color1);
  --jp-notebook-multiselected-color: var(--md-blue-50);

  /* The scroll padding is calculated to fill enough space at the bottom of the
  notebook to show one single-line cell (with appropriate padding) at the top
  when the notebook is scrolled all the way to the bottom. We also subtract one
  pixel so that no scrollbar appears if we have just one single-line cell in the
  notebook. This padding is to enable a 'scroll past end' feature in a notebook.
  */
  --jp-notebook-scroll-padding: calc(
    100% - var(--jp-code-font-size) * var(--jp-code-line-height) -
      var(--jp-code-padding) - var(--jp-cell-padding) - 1px
  );

  /* Rendermime styles */

  --jp-rendermime-error-background: #fdd;
  --jp-rendermime-table-row-background: var(--md-grey-100);
  --jp-rendermime-table-row-hover-background: var(--md-light-blue-50);

  /* Dialog specific styles */

  --jp-dialog-background: rgba(0, 0, 0, 0.25);

  /* Console specific styles */

  --jp-console-padding: 10px;

  /* Toolbar specific styles */

  --jp-toolbar-border-color: var(--jp-border-color1);
  --jp-toolbar-micro-height: 8px;
  --jp-toolbar-background: var(--jp-layout-color1);
  --jp-toolbar-box-shadow: 0px 0px 2px 0px rgba(0, 0, 0, 0.24);
  --jp-toolbar-header-margin: 4px 4px 0px 4px;
  --jp-toolbar-active-background: var(--md-grey-300);

  /* Input field styles */

  --jp-input-box-shadow: inset 0 0 2px var(--md-blue-300);
  --jp-input-active-background: var(--jp-layout-color1);
  --jp-input-hover-background: var(--jp-layout-color1);
  --jp-input-background: var(--md-grey-100);
  --jp-input-border-color: var(--jp-border-color1);
  --jp-input-active-border-color: var(--jp-brand-color1);
  --jp-input-active-box-shadow-color: rgba(19, 124, 189, 0.3);

  /* General editor styles */

  --jp-editor-selected-background: #d9d9d9;
  --jp-editor-selected-focused-background: #d7d4f0;
  --jp-editor-cursor-color: var(--jp-ui-font-color0);

  /* Code mirror specific styles */

  --jp-mirror-editor-keyword-color: #008000;
  --jp-mirror-editor-atom-color: #88f;
  --jp-mirror-editor-number-color: #080;
  --jp-mirror-editor-def-color: #00f;
  --jp-mirror-editor-variable-color: var(--md-grey-900);
  --jp-mirror-editor-variable-2-color: #05a;
  --jp-mirror-editor-variable-3-color: #085;
  --jp-mirror-editor-punctuation-color: #05a;
  --jp-mirror-editor-property-color: #05a;
  --jp-mirror-editor-operator-color: #aa22ff;
  --jp-mirror-editor-comment-color: #408080;
  --jp-mirror-editor-string-color: #ba2121;
  --jp-mirror-editor-string-2-color: #708;
  --jp-mirror-editor-meta-color: #aa22ff;
  --jp-mirror-editor-qualifier-color: #555;
  --jp-mirror-editor-builtin-color: #008000;
  --jp-mirror-editor-bracket-color: #997;
  --jp-mirror-editor-tag-color: #170;
  --jp-mirror-editor-attribute-color: #00c;
  --jp-mirror-editor-header-color: blue;
  --jp-mirror-editor-quote-color: #090;
  --jp-mirror-editor-link-color: #00c;
  --jp-mirror-editor-error-color: #f00;
  --jp-mirror-editor-hr-color: #999;

  /* Vega extension styles */

  --jp-vega-background: white;

  /* Sidebar-related styles */

  --jp-sidebar-min-width: 250px;

  /* Search-related styles */

  --jp-search-toggle-off-opacity: 0.5;
  --jp-search-toggle-hover-opacity: 0.8;
  --jp-search-toggle-on-opacity: 1;
  --jp-search-selected-match-background-color: rgb(245, 200, 0);
  --jp-search-selected-match-color: black;
  --jp-search-unselected-match-background-color: var(
    --jp-inverse-layout-color0
  );
  --jp-search-unselected-match-color: var(--jp-ui-inverse-font-color0);

  /* Icon colors that work well with light or dark backgrounds */
  --jp-icon-contrast-color0: var(--md-purple-600);
  --jp-icon-contrast-color1: var(--md-green-600);
  --jp-icon-contrast-color2: var(--md-pink-600);
  --jp-icon-contrast-color3: var(--md-blue-600);
}
</style>

<style type="text/css">
a.anchor-link {
   display: none;
}
.highlight  {
    margin: 0.4em;
}

/* Input area styling */
.jp-InputArea {
    overflow: hidden;
}

.jp-InputArea-editor {
    overflow: hidden;
}

@media print {
  body {
    margin: 0;
  }
}
</style>

<!-- Load mathjax -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-MML-AM_CHTML-full,Safe"> </script>
    <!-- MathJax configuration -->
    <script type="text/x-mathjax-config">
    init_mathjax = function() {
        if (window.MathJax) {
        // MathJax loaded
            MathJax.Hub.Config({
                TeX: {
                    equationNumbers: {
                    autoNumber: "AMS",
                    useLabelIds: true
                    }
                },
                tex2jax: {
                    inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                    displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                    processEscapes: true,
                    processEnvironments: true
                },
                displayAlign: 'center',
                CommonHTML: {
                    linebreaks: { 
                    automatic: true 
                    }
                },
                "HTML-CSS": {
                    linebreaks: { 
                    automatic: true 
                    }
                }
            });
        
            MathJax.Hub.Queue(["Typeset", MathJax.Hub]);
        }
    }
    init_mathjax();
    </script>
    <!-- End of mathjax configuration --></head>
<body class="jp-Notebook" data-jp-theme-light="true" data-jp-theme-name="JupyterLab Light">
<div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[1]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[2]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">DATA_DIR</span> <span class="o">=</span> <span class="s2">&quot;data/gender.parquet&quot;</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[3]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_parquet</span><span class="p">(</span><span class="n">DATA_DIR</span><span class="p">,</span> <span class="n">engine</span><span class="o">=</span><span class="s2">&quot;pyarrow&quot;</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt">Out[3]:</div>



<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/html">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>queries</th>
      <th>apps</th>
      <th>games</th>
      <th>gender</th>
      <th>birth_year</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>[216, 359, 12329, 3, 45, 4002, 2066, 32, 3931,...</td>
      <td>[4, 4, 25, 7, 30, 58, 16, 19, 17, 21, 10, 10, ...</td>
      <td>[9151, 208]</td>
      <td>M</td>
      <td>1366.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>[]</td>
      <td>[129, 71, 9, 8, 11, 25, 18, 58, 6, 16, 125, 12...</td>
      <td>[460, 4939, 14, 232, 6387, 1758, 5834, 3, 2]</td>
      <td>F</td>
      <td>1359.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>[23463, 18831]</td>
      <td>[9, 174, 65, 8, 63, 97, 62, 103, 61, 116, 59, ...</td>
      <td>[448, 723, 267, 9064, 10634, 166, 782, 224, 27...</td>
      <td>M</td>
      <td>1373.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>[1634, 3609, 654]</td>
      <td>[99, 73, 9, 8, 59, 37, 131, 3, 89, 6, 24, 16, ...</td>
      <td>[78, 2607, 478, 435, 9, 192]</td>
      <td>M</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>[11064, 227, 623, 1301, 43999, 35411, 2492, 11...</td>
      <td>[9, 8, 17, 54, 3, 25, 22, 6, 21, 7, 14, 5, 817...</td>
      <td>[1702, 1, 53]</td>
      <td>M</td>
      <td>1364.0</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[4]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">tail</span><span class="p">()</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt">Out[4]:</div>



<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/html">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>queries</th>
      <th>apps</th>
      <th>games</th>
      <th>gender</th>
      <th>birth_year</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>40266</th>
      <td>[13388, 10571, 122, 1961, 42946, 823, 3349, 10...</td>
      <td>[9, 8, 17, 3, 25, 22, 6, 24, 12, 7, 14, 5, 4, ...</td>
      <td>[3, 55, 1115, 135, 410, 38, 1426, 107, 374]</td>
      <td>M</td>
      <td>1394.0</td>
    </tr>
    <tr>
      <th>40267</th>
      <td>[2655, 11, 1732, 2847, 15222, 884, 39, 1433, 2...</td>
      <td>[8, 11, 10, 10, 39, 17, 771, 48, 3, 25, 95, 22...</td>
      <td>[717]</td>
      <td>M</td>
      <td>1354.0</td>
    </tr>
    <tr>
      <th>40268</th>
      <td>[9, 33200, 5028, 357, 4, 233, 262, 2180, 376, ...</td>
      <td>[54, 9, 8, 10, 10, 39, 17, 48, 3, 25, 6, 21, 1...</td>
      <td>[312, 22]</td>
      <td>M</td>
      <td>1364.0</td>
    </tr>
    <tr>
      <th>40269</th>
      <td>[9, 276, 27, 1074]</td>
      <td>[9, 8, 17, 48, 54, 3, 25, 22, 6, 21, 7, 45, 14...</td>
      <td>[73, 2, 53, 75]</td>
      <td>M</td>
      <td>1365.0</td>
    </tr>
    <tr>
      <th>40270</th>
      <td>[6421, 11377, 6980, 852, 31, 185, 2348, 534, 4...</td>
      <td>[43, 8, 10, 10, 39, 17, 48, 54, 3, 25, 22, 6, ...</td>
      <td>[355, 278, 185]</td>
      <td>M</td>
      <td>1390.0</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[5]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt">Out[5]:</div>




<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain">
<pre>(40271, 5)</pre>
</div>

</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[6]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">info</span><span class="p">()</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
RangeIndex: 40271 entries, 0 to 40270
Data columns (total 5 columns):
 #   Column      Non-Null Count  Dtype  
---  ------      --------------  -----  
 0   queries     40271 non-null  object 
 1   apps        40271 non-null  object 
 2   games       40271 non-null  object 
 3   gender      40271 non-null  object 
 4   birth_year  40271 non-null  float64
dtypes: float64(1), object(4)
memory usage: 1.5+ MB
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[5]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df</span><span class="p">[</span><span class="s2">&quot;birth_year&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;birth_year&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">uint</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>There is no <code>NaN</code> value heare as we can see in <code>birth_year</code> we have <code>0</code> which is not acceptable. So we should replace them with new values.</p>
<p>In addition to <code>birth_year</code> we should make gender column numeric, although it is our goal column.</p>

</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[6]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">valid_birth_year</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;birth_year&quot;</span><span class="p">][</span><span class="n">df</span><span class="p">[</span><span class="s2">&quot;birth_year&quot;</span><span class="p">]</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">]</span>
<span class="n">mean_birth_year</span> <span class="o">=</span> <span class="nb">round</span><span class="p">(</span><span class="n">valid_birth_year</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[7]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df</span><span class="p">[</span><span class="s2">&quot;birth_year&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;birth_year&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">mean_birth_year</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s2">&quot;gender&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;gender&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">({</span><span class="s1">&#39;M&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;F&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">})</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt">Out[7]:</div>



<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/html">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>queries</th>
      <th>apps</th>
      <th>games</th>
      <th>gender</th>
      <th>birth_year</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>[216, 359, 12329, 3, 45, 4002, 2066, 32, 3931,...</td>
      <td>[4, 4, 25, 7, 30, 58, 16, 19, 17, 21, 10, 10, ...</td>
      <td>[9151, 208]</td>
      <td>1</td>
      <td>1366</td>
    </tr>
    <tr>
      <th>1</th>
      <td>[]</td>
      <td>[129, 71, 9, 8, 11, 25, 18, 58, 6, 16, 125, 12...</td>
      <td>[460, 4939, 14, 232, 6387, 1758, 5834, 3, 2]</td>
      <td>0</td>
      <td>1359</td>
    </tr>
    <tr>
      <th>2</th>
      <td>[23463, 18831]</td>
      <td>[9, 174, 65, 8, 63, 97, 62, 103, 61, 116, 59, ...</td>
      <td>[448, 723, 267, 9064, 10634, 166, 782, 224, 27...</td>
      <td>1</td>
      <td>1373</td>
    </tr>
    <tr>
      <th>3</th>
      <td>[1634, 3609, 654]</td>
      <td>[99, 73, 9, 8, 59, 37, 131, 3, 89, 6, 24, 16, ...</td>
      <td>[78, 2607, 478, 435, 9, 192]</td>
      <td>1</td>
      <td>1371</td>
    </tr>
    <tr>
      <th>4</th>
      <td>[11064, 227, 623, 1301, 43999, 35411, 2492, 11...</td>
      <td>[9, 8, 17, 54, 3, 25, 22, 6, 21, 7, 14, 5, 817...</td>
      <td>[1702, 1, 53]</td>
      <td>1</td>
      <td>1364</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[10]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt">Out[10]:</div>



<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/html">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>gender</th>
      <th>birth_year</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>40271.000000</td>
      <td>40271.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>0.742991</td>
      <td>1370.967495</td>
    </tr>
    <tr>
      <th>std</th>
      <td>0.436990</td>
      <td>11.706620</td>
    </tr>
    <tr>
      <th>min</th>
      <td>0.000000</td>
      <td>1300.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>0.000000</td>
      <td>1364.000000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>1.000000</td>
      <td>1371.000000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>1.000000</td>
      <td>1380.000000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>1.000000</td>
      <td>1398.000000</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>

</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h2 id="Dealing-with-list-values">Dealing with list values<a class="anchor-link" href="#Dealing-with-list-values">&#182;</a></h2><p>As it's clear hear that three of our main columns which are <code>queries</code>, <code>apps</code>, and <code>games</code> are lists so we should desl with them.</p>
<p>Actually, if you look closely, you will find that lists are everywhere! Here are some practical problems, where you will probably encounter list values.</p>
<ul>
<li>Audio-video tags</li>
<li>Open-ended questions in survey data</li>
<li>List of all authors, artists, producers, etc. invloved in a creative product</li>
</ul>
<h3 id="What-is-wrong-with-list-values?">What is wrong with list values?<a class="anchor-link" href="#What-is-wrong-with-list-values?">&#182;</a></h3><p>List values mess up everything you know about data analysis. The simplest operations can not be performed without endless looping.</p>
<p>An example of this is here:</p>
<p><img src="data:image/png;base64,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" alt="image.png"></p>
<p><img src="data:image/png;base64,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" alt="image-2.png"></p>
<p>The reason this does not work is that Pandas does not have direct access to every individual element of the lists. Thus, Pandas is unable to apply functions like value_counts() properly.</p>

</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[8]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">to_1D</span><span class="p">(</span><span class="n">series</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">([</span><span class="n">x</span> <span class="k">for</span> <span class="n">_list</span> <span class="ow">in</span> <span class="n">series</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">_list</span><span class="p">])</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[9]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">to_1D</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;queries&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt">Out[9]:</div>




<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain">
<pre>2        8229
3        8174
4        7870
1        7816
5        6605
         ... 
43591       1
49796       1
36214       1
37550       1
41955       1
Length: 47287, dtype: int64</pre>
</div>

</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[10]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">to_1D</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;apps&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt">Out[10]:</div>




<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain">
<pre>4        41154
1        40271
2        40194
3        38390
10       37980
         ...  
22089        1
19999        1
16220        1
12370        1
30151        1
Length: 36598, dtype: int64</pre>
</div>

</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[11]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">to_1D</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;games&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt">Out[11]:</div>




<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain">
<pre>2        5534
1        3662
9        2324
4        2131
16       2045
         ... 
3942        1
30718       1
8524        1
8361        1
14970       1
Length: 15414, dtype: int64</pre>
</div>

</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[15]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">14</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>
<span class="n">ax</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">to_1D</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s2">&quot;queries&quot;</span><span class="p">])</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span><span class="o">.</span><span class="n">index</span><span class="p">,</span>
        <span class="n">to_1D</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s2">&quot;queries&quot;</span><span class="p">])</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Frequency&quot;</span><span class="p">,</span> <span class="n">size</span> <span class="o">=</span> <span class="mi">12</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Query Ids&quot;</span><span class="p">,</span> <span class="n">size</span> <span class="o">=</span> <span class="mi">14</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt">Out[15]:</div>




<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain">
<pre>Text(0.5, 1.0, &#39;Query Ids&#39;)</pre>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedImage jp-OutputArea-output ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[16]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">14</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>
<span class="n">ax</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">to_1D</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s2">&quot;apps&quot;</span><span class="p">])</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span><span class="o">.</span><span class="n">index</span><span class="p">,</span>
        <span class="n">to_1D</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s2">&quot;apps&quot;</span><span class="p">])</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Frequency&quot;</span><span class="p">,</span> <span class="n">size</span> <span class="o">=</span> <span class="mi">12</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;App Ids&quot;</span><span class="p">,</span> <span class="n">size</span> <span class="o">=</span> <span class="mi">14</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt">Out[16]:</div>




<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain">
<pre>Text(0.5, 1.0, &#39;App Ids&#39;)</pre>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedImage jp-OutputArea-output ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[17]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">14</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>
<span class="n">ax</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">to_1D</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s2">&quot;games&quot;</span><span class="p">])</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span><span class="o">.</span><span class="n">index</span><span class="p">,</span>
        <span class="n">to_1D</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s2">&quot;games&quot;</span><span class="p">])</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Frequency&quot;</span><span class="p">,</span> <span class="n">size</span> <span class="o">=</span> <span class="mi">12</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Game Ids&quot;</span><span class="p">,</span> <span class="n">size</span> <span class="o">=</span> <span class="mi">14</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt">Out[17]:</div>




<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain">
<pre>Text(0.5, 1.0, &#39;Game Ids&#39;)</pre>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedImage jp-OutputArea-output ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[12]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">df</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">&#39;queries&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">),</span> <span class="n">df</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">df</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">&#39;apps&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">),</span> <span class="n">df</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">df</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">&#39;games&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">),</span> <span class="n">df</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt">Out[12]:</div>



<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/html">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
      <th>1</th>
      <th>2</th>
      <th>3</th>
      <th>4</th>
      <th>5</th>
      <th>6</th>
      <th>7</th>
      <th>8</th>
      <th>9</th>
      <th>...</th>
      <th>88</th>
      <th>89</th>
      <th>90</th>
      <th>91</th>
      <th>92</th>
      <th>93</th>
      <th>94</th>
      <th>95</th>
      <th>gender</th>
      <th>birth_year</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>9151.0</td>
      <td>208.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1</td>
      <td>1366</td>
    </tr>
    <tr>
      <th>1</th>
      <td>460.0</td>
      <td>4939.0</td>
      <td>14.0</td>
      <td>232.0</td>
      <td>6387.0</td>
      <td>1758.0</td>
      <td>5834.0</td>
      <td>3.0</td>
      <td>2.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0</td>
      <td>1359</td>
    </tr>
    <tr>
      <th>2</th>
      <td>448.0</td>
      <td>723.0</td>
      <td>267.0</td>
      <td>9064.0</td>
      <td>10634.0</td>
      <td>166.0</td>
      <td>782.0</td>
      <td>224.0</td>
      <td>273.0</td>
      <td>4086.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1</td>
      <td>1373</td>
    </tr>
    <tr>
      <th>3</th>
      <td>78.0</td>
      <td>2607.0</td>
      <td>478.0</td>
      <td>435.0</td>
      <td>9.0</td>
      <td>192.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1</td>
      <td>1371</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1702.0</td>
      <td>1.0</td>
      <td>53.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1</td>
      <td>1364</td>
    </tr>
  </tbody>
</table>
<p>5 rows  932 columns</p>
</div>
</div>

</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[13]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>

<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span>  <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;gender&quot;</span><span class="p">]),</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;gender&quot;</span><span class="p">]</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[38]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[22]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span>
<span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeClassifier</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">cross_val_score</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt">Out[22]:</div>




<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain">
<pre>array([0.63935444, 0.64276847, 0.63687151, 0.63842334, 0.62259466,
       0.63749224, 0.63458553, 0.64141571, 0.63023906, 0.64452034])</pre>
</div>

</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[23]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">predicted</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[4]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">metrics</span>

<span class="k">def</span> <span class="nf">evaluate</span><span class="p">(</span><span class="n">predicted</span><span class="p">,</span> <span class="n">actual</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accuracy: &quot;</span><span class="p">,</span> <span class="n">metrics</span><span class="o">.</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">actual</span><span class="p">,</span> <span class="n">predicted</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Balanced Accuracy: &quot;</span><span class="p">,</span> <span class="n">metrics</span><span class="o">.</span><span class="n">balanced_accuracy_score</span><span class="p">(</span><span class="n">actual</span><span class="p">,</span> <span class="n">predicted</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Precision: &quot;</span><span class="p">,</span> <span class="n">metrics</span><span class="o">.</span><span class="n">precision_score</span><span class="p">(</span><span class="n">actual</span><span class="p">,</span> <span class="n">predicted</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Recall: &quot;</span><span class="p">,</span> <span class="n">metrics</span><span class="o">.</span><span class="n">recall_score</span><span class="p">(</span><span class="n">actual</span><span class="p">,</span> <span class="n">predicted</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;F1: &quot;</span><span class="p">,</span> <span class="n">metrics</span><span class="o">.</span><span class="n">f1_score</span><span class="p">(</span><span class="n">actual</span><span class="p">,</span> <span class="n">predicted</span><span class="p">))</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[25]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">evaluate</span><span class="p">(</span><span class="n">predicted</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Accuracy:  0.6441961514587213
Balanced Accuracy:  0.5421774831735213
Precision:  0.7637474541751528
Recall:  0.7532641446267158
F1:  0.7584695769425248
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[26]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">max_depth</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">cross_val_score</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt">Out[26]:</div>




<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain">
<pre>array([0.74332713, 0.74332713, 0.74332713, 0.74332713, 0.74332713,
       0.74332713, 0.7435579 , 0.74324744, 0.74324744, 0.74324744])</pre>
</div>

</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[27]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">predicted</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[28]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">evaluate</span><span class="p">(</span><span class="n">predicted</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Accuracy:  0.741651148355059
Balanced Accuracy:  0.5
Precision:  0.741651148355059
Recall:  1.0
F1:  0.8516644094375936
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[39]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">GridSearchCV</span>

<span class="n">parameters</span> <span class="o">=</span> <span class="p">{</span> <span class="s1">&#39;n_estimators&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">200</span><span class="p">],</span>
                   <span class="s1">&#39;min_samples_split&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span>
                   <span class="s1">&#39;min_samples_leaf&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span>
                   <span class="s1">&#39;max_depth&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">50</span> <span class="p">,</span><span class="mi">100</span><span class="p">]</span>
                 <span class="p">}</span>

<span class="n">grid_search</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">estimator</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">param_grid</span><span class="o">=</span><span class="n">parameters</span><span class="p">)</span>
<span class="n">grid_search</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt">Out[39]:</div>




<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain">
<pre>GridSearchCV(estimator=RandomForestClassifier(max_depth=10, random_state=0),
             param_grid={&#39;max_depth&#39;: [2, 5, 10, 20, 50, 100],
                         &#39;min_samples_leaf&#39;: [1, 2, 3],
                         &#39;min_samples_split&#39;: [2, 3],
                         &#39;n_estimators&#39;: [2, 5, 10, 20, 30, 50, 100, 200]})</pre>
</div>

</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[40]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">grid_search</span><span class="o">.</span><span class="n">best_params_</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt">Out[40]:</div>




<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain">
<pre>{&#39;max_depth&#39;: 20,
 &#39;min_samples_leaf&#39;: 1,
 &#39;min_samples_split&#39;: 2,
 &#39;n_estimators&#39;: 100}</pre>
</div>

</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[42]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">max_depth</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">min_samples_leaf</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">min_samples_split</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="n">cross_val_score</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt">Out[42]:</div>




<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain">
<pre>array([0.74270639, 0.74301676, 0.74394786, 0.74332713, 0.74363749,
       0.74301676, 0.74262651, 0.74324744, 0.74293698, 0.74231605])</pre>
</div>

</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[43]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">predicted</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[44]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">evaluate</span><span class="p">(</span><span class="n">predicted</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Accuracy:  0.7417752948479206
Balanced Accuracy:  0.5007099883573654
Precision:  0.7419234592445328
Recall:  0.9994978239035822
F1:  0.8516616745114819
</pre>
</div>
</div>

</div>

</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>As we can see although we have not-bad accuracy but balanced accuracy which is wanted for this task is not good so we should look for better moodels.</p>
<p>By remember that with these parameters:</p>

<pre><code>{'max_depth': 20,
 'min_samples_leaf': 1,
 'min_samples_split': 2,
 'n_estimators': 100
}</code></pre>
<p>We got these results:</p>

<pre><code>Accuracy:  0.7417752948479206
Balanced Accuracy:  0.5007099883573654
Precision:  0.7419234592445328
Recall:  0.9994978239035822
F1:  0.8516616745114819</code></pre>

</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[26]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsClassifier</span>

<span class="n">parameters</span> <span class="o">=</span> <span class="p">{</span> <span class="s1">&#39;n_neighbors&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">19</span><span class="p">,</span> <span class="mi">25</span><span class="p">,</span> <span class="mi">35</span><span class="p">,</span> <span class="mi">55</span><span class="p">,</span><span class="mi">75</span><span class="p">,</span> <span class="mi">99</span><span class="p">],</span>
                <span class="s1">&#39;leaf_size&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">20</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">70</span><span class="p">],</span>
              <span class="s1">&#39;weights&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;uniform&#39;</span><span class="p">,</span> <span class="s1">&#39;distance&#39;</span><span class="p">]</span>
                 <span class="p">}</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">()</span>

<span class="n">grid_search</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">estimator</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">param_grid</span><span class="o">=</span><span class="n">parameters</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s2">&quot;balanced_accuracy&quot;</span><span class="p">)</span>
<span class="n">grid_search</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Fitting 5 folds for each of 88 candidates, totalling 440 fits
[CV 1/5; 1/88] START leaf_size=20, n_neighbors=3, weights=uniform...............
[CV 1/5; 1/88] END leaf_size=20, n_neighbors=3, weights=uniform;, score=0.504 total time=   4.5s
[CV 2/5; 1/88] START leaf_size=20, n_neighbors=3, weights=uniform...............
[CV 2/5; 1/88] END leaf_size=20, n_neighbors=3, weights=uniform;, score=0.510 total time=   4.1s
[CV 3/5; 1/88] START leaf_size=20, n_neighbors=3, weights=uniform...............
[CV 3/5; 1/88] END leaf_size=20, n_neighbors=3, weights=uniform;, score=0.504 total time=   4.1s
[CV 4/5; 1/88] START leaf_size=20, n_neighbors=3, weights=uniform...............
[CV 4/5; 1/88] END leaf_size=20, n_neighbors=3, weights=uniform;, score=0.506 total time=   4.3s
[CV 5/5; 1/88] START leaf_size=20, n_neighbors=3, weights=uniform...............
[CV 5/5; 1/88] END leaf_size=20, n_neighbors=3, weights=uniform;, score=0.501 total time=   4.1s
[CV 1/5; 2/88] START leaf_size=20, n_neighbors=3, weights=distance..............
[CV 1/5; 2/88] END leaf_size=20, n_neighbors=3, weights=distance;, score=0.504 total time=   4.3s
[CV 2/5; 2/88] START leaf_size=20, n_neighbors=3, weights=distance..............
[CV 2/5; 2/88] END leaf_size=20, n_neighbors=3, weights=distance;, score=0.510 total time=   4.3s
[CV 3/5; 2/88] START leaf_size=20, n_neighbors=3, weights=distance..............
[CV 3/5; 2/88] END leaf_size=20, n_neighbors=3, weights=distance;, score=0.504 total time=   4.4s
[CV 4/5; 2/88] START leaf_size=20, n_neighbors=3, weights=distance..............
[CV 4/5; 2/88] END leaf_size=20, n_neighbors=3, weights=distance;, score=0.506 total time=   4.2s
[CV 5/5; 2/88] START leaf_size=20, n_neighbors=3, weights=distance..............
[CV 5/5; 2/88] END leaf_size=20, n_neighbors=3, weights=distance;, score=0.500 total time=   4.0s
[CV 1/5; 3/88] START leaf_size=20, n_neighbors=5, weights=uniform...............
[CV 1/5; 3/88] END leaf_size=20, n_neighbors=5, weights=uniform;, score=0.500 total time=   5.5s
[CV 2/5; 3/88] START leaf_size=20, n_neighbors=5, weights=uniform...............
[CV 2/5; 3/88] END leaf_size=20, n_neighbors=5, weights=uniform;, score=0.515 total time=   5.1s
[CV 3/5; 3/88] START leaf_size=20, n_neighbors=5, weights=uniform...............
[CV 3/5; 3/88] END leaf_size=20, n_neighbors=5, weights=uniform;, score=0.507 total time=   5.5s
[CV 4/5; 3/88] START leaf_size=20, n_neighbors=5, weights=uniform...............
[CV 4/5; 3/88] END leaf_size=20, n_neighbors=5, weights=uniform;, score=0.506 total time=   5.1s
[CV 5/5; 3/88] START leaf_size=20, n_neighbors=5, weights=uniform...............
[CV 5/5; 3/88] END leaf_size=20, n_neighbors=5, weights=uniform;, score=0.498 total time=   5.1s
[CV 1/5; 4/88] START leaf_size=20, n_neighbors=5, weights=distance..............
[CV 1/5; 4/88] END leaf_size=20, n_neighbors=5, weights=distance;, score=0.500 total time=   4.8s
[CV 2/5; 4/88] START leaf_size=20, n_neighbors=5, weights=distance..............
[CV 2/5; 4/88] END leaf_size=20, n_neighbors=5, weights=distance;, score=0.515 total time=   5.0s
[CV 3/5; 4/88] START leaf_size=20, n_neighbors=5, weights=distance..............
[CV 3/5; 4/88] END leaf_size=20, n_neighbors=5, weights=distance;, score=0.506 total time=   4.8s
[CV 4/5; 4/88] START leaf_size=20, n_neighbors=5, weights=distance..............
[CV 4/5; 4/88] END leaf_size=20, n_neighbors=5, weights=distance;, score=0.506 total time=   5.4s
[CV 5/5; 4/88] START leaf_size=20, n_neighbors=5, weights=distance..............
[CV 5/5; 4/88] END leaf_size=20, n_neighbors=5, weights=distance;, score=0.498 total time=   5.3s
[CV 1/5; 5/88] START leaf_size=20, n_neighbors=7, weights=uniform...............
[CV 1/5; 5/88] END leaf_size=20, n_neighbors=7, weights=uniform;, score=0.503 total time=   5.8s
[CV 2/5; 5/88] START leaf_size=20, n_neighbors=7, weights=uniform...............
[CV 2/5; 5/88] END leaf_size=20, n_neighbors=7, weights=uniform;, score=0.506 total time=   5.5s
[CV 3/5; 5/88] START leaf_size=20, n_neighbors=7, weights=uniform...............
[CV 3/5; 5/88] END leaf_size=20, n_neighbors=7, weights=uniform;, score=0.502 total time=   6.2s
[CV 4/5; 5/88] START leaf_size=20, n_neighbors=7, weights=uniform...............
[CV 4/5; 5/88] END leaf_size=20, n_neighbors=7, weights=uniform;, score=0.505 total time=   7.0s
[CV 5/5; 5/88] START leaf_size=20, n_neighbors=7, weights=uniform...............
[CV 5/5; 5/88] END leaf_size=20, n_neighbors=7, weights=uniform;, score=0.507 total time=   6.3s
[CV 1/5; 6/88] START leaf_size=20, n_neighbors=7, weights=distance..............
[CV 1/5; 6/88] END leaf_size=20, n_neighbors=7, weights=distance;, score=0.503 total time=   6.0s
[CV 2/5; 6/88] START leaf_size=20, n_neighbors=7, weights=distance..............
[CV 2/5; 6/88] END leaf_size=20, n_neighbors=7, weights=distance;, score=0.506 total time=   5.3s
[CV 3/5; 6/88] START leaf_size=20, n_neighbors=7, weights=distance..............
[CV 3/5; 6/88] END leaf_size=20, n_neighbors=7, weights=distance;, score=0.502 total time=   6.1s
[CV 4/5; 6/88] START leaf_size=20, n_neighbors=7, weights=distance..............
[CV 4/5; 6/88] END leaf_size=20, n_neighbors=7, weights=distance;, score=0.504 total time=   5.2s
[CV 5/5; 6/88] START leaf_size=20, n_neighbors=7, weights=distance..............
[CV 5/5; 6/88] END leaf_size=20, n_neighbors=7, weights=distance;, score=0.507 total time=   5.1s
[CV 1/5; 7/88] START leaf_size=20, n_neighbors=9, weights=uniform...............
[CV 1/5; 7/88] END leaf_size=20, n_neighbors=9, weights=uniform;, score=0.505 total time=   5.9s
[CV 2/5; 7/88] START leaf_size=20, n_neighbors=9, weights=uniform...............
[CV 2/5; 7/88] END leaf_size=20, n_neighbors=9, weights=uniform;, score=0.507 total time=   5.6s
[CV 3/5; 7/88] START leaf_size=20, n_neighbors=9, weights=uniform...............
[CV 3/5; 7/88] END leaf_size=20, n_neighbors=9, weights=uniform;, score=0.504 total time=   5.7s
[CV 4/5; 7/88] START leaf_size=20, n_neighbors=9, weights=uniform...............
[CV 4/5; 7/88] END leaf_size=20, n_neighbors=9, weights=uniform;, score=0.500 total time=   5.3s
[CV 5/5; 7/88] START leaf_size=20, n_neighbors=9, weights=uniform...............
[CV 5/5; 7/88] END leaf_size=20, n_neighbors=9, weights=uniform;, score=0.507 total time=   5.2s
[CV 1/5; 8/88] START leaf_size=20, n_neighbors=9, weights=distance..............
[CV 1/5; 8/88] END leaf_size=20, n_neighbors=9, weights=distance;, score=0.505 total time=   5.1s
[CV 2/5; 8/88] START leaf_size=20, n_neighbors=9, weights=distance..............
[CV 2/5; 8/88] END leaf_size=20, n_neighbors=9, weights=distance;, score=0.508 total time=   5.0s
[CV 3/5; 8/88] START leaf_size=20, n_neighbors=9, weights=distance..............
[CV 3/5; 8/88] END leaf_size=20, n_neighbors=9, weights=distance;, score=0.504 total time=   5.0s
[CV 4/5; 8/88] START leaf_size=20, n_neighbors=9, weights=distance..............
[CV 4/5; 8/88] END leaf_size=20, n_neighbors=9, weights=distance;, score=0.500 total time=   4.9s
[CV 5/5; 8/88] START leaf_size=20, n_neighbors=9, weights=distance..............
[CV 5/5; 8/88] END leaf_size=20, n_neighbors=9, weights=distance;, score=0.507 total time=   5.3s
[CV 1/5; 9/88] START leaf_size=20, n_neighbors=15, weights=uniform..............
[CV 1/5; 9/88] END leaf_size=20, n_neighbors=15, weights=uniform;, score=0.503 total time=   5.7s
[CV 2/5; 9/88] START leaf_size=20, n_neighbors=15, weights=uniform..............
[CV 2/5; 9/88] END leaf_size=20, n_neighbors=15, weights=uniform;, score=0.503 total time=   5.5s
[CV 3/5; 9/88] START leaf_size=20, n_neighbors=15, weights=uniform..............
[CV 3/5; 9/88] END leaf_size=20, n_neighbors=15, weights=uniform;, score=0.500 total time=   5.2s
[CV 4/5; 9/88] START leaf_size=20, n_neighbors=15, weights=uniform..............
[CV 4/5; 9/88] END leaf_size=20, n_neighbors=15, weights=uniform;, score=0.500 total time=   5.0s
[CV 5/5; 9/88] START leaf_size=20, n_neighbors=15, weights=uniform..............
[CV 5/5; 9/88] END leaf_size=20, n_neighbors=15, weights=uniform;, score=0.503 total time=   6.0s
[CV 1/5; 10/88] START leaf_size=20, n_neighbors=15, weights=distance............
[CV 1/5; 10/88] END leaf_size=20, n_neighbors=15, weights=distance;, score=0.503 total time=   5.6s
[CV 2/5; 10/88] START leaf_size=20, n_neighbors=15, weights=distance............
[CV 2/5; 10/88] END leaf_size=20, n_neighbors=15, weights=distance;, score=0.503 total time=   5.1s
[CV 3/5; 10/88] START leaf_size=20, n_neighbors=15, weights=distance............
[CV 3/5; 10/88] END leaf_size=20, n_neighbors=15, weights=distance;, score=0.500 total time=   4.9s
[CV 4/5; 10/88] START leaf_size=20, n_neighbors=15, weights=distance............
[CV 4/5; 10/88] END leaf_size=20, n_neighbors=15, weights=distance;, score=0.501 total time=   5.0s
[CV 5/5; 10/88] START leaf_size=20, n_neighbors=15, weights=distance............
[CV 5/5; 10/88] END leaf_size=20, n_neighbors=15, weights=distance;, score=0.503 total time=   4.8s
[CV 1/5; 11/88] START leaf_size=20, n_neighbors=19, weights=uniform.............
[CV 1/5; 11/88] END leaf_size=20, n_neighbors=19, weights=uniform;, score=0.501 total time=   5.3s
[CV 2/5; 11/88] START leaf_size=20, n_neighbors=19, weights=uniform.............
[CV 2/5; 11/88] END leaf_size=20, n_neighbors=19, weights=uniform;, score=0.501 total time=   5.1s
[CV 3/5; 11/88] START leaf_size=20, n_neighbors=19, weights=uniform.............
[CV 3/5; 11/88] END leaf_size=20, n_neighbors=19, weights=uniform;, score=0.501 total time=   5.2s
[CV 4/5; 11/88] START leaf_size=20, n_neighbors=19, weights=uniform.............
[CV 4/5; 11/88] END leaf_size=20, n_neighbors=19, weights=uniform;, score=0.500 total time=   5.3s
[CV 5/5; 11/88] START leaf_size=20, n_neighbors=19, weights=uniform.............
[CV 5/5; 11/88] END leaf_size=20, n_neighbors=19, weights=uniform;, score=0.502 total time=   5.4s
[CV 1/5; 12/88] START leaf_size=20, n_neighbors=19, weights=distance............
[CV 1/5; 12/88] END leaf_size=20, n_neighbors=19, weights=distance;, score=0.501 total time=   4.9s
[CV 2/5; 12/88] START leaf_size=20, n_neighbors=19, weights=distance............
[CV 2/5; 12/88] END leaf_size=20, n_neighbors=19, weights=distance;, score=0.502 total time=   5.1s
[CV 3/5; 12/88] START leaf_size=20, n_neighbors=19, weights=distance............
[CV 3/5; 12/88] END leaf_size=20, n_neighbors=19, weights=distance;, score=0.501 total time=   5.0s
[CV 4/5; 12/88] START leaf_size=20, n_neighbors=19, weights=distance............
[CV 4/5; 12/88] END leaf_size=20, n_neighbors=19, weights=distance;, score=0.500 total time=   5.0s
[CV 5/5; 12/88] START leaf_size=20, n_neighbors=19, weights=distance............
[CV 5/5; 12/88] END leaf_size=20, n_neighbors=19, weights=distance;, score=0.502 total time=   4.9s
[CV 1/5; 13/88] START leaf_size=20, n_neighbors=25, weights=uniform.............
[CV 1/5; 13/88] END leaf_size=20, n_neighbors=25, weights=uniform;, score=0.499 total time=   5.5s
[CV 2/5; 13/88] START leaf_size=20, n_neighbors=25, weights=uniform.............
[CV 2/5; 13/88] END leaf_size=20, n_neighbors=25, weights=uniform;, score=0.501 total time=   5.2s
[CV 3/5; 13/88] START leaf_size=20, n_neighbors=25, weights=uniform.............
[CV 3/5; 13/88] END leaf_size=20, n_neighbors=25, weights=uniform;, score=0.499 total time=   5.3s
[CV 4/5; 13/88] START leaf_size=20, n_neighbors=25, weights=uniform.............
[CV 4/5; 13/88] END leaf_size=20, n_neighbors=25, weights=uniform;, score=0.502 total time=   5.5s
[CV 5/5; 13/88] START leaf_size=20, n_neighbors=25, weights=uniform.............
[CV 5/5; 13/88] END leaf_size=20, n_neighbors=25, weights=uniform;, score=0.501 total time=   5.4s
[CV 1/5; 14/88] START leaf_size=20, n_neighbors=25, weights=distance............
[CV 1/5; 14/88] END leaf_size=20, n_neighbors=25, weights=distance;, score=0.499 total time=   5.2s
[CV 2/5; 14/88] START leaf_size=20, n_neighbors=25, weights=distance............
[CV 2/5; 14/88] END leaf_size=20, n_neighbors=25, weights=distance;, score=0.501 total time=   5.3s
[CV 3/5; 14/88] START leaf_size=20, n_neighbors=25, weights=distance............
[CV 3/5; 14/88] END leaf_size=20, n_neighbors=25, weights=distance;, score=0.499 total time=   5.2s
[CV 4/5; 14/88] START leaf_size=20, n_neighbors=25, weights=distance............
[CV 4/5; 14/88] END leaf_size=20, n_neighbors=25, weights=distance;, score=0.501 total time=   5.3s
[CV 5/5; 14/88] START leaf_size=20, n_neighbors=25, weights=distance............
[CV 5/5; 14/88] END leaf_size=20, n_neighbors=25, weights=distance;, score=0.501 total time=   5.2s
[CV 1/5; 15/88] START leaf_size=20, n_neighbors=35, weights=uniform.............
[CV 1/5; 15/88] END leaf_size=20, n_neighbors=35, weights=uniform;, score=0.500 total time=   5.4s
[CV 2/5; 15/88] START leaf_size=20, n_neighbors=35, weights=uniform.............
[CV 2/5; 15/88] END leaf_size=20, n_neighbors=35, weights=uniform;, score=0.500 total time=   5.0s
[CV 3/5; 15/88] START leaf_size=20, n_neighbors=35, weights=uniform.............
[CV 3/5; 15/88] END leaf_size=20, n_neighbors=35, weights=uniform;, score=0.500 total time=   5.1s
[CV 4/5; 15/88] START leaf_size=20, n_neighbors=35, weights=uniform.............
[CV 4/5; 15/88] END leaf_size=20, n_neighbors=35, weights=uniform;, score=0.500 total time=   5.3s
[CV 5/5; 15/88] START leaf_size=20, n_neighbors=35, weights=uniform.............
[CV 5/5; 15/88] END leaf_size=20, n_neighbors=35, weights=uniform;, score=0.501 total time=   5.4s
[CV 1/5; 16/88] START leaf_size=20, n_neighbors=35, weights=distance............
[CV 1/5; 16/88] END leaf_size=20, n_neighbors=35, weights=distance;, score=0.500 total time=   5.6s
[CV 2/5; 16/88] START leaf_size=20, n_neighbors=35, weights=distance............
[CV 2/5; 16/88] END leaf_size=20, n_neighbors=35, weights=distance;, score=0.500 total time=   5.1s
[CV 3/5; 16/88] START leaf_size=20, n_neighbors=35, weights=distance............
[CV 3/5; 16/88] END leaf_size=20, n_neighbors=35, weights=distance;, score=0.500 total time=   5.0s
[CV 4/5; 16/88] START leaf_size=20, n_neighbors=35, weights=distance............
[CV 4/5; 16/88] END leaf_size=20, n_neighbors=35, weights=distance;, score=0.500 total time=   5.1s
[CV 5/5; 16/88] START leaf_size=20, n_neighbors=35, weights=distance............
[CV 5/5; 16/88] END leaf_size=20, n_neighbors=35, weights=distance;, score=0.501 total time=   5.0s
[CV 1/5; 17/88] START leaf_size=20, n_neighbors=55, weights=uniform.............
[CV 1/5; 17/88] END leaf_size=20, n_neighbors=55, weights=uniform;, score=0.500 total time=   5.3s
[CV 2/5; 17/88] START leaf_size=20, n_neighbors=55, weights=uniform.............
[CV 2/5; 17/88] END leaf_size=20, n_neighbors=55, weights=uniform;, score=0.500 total time=   5.2s
[CV 3/5; 17/88] START leaf_size=20, n_neighbors=55, weights=uniform.............
[CV 3/5; 17/88] END leaf_size=20, n_neighbors=55, weights=uniform;, score=0.501 total time=   5.0s
[CV 4/5; 17/88] START leaf_size=20, n_neighbors=55, weights=uniform.............
[CV 4/5; 17/88] END leaf_size=20, n_neighbors=55, weights=uniform;, score=0.500 total time=   5.2s
[CV 5/5; 17/88] START leaf_size=20, n_neighbors=55, weights=uniform.............
[CV 5/5; 17/88] END leaf_size=20, n_neighbors=55, weights=uniform;, score=0.500 total time=   4.9s
[CV 1/5; 18/88] START leaf_size=20, n_neighbors=55, weights=distance............
[CV 1/5; 18/88] END leaf_size=20, n_neighbors=55, weights=distance;, score=0.500 total time=   5.0s
[CV 2/5; 18/88] START leaf_size=20, n_neighbors=55, weights=distance............
[CV 2/5; 18/88] END leaf_size=20, n_neighbors=55, weights=distance;, score=0.500 total time=   5.0s
[CV 3/5; 18/88] START leaf_size=20, n_neighbors=55, weights=distance............
[CV 3/5; 18/88] END leaf_size=20, n_neighbors=55, weights=distance;, score=0.500 total time=   5.0s
[CV 4/5; 18/88] START leaf_size=20, n_neighbors=55, weights=distance............
[CV 4/5; 18/88] END leaf_size=20, n_neighbors=55, weights=distance;, score=0.500 total time=   4.9s
[CV 5/5; 18/88] START leaf_size=20, n_neighbors=55, weights=distance............
[CV 5/5; 18/88] END leaf_size=20, n_neighbors=55, weights=distance;, score=0.500 total time=   5.4s
[CV 1/5; 19/88] START leaf_size=20, n_neighbors=75, weights=uniform.............
[CV 1/5; 19/88] END leaf_size=20, n_neighbors=75, weights=uniform;, score=0.500 total time=   5.6s
[CV 2/5; 19/88] START leaf_size=20, n_neighbors=75, weights=uniform.............
[CV 2/5; 19/88] END leaf_size=20, n_neighbors=75, weights=uniform;, score=0.500 total time=   6.0s
[CV 3/5; 19/88] START leaf_size=20, n_neighbors=75, weights=uniform.............
[CV 3/5; 19/88] END leaf_size=20, n_neighbors=75, weights=uniform;, score=0.500 total time=   5.6s
[CV 4/5; 19/88] START leaf_size=20, n_neighbors=75, weights=uniform.............
[CV 4/5; 19/88] END leaf_size=20, n_neighbors=75, weights=uniform;, score=0.500 total time=   5.4s
[CV 5/5; 19/88] START leaf_size=20, n_neighbors=75, weights=uniform.............
[CV 5/5; 19/88] END leaf_size=20, n_neighbors=75, weights=uniform;, score=0.500 total time=   5.4s
[CV 1/5; 20/88] START leaf_size=20, n_neighbors=75, weights=distance............
[CV 1/5; 20/88] END leaf_size=20, n_neighbors=75, weights=distance;, score=0.500 total time=   5.7s
[CV 2/5; 20/88] START leaf_size=20, n_neighbors=75, weights=distance............
[CV 2/5; 20/88] END leaf_size=20, n_neighbors=75, weights=distance;, score=0.500 total time=   5.9s
[CV 3/5; 20/88] START leaf_size=20, n_neighbors=75, weights=distance............
[CV 3/5; 20/88] END leaf_size=20, n_neighbors=75, weights=distance;, score=0.500 total time=   5.2s
[CV 4/5; 20/88] START leaf_size=20, n_neighbors=75, weights=distance............
[CV 4/5; 20/88] END leaf_size=20, n_neighbors=75, weights=distance;, score=0.500 total time=   5.1s
[CV 5/5; 20/88] START leaf_size=20, n_neighbors=75, weights=distance............
[CV 5/5; 20/88] END leaf_size=20, n_neighbors=75, weights=distance;, score=0.500 total time=   4.6s
[CV 1/5; 21/88] START leaf_size=20, n_neighbors=99, weights=uniform.............
[CV 1/5; 21/88] END leaf_size=20, n_neighbors=99, weights=uniform;, score=0.500 total time=   5.9s
[CV 2/5; 21/88] START leaf_size=20, n_neighbors=99, weights=uniform.............
[CV 2/5; 21/88] END leaf_size=20, n_neighbors=99, weights=uniform;, score=0.500 total time=   5.7s
[CV 3/5; 21/88] START leaf_size=20, n_neighbors=99, weights=uniform.............
[CV 3/5; 21/88] END leaf_size=20, n_neighbors=99, weights=uniform;, score=0.500 total time=   5.5s
[CV 4/5; 21/88] START leaf_size=20, n_neighbors=99, weights=uniform.............
[CV 4/5; 21/88] END leaf_size=20, n_neighbors=99, weights=uniform;, score=0.500 total time=   6.5s
[CV 5/5; 21/88] START leaf_size=20, n_neighbors=99, weights=uniform.............
[CV 5/5; 21/88] END leaf_size=20, n_neighbors=99, weights=uniform;, score=0.500 total time=   4.8s
[CV 1/5; 22/88] START leaf_size=20, n_neighbors=99, weights=distance............
[CV 1/5; 22/88] END leaf_size=20, n_neighbors=99, weights=distance;, score=0.500 total time=   5.3s
[CV 2/5; 22/88] START leaf_size=20, n_neighbors=99, weights=distance............
[CV 2/5; 22/88] END leaf_size=20, n_neighbors=99, weights=distance;, score=0.500 total time=   6.5s
[CV 3/5; 22/88] START leaf_size=20, n_neighbors=99, weights=distance............
[CV 3/5; 22/88] END leaf_size=20, n_neighbors=99, weights=distance;, score=0.500 total time=   5.1s
[CV 4/5; 22/88] START leaf_size=20, n_neighbors=99, weights=distance............
[CV 4/5; 22/88] END leaf_size=20, n_neighbors=99, weights=distance;, score=0.500 total time=   4.9s
[CV 5/5; 22/88] START leaf_size=20, n_neighbors=99, weights=distance............
[CV 5/5; 22/88] END leaf_size=20, n_neighbors=99, weights=distance;, score=0.500 total time=   5.5s
[CV 1/5; 23/88] START leaf_size=30, n_neighbors=3, weights=uniform..............
[CV 1/5; 23/88] END leaf_size=30, n_neighbors=3, weights=uniform;, score=0.504 total time=   4.5s
[CV 2/5; 23/88] START leaf_size=30, n_neighbors=3, weights=uniform..............
[CV 2/5; 23/88] END leaf_size=30, n_neighbors=3, weights=uniform;, score=0.510 total time=   4.6s
[CV 3/5; 23/88] START leaf_size=30, n_neighbors=3, weights=uniform..............
[CV 3/5; 23/88] END leaf_size=30, n_neighbors=3, weights=uniform;, score=0.504 total time=   4.5s
[CV 4/5; 23/88] START leaf_size=30, n_neighbors=3, weights=uniform..............
[CV 4/5; 23/88] END leaf_size=30, n_neighbors=3, weights=uniform;, score=0.506 total time=   4.8s
[CV 5/5; 23/88] START leaf_size=30, n_neighbors=3, weights=uniform..............
[CV 5/5; 23/88] END leaf_size=30, n_neighbors=3, weights=uniform;, score=0.501 total time=   4.4s
[CV 1/5; 24/88] START leaf_size=30, n_neighbors=3, weights=distance.............
[CV 1/5; 24/88] END leaf_size=30, n_neighbors=3, weights=distance;, score=0.504 total time=   4.6s
[CV 2/5; 24/88] START leaf_size=30, n_neighbors=3, weights=distance.............
[CV 2/5; 24/88] END leaf_size=30, n_neighbors=3, weights=distance;, score=0.510 total time=   4.3s
[CV 3/5; 24/88] START leaf_size=30, n_neighbors=3, weights=distance.............
[CV 3/5; 24/88] END leaf_size=30, n_neighbors=3, weights=distance;, score=0.504 total time=   4.4s
[CV 4/5; 24/88] START leaf_size=30, n_neighbors=3, weights=distance.............
[CV 4/5; 24/88] END leaf_size=30, n_neighbors=3, weights=distance;, score=0.506 total time=   4.3s
[CV 5/5; 24/88] START leaf_size=30, n_neighbors=3, weights=distance.............
[CV 5/5; 24/88] END leaf_size=30, n_neighbors=3, weights=distance;, score=0.500 total time=   4.6s
[CV 1/5; 25/88] START leaf_size=30, n_neighbors=5, weights=uniform..............
[CV 1/5; 25/88] END leaf_size=30, n_neighbors=5, weights=uniform;, score=0.500 total time=   5.9s
[CV 2/5; 25/88] START leaf_size=30, n_neighbors=5, weights=uniform..............
[CV 2/5; 25/88] END leaf_size=30, n_neighbors=5, weights=uniform;, score=0.515 total time=   6.3s
[CV 3/5; 25/88] START leaf_size=30, n_neighbors=5, weights=uniform..............
[CV 3/5; 25/88] END leaf_size=30, n_neighbors=5, weights=uniform;, score=0.507 total time=   5.9s
[CV 4/5; 25/88] START leaf_size=30, n_neighbors=5, weights=uniform..............
[CV 4/5; 25/88] END leaf_size=30, n_neighbors=5, weights=uniform;, score=0.506 total time=   6.2s
[CV 5/5; 25/88] START leaf_size=30, n_neighbors=5, weights=uniform..............
[CV 5/5; 25/88] END leaf_size=30, n_neighbors=5, weights=uniform;, score=0.498 total time=   5.7s
[CV 1/5; 26/88] START leaf_size=30, n_neighbors=5, weights=distance.............
[CV 1/5; 26/88] END leaf_size=30, n_neighbors=5, weights=distance;, score=0.500 total time=   5.8s
[CV 2/5; 26/88] START leaf_size=30, n_neighbors=5, weights=distance.............
[CV 2/5; 26/88] END leaf_size=30, n_neighbors=5, weights=distance;, score=0.515 total time=   5.3s
[CV 3/5; 26/88] START leaf_size=30, n_neighbors=5, weights=distance.............
[CV 3/5; 26/88] END leaf_size=30, n_neighbors=5, weights=distance;, score=0.506 total time=   5.8s
[CV 4/5; 26/88] START leaf_size=30, n_neighbors=5, weights=distance.............
[CV 4/5; 26/88] END leaf_size=30, n_neighbors=5, weights=distance;, score=0.506 total time=   5.5s
[CV 5/5; 26/88] START leaf_size=30, n_neighbors=5, weights=distance.............
[CV 5/5; 26/88] END leaf_size=30, n_neighbors=5, weights=distance;, score=0.498 total time=   5.7s
[CV 1/5; 27/88] START leaf_size=30, n_neighbors=7, weights=uniform..............
[CV 1/5; 27/88] END leaf_size=30, n_neighbors=7, weights=uniform;, score=0.503 total time=   5.5s
[CV 2/5; 27/88] START leaf_size=30, n_neighbors=7, weights=uniform..............
[CV 2/5; 27/88] END leaf_size=30, n_neighbors=7, weights=uniform;, score=0.506 total time=   5.4s
[CV 3/5; 27/88] START leaf_size=30, n_neighbors=7, weights=uniform..............
[CV 3/5; 27/88] END leaf_size=30, n_neighbors=7, weights=uniform;, score=0.502 total time=   5.1s
[CV 4/5; 27/88] START leaf_size=30, n_neighbors=7, weights=uniform..............
[CV 4/5; 27/88] END leaf_size=30, n_neighbors=7, weights=uniform;, score=0.505 total time=   5.5s
[CV 5/5; 27/88] START leaf_size=30, n_neighbors=7, weights=uniform..............
[CV 5/5; 27/88] END leaf_size=30, n_neighbors=7, weights=uniform;, score=0.507 total time=   4.9s
[CV 1/5; 28/88] START leaf_size=30, n_neighbors=7, weights=distance.............
[CV 1/5; 28/88] END leaf_size=30, n_neighbors=7, weights=distance;, score=0.503 total time=   5.0s
[CV 2/5; 28/88] START leaf_size=30, n_neighbors=7, weights=distance.............
[CV 2/5; 28/88] END leaf_size=30, n_neighbors=7, weights=distance;, score=0.506 total time=   4.8s
[CV 3/5; 28/88] START leaf_size=30, n_neighbors=7, weights=distance.............
[CV 3/5; 28/88] END leaf_size=30, n_neighbors=7, weights=distance;, score=0.502 total time=   5.2s
[CV 4/5; 28/88] START leaf_size=30, n_neighbors=7, weights=distance.............
[CV 4/5; 28/88] END leaf_size=30, n_neighbors=7, weights=distance;, score=0.504 total time=   5.0s
[CV 5/5; 28/88] START leaf_size=30, n_neighbors=7, weights=distance.............
[CV 5/5; 28/88] END leaf_size=30, n_neighbors=7, weights=distance;, score=0.507 total time=   5.1s
[CV 1/5; 29/88] START leaf_size=30, n_neighbors=9, weights=uniform..............
[CV 1/5; 29/88] END leaf_size=30, n_neighbors=9, weights=uniform;, score=0.505 total time=   5.8s
[CV 2/5; 29/88] START leaf_size=30, n_neighbors=9, weights=uniform..............
[CV 2/5; 29/88] END leaf_size=30, n_neighbors=9, weights=uniform;, score=0.507 total time=   5.6s
[CV 3/5; 29/88] START leaf_size=30, n_neighbors=9, weights=uniform..............
[CV 3/5; 29/88] END leaf_size=30, n_neighbors=9, weights=uniform;, score=0.504 total time=   5.1s
[CV 4/5; 29/88] START leaf_size=30, n_neighbors=9, weights=uniform..............
[CV 4/5; 29/88] END leaf_size=30, n_neighbors=9, weights=uniform;, score=0.500 total time=   5.5s
[CV 5/5; 29/88] START leaf_size=30, n_neighbors=9, weights=uniform..............
[CV 5/5; 29/88] END leaf_size=30, n_neighbors=9, weights=uniform;, score=0.507 total time=   5.5s
[CV 1/5; 30/88] START leaf_size=30, n_neighbors=9, weights=distance.............
[CV 1/5; 30/88] END leaf_size=30, n_neighbors=9, weights=distance;, score=0.505 total time=   5.2s
[CV 2/5; 30/88] START leaf_size=30, n_neighbors=9, weights=distance.............
[CV 2/5; 30/88] END leaf_size=30, n_neighbors=9, weights=distance;, score=0.508 total time=   5.0s
[CV 3/5; 30/88] START leaf_size=30, n_neighbors=9, weights=distance.............
[CV 3/5; 30/88] END leaf_size=30, n_neighbors=9, weights=distance;, score=0.504 total time=   5.0s
[CV 4/5; 30/88] START leaf_size=30, n_neighbors=9, weights=distance.............
[CV 4/5; 30/88] END leaf_size=30, n_neighbors=9, weights=distance;, score=0.500 total time=   5.5s
[CV 5/5; 30/88] START leaf_size=30, n_neighbors=9, weights=distance.............
[CV 5/5; 30/88] END leaf_size=30, n_neighbors=9, weights=distance;, score=0.507 total time=   4.8s
[CV 1/5; 31/88] START leaf_size=30, n_neighbors=15, weights=uniform.............
[CV 1/5; 31/88] END leaf_size=30, n_neighbors=15, weights=uniform;, score=0.503 total time=   5.2s
[CV 2/5; 31/88] START leaf_size=30, n_neighbors=15, weights=uniform.............
[CV 2/5; 31/88] END leaf_size=30, n_neighbors=15, weights=uniform;, score=0.503 total time=   5.5s
[CV 3/5; 31/88] START leaf_size=30, n_neighbors=15, weights=uniform.............
[CV 3/5; 31/88] END leaf_size=30, n_neighbors=15, weights=uniform;, score=0.500 total time=   5.6s
[CV 4/5; 31/88] START leaf_size=30, n_neighbors=15, weights=uniform.............
[CV 4/5; 31/88] END leaf_size=30, n_neighbors=15, weights=uniform;, score=0.500 total time=   5.1s
[CV 5/5; 31/88] START leaf_size=30, n_neighbors=15, weights=uniform.............
[CV 5/5; 31/88] END leaf_size=30, n_neighbors=15, weights=uniform;, score=0.503 total time=   5.1s
[CV 1/5; 32/88] START leaf_size=30, n_neighbors=15, weights=distance............
[CV 1/5; 32/88] END leaf_size=30, n_neighbors=15, weights=distance;, score=0.503 total time=   5.0s
[CV 2/5; 32/88] START leaf_size=30, n_neighbors=15, weights=distance............
[CV 2/5; 32/88] END leaf_size=30, n_neighbors=15, weights=distance;, score=0.503 total time=   5.0s
[CV 3/5; 32/88] START leaf_size=30, n_neighbors=15, weights=distance............
[CV 3/5; 32/88] END leaf_size=30, n_neighbors=15, weights=distance;, score=0.500 total time=   4.9s
[CV 4/5; 32/88] START leaf_size=30, n_neighbors=15, weights=distance............
[CV 4/5; 32/88] END leaf_size=30, n_neighbors=15, weights=distance;, score=0.501 total time=   5.2s
[CV 5/5; 32/88] START leaf_size=30, n_neighbors=15, weights=distance............
[CV 5/5; 32/88] END leaf_size=30, n_neighbors=15, weights=distance;, score=0.503 total time=   5.5s
[CV 1/5; 33/88] START leaf_size=30, n_neighbors=19, weights=uniform.............
[CV 1/5; 33/88] END leaf_size=30, n_neighbors=19, weights=uniform;, score=0.501 total time=   5.5s
[CV 2/5; 33/88] START leaf_size=30, n_neighbors=19, weights=uniform.............
[CV 2/5; 33/88] END leaf_size=30, n_neighbors=19, weights=uniform;, score=0.501 total time=   5.5s
[CV 3/5; 33/88] START leaf_size=30, n_neighbors=19, weights=uniform.............
[CV 3/5; 33/88] END leaf_size=30, n_neighbors=19, weights=uniform;, score=0.501 total time=   5.5s
[CV 4/5; 33/88] START leaf_size=30, n_neighbors=19, weights=uniform.............
[CV 4/5; 33/88] END leaf_size=30, n_neighbors=19, weights=uniform;, score=0.500 total time=   5.5s
[CV 5/5; 33/88] START leaf_size=30, n_neighbors=19, weights=uniform.............
[CV 5/5; 33/88] END leaf_size=30, n_neighbors=19, weights=uniform;, score=0.502 total time=   5.5s
[CV 1/5; 34/88] START leaf_size=30, n_neighbors=19, weights=distance............
[CV 1/5; 34/88] END leaf_size=30, n_neighbors=19, weights=distance;, score=0.501 total time=   5.4s
[CV 2/5; 34/88] START leaf_size=30, n_neighbors=19, weights=distance............
[CV 2/5; 34/88] END leaf_size=30, n_neighbors=19, weights=distance;, score=0.502 total time=   5.1s
[CV 3/5; 34/88] START leaf_size=30, n_neighbors=19, weights=distance............
[CV 3/5; 34/88] END leaf_size=30, n_neighbors=19, weights=distance;, score=0.501 total time=   5.0s
[CV 4/5; 34/88] START leaf_size=30, n_neighbors=19, weights=distance............
[CV 4/5; 34/88] END leaf_size=30, n_neighbors=19, weights=distance;, score=0.500 total time=   4.9s
[CV 5/5; 34/88] START leaf_size=30, n_neighbors=19, weights=distance............
[CV 5/5; 34/88] END leaf_size=30, n_neighbors=19, weights=distance;, score=0.502 total time=   5.1s
[CV 1/5; 35/88] START leaf_size=30, n_neighbors=25, weights=uniform.............
[CV 1/5; 35/88] END leaf_size=30, n_neighbors=25, weights=uniform;, score=0.499 total time=   5.5s
[CV 2/5; 35/88] START leaf_size=30, n_neighbors=25, weights=uniform.............
[CV 2/5; 35/88] END leaf_size=30, n_neighbors=25, weights=uniform;, score=0.501 total time=   5.6s
[CV 3/5; 35/88] START leaf_size=30, n_neighbors=25, weights=uniform.............
[CV 3/5; 35/88] END leaf_size=30, n_neighbors=25, weights=uniform;, score=0.499 total time=   5.5s
[CV 4/5; 35/88] START leaf_size=30, n_neighbors=25, weights=uniform.............
[CV 4/5; 35/88] END leaf_size=30, n_neighbors=25, weights=uniform;, score=0.502 total time=   5.4s
[CV 5/5; 35/88] START leaf_size=30, n_neighbors=25, weights=uniform.............
[CV 5/5; 35/88] END leaf_size=30, n_neighbors=25, weights=uniform;, score=0.501 total time=   5.4s
[CV 1/5; 36/88] START leaf_size=30, n_neighbors=25, weights=distance............
[CV 1/5; 36/88] END leaf_size=30, n_neighbors=25, weights=distance;, score=0.499 total time=   5.4s
[CV 2/5; 36/88] START leaf_size=30, n_neighbors=25, weights=distance............
[CV 2/5; 36/88] END leaf_size=30, n_neighbors=25, weights=distance;, score=0.501 total time=   6.1s
[CV 3/5; 36/88] START leaf_size=30, n_neighbors=25, weights=distance............
[CV 3/5; 36/88] END leaf_size=30, n_neighbors=25, weights=distance;, score=0.499 total time=   5.9s
[CV 4/5; 36/88] START leaf_size=30, n_neighbors=25, weights=distance............
[CV 4/5; 36/88] END leaf_size=30, n_neighbors=25, weights=distance;, score=0.501 total time=   4.9s
[CV 5/5; 36/88] START leaf_size=30, n_neighbors=25, weights=distance............
[CV 5/5; 36/88] END leaf_size=30, n_neighbors=25, weights=distance;, score=0.501 total time=   6.2s
[CV 1/5; 37/88] START leaf_size=30, n_neighbors=35, weights=uniform.............
[CV 1/5; 37/88] END leaf_size=30, n_neighbors=35, weights=uniform;, score=0.500 total time=   7.1s
[CV 2/5; 37/88] START leaf_size=30, n_neighbors=35, weights=uniform.............
[CV 2/5; 37/88] END leaf_size=30, n_neighbors=35, weights=uniform;, score=0.500 total time=   6.4s
[CV 3/5; 37/88] START leaf_size=30, n_neighbors=35, weights=uniform.............
[CV 3/5; 37/88] END leaf_size=30, n_neighbors=35, weights=uniform;, score=0.500 total time=   6.9s
[CV 4/5; 37/88] START leaf_size=30, n_neighbors=35, weights=uniform.............
[CV 4/5; 37/88] END leaf_size=30, n_neighbors=35, weights=uniform;, score=0.500 total time=   6.4s
[CV 5/5; 37/88] START leaf_size=30, n_neighbors=35, weights=uniform.............
[CV 5/5; 37/88] END leaf_size=30, n_neighbors=35, weights=uniform;, score=0.501 total time=   6.2s
[CV 1/5; 38/88] START leaf_size=30, n_neighbors=35, weights=distance............
[CV 1/5; 38/88] END leaf_size=30, n_neighbors=35, weights=distance;, score=0.500 total time=   6.9s
[CV 2/5; 38/88] START leaf_size=30, n_neighbors=35, weights=distance............
[CV 2/5; 38/88] END leaf_size=30, n_neighbors=35, weights=distance;, score=0.500 total time=   6.8s
[CV 3/5; 38/88] START leaf_size=30, n_neighbors=35, weights=distance............
[CV 3/5; 38/88] END leaf_size=30, n_neighbors=35, weights=distance;, score=0.500 total time=   6.2s
[CV 4/5; 38/88] START leaf_size=30, n_neighbors=35, weights=distance............
[CV 4/5; 38/88] END leaf_size=30, n_neighbors=35, weights=distance;, score=0.500 total time=   5.5s
[CV 5/5; 38/88] START leaf_size=30, n_neighbors=35, weights=distance............
[CV 5/5; 38/88] END leaf_size=30, n_neighbors=35, weights=distance;, score=0.501 total time=   5.1s
[CV 1/5; 39/88] START leaf_size=30, n_neighbors=55, weights=uniform.............
[CV 1/5; 39/88] END leaf_size=30, n_neighbors=55, weights=uniform;, score=0.500 total time=   4.9s
[CV 2/5; 39/88] START leaf_size=30, n_neighbors=55, weights=uniform.............
[CV 2/5; 39/88] END leaf_size=30, n_neighbors=55, weights=uniform;, score=0.500 total time=   5.3s
[CV 3/5; 39/88] START leaf_size=30, n_neighbors=55, weights=uniform.............
[CV 3/5; 39/88] END leaf_size=30, n_neighbors=55, weights=uniform;, score=0.501 total time=   5.3s
[CV 4/5; 39/88] START leaf_size=30, n_neighbors=55, weights=uniform.............
[CV 4/5; 39/88] END leaf_size=30, n_neighbors=55, weights=uniform;, score=0.500 total time=   6.3s
[CV 5/5; 39/88] START leaf_size=30, n_neighbors=55, weights=uniform.............
[CV 5/5; 39/88] END leaf_size=30, n_neighbors=55, weights=uniform;, score=0.500 total time=   6.4s
[CV 1/5; 40/88] START leaf_size=30, n_neighbors=55, weights=distance............
[CV 1/5; 40/88] END leaf_size=30, n_neighbors=55, weights=distance;, score=0.500 total time=   6.2s
[CV 2/5; 40/88] START leaf_size=30, n_neighbors=55, weights=distance............
[CV 2/5; 40/88] END leaf_size=30, n_neighbors=55, weights=distance;, score=0.500 total time=   6.0s
[CV 3/5; 40/88] START leaf_size=30, n_neighbors=55, weights=distance............
[CV 3/5; 40/88] END leaf_size=30, n_neighbors=55, weights=distance;, score=0.500 total time=   6.0s
[CV 4/5; 40/88] START leaf_size=30, n_neighbors=55, weights=distance............
[CV 4/5; 40/88] END leaf_size=30, n_neighbors=55, weights=distance;, score=0.500 total time=   6.2s
[CV 5/5; 40/88] START leaf_size=30, n_neighbors=55, weights=distance............
[CV 5/5; 40/88] END leaf_size=30, n_neighbors=55, weights=distance;, score=0.500 total time=   5.7s
[CV 1/5; 41/88] START leaf_size=30, n_neighbors=75, weights=uniform.............
[CV 1/5; 41/88] END leaf_size=30, n_neighbors=75, weights=uniform;, score=0.500 total time=   6.3s
[CV 2/5; 41/88] START leaf_size=30, n_neighbors=75, weights=uniform.............
[CV 2/5; 41/88] END leaf_size=30, n_neighbors=75, weights=uniform;, score=0.500 total time=   6.0s
[CV 3/5; 41/88] START leaf_size=30, n_neighbors=75, weights=uniform.............
[CV 3/5; 41/88] END leaf_size=30, n_neighbors=75, weights=uniform;, score=0.500 total time=   6.6s
[CV 4/5; 41/88] START leaf_size=30, n_neighbors=75, weights=uniform.............
[CV 4/5; 41/88] END leaf_size=30, n_neighbors=75, weights=uniform;, score=0.500 total time=   6.4s
[CV 5/5; 41/88] START leaf_size=30, n_neighbors=75, weights=uniform.............
[CV 5/5; 41/88] END leaf_size=30, n_neighbors=75, weights=uniform;, score=0.500 total time=   6.1s
[CV 1/5; 42/88] START leaf_size=30, n_neighbors=75, weights=distance............
[CV 1/5; 42/88] END leaf_size=30, n_neighbors=75, weights=distance;, score=0.500 total time=   6.6s
[CV 2/5; 42/88] START leaf_size=30, n_neighbors=75, weights=distance............
[CV 2/5; 42/88] END leaf_size=30, n_neighbors=75, weights=distance;, score=0.500 total time=   6.6s
[CV 3/5; 42/88] START leaf_size=30, n_neighbors=75, weights=distance............
[CV 3/5; 42/88] END leaf_size=30, n_neighbors=75, weights=distance;, score=0.500 total time=   5.6s
[CV 4/5; 42/88] START leaf_size=30, n_neighbors=75, weights=distance............
[CV 4/5; 42/88] END leaf_size=30, n_neighbors=75, weights=distance;, score=0.500 total time=   5.8s
[CV 5/5; 42/88] START leaf_size=30, n_neighbors=75, weights=distance............
[CV 5/5; 42/88] END leaf_size=30, n_neighbors=75, weights=distance;, score=0.500 total time=   4.8s
[CV 1/5; 43/88] START leaf_size=30, n_neighbors=99, weights=uniform.............
[CV 1/5; 43/88] END leaf_size=30, n_neighbors=99, weights=uniform;, score=0.500 total time=   4.8s
[CV 2/5; 43/88] START leaf_size=30, n_neighbors=99, weights=uniform.............
[CV 2/5; 43/88] END leaf_size=30, n_neighbors=99, weights=uniform;, score=0.500 total time=   4.8s
[CV 3/5; 43/88] START leaf_size=30, n_neighbors=99, weights=uniform.............
[CV 3/5; 43/88] END leaf_size=30, n_neighbors=99, weights=uniform;, score=0.500 total time=   4.8s
[CV 4/5; 43/88] START leaf_size=30, n_neighbors=99, weights=uniform.............
[CV 4/5; 43/88] END leaf_size=30, n_neighbors=99, weights=uniform;, score=0.500 total time=   4.7s
[CV 5/5; 43/88] START leaf_size=30, n_neighbors=99, weights=uniform.............
[CV 5/5; 43/88] END leaf_size=30, n_neighbors=99, weights=uniform;, score=0.500 total time=   4.7s
[CV 1/5; 44/88] START leaf_size=30, n_neighbors=99, weights=distance............
[CV 1/5; 44/88] END leaf_size=30, n_neighbors=99, weights=distance;, score=0.500 total time=   5.3s
[CV 2/5; 44/88] START leaf_size=30, n_neighbors=99, weights=distance............
[CV 2/5; 44/88] END leaf_size=30, n_neighbors=99, weights=distance;, score=0.500 total time=   5.6s
[CV 3/5; 44/88] START leaf_size=30, n_neighbors=99, weights=distance............
[CV 3/5; 44/88] END leaf_size=30, n_neighbors=99, weights=distance;, score=0.500 total time=   5.9s
[CV 4/5; 44/88] START leaf_size=30, n_neighbors=99, weights=distance............
[CV 4/5; 44/88] END leaf_size=30, n_neighbors=99, weights=distance;, score=0.500 total time=   5.8s
[CV 5/5; 44/88] START leaf_size=30, n_neighbors=99, weights=distance............
[CV 5/5; 44/88] END leaf_size=30, n_neighbors=99, weights=distance;, score=0.500 total time=   6.2s
[CV 1/5; 45/88] START leaf_size=50, n_neighbors=3, weights=uniform..............
[CV 1/5; 45/88] END leaf_size=50, n_neighbors=3, weights=uniform;, score=0.504 total time=   4.7s
[CV 2/5; 45/88] START leaf_size=50, n_neighbors=3, weights=uniform..............
[CV 2/5; 45/88] END leaf_size=50, n_neighbors=3, weights=uniform;, score=0.510 total time=   5.1s
[CV 3/5; 45/88] START leaf_size=50, n_neighbors=3, weights=uniform..............
[CV 3/5; 45/88] END leaf_size=50, n_neighbors=3, weights=uniform;, score=0.504 total time=   4.6s
[CV 4/5; 45/88] START leaf_size=50, n_neighbors=3, weights=uniform..............
[CV 4/5; 45/88] END leaf_size=50, n_neighbors=3, weights=uniform;, score=0.506 total time=   4.8s
[CV 5/5; 45/88] START leaf_size=50, n_neighbors=3, weights=uniform..............
[CV 5/5; 45/88] END leaf_size=50, n_neighbors=3, weights=uniform;, score=0.501 total time=   4.5s
[CV 1/5; 46/88] START leaf_size=50, n_neighbors=3, weights=distance.............
[CV 1/5; 46/88] END leaf_size=50, n_neighbors=3, weights=distance;, score=0.504 total time=   3.7s
[CV 2/5; 46/88] START leaf_size=50, n_neighbors=3, weights=distance.............
[CV 2/5; 46/88] END leaf_size=50, n_neighbors=3, weights=distance;, score=0.510 total time=   4.2s
[CV 3/5; 46/88] START leaf_size=50, n_neighbors=3, weights=distance.............
[CV 3/5; 46/88] END leaf_size=50, n_neighbors=3, weights=distance;, score=0.504 total time=   3.8s
[CV 4/5; 46/88] START leaf_size=50, n_neighbors=3, weights=distance.............
[CV 4/5; 46/88] END leaf_size=50, n_neighbors=3, weights=distance;, score=0.506 total time=   3.8s
[CV 5/5; 46/88] START leaf_size=50, n_neighbors=3, weights=distance.............
[CV 5/5; 46/88] END leaf_size=50, n_neighbors=3, weights=distance;, score=0.500 total time=   4.1s
[CV 1/5; 47/88] START leaf_size=50, n_neighbors=5, weights=uniform..............
[CV 1/5; 47/88] END leaf_size=50, n_neighbors=5, weights=uniform;, score=0.500 total time=   4.8s
[CV 2/5; 47/88] START leaf_size=50, n_neighbors=5, weights=uniform..............
[CV 2/5; 47/88] END leaf_size=50, n_neighbors=5, weights=uniform;, score=0.515 total time=   4.8s
[CV 3/5; 47/88] START leaf_size=50, n_neighbors=5, weights=uniform..............
[CV 3/5; 47/88] END leaf_size=50, n_neighbors=5, weights=uniform;, score=0.507 total time=   4.9s
[CV 4/5; 47/88] START leaf_size=50, n_neighbors=5, weights=uniform..............
[CV 4/5; 47/88] END leaf_size=50, n_neighbors=5, weights=uniform;, score=0.506 total time=   4.7s
[CV 5/5; 47/88] START leaf_size=50, n_neighbors=5, weights=uniform..............
[CV 5/5; 47/88] END leaf_size=50, n_neighbors=5, weights=uniform;, score=0.498 total time=   4.9s
[CV 1/5; 48/88] START leaf_size=50, n_neighbors=5, weights=distance.............
[CV 1/5; 48/88] END leaf_size=50, n_neighbors=5, weights=distance;, score=0.500 total time=   4.9s
[CV 2/5; 48/88] START leaf_size=50, n_neighbors=5, weights=distance.............
[CV 2/5; 48/88] END leaf_size=50, n_neighbors=5, weights=distance;, score=0.515 total time=   4.6s
[CV 3/5; 48/88] START leaf_size=50, n_neighbors=5, weights=distance.............
[CV 3/5; 48/88] END leaf_size=50, n_neighbors=5, weights=distance;, score=0.506 total time=   4.6s
[CV 4/5; 48/88] START leaf_size=50, n_neighbors=5, weights=distance.............
[CV 4/5; 48/88] END leaf_size=50, n_neighbors=5, weights=distance;, score=0.506 total time=   4.7s
[CV 5/5; 48/88] START leaf_size=50, n_neighbors=5, weights=distance.............
[CV 5/5; 48/88] END leaf_size=50, n_neighbors=5, weights=distance;, score=0.498 total time=   4.5s
[CV 1/5; 49/88] START leaf_size=50, n_neighbors=7, weights=uniform..............
[CV 1/5; 49/88] END leaf_size=50, n_neighbors=7, weights=uniform;, score=0.503 total time=   4.9s
[CV 2/5; 49/88] START leaf_size=50, n_neighbors=7, weights=uniform..............
[CV 2/5; 49/88] END leaf_size=50, n_neighbors=7, weights=uniform;, score=0.506 total time=   5.3s
[CV 3/5; 49/88] START leaf_size=50, n_neighbors=7, weights=uniform..............
[CV 3/5; 49/88] END leaf_size=50, n_neighbors=7, weights=uniform;, score=0.502 total time=   4.9s
[CV 4/5; 49/88] START leaf_size=50, n_neighbors=7, weights=uniform..............
[CV 4/5; 49/88] END leaf_size=50, n_neighbors=7, weights=uniform;, score=0.505 total time=   4.9s
[CV 5/5; 49/88] START leaf_size=50, n_neighbors=7, weights=uniform..............
[CV 5/5; 49/88] END leaf_size=50, n_neighbors=7, weights=uniform;, score=0.507 total time=   4.8s
[CV 1/5; 50/88] START leaf_size=50, n_neighbors=7, weights=distance.............
[CV 1/5; 50/88] END leaf_size=50, n_neighbors=7, weights=distance;, score=0.503 total time=   4.5s
[CV 2/5; 50/88] START leaf_size=50, n_neighbors=7, weights=distance.............
[CV 2/5; 50/88] END leaf_size=50, n_neighbors=7, weights=distance;, score=0.506 total time=   4.7s
[CV 3/5; 50/88] START leaf_size=50, n_neighbors=7, weights=distance.............
[CV 3/5; 50/88] END leaf_size=50, n_neighbors=7, weights=distance;, score=0.502 total time=   4.9s
[CV 4/5; 50/88] START leaf_size=50, n_neighbors=7, weights=distance.............
[CV 4/5; 50/88] END leaf_size=50, n_neighbors=7, weights=distance;, score=0.504 total time=   5.0s
[CV 5/5; 50/88] START leaf_size=50, n_neighbors=7, weights=distance.............
[CV 5/5; 50/88] END leaf_size=50, n_neighbors=7, weights=distance;, score=0.507 total time=   4.6s
[CV 1/5; 51/88] START leaf_size=50, n_neighbors=9, weights=uniform..............
[CV 1/5; 51/88] END leaf_size=50, n_neighbors=9, weights=uniform;, score=0.505 total time=   5.0s
[CV 2/5; 51/88] START leaf_size=50, n_neighbors=9, weights=uniform..............
[CV 2/5; 51/88] END leaf_size=50, n_neighbors=9, weights=uniform;, score=0.507 total time=   5.3s
[CV 3/5; 51/88] START leaf_size=50, n_neighbors=9, weights=uniform..............
[CV 3/5; 51/88] END leaf_size=50, n_neighbors=9, weights=uniform;, score=0.504 total time=   5.3s
[CV 4/5; 51/88] START leaf_size=50, n_neighbors=9, weights=uniform..............
[CV 4/5; 51/88] END leaf_size=50, n_neighbors=9, weights=uniform;, score=0.500 total time=   6.6s
[CV 5/5; 51/88] START leaf_size=50, n_neighbors=9, weights=uniform..............
[CV 5/5; 51/88] END leaf_size=50, n_neighbors=9, weights=uniform;, score=0.507 total time=   6.7s
[CV 1/5; 52/88] START leaf_size=50, n_neighbors=9, weights=distance.............
[CV 1/5; 52/88] END leaf_size=50, n_neighbors=9, weights=distance;, score=0.505 total time=   6.2s
[CV 2/5; 52/88] START leaf_size=50, n_neighbors=9, weights=distance.............
[CV 2/5; 52/88] END leaf_size=50, n_neighbors=9, weights=distance;, score=0.508 total time=   6.5s
[CV 3/5; 52/88] START leaf_size=50, n_neighbors=9, weights=distance.............
[CV 3/5; 52/88] END leaf_size=50, n_neighbors=9, weights=distance;, score=0.504 total time=   6.5s
[CV 4/5; 52/88] START leaf_size=50, n_neighbors=9, weights=distance.............
[CV 4/5; 52/88] END leaf_size=50, n_neighbors=9, weights=distance;, score=0.500 total time=   6.2s
[CV 5/5; 52/88] START leaf_size=50, n_neighbors=9, weights=distance.............
[CV 5/5; 52/88] END leaf_size=50, n_neighbors=9, weights=distance;, score=0.507 total time=   6.3s
[CV 1/5; 53/88] START leaf_size=50, n_neighbors=15, weights=uniform.............
[CV 1/5; 53/88] END leaf_size=50, n_neighbors=15, weights=uniform;, score=0.503 total time=   6.2s
[CV 2/5; 53/88] START leaf_size=50, n_neighbors=15, weights=uniform.............
[CV 2/5; 53/88] END leaf_size=50, n_neighbors=15, weights=uniform;, score=0.503 total time=   6.8s
[CV 3/5; 53/88] START leaf_size=50, n_neighbors=15, weights=uniform.............
[CV 3/5; 53/88] END leaf_size=50, n_neighbors=15, weights=uniform;, score=0.500 total time=   7.4s
[CV 4/5; 53/88] START leaf_size=50, n_neighbors=15, weights=uniform.............
[CV 4/5; 53/88] END leaf_size=50, n_neighbors=15, weights=uniform;, score=0.500 total time=   6.8s
[CV 5/5; 53/88] START leaf_size=50, n_neighbors=15, weights=uniform.............
[CV 5/5; 53/88] END leaf_size=50, n_neighbors=15, weights=uniform;, score=0.503 total time=   6.5s
[CV 1/5; 54/88] START leaf_size=50, n_neighbors=15, weights=distance............
[CV 1/5; 54/88] END leaf_size=50, n_neighbors=15, weights=distance;, score=0.503 total time=   6.5s
[CV 2/5; 54/88] START leaf_size=50, n_neighbors=15, weights=distance............
[CV 2/5; 54/88] END leaf_size=50, n_neighbors=15, weights=distance;, score=0.503 total time=   6.9s
[CV 3/5; 54/88] START leaf_size=50, n_neighbors=15, weights=distance............
[CV 3/5; 54/88] END leaf_size=50, n_neighbors=15, weights=distance;, score=0.500 total time=   6.8s
[CV 4/5; 54/88] START leaf_size=50, n_neighbors=15, weights=distance............
[CV 4/5; 54/88] END leaf_size=50, n_neighbors=15, weights=distance;, score=0.501 total time=   6.5s
[CV 5/5; 54/88] START leaf_size=50, n_neighbors=15, weights=distance............
[CV 5/5; 54/88] END leaf_size=50, n_neighbors=15, weights=distance;, score=0.503 total time=   7.0s
[CV 1/5; 55/88] START leaf_size=50, n_neighbors=19, weights=uniform.............
[CV 1/5; 55/88] END leaf_size=50, n_neighbors=19, weights=uniform;, score=0.501 total time=   7.5s
[CV 2/5; 55/88] START leaf_size=50, n_neighbors=19, weights=uniform.............
[CV 2/5; 55/88] END leaf_size=50, n_neighbors=19, weights=uniform;, score=0.501 total time=   6.9s
[CV 3/5; 55/88] START leaf_size=50, n_neighbors=19, weights=uniform.............
[CV 3/5; 55/88] END leaf_size=50, n_neighbors=19, weights=uniform;, score=0.501 total time=   7.3s
[CV 4/5; 55/88] START leaf_size=50, n_neighbors=19, weights=uniform.............
[CV 4/5; 55/88] END leaf_size=50, n_neighbors=19, weights=uniform;, score=0.500 total time=   7.0s
[CV 5/5; 55/88] START leaf_size=50, n_neighbors=19, weights=uniform.............
[CV 5/5; 55/88] END leaf_size=50, n_neighbors=19, weights=uniform;, score=0.502 total time=   7.4s
[CV 1/5; 56/88] START leaf_size=50, n_neighbors=19, weights=distance............
[CV 1/5; 56/88] END leaf_size=50, n_neighbors=19, weights=distance;, score=0.501 total time=   7.0s
[CV 2/5; 56/88] START leaf_size=50, n_neighbors=19, weights=distance............
[CV 2/5; 56/88] END leaf_size=50, n_neighbors=19, weights=distance;, score=0.502 total time=   7.0s
[CV 3/5; 56/88] START leaf_size=50, n_neighbors=19, weights=distance............
[CV 3/5; 56/88] END leaf_size=50, n_neighbors=19, weights=distance;, score=0.501 total time=   6.1s
[CV 4/5; 56/88] START leaf_size=50, n_neighbors=19, weights=distance............
[CV 4/5; 56/88] END leaf_size=50, n_neighbors=19, weights=distance;, score=0.500 total time=   5.7s
[CV 5/5; 56/88] START leaf_size=50, n_neighbors=19, weights=distance............
[CV 5/5; 56/88] END leaf_size=50, n_neighbors=19, weights=distance;, score=0.502 total time=   6.1s
[CV 1/5; 57/88] START leaf_size=50, n_neighbors=25, weights=uniform.............
[CV 1/5; 57/88] END leaf_size=50, n_neighbors=25, weights=uniform;, score=0.499 total time=   5.8s
[CV 2/5; 57/88] START leaf_size=50, n_neighbors=25, weights=uniform.............
[CV 2/5; 57/88] END leaf_size=50, n_neighbors=25, weights=uniform;, score=0.501 total time=   7.3s
[CV 3/5; 57/88] START leaf_size=50, n_neighbors=25, weights=uniform.............
[CV 3/5; 57/88] END leaf_size=50, n_neighbors=25, weights=uniform;, score=0.499 total time=   7.2s
[CV 4/5; 57/88] START leaf_size=50, n_neighbors=25, weights=uniform.............
[CV 4/5; 57/88] END leaf_size=50, n_neighbors=25, weights=uniform;, score=0.502 total time=   7.3s
[CV 5/5; 57/88] START leaf_size=50, n_neighbors=25, weights=uniform.............
[CV 5/5; 57/88] END leaf_size=50, n_neighbors=25, weights=uniform;, score=0.501 total time=   7.5s
[CV 1/5; 58/88] START leaf_size=50, n_neighbors=25, weights=distance............
[CV 1/5; 58/88] END leaf_size=50, n_neighbors=25, weights=distance;, score=0.499 total time=   7.3s
[CV 2/5; 58/88] START leaf_size=50, n_neighbors=25, weights=distance............
[CV 2/5; 58/88] END leaf_size=50, n_neighbors=25, weights=distance;, score=0.501 total time=   6.2s
[CV 3/5; 58/88] START leaf_size=50, n_neighbors=25, weights=distance............
[CV 3/5; 58/88] END leaf_size=50, n_neighbors=25, weights=distance;, score=0.499 total time=   6.3s
[CV 4/5; 58/88] START leaf_size=50, n_neighbors=25, weights=distance............
[CV 4/5; 58/88] END leaf_size=50, n_neighbors=25, weights=distance;, score=0.501 total time=   6.5s
[CV 5/5; 58/88] START leaf_size=50, n_neighbors=25, weights=distance............
[CV 5/5; 58/88] END leaf_size=50, n_neighbors=25, weights=distance;, score=0.501 total time=   5.9s
[CV 1/5; 59/88] START leaf_size=50, n_neighbors=35, weights=uniform.............
[CV 1/5; 59/88] END leaf_size=50, n_neighbors=35, weights=uniform;, score=0.500 total time=   6.7s
[CV 2/5; 59/88] START leaf_size=50, n_neighbors=35, weights=uniform.............
[CV 2/5; 59/88] END leaf_size=50, n_neighbors=35, weights=uniform;, score=0.500 total time=   7.0s
[CV 3/5; 59/88] START leaf_size=50, n_neighbors=35, weights=uniform.............
[CV 3/5; 59/88] END leaf_size=50, n_neighbors=35, weights=uniform;, score=0.500 total time=   6.4s
[CV 4/5; 59/88] START leaf_size=50, n_neighbors=35, weights=uniform.............
[CV 4/5; 59/88] END leaf_size=50, n_neighbors=35, weights=uniform;, score=0.500 total time=   6.9s
[CV 5/5; 59/88] START leaf_size=50, n_neighbors=35, weights=uniform.............
[CV 5/5; 59/88] END leaf_size=50, n_neighbors=35, weights=uniform;, score=0.501 total time=   6.9s
[CV 1/5; 60/88] START leaf_size=50, n_neighbors=35, weights=distance............
[CV 1/5; 60/88] END leaf_size=50, n_neighbors=35, weights=distance;, score=0.500 total time=   7.2s
[CV 2/5; 60/88] START leaf_size=50, n_neighbors=35, weights=distance............
[CV 2/5; 60/88] END leaf_size=50, n_neighbors=35, weights=distance;, score=0.500 total time=   6.9s
[CV 3/5; 60/88] START leaf_size=50, n_neighbors=35, weights=distance............
[CV 3/5; 60/88] END leaf_size=50, n_neighbors=35, weights=distance;, score=0.500 total time=   6.3s
[CV 4/5; 60/88] START leaf_size=50, n_neighbors=35, weights=distance............
[CV 4/5; 60/88] END leaf_size=50, n_neighbors=35, weights=distance;, score=0.500 total time=   4.9s
[CV 5/5; 60/88] START leaf_size=50, n_neighbors=35, weights=distance............
[CV 5/5; 60/88] END leaf_size=50, n_neighbors=35, weights=distance;, score=0.501 total time=   4.9s
[CV 1/5; 61/88] START leaf_size=50, n_neighbors=55, weights=uniform.............
[CV 1/5; 61/88] END leaf_size=50, n_neighbors=55, weights=uniform;, score=0.500 total time=   4.8s
[CV 2/5; 61/88] START leaf_size=50, n_neighbors=55, weights=uniform.............
[CV 2/5; 61/88] END leaf_size=50, n_neighbors=55, weights=uniform;, score=0.500 total time=   5.0s
[CV 3/5; 61/88] START leaf_size=50, n_neighbors=55, weights=uniform.............
[CV 3/5; 61/88] END leaf_size=50, n_neighbors=55, weights=uniform;, score=0.501 total time=   4.9s
[CV 4/5; 61/88] START leaf_size=50, n_neighbors=55, weights=uniform.............
[CV 4/5; 61/88] END leaf_size=50, n_neighbors=55, weights=uniform;, score=0.500 total time=   5.0s
[CV 5/5; 61/88] START leaf_size=50, n_neighbors=55, weights=uniform.............
[CV 5/5; 61/88] END leaf_size=50, n_neighbors=55, weights=uniform;, score=0.500 total time=   4.8s
[CV 1/5; 62/88] START leaf_size=50, n_neighbors=55, weights=distance............
[CV 1/5; 62/88] END leaf_size=50, n_neighbors=55, weights=distance;, score=0.500 total time=   4.7s
[CV 2/5; 62/88] START leaf_size=50, n_neighbors=55, weights=distance............
[CV 2/5; 62/88] END leaf_size=50, n_neighbors=55, weights=distance;, score=0.500 total time=   4.8s
[CV 3/5; 62/88] START leaf_size=50, n_neighbors=55, weights=distance............
[CV 3/5; 62/88] END leaf_size=50, n_neighbors=55, weights=distance;, score=0.500 total time=   4.6s
[CV 4/5; 62/88] START leaf_size=50, n_neighbors=55, weights=distance............
[CV 4/5; 62/88] END leaf_size=50, n_neighbors=55, weights=distance;, score=0.500 total time=   5.3s
[CV 5/5; 62/88] START leaf_size=50, n_neighbors=55, weights=distance............
[CV 5/5; 62/88] END leaf_size=50, n_neighbors=55, weights=distance;, score=0.500 total time=   6.1s
[CV 1/5; 63/88] START leaf_size=50, n_neighbors=75, weights=uniform.............
[CV 1/5; 63/88] END leaf_size=50, n_neighbors=75, weights=uniform;, score=0.500 total time=   6.8s
[CV 2/5; 63/88] START leaf_size=50, n_neighbors=75, weights=uniform.............
[CV 2/5; 63/88] END leaf_size=50, n_neighbors=75, weights=uniform;, score=0.500 total time=   6.4s
[CV 3/5; 63/88] START leaf_size=50, n_neighbors=75, weights=uniform.............
[CV 3/5; 63/88] END leaf_size=50, n_neighbors=75, weights=uniform;, score=0.500 total time=   6.6s
[CV 4/5; 63/88] START leaf_size=50, n_neighbors=75, weights=uniform.............
[CV 4/5; 63/88] END leaf_size=50, n_neighbors=75, weights=uniform;, score=0.500 total time=   7.2s
[CV 5/5; 63/88] START leaf_size=50, n_neighbors=75, weights=uniform.............
[CV 5/5; 63/88] END leaf_size=50, n_neighbors=75, weights=uniform;, score=0.500 total time=   6.9s
[CV 1/5; 64/88] START leaf_size=50, n_neighbors=75, weights=distance............
[CV 1/5; 64/88] END leaf_size=50, n_neighbors=75, weights=distance;, score=0.500 total time=   6.5s
[CV 2/5; 64/88] START leaf_size=50, n_neighbors=75, weights=distance............
[CV 2/5; 64/88] END leaf_size=50, n_neighbors=75, weights=distance;, score=0.500 total time=   6.7s
[CV 3/5; 64/88] START leaf_size=50, n_neighbors=75, weights=distance............
[CV 3/5; 64/88] END leaf_size=50, n_neighbors=75, weights=distance;, score=0.500 total time=   6.9s
[CV 4/5; 64/88] START leaf_size=50, n_neighbors=75, weights=distance............
[CV 4/5; 64/88] END leaf_size=50, n_neighbors=75, weights=distance;, score=0.500 total time=   7.1s
[CV 5/5; 64/88] START leaf_size=50, n_neighbors=75, weights=distance............
[CV 5/5; 64/88] END leaf_size=50, n_neighbors=75, weights=distance;, score=0.500 total time=   6.3s
[CV 1/5; 65/88] START leaf_size=50, n_neighbors=99, weights=uniform.............
[CV 1/5; 65/88] END leaf_size=50, n_neighbors=99, weights=uniform;, score=0.500 total time=   6.8s
[CV 2/5; 65/88] START leaf_size=50, n_neighbors=99, weights=uniform.............
[CV 2/5; 65/88] END leaf_size=50, n_neighbors=99, weights=uniform;, score=0.500 total time=   6.4s
[CV 3/5; 65/88] START leaf_size=50, n_neighbors=99, weights=uniform.............
[CV 3/5; 65/88] END leaf_size=50, n_neighbors=99, weights=uniform;, score=0.500 total time=   6.6s
[CV 4/5; 65/88] START leaf_size=50, n_neighbors=99, weights=uniform.............
[CV 4/5; 65/88] END leaf_size=50, n_neighbors=99, weights=uniform;, score=0.500 total time=   6.7s
[CV 5/5; 65/88] START leaf_size=50, n_neighbors=99, weights=uniform.............
[CV 5/5; 65/88] END leaf_size=50, n_neighbors=99, weights=uniform;, score=0.500 total time=   7.1s
[CV 1/5; 66/88] START leaf_size=50, n_neighbors=99, weights=distance............
[CV 1/5; 66/88] END leaf_size=50, n_neighbors=99, weights=distance;, score=0.500 total time=   7.3s
[CV 2/5; 66/88] START leaf_size=50, n_neighbors=99, weights=distance............
[CV 2/5; 66/88] END leaf_size=50, n_neighbors=99, weights=distance;, score=0.500 total time=   6.2s
[CV 3/5; 66/88] START leaf_size=50, n_neighbors=99, weights=distance............
[CV 3/5; 66/88] END leaf_size=50, n_neighbors=99, weights=distance;, score=0.500 total time=   6.7s
[CV 4/5; 66/88] START leaf_size=50, n_neighbors=99, weights=distance............
[CV 4/5; 66/88] END leaf_size=50, n_neighbors=99, weights=distance;, score=0.500 total time=   7.0s
[CV 5/5; 66/88] START leaf_size=50, n_neighbors=99, weights=distance............
[CV 5/5; 66/88] END leaf_size=50, n_neighbors=99, weights=distance;, score=0.500 total time=   8.0s
[CV 1/5; 67/88] START leaf_size=70, n_neighbors=3, weights=uniform..............
[CV 1/5; 67/88] END leaf_size=70, n_neighbors=3, weights=uniform;, score=0.504 total time=   5.9s
[CV 2/5; 67/88] START leaf_size=70, n_neighbors=3, weights=uniform..............
[CV 2/5; 67/88] END leaf_size=70, n_neighbors=3, weights=uniform;, score=0.510 total time=   4.7s
[CV 3/5; 67/88] START leaf_size=70, n_neighbors=3, weights=uniform..............
[CV 3/5; 67/88] END leaf_size=70, n_neighbors=3, weights=uniform;, score=0.504 total time=   5.2s
[CV 4/5; 67/88] START leaf_size=70, n_neighbors=3, weights=uniform..............
[CV 4/5; 67/88] END leaf_size=70, n_neighbors=3, weights=uniform;, score=0.506 total time=   4.8s
[CV 5/5; 67/88] START leaf_size=70, n_neighbors=3, weights=uniform..............
[CV 5/5; 67/88] END leaf_size=70, n_neighbors=3, weights=uniform;, score=0.501 total time=   4.8s
[CV 1/5; 68/88] START leaf_size=70, n_neighbors=3, weights=distance.............
[CV 1/5; 68/88] END leaf_size=70, n_neighbors=3, weights=distance;, score=0.504 total time=   5.7s
[CV 2/5; 68/88] START leaf_size=70, n_neighbors=3, weights=distance.............
[CV 2/5; 68/88] END leaf_size=70, n_neighbors=3, weights=distance;, score=0.510 total time=   5.6s
[CV 3/5; 68/88] START leaf_size=70, n_neighbors=3, weights=distance.............
[CV 3/5; 68/88] END leaf_size=70, n_neighbors=3, weights=distance;, score=0.504 total time=   5.4s
[CV 4/5; 68/88] START leaf_size=70, n_neighbors=3, weights=distance.............
[CV 4/5; 68/88] END leaf_size=70, n_neighbors=3, weights=distance;, score=0.506 total time=   5.8s
[CV 5/5; 68/88] START leaf_size=70, n_neighbors=3, weights=distance.............
[CV 5/5; 68/88] END leaf_size=70, n_neighbors=3, weights=distance;, score=0.500 total time=   5.5s
[CV 1/5; 69/88] START leaf_size=70, n_neighbors=5, weights=uniform..............
[CV 1/5; 69/88] END leaf_size=70, n_neighbors=5, weights=uniform;, score=0.500 total time=   7.7s
[CV 2/5; 69/88] START leaf_size=70, n_neighbors=5, weights=uniform..............
[CV 2/5; 69/88] END leaf_size=70, n_neighbors=5, weights=uniform;, score=0.515 total time=   7.6s
[CV 3/5; 69/88] START leaf_size=70, n_neighbors=5, weights=uniform..............
[CV 3/5; 69/88] END leaf_size=70, n_neighbors=5, weights=uniform;, score=0.507 total time=   5.8s
[CV 4/5; 69/88] START leaf_size=70, n_neighbors=5, weights=uniform..............
[CV 4/5; 69/88] END leaf_size=70, n_neighbors=5, weights=uniform;, score=0.506 total time=   7.3s
[CV 5/5; 69/88] START leaf_size=70, n_neighbors=5, weights=uniform..............
[CV 5/5; 69/88] END leaf_size=70, n_neighbors=5, weights=uniform;, score=0.498 total time=   7.6s
[CV 1/5; 70/88] START leaf_size=70, n_neighbors=5, weights=distance.............
[CV 1/5; 70/88] END leaf_size=70, n_neighbors=5, weights=distance;, score=0.500 total time=   7.5s
[CV 2/5; 70/88] START leaf_size=70, n_neighbors=5, weights=distance.............
[CV 2/5; 70/88] END leaf_size=70, n_neighbors=5, weights=distance;, score=0.515 total time=   7.3s
[CV 3/5; 70/88] START leaf_size=70, n_neighbors=5, weights=distance.............
[CV 3/5; 70/88] END leaf_size=70, n_neighbors=5, weights=distance;, score=0.506 total time=   7.1s
[CV 4/5; 70/88] START leaf_size=70, n_neighbors=5, weights=distance.............
[CV 4/5; 70/88] END leaf_size=70, n_neighbors=5, weights=distance;, score=0.506 total time=   7.1s
[CV 5/5; 70/88] START leaf_size=70, n_neighbors=5, weights=distance.............
[CV 5/5; 70/88] END leaf_size=70, n_neighbors=5, weights=distance;, score=0.498 total time=   6.6s
[CV 1/5; 71/88] START leaf_size=70, n_neighbors=7, weights=uniform..............
[CV 1/5; 71/88] END leaf_size=70, n_neighbors=7, weights=uniform;, score=0.503 total time=   7.4s
[CV 2/5; 71/88] START leaf_size=70, n_neighbors=7, weights=uniform..............
[CV 2/5; 71/88] END leaf_size=70, n_neighbors=7, weights=uniform;, score=0.506 total time=   7.1s
[CV 3/5; 71/88] START leaf_size=70, n_neighbors=7, weights=uniform..............
[CV 3/5; 71/88] END leaf_size=70, n_neighbors=7, weights=uniform;, score=0.502 total time=   6.7s
[CV 4/5; 71/88] START leaf_size=70, n_neighbors=7, weights=uniform..............
[CV 4/5; 71/88] END leaf_size=70, n_neighbors=7, weights=uniform;, score=0.505 total time=   7.4s
[CV 5/5; 71/88] START leaf_size=70, n_neighbors=7, weights=uniform..............
[CV 5/5; 71/88] END leaf_size=70, n_neighbors=7, weights=uniform;, score=0.507 total time=   7.0s
[CV 1/5; 72/88] START leaf_size=70, n_neighbors=7, weights=distance.............
[CV 1/5; 72/88] END leaf_size=70, n_neighbors=7, weights=distance;, score=0.503 total time=   7.5s
[CV 2/5; 72/88] START leaf_size=70, n_neighbors=7, weights=distance.............
[CV 2/5; 72/88] END leaf_size=70, n_neighbors=7, weights=distance;, score=0.506 total time=   6.6s
[CV 3/5; 72/88] START leaf_size=70, n_neighbors=7, weights=distance.............
[CV 3/5; 72/88] END leaf_size=70, n_neighbors=7, weights=distance;, score=0.502 total time=   7.1s
[CV 4/5; 72/88] START leaf_size=70, n_neighbors=7, weights=distance.............
[CV 4/5; 72/88] END leaf_size=70, n_neighbors=7, weights=distance;, score=0.504 total time=   6.9s
[CV 5/5; 72/88] START leaf_size=70, n_neighbors=7, weights=distance.............
[CV 5/5; 72/88] END leaf_size=70, n_neighbors=7, weights=distance;, score=0.507 total time=   6.8s
[CV 1/5; 73/88] START leaf_size=70, n_neighbors=9, weights=uniform..............
[CV 1/5; 73/88] END leaf_size=70, n_neighbors=9, weights=uniform;, score=0.505 total time=   7.4s
[CV 2/5; 73/88] START leaf_size=70, n_neighbors=9, weights=uniform..............
[CV 2/5; 73/88] END leaf_size=70, n_neighbors=9, weights=uniform;, score=0.507 total time=   7.8s
[CV 3/5; 73/88] START leaf_size=70, n_neighbors=9, weights=uniform..............
[CV 3/5; 73/88] END leaf_size=70, n_neighbors=9, weights=uniform;, score=0.504 total time=   7.6s
[CV 4/5; 73/88] START leaf_size=70, n_neighbors=9, weights=uniform..............
[CV 4/5; 73/88] END leaf_size=70, n_neighbors=9, weights=uniform;, score=0.500 total time=   7.7s
[CV 5/5; 73/88] START leaf_size=70, n_neighbors=9, weights=uniform..............
[CV 5/5; 73/88] END leaf_size=70, n_neighbors=9, weights=uniform;, score=0.507 total time=   7.3s
[CV 1/5; 74/88] START leaf_size=70, n_neighbors=9, weights=distance.............
[CV 1/5; 74/88] END leaf_size=70, n_neighbors=9, weights=distance;, score=0.505 total time=   6.3s
[CV 2/5; 74/88] START leaf_size=70, n_neighbors=9, weights=distance.............
[CV 2/5; 74/88] END leaf_size=70, n_neighbors=9, weights=distance;, score=0.508 total time=   6.5s
[CV 3/5; 74/88] START leaf_size=70, n_neighbors=9, weights=distance.............
[CV 3/5; 74/88] END leaf_size=70, n_neighbors=9, weights=distance;, score=0.504 total time=   6.5s
[CV 4/5; 74/88] START leaf_size=70, n_neighbors=9, weights=distance.............
[CV 4/5; 74/88] END leaf_size=70, n_neighbors=9, weights=distance;, score=0.500 total time=   6.5s
[CV 5/5; 74/88] START leaf_size=70, n_neighbors=9, weights=distance.............
[CV 5/5; 74/88] END leaf_size=70, n_neighbors=9, weights=distance;, score=0.507 total time=   6.3s
[CV 1/5; 75/88] START leaf_size=70, n_neighbors=15, weights=uniform.............
[CV 1/5; 75/88] END leaf_size=70, n_neighbors=15, weights=uniform;, score=0.503 total time=   7.0s
[CV 2/5; 75/88] START leaf_size=70, n_neighbors=15, weights=uniform.............
[CV 2/5; 75/88] END leaf_size=70, n_neighbors=15, weights=uniform;, score=0.503 total time=   7.3s
[CV 3/5; 75/88] START leaf_size=70, n_neighbors=15, weights=uniform.............
[CV 3/5; 75/88] END leaf_size=70, n_neighbors=15, weights=uniform;, score=0.500 total time=   7.3s
[CV 4/5; 75/88] START leaf_size=70, n_neighbors=15, weights=uniform.............
[CV 4/5; 75/88] END leaf_size=70, n_neighbors=15, weights=uniform;, score=0.500 total time=   7.6s
[CV 5/5; 75/88] START leaf_size=70, n_neighbors=15, weights=uniform.............
[CV 5/5; 75/88] END leaf_size=70, n_neighbors=15, weights=uniform;, score=0.503 total time=   7.5s
[CV 1/5; 76/88] START leaf_size=70, n_neighbors=15, weights=distance............
[CV 1/5; 76/88] END leaf_size=70, n_neighbors=15, weights=distance;, score=0.503 total time=   7.2s
[CV 2/5; 76/88] START leaf_size=70, n_neighbors=15, weights=distance............
[CV 2/5; 76/88] END leaf_size=70, n_neighbors=15, weights=distance;, score=0.503 total time=   7.5s
[CV 3/5; 76/88] START leaf_size=70, n_neighbors=15, weights=distance............
[CV 3/5; 76/88] END leaf_size=70, n_neighbors=15, weights=distance;, score=0.500 total time=   7.3s
[CV 4/5; 76/88] START leaf_size=70, n_neighbors=15, weights=distance............
[CV 4/5; 76/88] END leaf_size=70, n_neighbors=15, weights=distance;, score=0.501 total time=   7.3s
[CV 5/5; 76/88] START leaf_size=70, n_neighbors=15, weights=distance............
[CV 5/5; 76/88] END leaf_size=70, n_neighbors=15, weights=distance;, score=0.503 total time=   7.2s
[CV 1/5; 77/88] START leaf_size=70, n_neighbors=19, weights=uniform.............
[CV 1/5; 77/88] END leaf_size=70, n_neighbors=19, weights=uniform;, score=0.501 total time=   7.9s
[CV 2/5; 77/88] START leaf_size=70, n_neighbors=19, weights=uniform.............
[CV 2/5; 77/88] END leaf_size=70, n_neighbors=19, weights=uniform;, score=0.501 total time=   7.3s
[CV 3/5; 77/88] START leaf_size=70, n_neighbors=19, weights=uniform.............
[CV 3/5; 77/88] END leaf_size=70, n_neighbors=19, weights=uniform;, score=0.501 total time=   7.1s
[CV 4/5; 77/88] START leaf_size=70, n_neighbors=19, weights=uniform.............
[CV 4/5; 77/88] END leaf_size=70, n_neighbors=19, weights=uniform;, score=0.500 total time=   6.9s
[CV 5/5; 77/88] START leaf_size=70, n_neighbors=19, weights=uniform.............
[CV 5/5; 77/88] END leaf_size=70, n_neighbors=19, weights=uniform;, score=0.502 total time=   6.8s
[CV 1/5; 78/88] START leaf_size=70, n_neighbors=19, weights=distance............
[CV 1/5; 78/88] END leaf_size=70, n_neighbors=19, weights=distance;, score=0.501 total time=   7.1s
[CV 2/5; 78/88] START leaf_size=70, n_neighbors=19, weights=distance............
[CV 2/5; 78/88] END leaf_size=70, n_neighbors=19, weights=distance;, score=0.502 total time=   6.9s
[CV 3/5; 78/88] START leaf_size=70, n_neighbors=19, weights=distance............
[CV 3/5; 78/88] END leaf_size=70, n_neighbors=19, weights=distance;, score=0.501 total time=   6.7s
[CV 4/5; 78/88] START leaf_size=70, n_neighbors=19, weights=distance............
[CV 4/5; 78/88] END leaf_size=70, n_neighbors=19, weights=distance;, score=0.500 total time=   7.4s
[CV 5/5; 78/88] START leaf_size=70, n_neighbors=19, weights=distance............
[CV 5/5; 78/88] END leaf_size=70, n_neighbors=19, weights=distance;, score=0.502 total time=   7.0s
[CV 1/5; 79/88] START leaf_size=70, n_neighbors=25, weights=uniform.............
[CV 1/5; 79/88] END leaf_size=70, n_neighbors=25, weights=uniform;, score=0.499 total time=   7.6s
[CV 2/5; 79/88] START leaf_size=70, n_neighbors=25, weights=uniform.............
[CV 2/5; 79/88] END leaf_size=70, n_neighbors=25, weights=uniform;, score=0.501 total time=   7.2s
[CV 3/5; 79/88] START leaf_size=70, n_neighbors=25, weights=uniform.............
[CV 3/5; 79/88] END leaf_size=70, n_neighbors=25, weights=uniform;, score=0.499 total time=   7.3s
[CV 4/5; 79/88] START leaf_size=70, n_neighbors=25, weights=uniform.............
[CV 4/5; 79/88] END leaf_size=70, n_neighbors=25, weights=uniform;, score=0.502 total time=   7.5s
[CV 5/5; 79/88] START leaf_size=70, n_neighbors=25, weights=uniform.............
[CV 5/5; 79/88] END leaf_size=70, n_neighbors=25, weights=uniform;, score=0.501 total time=   7.2s
[CV 1/5; 80/88] START leaf_size=70, n_neighbors=25, weights=distance............
[CV 1/5; 80/88] END leaf_size=70, n_neighbors=25, weights=distance;, score=0.499 total time=   7.0s
[CV 2/5; 80/88] START leaf_size=70, n_neighbors=25, weights=distance............
[CV 2/5; 80/88] END leaf_size=70, n_neighbors=25, weights=distance;, score=0.501 total time=   7.2s
[CV 3/5; 80/88] START leaf_size=70, n_neighbors=25, weights=distance............
[CV 3/5; 80/88] END leaf_size=70, n_neighbors=25, weights=distance;, score=0.499 total time=   6.7s
[CV 4/5; 80/88] START leaf_size=70, n_neighbors=25, weights=distance............
[CV 4/5; 80/88] END leaf_size=70, n_neighbors=25, weights=distance;, score=0.501 total time=   7.0s
[CV 5/5; 80/88] START leaf_size=70, n_neighbors=25, weights=distance............
[CV 5/5; 80/88] END leaf_size=70, n_neighbors=25, weights=distance;, score=0.501 total time=   6.5s
[CV 1/5; 81/88] START leaf_size=70, n_neighbors=35, weights=uniform.............
[CV 1/5; 81/88] END leaf_size=70, n_neighbors=35, weights=uniform;, score=0.500 total time=   7.3s
[CV 2/5; 81/88] START leaf_size=70, n_neighbors=35, weights=uniform.............
[CV 2/5; 81/88] END leaf_size=70, n_neighbors=35, weights=uniform;, score=0.500 total time=   7.4s
[CV 3/5; 81/88] START leaf_size=70, n_neighbors=35, weights=uniform.............
[CV 3/5; 81/88] END leaf_size=70, n_neighbors=35, weights=uniform;, score=0.500 total time=   7.4s
[CV 4/5; 81/88] START leaf_size=70, n_neighbors=35, weights=uniform.............
[CV 4/5; 81/88] END leaf_size=70, n_neighbors=35, weights=uniform;, score=0.500 total time=   7.1s
[CV 5/5; 81/88] START leaf_size=70, n_neighbors=35, weights=uniform.............
[CV 5/5; 81/88] END leaf_size=70, n_neighbors=35, weights=uniform;, score=0.501 total time=   7.1s
[CV 1/5; 82/88] START leaf_size=70, n_neighbors=35, weights=distance............
[CV 1/5; 82/88] END leaf_size=70, n_neighbors=35, weights=distance;, score=0.500 total time=   7.0s
[CV 2/5; 82/88] START leaf_size=70, n_neighbors=35, weights=distance............
[CV 2/5; 82/88] END leaf_size=70, n_neighbors=35, weights=distance;, score=0.500 total time=   7.0s
[CV 3/5; 82/88] START leaf_size=70, n_neighbors=35, weights=distance............
[CV 3/5; 82/88] END leaf_size=70, n_neighbors=35, weights=distance;, score=0.500 total time=   7.1s
[CV 4/5; 82/88] START leaf_size=70, n_neighbors=35, weights=distance............
[CV 4/5; 82/88] END leaf_size=70, n_neighbors=35, weights=distance;, score=0.500 total time=   7.0s
[CV 5/5; 82/88] START leaf_size=70, n_neighbors=35, weights=distance............
[CV 5/5; 82/88] END leaf_size=70, n_neighbors=35, weights=distance;, score=0.501 total time=   5.8s
[CV 1/5; 83/88] START leaf_size=70, n_neighbors=55, weights=uniform.............
[CV 1/5; 83/88] END leaf_size=70, n_neighbors=55, weights=uniform;, score=0.500 total time=   5.6s
[CV 2/5; 83/88] START leaf_size=70, n_neighbors=55, weights=uniform.............
[CV 2/5; 83/88] END leaf_size=70, n_neighbors=55, weights=uniform;, score=0.500 total time=   5.3s
[CV 3/5; 83/88] START leaf_size=70, n_neighbors=55, weights=uniform.............
[CV 3/5; 83/88] END leaf_size=70, n_neighbors=55, weights=uniform;, score=0.501 total time=   5.8s
[CV 4/5; 83/88] START leaf_size=70, n_neighbors=55, weights=uniform.............
[CV 4/5; 83/88] END leaf_size=70, n_neighbors=55, weights=uniform;, score=0.500 total time=   5.3s
[CV 5/5; 83/88] START leaf_size=70, n_neighbors=55, weights=uniform.............
[CV 5/5; 83/88] END leaf_size=70, n_neighbors=55, weights=uniform;, score=0.500 total time=   6.0s
[CV 1/5; 84/88] START leaf_size=70, n_neighbors=55, weights=distance............
[CV 1/5; 84/88] END leaf_size=70, n_neighbors=55, weights=distance;, score=0.500 total time=   5.3s
[CV 2/5; 84/88] START leaf_size=70, n_neighbors=55, weights=distance............
[CV 2/5; 84/88] END leaf_size=70, n_neighbors=55, weights=distance;, score=0.500 total time=   6.2s
[CV 3/5; 84/88] START leaf_size=70, n_neighbors=55, weights=distance............
[CV 3/5; 84/88] END leaf_size=70, n_neighbors=55, weights=distance;, score=0.500 total time=   5.7s
[CV 4/5; 84/88] START leaf_size=70, n_neighbors=55, weights=distance............
[CV 4/5; 84/88] END leaf_size=70, n_neighbors=55, weights=distance;, score=0.500 total time=   5.6s
[CV 5/5; 84/88] START leaf_size=70, n_neighbors=55, weights=distance............
[CV 5/5; 84/88] END leaf_size=70, n_neighbors=55, weights=distance;, score=0.500 total time=   5.8s
[CV 1/5; 85/88] START leaf_size=70, n_neighbors=75, weights=uniform.............
[CV 1/5; 85/88] END leaf_size=70, n_neighbors=75, weights=uniform;, score=0.500 total time=   5.8s
[CV 2/5; 85/88] START leaf_size=70, n_neighbors=75, weights=uniform.............
[CV 2/5; 85/88] END leaf_size=70, n_neighbors=75, weights=uniform;, score=0.500 total time=   5.3s
[CV 3/5; 85/88] START leaf_size=70, n_neighbors=75, weights=uniform.............
[CV 3/5; 85/88] END leaf_size=70, n_neighbors=75, weights=uniform;, score=0.500 total time=   5.5s
[CV 4/5; 85/88] START leaf_size=70, n_neighbors=75, weights=uniform.............
[CV 4/5; 85/88] END leaf_size=70, n_neighbors=75, weights=uniform;, score=0.500 total time=   5.6s
[CV 5/5; 85/88] START leaf_size=70, n_neighbors=75, weights=uniform.............
[CV 5/5; 85/88] END leaf_size=70, n_neighbors=75, weights=uniform;, score=0.500 total time=   6.1s
[CV 1/5; 86/88] START leaf_size=70, n_neighbors=75, weights=distance............
[CV 1/5; 86/88] END leaf_size=70, n_neighbors=75, weights=distance;, score=0.500 total time=   5.4s
[CV 2/5; 86/88] START leaf_size=70, n_neighbors=75, weights=distance............
[CV 2/5; 86/88] END leaf_size=70, n_neighbors=75, weights=distance;, score=0.500 total time=   6.1s
[CV 3/5; 86/88] START leaf_size=70, n_neighbors=75, weights=distance............
[CV 3/5; 86/88] END leaf_size=70, n_neighbors=75, weights=distance;, score=0.500 total time=   5.4s
[CV 4/5; 86/88] START leaf_size=70, n_neighbors=75, weights=distance............
[CV 4/5; 86/88] END leaf_size=70, n_neighbors=75, weights=distance;, score=0.500 total time=   5.8s
[CV 5/5; 86/88] START leaf_size=70, n_neighbors=75, weights=distance............
[CV 5/5; 86/88] END leaf_size=70, n_neighbors=75, weights=distance;, score=0.500 total time=   4.6s
[CV 1/5; 87/88] START leaf_size=70, n_neighbors=99, weights=uniform.............
[CV 1/5; 87/88] END leaf_size=70, n_neighbors=99, weights=uniform;, score=0.500 total time=   5.7s
[CV 2/5; 87/88] START leaf_size=70, n_neighbors=99, weights=uniform.............
[CV 2/5; 87/88] END leaf_size=70, n_neighbors=99, weights=uniform;, score=0.500 total time=   5.2s
[CV 3/5; 87/88] START leaf_size=70, n_neighbors=99, weights=uniform.............
[CV 3/5; 87/88] END leaf_size=70, n_neighbors=99, weights=uniform;, score=0.500 total time=   5.8s
[CV 4/5; 87/88] START leaf_size=70, n_neighbors=99, weights=uniform.............
[CV 4/5; 87/88] END leaf_size=70, n_neighbors=99, weights=uniform;, score=0.500 total time=   5.4s
[CV 5/5; 87/88] START leaf_size=70, n_neighbors=99, weights=uniform.............
[CV 5/5; 87/88] END leaf_size=70, n_neighbors=99, weights=uniform;, score=0.500 total time=   5.5s
[CV 1/5; 88/88] START leaf_size=70, n_neighbors=99, weights=distance............
[CV 1/5; 88/88] END leaf_size=70, n_neighbors=99, weights=distance;, score=0.500 total time=   5.8s
[CV 2/5; 88/88] START leaf_size=70, n_neighbors=99, weights=distance............
[CV 2/5; 88/88] END leaf_size=70, n_neighbors=99, weights=distance;, score=0.500 total time=   5.3s
[CV 3/5; 88/88] START leaf_size=70, n_neighbors=99, weights=distance............
[CV 3/5; 88/88] END leaf_size=70, n_neighbors=99, weights=distance;, score=0.500 total time=   6.2s
[CV 4/5; 88/88] START leaf_size=70, n_neighbors=99, weights=distance............
[CV 4/5; 88/88] END leaf_size=70, n_neighbors=99, weights=distance;, score=0.500 total time=   5.4s
[CV 5/5; 88/88] START leaf_size=70, n_neighbors=99, weights=distance............
[CV 5/5; 88/88] END leaf_size=70, n_neighbors=99, weights=distance;, score=0.500 total time=   5.2s
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt">Out[26]:</div>




<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain">
<pre>GridSearchCV(estimator=KNeighborsClassifier(),
             param_grid={&#39;leaf_size&#39;: [20, 30, 50, 70],
                         &#39;n_neighbors&#39;: [3, 5, 7, 9, 15, 19, 25, 35, 55, 75,
                                         99],
                         &#39;weights&#39;: [&#39;uniform&#39;, &#39;distance&#39;]},
             scoring=&#39;balanced_accuracy&#39;, verbose=10)</pre>
</div>

</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[27]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">grid_search</span><span class="o">.</span><span class="n">best_params_</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt">Out[27]:</div>




<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain">
<pre>{&#39;leaf_size&#39;: 20, &#39;n_neighbors&#39;: 5, &#39;weights&#39;: &#39;uniform&#39;}</pre>
</div>

</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[29]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">leaf_size</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="s1">&#39;uniform&#39;</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">predicted</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[32]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">evaluate</span><span class="p">(</span><span class="n">predicted</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Accuracy:  0.7045313469894475
Balanced Accuracy:  0.5156838933793998
Precision:  0.7483416252072969
Recall:  0.9064278540341479
F1:  0.8198334595003786
</pre>
</div>
</div>

</div>

</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>As we can see although we have not-bad accuracy but balanced accuracy which is wanted for this task is not good so we should look for better moodels.</p>
<p>By remember that with these parameters:</p>

<pre><code>{'n_neighbors': 5,
 'leaf_size': 20,
 'weights': uniform
}</code></pre>
<p>We got these results:</p>

<pre><code>Accuracy:  0.7045313469894475
Balanced Accuracy:  0.5156838933793998
Precision:  0.7483416252072969
Recall:  0.9064278540341479
F1:  0.8198334595003786</code></pre>

</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[&nbsp;]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>

<span class="n">parameters</span> <span class="o">=</span> <span class="p">{</span>  <span class="s1">&#39;penalty&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;l1&#39;</span><span class="p">,</span> <span class="s1">&#39;l2&#39;</span><span class="p">,</span> <span class="s1">&#39;elasticnet&#39;</span><span class="p">,</span> <span class="s1">&#39;none&#39;</span><span class="p">],</span>
                <span class="s1">&#39;tol&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">1e-3</span><span class="p">,</span> <span class="mf">1e-4</span><span class="p">,</span> <span class="mf">1e-5</span><span class="p">],</span>
                <span class="s1">&#39;solver&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;newton-cg&#39;</span><span class="p">,</span> <span class="s1">&#39;lbfgs&#39;</span><span class="p">,</span> <span class="s1">&#39;liblinear&#39;</span><span class="p">,</span> <span class="s1">&#39;sag&#39;</span><span class="p">,</span> <span class="s1">&#39;saga&#39;</span><span class="p">],</span>
                <span class="s1">&#39;max_iter&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">150</span><span class="p">,</span> <span class="mi">200</span><span class="p">]</span>
                 <span class="p">}</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">()</span>

<span class="n">grid_search</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">estimator</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">param_grid</span><span class="o">=</span><span class="n">parameters</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s2">&quot;balanced_accuracy&quot;</span><span class="p">)</span>
<span class="n">grid_search</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Fitting 5 folds for each of 240 candidates, totalling 1200 fits
[CV 1/5; 1/240] START max_iter=50, penalty=l1, solver=newton-cg, tol=0.001......
[CV 1/5; 1/240] END max_iter=50, penalty=l1, solver=newton-cg, tol=0.001;, score=nan total time=   0.0s
[CV 2/5; 1/240] START max_iter=50, penalty=l1, solver=newton-cg, tol=0.001......
[CV 2/5; 1/240] END max_iter=50, penalty=l1, solver=newton-cg, tol=0.001;, score=nan total time=   0.0s
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver newton-cg supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver newton-cg supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver newton-cg supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 3/5; 1/240] START max_iter=50, penalty=l1, solver=newton-cg, tol=0.001......
[CV 3/5; 1/240] END max_iter=50, penalty=l1, solver=newton-cg, tol=0.001;, score=nan total time=   0.0s
[CV 4/5; 1/240] START max_iter=50, penalty=l1, solver=newton-cg, tol=0.001......
[CV 4/5; 1/240] END max_iter=50, penalty=l1, solver=newton-cg, tol=0.001;, score=nan total time=   0.0s
[CV 5/5; 1/240] START max_iter=50, penalty=l1, solver=newton-cg, tol=0.001......
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver newton-cg supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver newton-cg supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver newton-cg supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 5/5; 1/240] END max_iter=50, penalty=l1, solver=newton-cg, tol=0.001;, score=nan total time=   0.0s
[CV 1/5; 2/240] START max_iter=50, penalty=l1, solver=newton-cg, tol=0.0001.....
[CV 1/5; 2/240] END max_iter=50, penalty=l1, solver=newton-cg, tol=0.0001;, score=nan total time=   0.0s
[CV 2/5; 2/240] START max_iter=50, penalty=l1, solver=newton-cg, tol=0.0001.....
[CV 2/5; 2/240] END max_iter=50, penalty=l1, solver=newton-cg, tol=0.0001;, score=nan total time=   0.0s
[CV 3/5; 2/240] START max_iter=50, penalty=l1, solver=newton-cg, tol=0.0001.....
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver newton-cg supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver newton-cg supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver newton-cg supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 3/5; 2/240] END max_iter=50, penalty=l1, solver=newton-cg, tol=0.0001;, score=nan total time=   0.0s
[CV 4/5; 2/240] START max_iter=50, penalty=l1, solver=newton-cg, tol=0.0001.....
[CV 4/5; 2/240] END max_iter=50, penalty=l1, solver=newton-cg, tol=0.0001;, score=nan total time=   0.0s
[CV 5/5; 2/240] START max_iter=50, penalty=l1, solver=newton-cg, tol=0.0001.....
[CV 5/5; 2/240] END max_iter=50, penalty=l1, solver=newton-cg, tol=0.0001;, score=nan total time=   0.0s
[CV 1/5; 3/240] START max_iter=50, penalty=l1, solver=newton-cg, tol=1e-05......
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver newton-cg supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver newton-cg supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver newton-cg supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 1/5; 3/240] END max_iter=50, penalty=l1, solver=newton-cg, tol=1e-05;, score=nan total time=   0.0s
[CV 2/5; 3/240] START max_iter=50, penalty=l1, solver=newton-cg, tol=1e-05......
[CV 2/5; 3/240] END max_iter=50, penalty=l1, solver=newton-cg, tol=1e-05;, score=nan total time=   0.0s
[CV 3/5; 3/240] START max_iter=50, penalty=l1, solver=newton-cg, tol=1e-05......
[CV 3/5; 3/240] END max_iter=50, penalty=l1, solver=newton-cg, tol=1e-05;, score=nan total time=   0.0s
[CV 4/5; 3/240] START max_iter=50, penalty=l1, solver=newton-cg, tol=1e-05......
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver newton-cg supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver newton-cg supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver newton-cg supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 4/5; 3/240] END max_iter=50, penalty=l1, solver=newton-cg, tol=1e-05;, score=nan total time=   0.0s
[CV 5/5; 3/240] START max_iter=50, penalty=l1, solver=newton-cg, tol=1e-05......
[CV 5/5; 3/240] END max_iter=50, penalty=l1, solver=newton-cg, tol=1e-05;, score=nan total time=   0.0s
[CV 1/5; 4/240] START max_iter=50, penalty=l1, solver=lbfgs, tol=0.001..........
[CV 1/5; 4/240] END max_iter=50, penalty=l1, solver=lbfgs, tol=0.001;, score=nan total time=   0.0s
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 2/5; 4/240] START max_iter=50, penalty=l1, solver=lbfgs, tol=0.001..........
[CV 2/5; 4/240] END max_iter=50, penalty=l1, solver=lbfgs, tol=0.001;, score=nan total time=   0.0s
[CV 3/5; 4/240] START max_iter=50, penalty=l1, solver=lbfgs, tol=0.001..........
[CV 3/5; 4/240] END max_iter=50, penalty=l1, solver=lbfgs, tol=0.001;, score=nan total time=   0.0s
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 4/5; 4/240] START max_iter=50, penalty=l1, solver=lbfgs, tol=0.001..........
[CV 4/5; 4/240] END max_iter=50, penalty=l1, solver=lbfgs, tol=0.001;, score=nan total time=   0.0s
[CV 5/5; 4/240] START max_iter=50, penalty=l1, solver=lbfgs, tol=0.001..........
[CV 5/5; 4/240] END max_iter=50, penalty=l1, solver=lbfgs, tol=0.001;, score=nan total time=   0.0s
[CV 1/5; 5/240] START max_iter=50, penalty=l1, solver=lbfgs, tol=0.0001.........
[CV 1/5; 5/240] END max_iter=50, penalty=l1, solver=lbfgs, tol=0.0001;, score=nan total time=   0.0s
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 2/5; 5/240] START max_iter=50, penalty=l1, solver=lbfgs, tol=0.0001.........
[CV 2/5; 5/240] END max_iter=50, penalty=l1, solver=lbfgs, tol=0.0001;, score=nan total time=   0.0s
[CV 3/5; 5/240] START max_iter=50, penalty=l1, solver=lbfgs, tol=0.0001.........
[CV 3/5; 5/240] END max_iter=50, penalty=l1, solver=lbfgs, tol=0.0001;, score=nan total time=   0.0s
[CV 4/5; 5/240] START max_iter=50, penalty=l1, solver=lbfgs, tol=0.0001.........
[CV 4/5; 5/240] END max_iter=50, penalty=l1, solver=lbfgs, tol=0.0001;, score=nan total time=   0.0s
[CV 5/5; 5/240] START max_iter=50, penalty=l1, solver=lbfgs, tol=0.0001.........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 5/5; 5/240] END max_iter=50, penalty=l1, solver=lbfgs, tol=0.0001;, score=nan total time=   0.0s
[CV 1/5; 6/240] START max_iter=50, penalty=l1, solver=lbfgs, tol=1e-05..........
[CV 1/5; 6/240] END max_iter=50, penalty=l1, solver=lbfgs, tol=1e-05;, score=nan total time=   0.0s
[CV 2/5; 6/240] START max_iter=50, penalty=l1, solver=lbfgs, tol=1e-05..........
[CV 2/5; 6/240] END max_iter=50, penalty=l1, solver=lbfgs, tol=1e-05;, score=nan total time=   0.0s
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 3/5; 6/240] START max_iter=50, penalty=l1, solver=lbfgs, tol=1e-05..........
[CV 3/5; 6/240] END max_iter=50, penalty=l1, solver=lbfgs, tol=1e-05;, score=nan total time=   0.0s
[CV 4/5; 6/240] START max_iter=50, penalty=l1, solver=lbfgs, tol=1e-05..........
[CV 4/5; 6/240] END max_iter=50, penalty=l1, solver=lbfgs, tol=1e-05;, score=nan total time=   0.0s
[CV 5/5; 6/240] START max_iter=50, penalty=l1, solver=lbfgs, tol=1e-05..........
[CV 5/5; 6/240] END max_iter=50, penalty=l1, solver=lbfgs, tol=1e-05;, score=nan total time=   0.0s
[CV 1/5; 7/240] START max_iter=50, penalty=l1, solver=liblinear, tol=0.001......
[CV 1/5; 7/240] END max_iter=50, penalty=l1, solver=liblinear, tol=0.001;, score=0.498 total time=   0.5s
[CV 2/5; 7/240] START max_iter=50, penalty=l1, solver=liblinear, tol=0.001......
[CV 2/5; 7/240] END max_iter=50, penalty=l1, solver=liblinear, tol=0.001;, score=0.499 total time=   0.7s
[CV 3/5; 7/240] START max_iter=50, penalty=l1, solver=liblinear, tol=0.001......
[CV 3/5; 7/240] END max_iter=50, penalty=l1, solver=liblinear, tol=0.001;, score=0.500 total time=   0.8s
[CV 4/5; 7/240] START max_iter=50, penalty=l1, solver=liblinear, tol=0.001......
[CV 4/5; 7/240] END max_iter=50, penalty=l1, solver=liblinear, tol=0.001;, score=0.499 total time=   0.7s
[CV 5/5; 7/240] START max_iter=50, penalty=l1, solver=liblinear, tol=0.001......
[CV 5/5; 7/240] END max_iter=50, penalty=l1, solver=liblinear, tol=0.001;, score=0.500 total time=   0.6s
[CV 1/5; 8/240] START max_iter=50, penalty=l1, solver=liblinear, tol=0.0001.....
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\svm\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(&#34;Liblinear failed to converge, increase &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 1/5; 8/240] END max_iter=50, penalty=l1, solver=liblinear, tol=0.0001;, score=0.498 total time= 4.1min
[CV 2/5; 8/240] START max_iter=50, penalty=l1, solver=liblinear, tol=0.0001.....
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\svm\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(&#34;Liblinear failed to converge, increase &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 2/5; 8/240] END max_iter=50, penalty=l1, solver=liblinear, tol=0.0001;, score=0.499 total time= 3.8min
[CV 3/5; 8/240] START max_iter=50, penalty=l1, solver=liblinear, tol=0.0001.....
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\svm\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(&#34;Liblinear failed to converge, increase &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 3/5; 8/240] END max_iter=50, penalty=l1, solver=liblinear, tol=0.0001;, score=0.499 total time= 4.3min
[CV 4/5; 8/240] START max_iter=50, penalty=l1, solver=liblinear, tol=0.0001.....
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\svm\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(&#34;Liblinear failed to converge, increase &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 4/5; 8/240] END max_iter=50, penalty=l1, solver=liblinear, tol=0.0001;, score=0.498 total time= 3.6min
[CV 5/5; 8/240] START max_iter=50, penalty=l1, solver=liblinear, tol=0.0001.....
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\svm\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(&#34;Liblinear failed to converge, increase &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 5/5; 8/240] END max_iter=50, penalty=l1, solver=liblinear, tol=0.0001;, score=0.500 total time= 3.6min
[CV 1/5; 9/240] START max_iter=50, penalty=l1, solver=liblinear, tol=1e-05......
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\svm\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(&#34;Liblinear failed to converge, increase &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 1/5; 9/240] END max_iter=50, penalty=l1, solver=liblinear, tol=1e-05;, score=0.498 total time= 3.5min
[CV 2/5; 9/240] START max_iter=50, penalty=l1, solver=liblinear, tol=1e-05......
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\svm\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(&#34;Liblinear failed to converge, increase &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 2/5; 9/240] END max_iter=50, penalty=l1, solver=liblinear, tol=1e-05;, score=0.499 total time= 3.6min
[CV 3/5; 9/240] START max_iter=50, penalty=l1, solver=liblinear, tol=1e-05......
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\svm\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(&#34;Liblinear failed to converge, increase &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 3/5; 9/240] END max_iter=50, penalty=l1, solver=liblinear, tol=1e-05;, score=0.499 total time= 3.5min
[CV 4/5; 9/240] START max_iter=50, penalty=l1, solver=liblinear, tol=1e-05......
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\svm\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(&#34;Liblinear failed to converge, increase &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 4/5; 9/240] END max_iter=50, penalty=l1, solver=liblinear, tol=1e-05;, score=0.499 total time= 3.5min
[CV 5/5; 9/240] START max_iter=50, penalty=l1, solver=liblinear, tol=1e-05......
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\svm\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(&#34;Liblinear failed to converge, increase &#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver sag supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 5/5; 9/240] END max_iter=50, penalty=l1, solver=liblinear, tol=1e-05;, score=0.500 total time= 3.8min
[CV 1/5; 10/240] START max_iter=50, penalty=l1, solver=sag, tol=0.001...........
[CV 1/5; 10/240] END max_iter=50, penalty=l1, solver=sag, tol=0.001;, score=nan total time=   0.0s
[CV 2/5; 10/240] START max_iter=50, penalty=l1, solver=sag, tol=0.001...........
[CV 2/5; 10/240] END max_iter=50, penalty=l1, solver=sag, tol=0.001;, score=nan total time=   0.0s
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver sag supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver sag supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver sag supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 3/5; 10/240] START max_iter=50, penalty=l1, solver=sag, tol=0.001...........
[CV 3/5; 10/240] END max_iter=50, penalty=l1, solver=sag, tol=0.001;, score=nan total time=   0.0s
[CV 4/5; 10/240] START max_iter=50, penalty=l1, solver=sag, tol=0.001...........
[CV 4/5; 10/240] END max_iter=50, penalty=l1, solver=sag, tol=0.001;, score=nan total time=   0.0s
[CV 5/5; 10/240] START max_iter=50, penalty=l1, solver=sag, tol=0.001...........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver sag supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver sag supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver sag supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 5/5; 10/240] END max_iter=50, penalty=l1, solver=sag, tol=0.001;, score=nan total time=   0.0s
[CV 1/5; 11/240] START max_iter=50, penalty=l1, solver=sag, tol=0.0001..........
[CV 1/5; 11/240] END max_iter=50, penalty=l1, solver=sag, tol=0.0001;, score=nan total time=   0.0s
[CV 2/5; 11/240] START max_iter=50, penalty=l1, solver=sag, tol=0.0001..........
[CV 2/5; 11/240] END max_iter=50, penalty=l1, solver=sag, tol=0.0001;, score=nan total time=   0.0s
[CV 3/5; 11/240] START max_iter=50, penalty=l1, solver=sag, tol=0.0001..........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver sag supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver sag supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver sag supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 3/5; 11/240] END max_iter=50, penalty=l1, solver=sag, tol=0.0001;, score=nan total time=   0.0s
[CV 4/5; 11/240] START max_iter=50, penalty=l1, solver=sag, tol=0.0001..........
[CV 4/5; 11/240] END max_iter=50, penalty=l1, solver=sag, tol=0.0001;, score=nan total time=   0.0s
[CV 5/5; 11/240] START max_iter=50, penalty=l1, solver=sag, tol=0.0001..........
[CV 5/5; 11/240] END max_iter=50, penalty=l1, solver=sag, tol=0.0001;, score=nan total time=   0.0s
[CV 1/5; 12/240] START max_iter=50, penalty=l1, solver=sag, tol=1e-05...........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver sag supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver sag supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver sag supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 1/5; 12/240] END max_iter=50, penalty=l1, solver=sag, tol=1e-05;, score=nan total time=   0.0s
[CV 2/5; 12/240] START max_iter=50, penalty=l1, solver=sag, tol=1e-05...........
[CV 2/5; 12/240] END max_iter=50, penalty=l1, solver=sag, tol=1e-05;, score=nan total time=   0.0s
[CV 3/5; 12/240] START max_iter=50, penalty=l1, solver=sag, tol=1e-05...........
[CV 3/5; 12/240] END max_iter=50, penalty=l1, solver=sag, tol=1e-05;, score=nan total time=   0.0s
[CV 4/5; 12/240] START max_iter=50, penalty=l1, solver=sag, tol=1e-05...........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver sag supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver sag supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 4/5; 12/240] END max_iter=50, penalty=l1, solver=sag, tol=1e-05;, score=nan total time=   0.0s
[CV 5/5; 12/240] START max_iter=50, penalty=l1, solver=sag, tol=1e-05...........
[CV 5/5; 12/240] END max_iter=50, penalty=l1, solver=sag, tol=1e-05;, score=nan total time=   0.0s
[CV 1/5; 13/240] START max_iter=50, penalty=l1, solver=saga, tol=0.001..........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(&#34;The max_iter was reached which means &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 1/5; 13/240] END max_iter=50, penalty=l1, solver=saga, tol=0.001;, score=0.499 total time=  20.0s
[CV 2/5; 13/240] START max_iter=50, penalty=l1, solver=saga, tol=0.001..........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(&#34;The max_iter was reached which means &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 2/5; 13/240] END max_iter=50, penalty=l1, solver=saga, tol=0.001;, score=0.500 total time=  19.3s
[CV 3/5; 13/240] START max_iter=50, penalty=l1, solver=saga, tol=0.001..........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(&#34;The max_iter was reached which means &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 3/5; 13/240] END max_iter=50, penalty=l1, solver=saga, tol=0.001;, score=0.500 total time=  19.6s
[CV 4/5; 13/240] START max_iter=50, penalty=l1, solver=saga, tol=0.001..........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(&#34;The max_iter was reached which means &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 4/5; 13/240] END max_iter=50, penalty=l1, solver=saga, tol=0.001;, score=0.499 total time=  20.5s
[CV 5/5; 13/240] START max_iter=50, penalty=l1, solver=saga, tol=0.001..........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(&#34;The max_iter was reached which means &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 5/5; 13/240] END max_iter=50, penalty=l1, solver=saga, tol=0.001;, score=0.499 total time=  19.7s
[CV 1/5; 14/240] START max_iter=50, penalty=l1, solver=saga, tol=0.0001.........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(&#34;The max_iter was reached which means &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 1/5; 14/240] END max_iter=50, penalty=l1, solver=saga, tol=0.0001;, score=0.499 total time=  20.0s
[CV 2/5; 14/240] START max_iter=50, penalty=l1, solver=saga, tol=0.0001.........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(&#34;The max_iter was reached which means &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 2/5; 14/240] END max_iter=50, penalty=l1, solver=saga, tol=0.0001;, score=0.500 total time=  20.3s
[CV 3/5; 14/240] START max_iter=50, penalty=l1, solver=saga, tol=0.0001.........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(&#34;The max_iter was reached which means &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 3/5; 14/240] END max_iter=50, penalty=l1, solver=saga, tol=0.0001;, score=0.500 total time=  19.8s
[CV 4/5; 14/240] START max_iter=50, penalty=l1, solver=saga, tol=0.0001.........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(&#34;The max_iter was reached which means &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 4/5; 14/240] END max_iter=50, penalty=l1, solver=saga, tol=0.0001;, score=0.499 total time=  18.7s
[CV 5/5; 14/240] START max_iter=50, penalty=l1, solver=saga, tol=0.0001.........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(&#34;The max_iter was reached which means &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 5/5; 14/240] END max_iter=50, penalty=l1, solver=saga, tol=0.0001;, score=0.499 total time=  19.3s
[CV 1/5; 15/240] START max_iter=50, penalty=l1, solver=saga, tol=1e-05..........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(&#34;The max_iter was reached which means &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 1/5; 15/240] END max_iter=50, penalty=l1, solver=saga, tol=1e-05;, score=0.499 total time=  20.4s
[CV 2/5; 15/240] START max_iter=50, penalty=l1, solver=saga, tol=1e-05..........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(&#34;The max_iter was reached which means &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 2/5; 15/240] END max_iter=50, penalty=l1, solver=saga, tol=1e-05;, score=0.500 total time=  19.1s
[CV 3/5; 15/240] START max_iter=50, penalty=l1, solver=saga, tol=1e-05..........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(&#34;The max_iter was reached which means &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 3/5; 15/240] END max_iter=50, penalty=l1, solver=saga, tol=1e-05;, score=0.500 total time=  19.6s
[CV 4/5; 15/240] START max_iter=50, penalty=l1, solver=saga, tol=1e-05..........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(&#34;The max_iter was reached which means &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 4/5; 15/240] END max_iter=50, penalty=l1, solver=saga, tol=1e-05;, score=0.499 total time=  20.4s
[CV 5/5; 15/240] START max_iter=50, penalty=l1, solver=saga, tol=1e-05..........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(&#34;The max_iter was reached which means &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 5/5; 15/240] END max_iter=50, penalty=l1, solver=saga, tol=1e-05;, score=0.499 total time=  20.1s
[CV 1/5; 16/240] START max_iter=50, penalty=l2, solver=newton-cg, tol=0.001.....
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\utils\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.
  warnings.warn(&#34;newton-cg failed to converge. Increase the &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 1/5; 16/240] END max_iter=50, penalty=l2, solver=newton-cg, tol=0.001;, score=0.497 total time= 1.7min
[CV 2/5; 16/240] START max_iter=50, penalty=l2, solver=newton-cg, tol=0.001.....
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\utils\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.
  warnings.warn(&#34;newton-cg failed to converge. Increase the &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 2/5; 16/240] END max_iter=50, penalty=l2, solver=newton-cg, tol=0.001;, score=0.499 total time= 1.6min
[CV 3/5; 16/240] START max_iter=50, penalty=l2, solver=newton-cg, tol=0.001.....
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\utils\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.
  warnings.warn(&#34;newton-cg failed to converge. Increase the &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 3/5; 16/240] END max_iter=50, penalty=l2, solver=newton-cg, tol=0.001;, score=0.498 total time= 1.6min
[CV 4/5; 16/240] START max_iter=50, penalty=l2, solver=newton-cg, tol=0.001.....
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\utils\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.
  warnings.warn(&#34;newton-cg failed to converge. Increase the &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 4/5; 16/240] END max_iter=50, penalty=l2, solver=newton-cg, tol=0.001;, score=0.498 total time= 1.7min
[CV 5/5; 16/240] START max_iter=50, penalty=l2, solver=newton-cg, tol=0.001.....
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\utils\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.
  warnings.warn(&#34;newton-cg failed to converge. Increase the &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 5/5; 16/240] END max_iter=50, penalty=l2, solver=newton-cg, tol=0.001;, score=0.500 total time= 1.6min
[CV 1/5; 17/240] START max_iter=50, penalty=l2, solver=newton-cg, tol=0.0001....
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\utils\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.
  warnings.warn(&#34;newton-cg failed to converge. Increase the &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 1/5; 17/240] END max_iter=50, penalty=l2, solver=newton-cg, tol=0.0001;, score=0.497 total time= 1.7min
[CV 2/5; 17/240] START max_iter=50, penalty=l2, solver=newton-cg, tol=0.0001....
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\utils\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.
  warnings.warn(&#34;newton-cg failed to converge. Increase the &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 2/5; 17/240] END max_iter=50, penalty=l2, solver=newton-cg, tol=0.0001;, score=0.499 total time= 1.6min
[CV 3/5; 17/240] START max_iter=50, penalty=l2, solver=newton-cg, tol=0.0001....
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\utils\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.
  warnings.warn(&#34;newton-cg failed to converge. Increase the &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 3/5; 17/240] END max_iter=50, penalty=l2, solver=newton-cg, tol=0.0001;, score=0.498 total time= 1.6min
[CV 4/5; 17/240] START max_iter=50, penalty=l2, solver=newton-cg, tol=0.0001....
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\utils\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.
  warnings.warn(&#34;newton-cg failed to converge. Increase the &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 4/5; 17/240] END max_iter=50, penalty=l2, solver=newton-cg, tol=0.0001;, score=0.498 total time= 1.8min
[CV 5/5; 17/240] START max_iter=50, penalty=l2, solver=newton-cg, tol=0.0001....
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\utils\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.
  warnings.warn(&#34;newton-cg failed to converge. Increase the &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 5/5; 17/240] END max_iter=50, penalty=l2, solver=newton-cg, tol=0.0001;, score=0.500 total time= 1.6min
[CV 1/5; 18/240] START max_iter=50, penalty=l2, solver=newton-cg, tol=1e-05.....
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\utils\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.
  warnings.warn(&#34;newton-cg failed to converge. Increase the &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 1/5; 18/240] END max_iter=50, penalty=l2, solver=newton-cg, tol=1e-05;, score=0.497 total time= 1.7min
[CV 2/5; 18/240] START max_iter=50, penalty=l2, solver=newton-cg, tol=1e-05.....
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\utils\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.
  warnings.warn(&#34;newton-cg failed to converge. Increase the &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 2/5; 18/240] END max_iter=50, penalty=l2, solver=newton-cg, tol=1e-05;, score=0.499 total time= 1.6min
[CV 3/5; 18/240] START max_iter=50, penalty=l2, solver=newton-cg, tol=1e-05.....
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\utils\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.
  warnings.warn(&#34;newton-cg failed to converge. Increase the &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 3/5; 18/240] END max_iter=50, penalty=l2, solver=newton-cg, tol=1e-05;, score=0.498 total time= 1.8min
[CV 4/5; 18/240] START max_iter=50, penalty=l2, solver=newton-cg, tol=1e-05.....
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\utils\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.
  warnings.warn(&#34;newton-cg failed to converge. Increase the &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 4/5; 18/240] END max_iter=50, penalty=l2, solver=newton-cg, tol=1e-05;, score=0.498 total time= 2.3min
[CV 5/5; 18/240] START max_iter=50, penalty=l2, solver=newton-cg, tol=1e-05.....
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\utils\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.
  warnings.warn(&#34;newton-cg failed to converge. Increase the &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 5/5; 18/240] END max_iter=50, penalty=l2, solver=newton-cg, tol=1e-05;, score=0.500 total time= 2.1min
[CV 1/5; 19/240] START max_iter=50, penalty=l2, solver=lbfgs, tol=0.001.........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 1/5; 19/240] END max_iter=50, penalty=l2, solver=lbfgs, tol=0.001;, score=0.499 total time=   1.7s
[CV 2/5; 19/240] START max_iter=50, penalty=l2, solver=lbfgs, tol=0.001.........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 2/5; 19/240] END max_iter=50, penalty=l2, solver=lbfgs, tol=0.001;, score=0.500 total time=   1.6s
[CV 3/5; 19/240] START max_iter=50, penalty=l2, solver=lbfgs, tol=0.001.........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 3/5; 19/240] END max_iter=50, penalty=l2, solver=lbfgs, tol=0.001;, score=0.501 total time=   1.6s
[CV 4/5; 19/240] START max_iter=50, penalty=l2, solver=lbfgs, tol=0.001.........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 4/5; 19/240] END max_iter=50, penalty=l2, solver=lbfgs, tol=0.001;, score=0.500 total time=   1.6s
[CV 5/5; 19/240] START max_iter=50, penalty=l2, solver=lbfgs, tol=0.001.........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 5/5; 19/240] END max_iter=50, penalty=l2, solver=lbfgs, tol=0.001;, score=0.500 total time=   1.6s
[CV 1/5; 20/240] START max_iter=50, penalty=l2, solver=lbfgs, tol=0.0001........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 1/5; 20/240] END max_iter=50, penalty=l2, solver=lbfgs, tol=0.0001;, score=0.499 total time=   1.6s
[CV 2/5; 20/240] START max_iter=50, penalty=l2, solver=lbfgs, tol=0.0001........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 2/5; 20/240] END max_iter=50, penalty=l2, solver=lbfgs, tol=0.0001;, score=0.500 total time=   1.6s
[CV 3/5; 20/240] START max_iter=50, penalty=l2, solver=lbfgs, tol=0.0001........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 3/5; 20/240] END max_iter=50, penalty=l2, solver=lbfgs, tol=0.0001;, score=0.501 total time=   1.6s
[CV 4/5; 20/240] START max_iter=50, penalty=l2, solver=lbfgs, tol=0.0001........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 4/5; 20/240] END max_iter=50, penalty=l2, solver=lbfgs, tol=0.0001;, score=0.500 total time=   1.6s
[CV 5/5; 20/240] START max_iter=50, penalty=l2, solver=lbfgs, tol=0.0001........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 5/5; 20/240] END max_iter=50, penalty=l2, solver=lbfgs, tol=0.0001;, score=0.500 total time=   1.6s
[CV 1/5; 21/240] START max_iter=50, penalty=l2, solver=lbfgs, tol=1e-05.........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 1/5; 21/240] END max_iter=50, penalty=l2, solver=lbfgs, tol=1e-05;, score=0.499 total time=   1.5s
[CV 2/5; 21/240] START max_iter=50, penalty=l2, solver=lbfgs, tol=1e-05.........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 2/5; 21/240] END max_iter=50, penalty=l2, solver=lbfgs, tol=1e-05;, score=0.500 total time=   1.6s
[CV 3/5; 21/240] START max_iter=50, penalty=l2, solver=lbfgs, tol=1e-05.........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 3/5; 21/240] END max_iter=50, penalty=l2, solver=lbfgs, tol=1e-05;, score=0.501 total time=   1.6s
[CV 4/5; 21/240] START max_iter=50, penalty=l2, solver=lbfgs, tol=1e-05.........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 4/5; 21/240] END max_iter=50, penalty=l2, solver=lbfgs, tol=1e-05;, score=0.500 total time=   1.6s
[CV 5/5; 21/240] START max_iter=50, penalty=l2, solver=lbfgs, tol=1e-05.........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 5/5; 21/240] END max_iter=50, penalty=l2, solver=lbfgs, tol=1e-05;, score=0.500 total time=   1.6s
[CV 1/5; 22/240] START max_iter=50, penalty=l2, solver=liblinear, tol=0.001.....
[CV 1/5; 22/240] END max_iter=50, penalty=l2, solver=liblinear, tol=0.001;, score=0.498 total time=  18.1s
[CV 2/5; 22/240] START max_iter=50, penalty=l2, solver=liblinear, tol=0.001.....
[CV 2/5; 22/240] END max_iter=50, penalty=l2, solver=liblinear, tol=0.001;, score=0.499 total time=  17.2s
[CV 3/5; 22/240] START max_iter=50, penalty=l2, solver=liblinear, tol=0.001.....
[CV 3/5; 22/240] END max_iter=50, penalty=l2, solver=liblinear, tol=0.001;, score=0.499 total time=  17.9s
[CV 4/5; 22/240] START max_iter=50, penalty=l2, solver=liblinear, tol=0.001.....
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\svm\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(&#34;Liblinear failed to converge, increase &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 4/5; 22/240] END max_iter=50, penalty=l2, solver=liblinear, tol=0.001;, score=0.498 total time=  22.4s
[CV 5/5; 22/240] START max_iter=50, penalty=l2, solver=liblinear, tol=0.001.....
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\svm\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(&#34;Liblinear failed to converge, increase &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 5/5; 22/240] END max_iter=50, penalty=l2, solver=liblinear, tol=0.001;, score=0.499 total time=  11.8s
[CV 1/5; 23/240] START max_iter=50, penalty=l2, solver=liblinear, tol=0.0001....
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\svm\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(&#34;Liblinear failed to converge, increase &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 1/5; 23/240] END max_iter=50, penalty=l2, solver=liblinear, tol=0.0001;, score=0.497 total time=  53.2s
[CV 2/5; 23/240] START max_iter=50, penalty=l2, solver=liblinear, tol=0.0001....
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\svm\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(&#34;Liblinear failed to converge, increase &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 2/5; 23/240] END max_iter=50, penalty=l2, solver=liblinear, tol=0.0001;, score=0.500 total time= 2.3min
[CV 3/5; 23/240] START max_iter=50, penalty=l2, solver=liblinear, tol=0.0001....
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\svm\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(&#34;Liblinear failed to converge, increase &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 3/5; 23/240] END max_iter=50, penalty=l2, solver=liblinear, tol=0.0001;, score=0.499 total time= 2.5min
[CV 4/5; 23/240] START max_iter=50, penalty=l2, solver=liblinear, tol=0.0001....
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\svm\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(&#34;Liblinear failed to converge, increase &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 4/5; 23/240] END max_iter=50, penalty=l2, solver=liblinear, tol=0.0001;, score=0.498 total time=  21.0s
[CV 5/5; 23/240] START max_iter=50, penalty=l2, solver=liblinear, tol=0.0001....
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\svm\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(&#34;Liblinear failed to converge, increase &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 5/5; 23/240] END max_iter=50, penalty=l2, solver=liblinear, tol=0.0001;, score=0.499 total time=  10.9s
[CV 1/5; 24/240] START max_iter=50, penalty=l2, solver=liblinear, tol=1e-05.....
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\svm\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(&#34;Liblinear failed to converge, increase &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 1/5; 24/240] END max_iter=50, penalty=l2, solver=liblinear, tol=1e-05;, score=0.497 total time=  51.2s
[CV 2/5; 24/240] START max_iter=50, penalty=l2, solver=liblinear, tol=1e-05.....
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\svm\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(&#34;Liblinear failed to converge, increase &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 2/5; 24/240] END max_iter=50, penalty=l2, solver=liblinear, tol=1e-05;, score=0.500 total time= 2.5min
[CV 3/5; 24/240] START max_iter=50, penalty=l2, solver=liblinear, tol=1e-05.....
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\svm\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(&#34;Liblinear failed to converge, increase &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 3/5; 24/240] END max_iter=50, penalty=l2, solver=liblinear, tol=1e-05;, score=0.499 total time= 2.7min
[CV 4/5; 24/240] START max_iter=50, penalty=l2, solver=liblinear, tol=1e-05.....
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\svm\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(&#34;Liblinear failed to converge, increase &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 4/5; 24/240] END max_iter=50, penalty=l2, solver=liblinear, tol=1e-05;, score=0.498 total time=  25.5s
[CV 5/5; 24/240] START max_iter=50, penalty=l2, solver=liblinear, tol=1e-05.....
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\svm\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(&#34;Liblinear failed to converge, increase &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 5/5; 24/240] END max_iter=50, penalty=l2, solver=liblinear, tol=1e-05;, score=0.499 total time=  13.2s
[CV 1/5; 25/240] START max_iter=50, penalty=l2, solver=sag, tol=0.001...........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(&#34;The max_iter was reached which means &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 1/5; 25/240] END max_iter=50, penalty=l2, solver=sag, tol=0.001;, score=0.499 total time=  13.8s
[CV 2/5; 25/240] START max_iter=50, penalty=l2, solver=sag, tol=0.001...........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(&#34;The max_iter was reached which means &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 2/5; 25/240] END max_iter=50, penalty=l2, solver=sag, tol=0.001;, score=0.500 total time=  13.6s
[CV 3/5; 25/240] START max_iter=50, penalty=l2, solver=sag, tol=0.001...........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(&#34;The max_iter was reached which means &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 3/5; 25/240] END max_iter=50, penalty=l2, solver=sag, tol=0.001;, score=0.500 total time=  12.3s
[CV 4/5; 25/240] START max_iter=50, penalty=l2, solver=sag, tol=0.001...........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(&#34;The max_iter was reached which means &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 4/5; 25/240] END max_iter=50, penalty=l2, solver=sag, tol=0.001;, score=0.500 total time=  12.1s
[CV 5/5; 25/240] START max_iter=50, penalty=l2, solver=sag, tol=0.001...........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(&#34;The max_iter was reached which means &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 5/5; 25/240] END max_iter=50, penalty=l2, solver=sag, tol=0.001;, score=0.500 total time=  12.1s
[CV 1/5; 26/240] START max_iter=50, penalty=l2, solver=sag, tol=0.0001..........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(&#34;The max_iter was reached which means &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 1/5; 26/240] END max_iter=50, penalty=l2, solver=sag, tol=0.0001;, score=0.499 total time=  11.9s
[CV 2/5; 26/240] START max_iter=50, penalty=l2, solver=sag, tol=0.0001..........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(&#34;The max_iter was reached which means &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 2/5; 26/240] END max_iter=50, penalty=l2, solver=sag, tol=0.0001;, score=0.500 total time=  11.8s
[CV 3/5; 26/240] START max_iter=50, penalty=l2, solver=sag, tol=0.0001..........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(&#34;The max_iter was reached which means &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 3/5; 26/240] END max_iter=50, penalty=l2, solver=sag, tol=0.0001;, score=0.500 total time=  11.1s
[CV 4/5; 26/240] START max_iter=50, penalty=l2, solver=sag, tol=0.0001..........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(&#34;The max_iter was reached which means &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 4/5; 26/240] END max_iter=50, penalty=l2, solver=sag, tol=0.0001;, score=0.500 total time=  11.8s
[CV 5/5; 26/240] START max_iter=50, penalty=l2, solver=sag, tol=0.0001..........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(&#34;The max_iter was reached which means &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 5/5; 26/240] END max_iter=50, penalty=l2, solver=sag, tol=0.0001;, score=0.500 total time=  12.4s
[CV 1/5; 27/240] START max_iter=50, penalty=l2, solver=sag, tol=1e-05...........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(&#34;The max_iter was reached which means &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 1/5; 27/240] END max_iter=50, penalty=l2, solver=sag, tol=1e-05;, score=0.499 total time=  13.3s
[CV 2/5; 27/240] START max_iter=50, penalty=l2, solver=sag, tol=1e-05...........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(&#34;The max_iter was reached which means &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 2/5; 27/240] END max_iter=50, penalty=l2, solver=sag, tol=1e-05;, score=0.500 total time=  12.8s
[CV 3/5; 27/240] START max_iter=50, penalty=l2, solver=sag, tol=1e-05...........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(&#34;The max_iter was reached which means &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 3/5; 27/240] END max_iter=50, penalty=l2, solver=sag, tol=1e-05;, score=0.500 total time=  13.3s
[CV 4/5; 27/240] START max_iter=50, penalty=l2, solver=sag, tol=1e-05...........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(&#34;The max_iter was reached which means &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 4/5; 27/240] END max_iter=50, penalty=l2, solver=sag, tol=1e-05;, score=0.500 total time=  13.1s
[CV 5/5; 27/240] START max_iter=50, penalty=l2, solver=sag, tol=1e-05...........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(&#34;The max_iter was reached which means &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 5/5; 27/240] END max_iter=50, penalty=l2, solver=sag, tol=1e-05;, score=0.500 total time=  13.9s
[CV 1/5; 28/240] START max_iter=50, penalty=l2, solver=saga, tol=0.001..........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(&#34;The max_iter was reached which means &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 1/5; 28/240] END max_iter=50, penalty=l2, solver=saga, tol=0.001;, score=0.499 total time=  15.5s
[CV 2/5; 28/240] START max_iter=50, penalty=l2, solver=saga, tol=0.001..........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(&#34;The max_iter was reached which means &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 2/5; 28/240] END max_iter=50, penalty=l2, solver=saga, tol=0.001;, score=0.500 total time=  15.9s
[CV 3/5; 28/240] START max_iter=50, penalty=l2, solver=saga, tol=0.001..........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(&#34;The max_iter was reached which means &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 3/5; 28/240] END max_iter=50, penalty=l2, solver=saga, tol=0.001;, score=0.500 total time=  16.1s
[CV 4/5; 28/240] START max_iter=50, penalty=l2, solver=saga, tol=0.001..........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(&#34;The max_iter was reached which means &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 4/5; 28/240] END max_iter=50, penalty=l2, solver=saga, tol=0.001;, score=0.499 total time=  16.2s
[CV 5/5; 28/240] START max_iter=50, penalty=l2, solver=saga, tol=0.001..........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(&#34;The max_iter was reached which means &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 5/5; 28/240] END max_iter=50, penalty=l2, solver=saga, tol=0.001;, score=0.499 total time=  15.7s
[CV 1/5; 29/240] START max_iter=50, penalty=l2, solver=saga, tol=0.0001.........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(&#34;The max_iter was reached which means &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 1/5; 29/240] END max_iter=50, penalty=l2, solver=saga, tol=0.0001;, score=0.499 total time=  15.6s
[CV 2/5; 29/240] START max_iter=50, penalty=l2, solver=saga, tol=0.0001.........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(&#34;The max_iter was reached which means &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 2/5; 29/240] END max_iter=50, penalty=l2, solver=saga, tol=0.0001;, score=0.500 total time=  15.6s
[CV 3/5; 29/240] START max_iter=50, penalty=l2, solver=saga, tol=0.0001.........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(&#34;The max_iter was reached which means &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 3/5; 29/240] END max_iter=50, penalty=l2, solver=saga, tol=0.0001;, score=0.500 total time=  15.5s
[CV 4/5; 29/240] START max_iter=50, penalty=l2, solver=saga, tol=0.0001.........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(&#34;The max_iter was reached which means &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 4/5; 29/240] END max_iter=50, penalty=l2, solver=saga, tol=0.0001;, score=0.499 total time=  14.9s
[CV 5/5; 29/240] START max_iter=50, penalty=l2, solver=saga, tol=0.0001.........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(&#34;The max_iter was reached which means &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 5/5; 29/240] END max_iter=50, penalty=l2, solver=saga, tol=0.0001;, score=0.499 total time=  15.4s
[CV 1/5; 30/240] START max_iter=50, penalty=l2, solver=saga, tol=1e-05..........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(&#34;The max_iter was reached which means &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 1/5; 30/240] END max_iter=50, penalty=l2, solver=saga, tol=1e-05;, score=0.499 total time=  15.2s
[CV 2/5; 30/240] START max_iter=50, penalty=l2, solver=saga, tol=1e-05..........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(&#34;The max_iter was reached which means &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 2/5; 30/240] END max_iter=50, penalty=l2, solver=saga, tol=1e-05;, score=0.500 total time=  15.4s
[CV 3/5; 30/240] START max_iter=50, penalty=l2, solver=saga, tol=1e-05..........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(&#34;The max_iter was reached which means &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 3/5; 30/240] END max_iter=50, penalty=l2, solver=saga, tol=1e-05;, score=0.500 total time=  15.6s
[CV 4/5; 30/240] START max_iter=50, penalty=l2, solver=saga, tol=1e-05..........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(&#34;The max_iter was reached which means &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 4/5; 30/240] END max_iter=50, penalty=l2, solver=saga, tol=1e-05;, score=0.499 total time=  15.5s
[CV 5/5; 30/240] START max_iter=50, penalty=l2, solver=saga, tol=1e-05..........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(&#34;The max_iter was reached which means &#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver newton-cg supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 5/5; 30/240] END max_iter=50, penalty=l2, solver=saga, tol=1e-05;, score=0.499 total time=  15.7s
[CV 1/5; 31/240] START max_iter=50, penalty=elasticnet, solver=newton-cg, tol=0.001
[CV 1/5; 31/240] END max_iter=50, penalty=elasticnet, solver=newton-cg, tol=0.001;, score=nan total time=   0.0s
[CV 2/5; 31/240] START max_iter=50, penalty=elasticnet, solver=newton-cg, tol=0.001
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver newton-cg supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver newton-cg supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver newton-cg supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 2/5; 31/240] END max_iter=50, penalty=elasticnet, solver=newton-cg, tol=0.001;, score=nan total time=   0.0s
[CV 3/5; 31/240] START max_iter=50, penalty=elasticnet, solver=newton-cg, tol=0.001
[CV 3/5; 31/240] END max_iter=50, penalty=elasticnet, solver=newton-cg, tol=0.001;, score=nan total time=   0.0s
[CV 4/5; 31/240] START max_iter=50, penalty=elasticnet, solver=newton-cg, tol=0.001
[CV 4/5; 31/240] END max_iter=50, penalty=elasticnet, solver=newton-cg, tol=0.001;, score=nan total time=   0.0s
[CV 5/5; 31/240] START max_iter=50, penalty=elasticnet, solver=newton-cg, tol=0.001
[CV 5/5; 31/240] END max_iter=50, penalty=elasticnet, solver=newton-cg, tol=0.001;, score=nan total time=   0.0s
[CV 1/5; 32/240] START max_iter=50, penalty=elasticnet, solver=newton-cg, tol=0.0001
[CV 1/5; 32/240] END max_iter=50, penalty=elasticnet, solver=newton-cg, tol=0.0001;, score=nan total time=   0.0s
[CV 2/5; 32/240] START max_iter=50, penalty=elasticnet, solver=newton-cg, tol=0.0001</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver newton-cg supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver newton-cg supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver newton-cg supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>
[CV 2/5; 32/240] END max_iter=50, penalty=elasticnet, solver=newton-cg, tol=0.0001;, score=nan total time=   0.0s
[CV 3/5; 32/240] START max_iter=50, penalty=elasticnet, solver=newton-cg, tol=0.0001
[CV 3/5; 32/240] END max_iter=50, penalty=elasticnet, solver=newton-cg, tol=0.0001;, score=nan total time=   0.0s
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver newton-cg supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver newton-cg supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver newton-cg supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 4/5; 32/240] START max_iter=50, penalty=elasticnet, solver=newton-cg, tol=0.0001
[CV 4/5; 32/240] END max_iter=50, penalty=elasticnet, solver=newton-cg, tol=0.0001;, score=nan total time=   0.0s
[CV 5/5; 32/240] START max_iter=50, penalty=elasticnet, solver=newton-cg, tol=0.0001
[CV 5/5; 32/240] END max_iter=50, penalty=elasticnet, solver=newton-cg, tol=0.0001;, score=nan total time=   0.0s
[CV 1/5; 33/240] START max_iter=50, penalty=elasticnet, solver=newton-cg, tol=1e-05</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver newton-cg supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver newton-cg supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>
[CV 1/5; 33/240] END max_iter=50, penalty=elasticnet, solver=newton-cg, tol=1e-05;, score=nan total time=   0.0s
[CV 2/5; 33/240] START max_iter=50, penalty=elasticnet, solver=newton-cg, tol=1e-05
[CV 2/5; 33/240] END max_iter=50, penalty=elasticnet, solver=newton-cg, tol=1e-05;, score=nan total time=   0.0s
[CV 3/5; 33/240] START max_iter=50, penalty=elasticnet, solver=newton-cg, tol=1e-05
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver newton-cg supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver newton-cg supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver newton-cg supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 3/5; 33/240] END max_iter=50, penalty=elasticnet, solver=newton-cg, tol=1e-05;, score=nan total time=   0.0s
[CV 4/5; 33/240] START max_iter=50, penalty=elasticnet, solver=newton-cg, tol=1e-05
[CV 4/5; 33/240] END max_iter=50, penalty=elasticnet, solver=newton-cg, tol=1e-05;, score=nan total time=   0.0s
[CV 5/5; 33/240] START max_iter=50, penalty=elasticnet, solver=newton-cg, tol=1e-05
[CV 5/5; 33/240] END max_iter=50, penalty=elasticnet, solver=newton-cg, tol=1e-05;, score=nan total time=   0.0s
[CV 1/5; 34/240] START max_iter=50, penalty=elasticnet, solver=lbfgs, tol=0.001.</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>
[CV 1/5; 34/240] END max_iter=50, penalty=elasticnet, solver=lbfgs, tol=0.001;, score=nan total time=   0.0s
[CV 2/5; 34/240] START max_iter=50, penalty=elasticnet, solver=lbfgs, tol=0.001.
[CV 2/5; 34/240] END max_iter=50, penalty=elasticnet, solver=lbfgs, tol=0.001;, score=nan total time=   0.0s
[CV 3/5; 34/240] START max_iter=50, penalty=elasticnet, solver=lbfgs, tol=0.001.
[CV 3/5; 34/240] END max_iter=50, penalty=elasticnet, solver=lbfgs, tol=0.001;, score=nan total time=   0.0s
[CV 4/5; 34/240] START max_iter=50, penalty=elasticnet, solver=lbfgs, tol=0.001.</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>
[CV 4/5; 34/240] END max_iter=50, penalty=elasticnet, solver=lbfgs, tol=0.001;, score=nan total time=   0.0s
[CV 5/5; 34/240] START max_iter=50, penalty=elasticnet, solver=lbfgs, tol=0.001.
[CV 5/5; 34/240] END max_iter=50, penalty=elasticnet, solver=lbfgs, tol=0.001;, score=nan total time=   0.0s
[CV 1/5; 35/240] START max_iter=50, penalty=elasticnet, solver=lbfgs, tol=0.0001
[CV 1/5; 35/240] END max_iter=50, penalty=elasticnet, solver=lbfgs, tol=0.0001;, score=nan total time=   0.0s
[CV 2/5; 35/240] START max_iter=50, penalty=elasticnet, solver=lbfgs, tol=0.0001
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 2/5; 35/240] END max_iter=50, penalty=elasticnet, solver=lbfgs, tol=0.0001;, score=nan total time=   0.0s
[CV 3/5; 35/240] START max_iter=50, penalty=elasticnet, solver=lbfgs, tol=0.0001
[CV 3/5; 35/240] END max_iter=50, penalty=elasticnet, solver=lbfgs, tol=0.0001;, score=nan total time=   0.0s
[CV 4/5; 35/240] START max_iter=50, penalty=elasticnet, solver=lbfgs, tol=0.0001
[CV 4/5; 35/240] END max_iter=50, penalty=elasticnet, solver=lbfgs, tol=0.0001;, score=nan total time=   0.0s
[CV 5/5; 35/240] START max_iter=50, penalty=elasticnet, solver=lbfgs, tol=0.0001
[CV 5/5; 35/240] END max_iter=50, penalty=elasticnet, solver=lbfgs, tol=0.0001;, score=nan total time=   0.0s
[CV 1/5; 36/240] START max_iter=50, penalty=elasticnet, solver=lbfgs, tol=1e-05.
[CV 1/5; 36/240] END max_iter=50, penalty=elasticnet, solver=lbfgs, tol=1e-05;, score=nan total time=   0.0s
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 2/5; 36/240] START max_iter=50, penalty=elasticnet, solver=lbfgs, tol=1e-05.
[CV 2/5; 36/240] END max_iter=50, penalty=elasticnet, solver=lbfgs, tol=1e-05;, score=nan total time=   0.0s
[CV 3/5; 36/240] START max_iter=50, penalty=elasticnet, solver=lbfgs, tol=1e-05.
[CV 3/5; 36/240] END max_iter=50, penalty=elasticnet, solver=lbfgs, tol=1e-05;, score=nan total time=   0.0s
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 4/5; 36/240] START max_iter=50, penalty=elasticnet, solver=lbfgs, tol=1e-05.
[CV 4/5; 36/240] END max_iter=50, penalty=elasticnet, solver=lbfgs, tol=1e-05;, score=nan total time=   0.0s
[CV 5/5; 36/240] START max_iter=50, penalty=elasticnet, solver=lbfgs, tol=1e-05.
[CV 5/5; 36/240] END max_iter=50, penalty=elasticnet, solver=lbfgs, tol=1e-05;, score=nan total time=   0.0s
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 1/5; 37/240] START max_iter=50, penalty=elasticnet, solver=liblinear, tol=0.001
[CV 1/5; 37/240] END max_iter=50, penalty=elasticnet, solver=liblinear, tol=0.001;, score=nan total time=   0.0s
[CV 2/5; 37/240] START max_iter=50, penalty=elasticnet, solver=liblinear, tol=0.001
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 450, in _check_solver
    raise ValueError(&#34;Only &#39;saga&#39; solver supports elasticnet penalty,&#34;
ValueError: Only &#39;saga&#39; solver supports elasticnet penalty, got solver=liblinear.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 450, in _check_solver
    raise ValueError(&#34;Only &#39;saga&#39; solver supports elasticnet penalty,&#34;
ValueError: Only &#39;saga&#39; solver supports elasticnet penalty, got solver=liblinear.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 2/5; 37/240] END max_iter=50, penalty=elasticnet, solver=liblinear, tol=0.001;, score=nan total time=   0.0s
[CV 3/5; 37/240] START max_iter=50, penalty=elasticnet, solver=liblinear, tol=0.001
[CV 3/5; 37/240] END max_iter=50, penalty=elasticnet, solver=liblinear, tol=0.001;, score=nan total time=   0.0s
[CV 4/5; 37/240] START max_iter=50, penalty=elasticnet, solver=liblinear, tol=0.001
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 450, in _check_solver
    raise ValueError(&#34;Only &#39;saga&#39; solver supports elasticnet penalty,&#34;
ValueError: Only &#39;saga&#39; solver supports elasticnet penalty, got solver=liblinear.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 450, in _check_solver
    raise ValueError(&#34;Only &#39;saga&#39; solver supports elasticnet penalty,&#34;
ValueError: Only &#39;saga&#39; solver supports elasticnet penalty, got solver=liblinear.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 4/5; 37/240] END max_iter=50, penalty=elasticnet, solver=liblinear, tol=0.001;, score=nan total time=   0.0s
[CV 5/5; 37/240] START max_iter=50, penalty=elasticnet, solver=liblinear, tol=0.001
[CV 5/5; 37/240] END max_iter=50, penalty=elasticnet, solver=liblinear, tol=0.001;, score=nan total time=   0.0s
[CV 1/5; 38/240] START max_iter=50, penalty=elasticnet, solver=liblinear, tol=0.0001
[CV 1/5; 38/240] END max_iter=50, penalty=elasticnet, solver=liblinear, tol=0.0001;, score=nan total time=   0.0s
[CV 2/5; 38/240] START max_iter=50, penalty=elasticnet, solver=liblinear, tol=0.0001</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 450, in _check_solver
    raise ValueError(&#34;Only &#39;saga&#39; solver supports elasticnet penalty,&#34;
ValueError: Only &#39;saga&#39; solver supports elasticnet penalty, got solver=liblinear.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 450, in _check_solver
    raise ValueError(&#34;Only &#39;saga&#39; solver supports elasticnet penalty,&#34;
ValueError: Only &#39;saga&#39; solver supports elasticnet penalty, got solver=liblinear.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 450, in _check_solver
    raise ValueError(&#34;Only &#39;saga&#39; solver supports elasticnet penalty,&#34;
ValueError: Only &#39;saga&#39; solver supports elasticnet penalty, got solver=liblinear.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>
[CV 2/5; 38/240] END max_iter=50, penalty=elasticnet, solver=liblinear, tol=0.0001;, score=nan total time=   0.0s
[CV 3/5; 38/240] START max_iter=50, penalty=elasticnet, solver=liblinear, tol=0.0001
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 450, in _check_solver
    raise ValueError(&#34;Only &#39;saga&#39; solver supports elasticnet penalty,&#34;
ValueError: Only &#39;saga&#39; solver supports elasticnet penalty, got solver=liblinear.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 450, in _check_solver
    raise ValueError(&#34;Only &#39;saga&#39; solver supports elasticnet penalty,&#34;
ValueError: Only &#39;saga&#39; solver supports elasticnet penalty, got solver=liblinear.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 3/5; 38/240] END max_iter=50, penalty=elasticnet, solver=liblinear, tol=0.0001;, score=nan total time=   0.0s
[CV 4/5; 38/240] START max_iter=50, penalty=elasticnet, solver=liblinear, tol=0.0001
[CV 4/5; 38/240] END max_iter=50, penalty=elasticnet, solver=liblinear, tol=0.0001;, score=nan total time=   0.0s
[CV 5/5; 38/240] START max_iter=50, penalty=elasticnet, solver=liblinear, tol=0.0001
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 450, in _check_solver
    raise ValueError(&#34;Only &#39;saga&#39; solver supports elasticnet penalty,&#34;
ValueError: Only &#39;saga&#39; solver supports elasticnet penalty, got solver=liblinear.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 450, in _check_solver
    raise ValueError(&#34;Only &#39;saga&#39; solver supports elasticnet penalty,&#34;
ValueError: Only &#39;saga&#39; solver supports elasticnet penalty, got solver=liblinear.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 5/5; 38/240] END max_iter=50, penalty=elasticnet, solver=liblinear, tol=0.0001;, score=nan total time=   0.0s
[CV 1/5; 39/240] START max_iter=50, penalty=elasticnet, solver=liblinear, tol=1e-05
[CV 1/5; 39/240] END max_iter=50, penalty=elasticnet, solver=liblinear, tol=1e-05;, score=nan total time=   0.0s
[CV 2/5; 39/240] START max_iter=50, penalty=elasticnet, solver=liblinear, tol=1e-05
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 450, in _check_solver
    raise ValueError(&#34;Only &#39;saga&#39; solver supports elasticnet penalty,&#34;
ValueError: Only &#39;saga&#39; solver supports elasticnet penalty, got solver=liblinear.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 450, in _check_solver
    raise ValueError(&#34;Only &#39;saga&#39; solver supports elasticnet penalty,&#34;
ValueError: Only &#39;saga&#39; solver supports elasticnet penalty, got solver=liblinear.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 2/5; 39/240] END max_iter=50, penalty=elasticnet, solver=liblinear, tol=1e-05;, score=nan total time=   0.0s
[CV 3/5; 39/240] START max_iter=50, penalty=elasticnet, solver=liblinear, tol=1e-05
[CV 3/5; 39/240] END max_iter=50, penalty=elasticnet, solver=liblinear, tol=1e-05;, score=nan total time=   0.0s
[CV 4/5; 39/240] START max_iter=50, penalty=elasticnet, solver=liblinear, tol=1e-05
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 450, in _check_solver
    raise ValueError(&#34;Only &#39;saga&#39; solver supports elasticnet penalty,&#34;
ValueError: Only &#39;saga&#39; solver supports elasticnet penalty, got solver=liblinear.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 450, in _check_solver
    raise ValueError(&#34;Only &#39;saga&#39; solver supports elasticnet penalty,&#34;
ValueError: Only &#39;saga&#39; solver supports elasticnet penalty, got solver=liblinear.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver sag supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 4/5; 39/240] END max_iter=50, penalty=elasticnet, solver=liblinear, tol=1e-05;, score=nan total time=   0.0s
[CV 5/5; 39/240] START max_iter=50, penalty=elasticnet, solver=liblinear, tol=1e-05
[CV 5/5; 39/240] END max_iter=50, penalty=elasticnet, solver=liblinear, tol=1e-05;, score=nan total time=   0.0s
[CV 1/5; 40/240] START max_iter=50, penalty=elasticnet, solver=sag, tol=0.001...
[CV 1/5; 40/240] END max_iter=50, penalty=elasticnet, solver=sag, tol=0.001;, score=nan total time=   0.0s
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver sag supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver sag supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver sag supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 2/5; 40/240] START max_iter=50, penalty=elasticnet, solver=sag, tol=0.001...
[CV 2/5; 40/240] END max_iter=50, penalty=elasticnet, solver=sag, tol=0.001;, score=nan total time=   0.0s
[CV 3/5; 40/240] START max_iter=50, penalty=elasticnet, solver=sag, tol=0.001...
[CV 3/5; 40/240] END max_iter=50, penalty=elasticnet, solver=sag, tol=0.001;, score=nan total time=   0.0s
[CV 4/5; 40/240] START max_iter=50, penalty=elasticnet, solver=sag, tol=0.001...
[CV 4/5; 40/240] END max_iter=50, penalty=elasticnet, solver=sag, tol=0.001;, score=nan total time=   0.0s
[CV 5/5; 40/240] START max_iter=50, penalty=elasticnet, solver=sag, tol=0.001...</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver sag supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver sag supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver sag supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>
[CV 5/5; 40/240] END max_iter=50, penalty=elasticnet, solver=sag, tol=0.001;, score=nan total time=   0.0s
[CV 1/5; 41/240] START max_iter=50, penalty=elasticnet, solver=sag, tol=0.0001..
[CV 1/5; 41/240] END max_iter=50, penalty=elasticnet, solver=sag, tol=0.0001;, score=nan total time=   0.0s
[CV 2/5; 41/240] START max_iter=50, penalty=elasticnet, solver=sag, tol=0.0001..
[CV 2/5; 41/240] END max_iter=50, penalty=elasticnet, solver=sag, tol=0.0001;, score=nan total time=   0.0s
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver sag supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver sag supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver sag supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 3/5; 41/240] START max_iter=50, penalty=elasticnet, solver=sag, tol=0.0001..
[CV 3/5; 41/240] END max_iter=50, penalty=elasticnet, solver=sag, tol=0.0001;, score=nan total time=   0.0s
[CV 4/5; 41/240] START max_iter=50, penalty=elasticnet, solver=sag, tol=0.0001..
[CV 4/5; 41/240] END max_iter=50, penalty=elasticnet, solver=sag, tol=0.0001;, score=nan total time=   0.0s
[CV 5/5; 41/240] START max_iter=50, penalty=elasticnet, solver=sag, tol=0.0001..
[CV 5/5; 41/240] END max_iter=50, penalty=elasticnet, solver=sag, tol=0.0001;, score=nan total time=   0.0s
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver sag supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver sag supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 1/5; 42/240] START max_iter=50, penalty=elasticnet, solver=sag, tol=1e-05...
[CV 1/5; 42/240] END max_iter=50, penalty=elasticnet, solver=sag, tol=1e-05;, score=nan total time=   0.0s
[CV 2/5; 42/240] START max_iter=50, penalty=elasticnet, solver=sag, tol=1e-05...
[CV 2/5; 42/240] END max_iter=50, penalty=elasticnet, solver=sag, tol=1e-05;, score=nan total time=   0.0s
[CV 3/5; 42/240] START max_iter=50, penalty=elasticnet, solver=sag, tol=1e-05...
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver sag supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver sag supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver sag supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 3/5; 42/240] END max_iter=50, penalty=elasticnet, solver=sag, tol=1e-05;, score=nan total time=   0.0s
[CV 4/5; 42/240] START max_iter=50, penalty=elasticnet, solver=sag, tol=1e-05...
[CV 4/5; 42/240] END max_iter=50, penalty=elasticnet, solver=sag, tol=1e-05;, score=nan total time=   0.0s
[CV 5/5; 42/240] START max_iter=50, penalty=elasticnet, solver=sag, tol=1e-05...
[CV 5/5; 42/240] END max_iter=50, penalty=elasticnet, solver=sag, tol=1e-05;, score=nan total time=   0.0s
[CV 1/5; 43/240] START max_iter=50, penalty=elasticnet, solver=saga, tol=0.001..
[CV 1/5; 43/240] END max_iter=50, penalty=elasticnet, solver=saga, tol=0.001;, score=nan total time=   0.0s
[CV 2/5; 43/240] START max_iter=50, penalty=elasticnet, solver=saga, tol=0.001..
[CV 2/5; 43/240] END max_iter=50, penalty=elasticnet, solver=saga, tol=0.001;, score=nan total time=   0.0s
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1314, in fit
    raise ValueError(&#34;l1_ratio must be between 0 and 1;&#34;
ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1314, in fit
    raise ValueError(&#34;l1_ratio must be between 0 and 1;&#34;
ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1314, in fit
    raise ValueError(&#34;l1_ratio must be between 0 and 1;&#34;
ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 3/5; 43/240] START max_iter=50, penalty=elasticnet, solver=saga, tol=0.001..
[CV 3/5; 43/240] END max_iter=50, penalty=elasticnet, solver=saga, tol=0.001;, score=nan total time=   0.0s
[CV 4/5; 43/240] START max_iter=50, penalty=elasticnet, solver=saga, tol=0.001..
[CV 4/5; 43/240] END max_iter=50, penalty=elasticnet, solver=saga, tol=0.001;, score=nan total time=   0.0s
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1314, in fit
    raise ValueError(&#34;l1_ratio must be between 0 and 1;&#34;
ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1314, in fit
    raise ValueError(&#34;l1_ratio must be between 0 and 1;&#34;
ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1314, in fit
    raise ValueError(&#34;l1_ratio must be between 0 and 1;&#34;
ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 5/5; 43/240] START max_iter=50, penalty=elasticnet, solver=saga, tol=0.001..
[CV 5/5; 43/240] END max_iter=50, penalty=elasticnet, solver=saga, tol=0.001;, score=nan total time=   0.0s
[CV 1/5; 44/240] START max_iter=50, penalty=elasticnet, solver=saga, tol=0.0001.
[CV 1/5; 44/240] END max_iter=50, penalty=elasticnet, solver=saga, tol=0.0001;, score=nan total time=   0.0s
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1314, in fit
    raise ValueError(&#34;l1_ratio must be between 0 and 1;&#34;
ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1314, in fit
    raise ValueError(&#34;l1_ratio must be between 0 and 1;&#34;
ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1314, in fit
    raise ValueError(&#34;l1_ratio must be between 0 and 1;&#34;
ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 2/5; 44/240] START max_iter=50, penalty=elasticnet, solver=saga, tol=0.0001.
[CV 2/5; 44/240] END max_iter=50, penalty=elasticnet, solver=saga, tol=0.0001;, score=nan total time=   0.0s
[CV 3/5; 44/240] START max_iter=50, penalty=elasticnet, solver=saga, tol=0.0001.
[CV 3/5; 44/240] END max_iter=50, penalty=elasticnet, solver=saga, tol=0.0001;, score=nan total time=   0.0s
[CV 4/5; 44/240] START max_iter=50, penalty=elasticnet, solver=saga, tol=0.0001.
[CV 4/5; 44/240] END max_iter=50, penalty=elasticnet, solver=saga, tol=0.0001;, score=nan total time=   0.0s
[CV 5/5; 44/240] START max_iter=50, penalty=elasticnet, solver=saga, tol=0.0001.</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1314, in fit
    raise ValueError(&#34;l1_ratio must be between 0 and 1;&#34;
ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1314, in fit
    raise ValueError(&#34;l1_ratio must be between 0 and 1;&#34;
ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1314, in fit
    raise ValueError(&#34;l1_ratio must be between 0 and 1;&#34;
ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>
[CV 5/5; 44/240] END max_iter=50, penalty=elasticnet, solver=saga, tol=0.0001;, score=nan total time=   0.0s
[CV 1/5; 45/240] START max_iter=50, penalty=elasticnet, solver=saga, tol=1e-05..
[CV 1/5; 45/240] END max_iter=50, penalty=elasticnet, solver=saga, tol=1e-05;, score=nan total time=   0.0s
[CV 2/5; 45/240] START max_iter=50, penalty=elasticnet, solver=saga, tol=1e-05..
[CV 2/5; 45/240] END max_iter=50, penalty=elasticnet, solver=saga, tol=1e-05;, score=nan total time=   0.0s
[CV 3/5; 45/240] START max_iter=50, penalty=elasticnet, solver=saga, tol=1e-05..</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1314, in fit
    raise ValueError(&#34;l1_ratio must be between 0 and 1;&#34;
ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1314, in fit
    raise ValueError(&#34;l1_ratio must be between 0 and 1;&#34;
ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1314, in fit
    raise ValueError(&#34;l1_ratio must be between 0 and 1;&#34;
ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>
[CV 3/5; 45/240] END max_iter=50, penalty=elasticnet, solver=saga, tol=1e-05;, score=nan total time=   0.0s
[CV 4/5; 45/240] START max_iter=50, penalty=elasticnet, solver=saga, tol=1e-05..
[CV 4/5; 45/240] END max_iter=50, penalty=elasticnet, solver=saga, tol=1e-05;, score=nan total time=   0.0s
[CV 5/5; 45/240] START max_iter=50, penalty=elasticnet, solver=saga, tol=1e-05..
[CV 5/5; 45/240] END max_iter=50, penalty=elasticnet, solver=saga, tol=1e-05;, score=nan total time=   0.0s
[CV 1/5; 46/240] START max_iter=50, penalty=none, solver=newton-cg, tol=0.001...</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\utils\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.
  warnings.warn(&#34;newton-cg failed to converge. Increase the &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>
[CV 1/5; 46/240] END max_iter=50, penalty=none, solver=newton-cg, tol=0.001;, score=0.497 total time= 2.3min
[CV 2/5; 46/240] START max_iter=50, penalty=none, solver=newton-cg, tol=0.001...
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\utils\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.
  warnings.warn(&#34;newton-cg failed to converge. Increase the &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 2/5; 46/240] END max_iter=50, penalty=none, solver=newton-cg, tol=0.001;, score=0.499 total time= 2.4min
[CV 3/5; 46/240] START max_iter=50, penalty=none, solver=newton-cg, tol=0.001...
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\utils\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.
  warnings.warn(&#34;newton-cg failed to converge. Increase the &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 3/5; 46/240] END max_iter=50, penalty=none, solver=newton-cg, tol=0.001;, score=0.498 total time= 2.4min
[CV 4/5; 46/240] START max_iter=50, penalty=none, solver=newton-cg, tol=0.001...
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\utils\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.
  warnings.warn(&#34;newton-cg failed to converge. Increase the &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 4/5; 46/240] END max_iter=50, penalty=none, solver=newton-cg, tol=0.001;, score=0.499 total time= 2.1min
[CV 5/5; 46/240] START max_iter=50, penalty=none, solver=newton-cg, tol=0.001...
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\utils\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.
  warnings.warn(&#34;newton-cg failed to converge. Increase the &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 5/5; 46/240] END max_iter=50, penalty=none, solver=newton-cg, tol=0.001;, score=0.500 total time= 2.4min
[CV 1/5; 47/240] START max_iter=50, penalty=none, solver=newton-cg, tol=0.0001..
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\utils\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.
  warnings.warn(&#34;newton-cg failed to converge. Increase the &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 1/5; 47/240] END max_iter=50, penalty=none, solver=newton-cg, tol=0.0001;, score=0.497 total time= 2.3min
[CV 2/5; 47/240] START max_iter=50, penalty=none, solver=newton-cg, tol=0.0001..
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\utils\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.
  warnings.warn(&#34;newton-cg failed to converge. Increase the &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 2/5; 47/240] END max_iter=50, penalty=none, solver=newton-cg, tol=0.0001;, score=0.499 total time= 2.2min
[CV 3/5; 47/240] START max_iter=50, penalty=none, solver=newton-cg, tol=0.0001..
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\utils\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.
  warnings.warn(&#34;newton-cg failed to converge. Increase the &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 3/5; 47/240] END max_iter=50, penalty=none, solver=newton-cg, tol=0.0001;, score=0.498 total time= 2.2min
[CV 4/5; 47/240] START max_iter=50, penalty=none, solver=newton-cg, tol=0.0001..
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\utils\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.
  warnings.warn(&#34;newton-cg failed to converge. Increase the &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 4/5; 47/240] END max_iter=50, penalty=none, solver=newton-cg, tol=0.0001;, score=0.499 total time= 2.2min
[CV 5/5; 47/240] START max_iter=50, penalty=none, solver=newton-cg, tol=0.0001..
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\utils\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.
  warnings.warn(&#34;newton-cg failed to converge. Increase the &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 5/5; 47/240] END max_iter=50, penalty=none, solver=newton-cg, tol=0.0001;, score=0.500 total time= 2.4min
[CV 1/5; 48/240] START max_iter=50, penalty=none, solver=newton-cg, tol=1e-05...
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\utils\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.
  warnings.warn(&#34;newton-cg failed to converge. Increase the &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 1/5; 48/240] END max_iter=50, penalty=none, solver=newton-cg, tol=1e-05;, score=0.497 total time= 2.3min
[CV 2/5; 48/240] START max_iter=50, penalty=none, solver=newton-cg, tol=1e-05...
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\utils\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.
  warnings.warn(&#34;newton-cg failed to converge. Increase the &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 2/5; 48/240] END max_iter=50, penalty=none, solver=newton-cg, tol=1e-05;, score=0.499 total time= 2.3min
[CV 3/5; 48/240] START max_iter=50, penalty=none, solver=newton-cg, tol=1e-05...
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\utils\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.
  warnings.warn(&#34;newton-cg failed to converge. Increase the &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 3/5; 48/240] END max_iter=50, penalty=none, solver=newton-cg, tol=1e-05;, score=0.498 total time= 2.3min
[CV 4/5; 48/240] START max_iter=50, penalty=none, solver=newton-cg, tol=1e-05...
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\utils\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.
  warnings.warn(&#34;newton-cg failed to converge. Increase the &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 4/5; 48/240] END max_iter=50, penalty=none, solver=newton-cg, tol=1e-05;, score=0.499 total time= 2.2min
[CV 5/5; 48/240] START max_iter=50, penalty=none, solver=newton-cg, tol=1e-05...
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\utils\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.
  warnings.warn(&#34;newton-cg failed to converge. Increase the &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 5/5; 48/240] END max_iter=50, penalty=none, solver=newton-cg, tol=1e-05;, score=0.500 total time= 2.3min
[CV 1/5; 49/240] START max_iter=50, penalty=none, solver=lbfgs, tol=0.001.......
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 1/5; 49/240] END max_iter=50, penalty=none, solver=lbfgs, tol=0.001;, score=0.499 total time=   1.7s
[CV 2/5; 49/240] START max_iter=50, penalty=none, solver=lbfgs, tol=0.001.......
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 2/5; 49/240] END max_iter=50, penalty=none, solver=lbfgs, tol=0.001;, score=0.500 total time=   1.7s
[CV 3/5; 49/240] START max_iter=50, penalty=none, solver=lbfgs, tol=0.001.......
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 3/5; 49/240] END max_iter=50, penalty=none, solver=lbfgs, tol=0.001;, score=0.501 total time=   1.7s
[CV 4/5; 49/240] START max_iter=50, penalty=none, solver=lbfgs, tol=0.001.......
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 4/5; 49/240] END max_iter=50, penalty=none, solver=lbfgs, tol=0.001;, score=0.500 total time=   1.7s
[CV 5/5; 49/240] START max_iter=50, penalty=none, solver=lbfgs, tol=0.001.......
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 5/5; 49/240] END max_iter=50, penalty=none, solver=lbfgs, tol=0.001;, score=0.500 total time=   1.7s
[CV 1/5; 50/240] START max_iter=50, penalty=none, solver=lbfgs, tol=0.0001......
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 1/5; 50/240] END max_iter=50, penalty=none, solver=lbfgs, tol=0.0001;, score=0.499 total time=   1.7s
[CV 2/5; 50/240] START max_iter=50, penalty=none, solver=lbfgs, tol=0.0001......
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 2/5; 50/240] END max_iter=50, penalty=none, solver=lbfgs, tol=0.0001;, score=0.500 total time=   1.7s
[CV 3/5; 50/240] START max_iter=50, penalty=none, solver=lbfgs, tol=0.0001......
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 3/5; 50/240] END max_iter=50, penalty=none, solver=lbfgs, tol=0.0001;, score=0.501 total time=   1.7s
[CV 4/5; 50/240] START max_iter=50, penalty=none, solver=lbfgs, tol=0.0001......
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 4/5; 50/240] END max_iter=50, penalty=none, solver=lbfgs, tol=0.0001;, score=0.500 total time=   1.7s
[CV 5/5; 50/240] START max_iter=50, penalty=none, solver=lbfgs, tol=0.0001......
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 5/5; 50/240] END max_iter=50, penalty=none, solver=lbfgs, tol=0.0001;, score=0.500 total time=   1.7s
[CV 1/5; 51/240] START max_iter=50, penalty=none, solver=lbfgs, tol=1e-05.......
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 1/5; 51/240] END max_iter=50, penalty=none, solver=lbfgs, tol=1e-05;, score=0.499 total time=   1.7s
[CV 2/5; 51/240] START max_iter=50, penalty=none, solver=lbfgs, tol=1e-05.......
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 2/5; 51/240] END max_iter=50, penalty=none, solver=lbfgs, tol=1e-05;, score=0.500 total time=   1.7s
[CV 3/5; 51/240] START max_iter=50, penalty=none, solver=lbfgs, tol=1e-05.......
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 3/5; 51/240] END max_iter=50, penalty=none, solver=lbfgs, tol=1e-05;, score=0.501 total time=   1.7s
[CV 4/5; 51/240] START max_iter=50, penalty=none, solver=lbfgs, tol=1e-05.......
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 4/5; 51/240] END max_iter=50, penalty=none, solver=lbfgs, tol=1e-05;, score=0.500 total time=   1.7s
[CV 5/5; 51/240] START max_iter=50, penalty=none, solver=lbfgs, tol=1e-05.......
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 454, in _check_solver
    raise ValueError(
ValueError: penalty=&#39;none&#39; is not supported for the liblinear solver

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 5/5; 51/240] END max_iter=50, penalty=none, solver=lbfgs, tol=1e-05;, score=0.500 total time=   1.7s
[CV 1/5; 52/240] START max_iter=50, penalty=none, solver=liblinear, tol=0.001...
[CV 1/5; 52/240] END max_iter=50, penalty=none, solver=liblinear, tol=0.001;, score=nan total time=   0.0s
[CV 2/5; 52/240] START max_iter=50, penalty=none, solver=liblinear, tol=0.001...
[CV 2/5; 52/240] END max_iter=50, penalty=none, solver=liblinear, tol=0.001;, score=nan total time=   0.0s
[CV 3/5; 52/240] START max_iter=50, penalty=none, solver=liblinear, tol=0.001...</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 454, in _check_solver
    raise ValueError(
ValueError: penalty=&#39;none&#39; is not supported for the liblinear solver

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 454, in _check_solver
    raise ValueError(
ValueError: penalty=&#39;none&#39; is not supported for the liblinear solver

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 454, in _check_solver
    raise ValueError(
ValueError: penalty=&#39;none&#39; is not supported for the liblinear solver

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>
[CV 3/5; 52/240] END max_iter=50, penalty=none, solver=liblinear, tol=0.001;, score=nan total time=   0.0s
[CV 4/5; 52/240] START max_iter=50, penalty=none, solver=liblinear, tol=0.001...
[CV 4/5; 52/240] END max_iter=50, penalty=none, solver=liblinear, tol=0.001;, score=nan total time=   0.0s
[CV 5/5; 52/240] START max_iter=50, penalty=none, solver=liblinear, tol=0.001...
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 454, in _check_solver
    raise ValueError(
ValueError: penalty=&#39;none&#39; is not supported for the liblinear solver

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 454, in _check_solver
    raise ValueError(
ValueError: penalty=&#39;none&#39; is not supported for the liblinear solver

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 454, in _check_solver
    raise ValueError(
ValueError: penalty=&#39;none&#39; is not supported for the liblinear solver

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 5/5; 52/240] END max_iter=50, penalty=none, solver=liblinear, tol=0.001;, score=nan total time=   0.0s
[CV 1/5; 53/240] START max_iter=50, penalty=none, solver=liblinear, tol=0.0001..
[CV 1/5; 53/240] END max_iter=50, penalty=none, solver=liblinear, tol=0.0001;, score=nan total time=   0.0s
[CV 2/5; 53/240] START max_iter=50, penalty=none, solver=liblinear, tol=0.0001..
[CV 2/5; 53/240] END max_iter=50, penalty=none, solver=liblinear, tol=0.0001;, score=nan total time=   0.0s
[CV 3/5; 53/240] START max_iter=50, penalty=none, solver=liblinear, tol=0.0001..
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 454, in _check_solver
    raise ValueError(
ValueError: penalty=&#39;none&#39; is not supported for the liblinear solver

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 454, in _check_solver
    raise ValueError(
ValueError: penalty=&#39;none&#39; is not supported for the liblinear solver

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 454, in _check_solver
    raise ValueError(
ValueError: penalty=&#39;none&#39; is not supported for the liblinear solver

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 3/5; 53/240] END max_iter=50, penalty=none, solver=liblinear, tol=0.0001;, score=nan total time=   0.0s
[CV 4/5; 53/240] START max_iter=50, penalty=none, solver=liblinear, tol=0.0001..
[CV 4/5; 53/240] END max_iter=50, penalty=none, solver=liblinear, tol=0.0001;, score=nan total time=   0.0s
[CV 5/5; 53/240] START max_iter=50, penalty=none, solver=liblinear, tol=0.0001..
[CV 5/5; 53/240] END max_iter=50, penalty=none, solver=liblinear, tol=0.0001;, score=nan total time=   0.0s
[CV 1/5; 54/240] START max_iter=50, penalty=none, solver=liblinear, tol=1e-05...
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 454, in _check_solver
    raise ValueError(
ValueError: penalty=&#39;none&#39; is not supported for the liblinear solver

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 454, in _check_solver
    raise ValueError(
ValueError: penalty=&#39;none&#39; is not supported for the liblinear solver

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 454, in _check_solver
    raise ValueError(
ValueError: penalty=&#39;none&#39; is not supported for the liblinear solver

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 1/5; 54/240] END max_iter=50, penalty=none, solver=liblinear, tol=1e-05;, score=nan total time=   0.0s
[CV 2/5; 54/240] START max_iter=50, penalty=none, solver=liblinear, tol=1e-05...
[CV 2/5; 54/240] END max_iter=50, penalty=none, solver=liblinear, tol=1e-05;, score=nan total time=   0.0s
[CV 3/5; 54/240] START max_iter=50, penalty=none, solver=liblinear, tol=1e-05...
[CV 3/5; 54/240] END max_iter=50, penalty=none, solver=liblinear, tol=1e-05;, score=nan total time=   0.0s
[CV 4/5; 54/240] START max_iter=50, penalty=none, solver=liblinear, tol=1e-05...
[CV 4/5; 54/240] END max_iter=50, penalty=none, solver=liblinear, tol=1e-05;, score=nan total time=   0.0s
[CV 5/5; 54/240] START max_iter=50, penalty=none, solver=liblinear, tol=1e-05...
[CV 5/5; 54/240] END max_iter=50, penalty=none, solver=liblinear, tol=1e-05;, score=nan total time=   0.0s
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 454, in _check_solver
    raise ValueError(
ValueError: penalty=&#39;none&#39; is not supported for the liblinear solver

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 454, in _check_solver
    raise ValueError(
ValueError: penalty=&#39;none&#39; is not supported for the liblinear solver

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 1/5; 55/240] START max_iter=50, penalty=none, solver=sag, tol=0.001.........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(&#34;The max_iter was reached which means &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 1/5; 55/240] END max_iter=50, penalty=none, solver=sag, tol=0.001;, score=0.499 total time=  11.9s
[CV 2/5; 55/240] START max_iter=50, penalty=none, solver=sag, tol=0.001.........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(&#34;The max_iter was reached which means &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 2/5; 55/240] END max_iter=50, penalty=none, solver=sag, tol=0.001;, score=0.500 total time=  11.6s
[CV 3/5; 55/240] START max_iter=50, penalty=none, solver=sag, tol=0.001.........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(&#34;The max_iter was reached which means &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 3/5; 55/240] END max_iter=50, penalty=none, solver=sag, tol=0.001;, score=0.500 total time=  11.3s
[CV 4/5; 55/240] START max_iter=50, penalty=none, solver=sag, tol=0.001.........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(&#34;The max_iter was reached which means &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 4/5; 55/240] END max_iter=50, penalty=none, solver=sag, tol=0.001;, score=0.500 total time=  11.8s
[CV 5/5; 55/240] START max_iter=50, penalty=none, solver=sag, tol=0.001.........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(&#34;The max_iter was reached which means &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 5/5; 55/240] END max_iter=50, penalty=none, solver=sag, tol=0.001;, score=0.500 total time=  11.2s
[CV 1/5; 56/240] START max_iter=50, penalty=none, solver=sag, tol=0.0001........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(&#34;The max_iter was reached which means &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 1/5; 56/240] END max_iter=50, penalty=none, solver=sag, tol=0.0001;, score=0.499 total time=  11.2s
[CV 2/5; 56/240] START max_iter=50, penalty=none, solver=sag, tol=0.0001........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(&#34;The max_iter was reached which means &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 2/5; 56/240] END max_iter=50, penalty=none, solver=sag, tol=0.0001;, score=0.500 total time=  11.4s
[CV 3/5; 56/240] START max_iter=50, penalty=none, solver=sag, tol=0.0001........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(&#34;The max_iter was reached which means &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 3/5; 56/240] END max_iter=50, penalty=none, solver=sag, tol=0.0001;, score=0.500 total time=  11.4s
[CV 4/5; 56/240] START max_iter=50, penalty=none, solver=sag, tol=0.0001........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(&#34;The max_iter was reached which means &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 4/5; 56/240] END max_iter=50, penalty=none, solver=sag, tol=0.0001;, score=0.500 total time=  11.1s
[CV 5/5; 56/240] START max_iter=50, penalty=none, solver=sag, tol=0.0001........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(&#34;The max_iter was reached which means &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 5/5; 56/240] END max_iter=50, penalty=none, solver=sag, tol=0.0001;, score=0.500 total time=  11.2s
[CV 1/5; 57/240] START max_iter=50, penalty=none, solver=sag, tol=1e-05.........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(&#34;The max_iter was reached which means &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 1/5; 57/240] END max_iter=50, penalty=none, solver=sag, tol=1e-05;, score=0.499 total time=  11.1s
[CV 2/5; 57/240] START max_iter=50, penalty=none, solver=sag, tol=1e-05.........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(&#34;The max_iter was reached which means &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 2/5; 57/240] END max_iter=50, penalty=none, solver=sag, tol=1e-05;, score=0.500 total time=  11.3s
[CV 3/5; 57/240] START max_iter=50, penalty=none, solver=sag, tol=1e-05.........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(&#34;The max_iter was reached which means &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 3/5; 57/240] END max_iter=50, penalty=none, solver=sag, tol=1e-05;, score=0.500 total time=  11.2s
[CV 4/5; 57/240] START max_iter=50, penalty=none, solver=sag, tol=1e-05.........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(&#34;The max_iter was reached which means &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 4/5; 57/240] END max_iter=50, penalty=none, solver=sag, tol=1e-05;, score=0.500 total time=  11.1s
[CV 5/5; 57/240] START max_iter=50, penalty=none, solver=sag, tol=1e-05.........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(&#34;The max_iter was reached which means &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 5/5; 57/240] END max_iter=50, penalty=none, solver=sag, tol=1e-05;, score=0.500 total time=  11.4s
[CV 1/5; 58/240] START max_iter=50, penalty=none, solver=saga, tol=0.001........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(&#34;The max_iter was reached which means &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 1/5; 58/240] END max_iter=50, penalty=none, solver=saga, tol=0.001;, score=0.499 total time=  12.4s
[CV 2/5; 58/240] START max_iter=50, penalty=none, solver=saga, tol=0.001........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(&#34;The max_iter was reached which means &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 2/5; 58/240] END max_iter=50, penalty=none, solver=saga, tol=0.001;, score=0.500 total time=  12.7s
[CV 3/5; 58/240] START max_iter=50, penalty=none, solver=saga, tol=0.001........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(&#34;The max_iter was reached which means &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 3/5; 58/240] END max_iter=50, penalty=none, solver=saga, tol=0.001;, score=0.500 total time=  12.8s
[CV 4/5; 58/240] START max_iter=50, penalty=none, solver=saga, tol=0.001........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(&#34;The max_iter was reached which means &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 4/5; 58/240] END max_iter=50, penalty=none, solver=saga, tol=0.001;, score=0.499 total time=  12.5s
[CV 5/5; 58/240] START max_iter=50, penalty=none, solver=saga, tol=0.001........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(&#34;The max_iter was reached which means &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 5/5; 58/240] END max_iter=50, penalty=none, solver=saga, tol=0.001;, score=0.499 total time=  12.5s
[CV 1/5; 59/240] START max_iter=50, penalty=none, solver=saga, tol=0.0001.......
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(&#34;The max_iter was reached which means &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 1/5; 59/240] END max_iter=50, penalty=none, solver=saga, tol=0.0001;, score=0.499 total time=  12.5s
[CV 2/5; 59/240] START max_iter=50, penalty=none, solver=saga, tol=0.0001.......
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(&#34;The max_iter was reached which means &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 2/5; 59/240] END max_iter=50, penalty=none, solver=saga, tol=0.0001;, score=0.500 total time=  12.7s
[CV 3/5; 59/240] START max_iter=50, penalty=none, solver=saga, tol=0.0001.......
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(&#34;The max_iter was reached which means &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 3/5; 59/240] END max_iter=50, penalty=none, solver=saga, tol=0.0001;, score=0.500 total time=  13.6s
[CV 4/5; 59/240] START max_iter=50, penalty=none, solver=saga, tol=0.0001.......
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(&#34;The max_iter was reached which means &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 4/5; 59/240] END max_iter=50, penalty=none, solver=saga, tol=0.0001;, score=0.499 total time=  12.7s
[CV 5/5; 59/240] START max_iter=50, penalty=none, solver=saga, tol=0.0001.......
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(&#34;The max_iter was reached which means &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 5/5; 59/240] END max_iter=50, penalty=none, solver=saga, tol=0.0001;, score=0.499 total time=  14.0s
[CV 1/5; 60/240] START max_iter=50, penalty=none, solver=saga, tol=1e-05........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(&#34;The max_iter was reached which means &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 1/5; 60/240] END max_iter=50, penalty=none, solver=saga, tol=1e-05;, score=0.499 total time=  13.4s
[CV 2/5; 60/240] START max_iter=50, penalty=none, solver=saga, tol=1e-05........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(&#34;The max_iter was reached which means &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 2/5; 60/240] END max_iter=50, penalty=none, solver=saga, tol=1e-05;, score=0.500 total time=  12.9s
[CV 3/5; 60/240] START max_iter=50, penalty=none, solver=saga, tol=1e-05........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(&#34;The max_iter was reached which means &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 3/5; 60/240] END max_iter=50, penalty=none, solver=saga, tol=1e-05;, score=0.500 total time=  13.0s
[CV 4/5; 60/240] START max_iter=50, penalty=none, solver=saga, tol=1e-05........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(&#34;The max_iter was reached which means &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 4/5; 60/240] END max_iter=50, penalty=none, solver=saga, tol=1e-05;, score=0.499 total time=  12.7s
[CV 5/5; 60/240] START max_iter=50, penalty=none, solver=saga, tol=1e-05........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(&#34;The max_iter was reached which means &#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver newton-cg supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 5/5; 60/240] END max_iter=50, penalty=none, solver=saga, tol=1e-05;, score=0.499 total time=  12.6s
[CV 1/5; 61/240] START max_iter=100, penalty=l1, solver=newton-cg, tol=0.001....
[CV 1/5; 61/240] END max_iter=100, penalty=l1, solver=newton-cg, tol=0.001;, score=nan total time=   0.0s
[CV 2/5; 61/240] START max_iter=100, penalty=l1, solver=newton-cg, tol=0.001....
[CV 2/5; 61/240] END max_iter=100, penalty=l1, solver=newton-cg, tol=0.001;, score=nan total time=   0.0s
[CV 3/5; 61/240] START max_iter=100, penalty=l1, solver=newton-cg, tol=0.001....
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver newton-cg supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver newton-cg supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver newton-cg supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 3/5; 61/240] END max_iter=100, penalty=l1, solver=newton-cg, tol=0.001;, score=nan total time=   0.0s
[CV 4/5; 61/240] START max_iter=100, penalty=l1, solver=newton-cg, tol=0.001....
[CV 4/5; 61/240] END max_iter=100, penalty=l1, solver=newton-cg, tol=0.001;, score=nan total time=   0.0s
[CV 5/5; 61/240] START max_iter=100, penalty=l1, solver=newton-cg, tol=0.001....
[CV 5/5; 61/240] END max_iter=100, penalty=l1, solver=newton-cg, tol=0.001;, score=nan total time=   0.0s
[CV 1/5; 62/240] START max_iter=100, penalty=l1, solver=newton-cg, tol=0.0001...
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver newton-cg supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver newton-cg supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver newton-cg supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 1/5; 62/240] END max_iter=100, penalty=l1, solver=newton-cg, tol=0.0001;, score=nan total time=   0.0s
[CV 2/5; 62/240] START max_iter=100, penalty=l1, solver=newton-cg, tol=0.0001...
[CV 2/5; 62/240] END max_iter=100, penalty=l1, solver=newton-cg, tol=0.0001;, score=nan total time=   0.0s
[CV 3/5; 62/240] START max_iter=100, penalty=l1, solver=newton-cg, tol=0.0001...
[CV 3/5; 62/240] END max_iter=100, penalty=l1, solver=newton-cg, tol=0.0001;, score=nan total time=   0.0s
[CV 4/5; 62/240] START max_iter=100, penalty=l1, solver=newton-cg, tol=0.0001...
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver newton-cg supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver newton-cg supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver newton-cg supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 4/5; 62/240] END max_iter=100, penalty=l1, solver=newton-cg, tol=0.0001;, score=nan total time=   0.0s
[CV 5/5; 62/240] START max_iter=100, penalty=l1, solver=newton-cg, tol=0.0001...
[CV 5/5; 62/240] END max_iter=100, penalty=l1, solver=newton-cg, tol=0.0001;, score=nan total time=   0.0s
[CV 1/5; 63/240] START max_iter=100, penalty=l1, solver=newton-cg, tol=1e-05....
[CV 1/5; 63/240] END max_iter=100, penalty=l1, solver=newton-cg, tol=1e-05;, score=nan total time=   0.0s
[CV 2/5; 63/240] START max_iter=100, penalty=l1, solver=newton-cg, tol=1e-05....
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver newton-cg supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver newton-cg supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver newton-cg supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 2/5; 63/240] END max_iter=100, penalty=l1, solver=newton-cg, tol=1e-05;, score=nan total time=   0.0s
[CV 3/5; 63/240] START max_iter=100, penalty=l1, solver=newton-cg, tol=1e-05....
[CV 3/5; 63/240] END max_iter=100, penalty=l1, solver=newton-cg, tol=1e-05;, score=nan total time=   0.0s
[CV 4/5; 63/240] START max_iter=100, penalty=l1, solver=newton-cg, tol=1e-05....
[CV 4/5; 63/240] END max_iter=100, penalty=l1, solver=newton-cg, tol=1e-05;, score=nan total time=   0.0s
[CV 5/5; 63/240] START max_iter=100, penalty=l1, solver=newton-cg, tol=1e-05....
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver newton-cg supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver newton-cg supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 5/5; 63/240] END max_iter=100, penalty=l1, solver=newton-cg, tol=1e-05;, score=nan total time=   0.0s
[CV 1/5; 64/240] START max_iter=100, penalty=l1, solver=lbfgs, tol=0.001........
[CV 1/5; 64/240] END max_iter=100, penalty=l1, solver=lbfgs, tol=0.001;, score=nan total time=   0.0s
[CV 2/5; 64/240] START max_iter=100, penalty=l1, solver=lbfgs, tol=0.001........
[CV 2/5; 64/240] END max_iter=100, penalty=l1, solver=lbfgs, tol=0.001;, score=nan total time=   0.0s
[CV 3/5; 64/240] START max_iter=100, penalty=l1, solver=lbfgs, tol=0.001........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 3/5; 64/240] END max_iter=100, penalty=l1, solver=lbfgs, tol=0.001;, score=nan total time=   0.0s
[CV 4/5; 64/240] START max_iter=100, penalty=l1, solver=lbfgs, tol=0.001........
[CV 4/5; 64/240] END max_iter=100, penalty=l1, solver=lbfgs, tol=0.001;, score=nan total time=   0.0s
[CV 5/5; 64/240] START max_iter=100, penalty=l1, solver=lbfgs, tol=0.001........
[CV 5/5; 64/240] END max_iter=100, penalty=l1, solver=lbfgs, tol=0.001;, score=nan total time=   0.0s
[CV 1/5; 65/240] START max_iter=100, penalty=l1, solver=lbfgs, tol=0.0001.......</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>
[CV 1/5; 65/240] END max_iter=100, penalty=l1, solver=lbfgs, tol=0.0001;, score=nan total time=   0.0s
[CV 2/5; 65/240] START max_iter=100, penalty=l1, solver=lbfgs, tol=0.0001.......
[CV 2/5; 65/240] END max_iter=100, penalty=l1, solver=lbfgs, tol=0.0001;, score=nan total time=   0.0s
[CV 3/5; 65/240] START max_iter=100, penalty=l1, solver=lbfgs, tol=0.0001.......
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 3/5; 65/240] END max_iter=100, penalty=l1, solver=lbfgs, tol=0.0001;, score=nan total time=   0.0s
[CV 4/5; 65/240] START max_iter=100, penalty=l1, solver=lbfgs, tol=0.0001.......
[CV 4/5; 65/240] END max_iter=100, penalty=l1, solver=lbfgs, tol=0.0001;, score=nan total time=   0.0s
[CV 5/5; 65/240] START max_iter=100, penalty=l1, solver=lbfgs, tol=0.0001.......
[CV 5/5; 65/240] END max_iter=100, penalty=l1, solver=lbfgs, tol=0.0001;, score=nan total time=   0.0s
[CV 1/5; 66/240] START max_iter=100, penalty=l1, solver=lbfgs, tol=1e-05........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 1/5; 66/240] END max_iter=100, penalty=l1, solver=lbfgs, tol=1e-05;, score=nan total time=   0.0s
[CV 2/5; 66/240] START max_iter=100, penalty=l1, solver=lbfgs, tol=1e-05........
[CV 2/5; 66/240] END max_iter=100, penalty=l1, solver=lbfgs, tol=1e-05;, score=nan total time=   0.0s
[CV 3/5; 66/240] START max_iter=100, penalty=l1, solver=lbfgs, tol=1e-05........
[CV 3/5; 66/240] END max_iter=100, penalty=l1, solver=lbfgs, tol=1e-05;, score=nan total time=   0.0s
[CV 4/5; 66/240] START max_iter=100, penalty=l1, solver=lbfgs, tol=1e-05........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 4/5; 66/240] END max_iter=100, penalty=l1, solver=lbfgs, tol=1e-05;, score=nan total time=   0.0s
[CV 5/5; 66/240] START max_iter=100, penalty=l1, solver=lbfgs, tol=1e-05........
[CV 5/5; 66/240] END max_iter=100, penalty=l1, solver=lbfgs, tol=1e-05;, score=nan total time=   0.0s
[CV 1/5; 67/240] START max_iter=100, penalty=l1, solver=liblinear, tol=0.001....
[CV 1/5; 67/240] END max_iter=100, penalty=l1, solver=liblinear, tol=0.001;, score=0.498 total time=   0.7s
[CV 2/5; 67/240] START max_iter=100, penalty=l1, solver=liblinear, tol=0.001....
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\svm\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(&#34;Liblinear failed to converge, increase &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 2/5; 67/240] END max_iter=100, penalty=l1, solver=liblinear, tol=0.001;, score=0.500 total time=10.8min
[CV 3/5; 67/240] START max_iter=100, penalty=l1, solver=liblinear, tol=0.001....
[CV 3/5; 67/240] END max_iter=100, penalty=l1, solver=liblinear, tol=0.001;, score=0.499 total time=   0.8s
[CV 4/5; 67/240] START max_iter=100, penalty=l1, solver=liblinear, tol=0.001....
[CV 4/5; 67/240] END max_iter=100, penalty=l1, solver=liblinear, tol=0.001;, score=0.498 total time=   0.6s
[CV 5/5; 67/240] START max_iter=100, penalty=l1, solver=liblinear, tol=0.001....
[CV 5/5; 67/240] END max_iter=100, penalty=l1, solver=liblinear, tol=0.001;, score=0.500 total time=   0.6s
[CV 1/5; 68/240] START max_iter=100, penalty=l1, solver=liblinear, tol=0.0001...
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\svm\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(&#34;Liblinear failed to converge, increase &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 1/5; 68/240] END max_iter=100, penalty=l1, solver=liblinear, tol=0.0001;, score=0.497 total time= 8.4min
[CV 2/5; 68/240] START max_iter=100, penalty=l1, solver=liblinear, tol=0.0001...
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\svm\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(&#34;Liblinear failed to converge, increase &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 2/5; 68/240] END max_iter=100, penalty=l1, solver=liblinear, tol=0.0001;, score=0.500 total time= 8.1min
[CV 3/5; 68/240] START max_iter=100, penalty=l1, solver=liblinear, tol=0.0001...
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\svm\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(&#34;Liblinear failed to converge, increase &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 3/5; 68/240] END max_iter=100, penalty=l1, solver=liblinear, tol=0.0001;, score=0.499 total time= 8.3min
[CV 4/5; 68/240] START max_iter=100, penalty=l1, solver=liblinear, tol=0.0001...
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\svm\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(&#34;Liblinear failed to converge, increase &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 4/5; 68/240] END max_iter=100, penalty=l1, solver=liblinear, tol=0.0001;, score=0.499 total time= 8.1min
[CV 5/5; 68/240] START max_iter=100, penalty=l1, solver=liblinear, tol=0.0001...
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\svm\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(&#34;Liblinear failed to converge, increase &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 5/5; 68/240] END max_iter=100, penalty=l1, solver=liblinear, tol=0.0001;, score=0.500 total time= 8.4min
[CV 1/5; 69/240] START max_iter=100, penalty=l1, solver=liblinear, tol=1e-05....
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\svm\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(&#34;Liblinear failed to converge, increase &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 1/5; 69/240] END max_iter=100, penalty=l1, solver=liblinear, tol=1e-05;, score=0.498 total time= 7.9min
[CV 2/5; 69/240] START max_iter=100, penalty=l1, solver=liblinear, tol=1e-05....
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\svm\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(&#34;Liblinear failed to converge, increase &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 2/5; 69/240] END max_iter=100, penalty=l1, solver=liblinear, tol=1e-05;, score=0.500 total time= 8.2min
[CV 3/5; 69/240] START max_iter=100, penalty=l1, solver=liblinear, tol=1e-05....
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\svm\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(&#34;Liblinear failed to converge, increase &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 3/5; 69/240] END max_iter=100, penalty=l1, solver=liblinear, tol=1e-05;, score=0.499 total time= 8.2min
[CV 4/5; 69/240] START max_iter=100, penalty=l1, solver=liblinear, tol=1e-05....
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\svm\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(&#34;Liblinear failed to converge, increase &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 4/5; 69/240] END max_iter=100, penalty=l1, solver=liblinear, tol=1e-05;, score=0.499 total time= 8.0min
[CV 5/5; 69/240] START max_iter=100, penalty=l1, solver=liblinear, tol=1e-05....
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\svm\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(&#34;Liblinear failed to converge, increase &#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver sag supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver sag supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 5/5; 69/240] END max_iter=100, penalty=l1, solver=liblinear, tol=1e-05;, score=0.501 total time= 7.9min
[CV 1/5; 70/240] START max_iter=100, penalty=l1, solver=sag, tol=0.001..........
[CV 1/5; 70/240] END max_iter=100, penalty=l1, solver=sag, tol=0.001;, score=nan total time=   0.0s
[CV 2/5; 70/240] START max_iter=100, penalty=l1, solver=sag, tol=0.001..........
[CV 2/5; 70/240] END max_iter=100, penalty=l1, solver=sag, tol=0.001;, score=nan total time=   0.0s
[CV 3/5; 70/240] START max_iter=100, penalty=l1, solver=sag, tol=0.001..........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver sag supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver sag supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver sag supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver sag supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 3/5; 70/240] END max_iter=100, penalty=l1, solver=sag, tol=0.001;, score=nan total time=   0.0s
[CV 4/5; 70/240] START max_iter=100, penalty=l1, solver=sag, tol=0.001..........
[CV 4/5; 70/240] END max_iter=100, penalty=l1, solver=sag, tol=0.001;, score=nan total time=   0.0s
[CV 5/5; 70/240] START max_iter=100, penalty=l1, solver=sag, tol=0.001..........
[CV 5/5; 70/240] END max_iter=100, penalty=l1, solver=sag, tol=0.001;, score=nan total time=   0.0s
[CV 1/5; 71/240] START max_iter=100, penalty=l1, solver=sag, tol=0.0001.........
[CV 1/5; 71/240] END max_iter=100, penalty=l1, solver=sag, tol=0.0001;, score=nan total time=   0.0s
[CV 2/5; 71/240] START max_iter=100, penalty=l1, solver=sag, tol=0.0001.........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver sag supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver sag supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver sag supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver sag supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 2/5; 71/240] END max_iter=100, penalty=l1, solver=sag, tol=0.0001;, score=nan total time=   0.0s
[CV 3/5; 71/240] START max_iter=100, penalty=l1, solver=sag, tol=0.0001.........
[CV 3/5; 71/240] END max_iter=100, penalty=l1, solver=sag, tol=0.0001;, score=nan total time=   0.0s
[CV 4/5; 71/240] START max_iter=100, penalty=l1, solver=sag, tol=0.0001.........
[CV 4/5; 71/240] END max_iter=100, penalty=l1, solver=sag, tol=0.0001;, score=nan total time=   0.0s
[CV 5/5; 71/240] START max_iter=100, penalty=l1, solver=sag, tol=0.0001.........
[CV 5/5; 71/240] END max_iter=100, penalty=l1, solver=sag, tol=0.0001;, score=nan total time=   0.0s
[CV 1/5; 72/240] START max_iter=100, penalty=l1, solver=sag, tol=1e-05..........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver sag supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver sag supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver sag supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver sag supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 1/5; 72/240] END max_iter=100, penalty=l1, solver=sag, tol=1e-05;, score=nan total time=   0.0s
[CV 2/5; 72/240] START max_iter=100, penalty=l1, solver=sag, tol=1e-05..........
[CV 2/5; 72/240] END max_iter=100, penalty=l1, solver=sag, tol=1e-05;, score=nan total time=   0.0s
[CV 3/5; 72/240] START max_iter=100, penalty=l1, solver=sag, tol=1e-05..........
[CV 3/5; 72/240] END max_iter=100, penalty=l1, solver=sag, tol=1e-05;, score=nan total time=   0.0s
[CV 4/5; 72/240] START max_iter=100, penalty=l1, solver=sag, tol=1e-05..........
[CV 4/5; 72/240] END max_iter=100, penalty=l1, solver=sag, tol=1e-05;, score=nan total time=   0.0s
[CV 5/5; 72/240] START max_iter=100, penalty=l1, solver=sag, tol=1e-05..........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver sag supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 5/5; 72/240] END max_iter=100, penalty=l1, solver=sag, tol=1e-05;, score=nan total time=   0.0s
[CV 1/5; 73/240] START max_iter=100, penalty=l1, solver=saga, tol=0.001.........
[CV 1/5; 73/240] END max_iter=100, penalty=l1, solver=saga, tol=0.001;, score=0.499 total time=  36.8s
[CV 2/5; 73/240] START max_iter=100, penalty=l1, solver=saga, tol=0.001.........
[CV 2/5; 73/240] END max_iter=100, penalty=l1, solver=saga, tol=0.001;, score=0.500 total time=  35.4s
[CV 3/5; 73/240] START max_iter=100, penalty=l1, solver=saga, tol=0.001.........
[CV 3/5; 73/240] END max_iter=100, penalty=l1, solver=saga, tol=0.001;, score=0.500 total time=  36.5s
[CV 4/5; 73/240] START max_iter=100, penalty=l1, solver=saga, tol=0.001.........
[CV 4/5; 73/240] END max_iter=100, penalty=l1, solver=saga, tol=0.001;, score=0.499 total time=  35.4s
[CV 5/5; 73/240] START max_iter=100, penalty=l1, solver=saga, tol=0.001.........
[CV 5/5; 73/240] END max_iter=100, penalty=l1, solver=saga, tol=0.001;, score=0.500 total time=  36.7s
[CV 1/5; 74/240] START max_iter=100, penalty=l1, solver=saga, tol=0.0001........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(&#34;The max_iter was reached which means &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 1/5; 74/240] END max_iter=100, penalty=l1, solver=saga, tol=0.0001;, score=0.499 total time=  36.3s
[CV 2/5; 74/240] START max_iter=100, penalty=l1, solver=saga, tol=0.0001........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(&#34;The max_iter was reached which means &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 2/5; 74/240] END max_iter=100, penalty=l1, solver=saga, tol=0.0001;, score=0.500 total time=  35.5s
[CV 3/5; 74/240] START max_iter=100, penalty=l1, solver=saga, tol=0.0001........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(&#34;The max_iter was reached which means &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 3/5; 74/240] END max_iter=100, penalty=l1, solver=saga, tol=0.0001;, score=0.500 total time=  38.1s
[CV 4/5; 74/240] START max_iter=100, penalty=l1, solver=saga, tol=0.0001........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(&#34;The max_iter was reached which means &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 4/5; 74/240] END max_iter=100, penalty=l1, solver=saga, tol=0.0001;, score=0.499 total time=  38.3s
[CV 5/5; 74/240] START max_iter=100, penalty=l1, solver=saga, tol=0.0001........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(&#34;The max_iter was reached which means &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 5/5; 74/240] END max_iter=100, penalty=l1, solver=saga, tol=0.0001;, score=0.500 total time=  38.0s
[CV 1/5; 75/240] START max_iter=100, penalty=l1, solver=saga, tol=1e-05.........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(&#34;The max_iter was reached which means &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 1/5; 75/240] END max_iter=100, penalty=l1, solver=saga, tol=1e-05;, score=0.499 total time=  38.6s
[CV 2/5; 75/240] START max_iter=100, penalty=l1, solver=saga, tol=1e-05.........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(&#34;The max_iter was reached which means &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 2/5; 75/240] END max_iter=100, penalty=l1, solver=saga, tol=1e-05;, score=0.500 total time=  39.6s
[CV 3/5; 75/240] START max_iter=100, penalty=l1, solver=saga, tol=1e-05.........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(&#34;The max_iter was reached which means &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 3/5; 75/240] END max_iter=100, penalty=l1, solver=saga, tol=1e-05;, score=0.500 total time=  40.6s
[CV 4/5; 75/240] START max_iter=100, penalty=l1, solver=saga, tol=1e-05.........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(&#34;The max_iter was reached which means &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 4/5; 75/240] END max_iter=100, penalty=l1, solver=saga, tol=1e-05;, score=0.499 total time=  41.6s
[CV 5/5; 75/240] START max_iter=100, penalty=l1, solver=saga, tol=1e-05.........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(&#34;The max_iter was reached which means &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 5/5; 75/240] END max_iter=100, penalty=l1, solver=saga, tol=1e-05;, score=0.500 total time=  40.5s
[CV 1/5; 76/240] START max_iter=100, penalty=l2, solver=newton-cg, tol=0.001....
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\utils\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.
  warnings.warn(&#34;newton-cg failed to converge. Increase the &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 1/5; 76/240] END max_iter=100, penalty=l2, solver=newton-cg, tol=0.001;, score=0.497 total time= 3.7min
[CV 2/5; 76/240] START max_iter=100, penalty=l2, solver=newton-cg, tol=0.001....
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\utils\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.
  warnings.warn(&#34;newton-cg failed to converge. Increase the &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 2/5; 76/240] END max_iter=100, penalty=l2, solver=newton-cg, tol=0.001;, score=0.500 total time= 3.6min
[CV 3/5; 76/240] START max_iter=100, penalty=l2, solver=newton-cg, tol=0.001....
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\utils\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.
  warnings.warn(&#34;newton-cg failed to converge. Increase the &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 3/5; 76/240] END max_iter=100, penalty=l2, solver=newton-cg, tol=0.001;, score=0.499 total time= 3.3min
[CV 4/5; 76/240] START max_iter=100, penalty=l2, solver=newton-cg, tol=0.001....
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\utils\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.
  warnings.warn(&#34;newton-cg failed to converge. Increase the &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 4/5; 76/240] END max_iter=100, penalty=l2, solver=newton-cg, tol=0.001;, score=0.499 total time= 3.9min
[CV 5/5; 76/240] START max_iter=100, penalty=l2, solver=newton-cg, tol=0.001....
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\utils\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.
  warnings.warn(&#34;newton-cg failed to converge. Increase the &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 5/5; 76/240] END max_iter=100, penalty=l2, solver=newton-cg, tol=0.001;, score=0.500 total time= 3.7min
[CV 1/5; 77/240] START max_iter=100, penalty=l2, solver=newton-cg, tol=0.0001...
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\utils\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.
  warnings.warn(&#34;newton-cg failed to converge. Increase the &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 1/5; 77/240] END max_iter=100, penalty=l2, solver=newton-cg, tol=0.0001;, score=0.497 total time= 3.8min
[CV 2/5; 77/240] START max_iter=100, penalty=l2, solver=newton-cg, tol=0.0001...
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\utils\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.
  warnings.warn(&#34;newton-cg failed to converge. Increase the &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 2/5; 77/240] END max_iter=100, penalty=l2, solver=newton-cg, tol=0.0001;, score=0.500 total time= 3.7min
[CV 3/5; 77/240] START max_iter=100, penalty=l2, solver=newton-cg, tol=0.0001...
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\utils\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.
  warnings.warn(&#34;newton-cg failed to converge. Increase the &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 3/5; 77/240] END max_iter=100, penalty=l2, solver=newton-cg, tol=0.0001;, score=0.499 total time= 3.8min
[CV 4/5; 77/240] START max_iter=100, penalty=l2, solver=newton-cg, tol=0.0001...
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\utils\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.
  warnings.warn(&#34;newton-cg failed to converge. Increase the &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 4/5; 77/240] END max_iter=100, penalty=l2, solver=newton-cg, tol=0.0001;, score=0.499 total time= 3.6min
[CV 5/5; 77/240] START max_iter=100, penalty=l2, solver=newton-cg, tol=0.0001...
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\utils\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.
  warnings.warn(&#34;newton-cg failed to converge. Increase the &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 5/5; 77/240] END max_iter=100, penalty=l2, solver=newton-cg, tol=0.0001;, score=0.500 total time= 3.4min
[CV 1/5; 78/240] START max_iter=100, penalty=l2, solver=newton-cg, tol=1e-05....
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\utils\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.
  warnings.warn(&#34;newton-cg failed to converge. Increase the &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 1/5; 78/240] END max_iter=100, penalty=l2, solver=newton-cg, tol=1e-05;, score=0.497 total time= 3.7min
[CV 2/5; 78/240] START max_iter=100, penalty=l2, solver=newton-cg, tol=1e-05....
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\utils\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.
  warnings.warn(&#34;newton-cg failed to converge. Increase the &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 2/5; 78/240] END max_iter=100, penalty=l2, solver=newton-cg, tol=1e-05;, score=0.500 total time= 3.6min
[CV 3/5; 78/240] START max_iter=100, penalty=l2, solver=newton-cg, tol=1e-05....
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\utils\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.
  warnings.warn(&#34;newton-cg failed to converge. Increase the &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 3/5; 78/240] END max_iter=100, penalty=l2, solver=newton-cg, tol=1e-05;, score=0.499 total time= 3.4min
[CV 4/5; 78/240] START max_iter=100, penalty=l2, solver=newton-cg, tol=1e-05....
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\utils\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.
  warnings.warn(&#34;newton-cg failed to converge. Increase the &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 4/5; 78/240] END max_iter=100, penalty=l2, solver=newton-cg, tol=1e-05;, score=0.499 total time= 3.8min
[CV 5/5; 78/240] START max_iter=100, penalty=l2, solver=newton-cg, tol=1e-05....
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\utils\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.
  warnings.warn(&#34;newton-cg failed to converge. Increase the &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 5/5; 78/240] END max_iter=100, penalty=l2, solver=newton-cg, tol=1e-05;, score=0.500 total time= 3.5min
[CV 1/5; 79/240] START max_iter=100, penalty=l2, solver=lbfgs, tol=0.001........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 1/5; 79/240] END max_iter=100, penalty=l2, solver=lbfgs, tol=0.001;, score=0.498 total time=   2.1s
[CV 2/5; 79/240] START max_iter=100, penalty=l2, solver=lbfgs, tol=0.001........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 2/5; 79/240] END max_iter=100, penalty=l2, solver=lbfgs, tol=0.001;, score=0.500 total time=   2.0s
[CV 3/5; 79/240] START max_iter=100, penalty=l2, solver=lbfgs, tol=0.001........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 3/5; 79/240] END max_iter=100, penalty=l2, solver=lbfgs, tol=0.001;, score=0.500 total time=   2.1s
[CV 4/5; 79/240] START max_iter=100, penalty=l2, solver=lbfgs, tol=0.001........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 4/5; 79/240] END max_iter=100, penalty=l2, solver=lbfgs, tol=0.001;, score=0.499 total time=   2.1s
[CV 5/5; 79/240] START max_iter=100, penalty=l2, solver=lbfgs, tol=0.001........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 5/5; 79/240] END max_iter=100, penalty=l2, solver=lbfgs, tol=0.001;, score=0.500 total time=   2.0s
[CV 1/5; 80/240] START max_iter=100, penalty=l2, solver=lbfgs, tol=0.0001.......
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 1/5; 80/240] END max_iter=100, penalty=l2, solver=lbfgs, tol=0.0001;, score=0.498 total time=   2.0s
[CV 2/5; 80/240] START max_iter=100, penalty=l2, solver=lbfgs, tol=0.0001.......
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 2/5; 80/240] END max_iter=100, penalty=l2, solver=lbfgs, tol=0.0001;, score=0.500 total time=   2.0s
[CV 3/5; 80/240] START max_iter=100, penalty=l2, solver=lbfgs, tol=0.0001.......
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 3/5; 80/240] END max_iter=100, penalty=l2, solver=lbfgs, tol=0.0001;, score=0.500 total time=   2.1s
[CV 4/5; 80/240] START max_iter=100, penalty=l2, solver=lbfgs, tol=0.0001.......
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 4/5; 80/240] END max_iter=100, penalty=l2, solver=lbfgs, tol=0.0001;, score=0.499 total time=   2.1s
[CV 5/5; 80/240] START max_iter=100, penalty=l2, solver=lbfgs, tol=0.0001.......
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 5/5; 80/240] END max_iter=100, penalty=l2, solver=lbfgs, tol=0.0001;, score=0.500 total time=   2.1s
[CV 1/5; 81/240] START max_iter=100, penalty=l2, solver=lbfgs, tol=1e-05........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 1/5; 81/240] END max_iter=100, penalty=l2, solver=lbfgs, tol=1e-05;, score=0.498 total time=   2.0s
[CV 2/5; 81/240] START max_iter=100, penalty=l2, solver=lbfgs, tol=1e-05........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 2/5; 81/240] END max_iter=100, penalty=l2, solver=lbfgs, tol=1e-05;, score=0.500 total time=   2.0s
[CV 3/5; 81/240] START max_iter=100, penalty=l2, solver=lbfgs, tol=1e-05........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 3/5; 81/240] END max_iter=100, penalty=l2, solver=lbfgs, tol=1e-05;, score=0.500 total time=   2.2s
[CV 4/5; 81/240] START max_iter=100, penalty=l2, solver=lbfgs, tol=1e-05........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 4/5; 81/240] END max_iter=100, penalty=l2, solver=lbfgs, tol=1e-05;, score=0.499 total time=   2.2s
[CV 5/5; 81/240] START max_iter=100, penalty=l2, solver=lbfgs, tol=1e-05........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 5/5; 81/240] END max_iter=100, penalty=l2, solver=lbfgs, tol=1e-05;, score=0.500 total time=   2.1s
[CV 1/5; 82/240] START max_iter=100, penalty=l2, solver=liblinear, tol=0.001....
[CV 1/5; 82/240] END max_iter=100, penalty=l2, solver=liblinear, tol=0.001;, score=0.498 total time=  17.0s
[CV 2/5; 82/240] START max_iter=100, penalty=l2, solver=liblinear, tol=0.001....
[CV 2/5; 82/240] END max_iter=100, penalty=l2, solver=liblinear, tol=0.001;, score=0.499 total time=  14.6s
[CV 3/5; 82/240] START max_iter=100, penalty=l2, solver=liblinear, tol=0.001....
[CV 3/5; 82/240] END max_iter=100, penalty=l2, solver=liblinear, tol=0.001;, score=0.499 total time=  14.9s
[CV 4/5; 82/240] START max_iter=100, penalty=l2, solver=liblinear, tol=0.001....
[CV 4/5; 82/240] END max_iter=100, penalty=l2, solver=liblinear, tol=0.001;, score=0.499 total time=  31.1s
[CV 5/5; 82/240] START max_iter=100, penalty=l2, solver=liblinear, tol=0.001....
[CV 5/5; 82/240] END max_iter=100, penalty=l2, solver=liblinear, tol=0.001;, score=0.500 total time=  24.1s
[CV 1/5; 83/240] START max_iter=100, penalty=l2, solver=liblinear, tol=0.0001...
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\svm\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(&#34;Liblinear failed to converge, increase &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 1/5; 83/240] END max_iter=100, penalty=l2, solver=liblinear, tol=0.0001;, score=0.497 total time= 3.1min
[CV 2/5; 83/240] START max_iter=100, penalty=l2, solver=liblinear, tol=0.0001...
[CV 2/5; 83/240] END max_iter=100, penalty=l2, solver=liblinear, tol=0.0001;, score=0.499 total time= 5.2min
[CV 3/5; 83/240] START max_iter=100, penalty=l2, solver=liblinear, tol=0.0001...
[CV 3/5; 83/240] END max_iter=100, penalty=l2, solver=liblinear, tol=0.0001;, score=0.499 total time= 4.3min
[CV 4/5; 83/240] START max_iter=100, penalty=l2, solver=liblinear, tol=0.0001...
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\svm\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(&#34;Liblinear failed to converge, increase &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 4/5; 83/240] END max_iter=100, penalty=l2, solver=liblinear, tol=0.0001;, score=0.499 total time= 2.6min
[CV 5/5; 83/240] START max_iter=100, penalty=l2, solver=liblinear, tol=0.0001...
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\svm\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(&#34;Liblinear failed to converge, increase &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 5/5; 83/240] END max_iter=100, penalty=l2, solver=liblinear, tol=0.0001;, score=0.500 total time= 1.4min
[CV 1/5; 84/240] START max_iter=100, penalty=l2, solver=liblinear, tol=1e-05....
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\svm\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(&#34;Liblinear failed to converge, increase &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 1/5; 84/240] END max_iter=100, penalty=l2, solver=liblinear, tol=1e-05;, score=0.497 total time= 3.0min
[CV 2/5; 84/240] START max_iter=100, penalty=l2, solver=liblinear, tol=1e-05....
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\svm\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(&#34;Liblinear failed to converge, increase &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 2/5; 84/240] END max_iter=100, penalty=l2, solver=liblinear, tol=1e-05;, score=0.499 total time= 7.6min
[CV 3/5; 84/240] START max_iter=100, penalty=l2, solver=liblinear, tol=1e-05....
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\svm\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(&#34;Liblinear failed to converge, increase &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 3/5; 84/240] END max_iter=100, penalty=l2, solver=liblinear, tol=1e-05;, score=0.499 total time= 7.3min
[CV 4/5; 84/240] START max_iter=100, penalty=l2, solver=liblinear, tol=1e-05....
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\svm\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(&#34;Liblinear failed to converge, increase &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 4/5; 84/240] END max_iter=100, penalty=l2, solver=liblinear, tol=1e-05;, score=0.499 total time= 2.6min
[CV 5/5; 84/240] START max_iter=100, penalty=l2, solver=liblinear, tol=1e-05....
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\svm\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(&#34;Liblinear failed to converge, increase &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 5/5; 84/240] END max_iter=100, penalty=l2, solver=liblinear, tol=1e-05;, score=0.500 total time= 1.5min
[CV 1/5; 85/240] START max_iter=100, penalty=l2, solver=sag, tol=0.001..........
[CV 1/5; 85/240] END max_iter=100, penalty=l2, solver=sag, tol=0.001;, score=0.499 total time=  11.3s
[CV 2/5; 85/240] START max_iter=100, penalty=l2, solver=sag, tol=0.001..........
[CV 2/5; 85/240] END max_iter=100, penalty=l2, solver=sag, tol=0.001;, score=0.500 total time=  11.2s
[CV 3/5; 85/240] START max_iter=100, penalty=l2, solver=sag, tol=0.001..........
[CV 3/5; 85/240] END max_iter=100, penalty=l2, solver=sag, tol=0.001;, score=0.500 total time=  11.7s
[CV 4/5; 85/240] START max_iter=100, penalty=l2, solver=sag, tol=0.001..........
[CV 4/5; 85/240] END max_iter=100, penalty=l2, solver=sag, tol=0.001;, score=0.499 total time=  11.6s
[CV 5/5; 85/240] START max_iter=100, penalty=l2, solver=sag, tol=0.001..........
[CV 5/5; 85/240] END max_iter=100, penalty=l2, solver=sag, tol=0.001;, score=0.500 total time=  11.5s
[CV 1/5; 86/240] START max_iter=100, penalty=l2, solver=sag, tol=0.0001.........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(&#34;The max_iter was reached which means &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 1/5; 86/240] END max_iter=100, penalty=l2, solver=sag, tol=0.0001;, score=0.499 total time=  20.2s
[CV 2/5; 86/240] START max_iter=100, penalty=l2, solver=sag, tol=0.0001.........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(&#34;The max_iter was reached which means &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 2/5; 86/240] END max_iter=100, penalty=l2, solver=sag, tol=0.0001;, score=0.499 total time=  20.1s
[CV 3/5; 86/240] START max_iter=100, penalty=l2, solver=sag, tol=0.0001.........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(&#34;The max_iter was reached which means &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 3/5; 86/240] END max_iter=100, penalty=l2, solver=sag, tol=0.0001;, score=0.500 total time=  20.0s
[CV 4/5; 86/240] START max_iter=100, penalty=l2, solver=sag, tol=0.0001.........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(&#34;The max_iter was reached which means &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 4/5; 86/240] END max_iter=100, penalty=l2, solver=sag, tol=0.0001;, score=0.500 total time=  20.3s
[CV 5/5; 86/240] START max_iter=100, penalty=l2, solver=sag, tol=0.0001.........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(&#34;The max_iter was reached which means &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 5/5; 86/240] END max_iter=100, penalty=l2, solver=sag, tol=0.0001;, score=0.500 total time=  20.5s
[CV 1/5; 87/240] START max_iter=100, penalty=l2, solver=sag, tol=1e-05..........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(&#34;The max_iter was reached which means &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 1/5; 87/240] END max_iter=100, penalty=l2, solver=sag, tol=1e-05;, score=0.499 total time=  20.0s
[CV 2/5; 87/240] START max_iter=100, penalty=l2, solver=sag, tol=1e-05..........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(&#34;The max_iter was reached which means &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 2/5; 87/240] END max_iter=100, penalty=l2, solver=sag, tol=1e-05;, score=0.499 total time=  20.3s
[CV 3/5; 87/240] START max_iter=100, penalty=l2, solver=sag, tol=1e-05..........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(&#34;The max_iter was reached which means &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 3/5; 87/240] END max_iter=100, penalty=l2, solver=sag, tol=1e-05;, score=0.500 total time=  20.1s
[CV 4/5; 87/240] START max_iter=100, penalty=l2, solver=sag, tol=1e-05..........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(&#34;The max_iter was reached which means &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 4/5; 87/240] END max_iter=100, penalty=l2, solver=sag, tol=1e-05;, score=0.500 total time=  20.0s
[CV 5/5; 87/240] START max_iter=100, penalty=l2, solver=sag, tol=1e-05..........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(&#34;The max_iter was reached which means &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 5/5; 87/240] END max_iter=100, penalty=l2, solver=sag, tol=1e-05;, score=0.500 total time=  20.3s
[CV 1/5; 88/240] START max_iter=100, penalty=l2, solver=saga, tol=0.001.........
[CV 1/5; 88/240] END max_iter=100, penalty=l2, solver=saga, tol=0.001;, score=0.499 total time=  21.9s
[CV 2/5; 88/240] START max_iter=100, penalty=l2, solver=saga, tol=0.001.........
[CV 2/5; 88/240] END max_iter=100, penalty=l2, solver=saga, tol=0.001;, score=0.500 total time=  21.5s
[CV 3/5; 88/240] START max_iter=100, penalty=l2, solver=saga, tol=0.001.........
[CV 3/5; 88/240] END max_iter=100, penalty=l2, solver=saga, tol=0.001;, score=0.500 total time=  22.1s
[CV 4/5; 88/240] START max_iter=100, penalty=l2, solver=saga, tol=0.001.........
[CV 4/5; 88/240] END max_iter=100, penalty=l2, solver=saga, tol=0.001;, score=0.499 total time=  22.1s
[CV 5/5; 88/240] START max_iter=100, penalty=l2, solver=saga, tol=0.001.........
[CV 5/5; 88/240] END max_iter=100, penalty=l2, solver=saga, tol=0.001;, score=0.500 total time=  23.2s
[CV 1/5; 89/240] START max_iter=100, penalty=l2, solver=saga, tol=0.0001........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(&#34;The max_iter was reached which means &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 1/5; 89/240] END max_iter=100, penalty=l2, solver=saga, tol=0.0001;, score=0.499 total time=  24.9s
[CV 2/5; 89/240] START max_iter=100, penalty=l2, solver=saga, tol=0.0001........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(&#34;The max_iter was reached which means &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 2/5; 89/240] END max_iter=100, penalty=l2, solver=saga, tol=0.0001;, score=0.500 total time=  29.0s
[CV 3/5; 89/240] START max_iter=100, penalty=l2, solver=saga, tol=0.0001........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(&#34;The max_iter was reached which means &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 3/5; 89/240] END max_iter=100, penalty=l2, solver=saga, tol=0.0001;, score=0.500 total time=  28.8s
[CV 4/5; 89/240] START max_iter=100, penalty=l2, solver=saga, tol=0.0001........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(&#34;The max_iter was reached which means &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 4/5; 89/240] END max_iter=100, penalty=l2, solver=saga, tol=0.0001;, score=0.499 total time=  27.0s
[CV 5/5; 89/240] START max_iter=100, penalty=l2, solver=saga, tol=0.0001........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(&#34;The max_iter was reached which means &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 5/5; 89/240] END max_iter=100, penalty=l2, solver=saga, tol=0.0001;, score=0.500 total time=  27.4s
[CV 1/5; 90/240] START max_iter=100, penalty=l2, solver=saga, tol=1e-05.........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(&#34;The max_iter was reached which means &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 1/5; 90/240] END max_iter=100, penalty=l2, solver=saga, tol=1e-05;, score=0.499 total time=  24.6s
[CV 2/5; 90/240] START max_iter=100, penalty=l2, solver=saga, tol=1e-05.........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(&#34;The max_iter was reached which means &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 2/5; 90/240] END max_iter=100, penalty=l2, solver=saga, tol=1e-05;, score=0.500 total time=  26.2s
[CV 3/5; 90/240] START max_iter=100, penalty=l2, solver=saga, tol=1e-05.........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(&#34;The max_iter was reached which means &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 3/5; 90/240] END max_iter=100, penalty=l2, solver=saga, tol=1e-05;, score=0.500 total time=  25.7s
[CV 4/5; 90/240] START max_iter=100, penalty=l2, solver=saga, tol=1e-05.........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(&#34;The max_iter was reached which means &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 4/5; 90/240] END max_iter=100, penalty=l2, solver=saga, tol=1e-05;, score=0.499 total time=  26.0s
[CV 5/5; 90/240] START max_iter=100, penalty=l2, solver=saga, tol=1e-05.........
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  warnings.warn(&#34;The max_iter was reached which means &#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver newton-cg supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 5/5; 90/240] END max_iter=100, penalty=l2, solver=saga, tol=1e-05;, score=0.500 total time=  26.4s
[CV 1/5; 91/240] START max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.001
[CV 1/5; 91/240] END max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.001;, score=nan total time=   0.0s
[CV 2/5; 91/240] START max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.001
[CV 2/5; 91/240] END max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.001;, score=nan total time=   0.0s
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver newton-cg supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver newton-cg supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver newton-cg supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 3/5; 91/240] START max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.001
[CV 3/5; 91/240] END max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.001;, score=nan total time=   0.0s
[CV 4/5; 91/240] START max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.001
[CV 4/5; 91/240] END max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.001;, score=nan total time=   0.0s
[CV 5/5; 91/240] START max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.001
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver newton-cg supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver newton-cg supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver newton-cg supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 5/5; 91/240] END max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.001;, score=nan total time=   0.0s
[CV 1/5; 92/240] START max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.0001
[CV 1/5; 92/240] END max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.0001;, score=nan total time=   0.0s
[CV 2/5; 92/240] START max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.0001
[CV 2/5; 92/240] END max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.0001;, score=nan total time=   0.0s
[CV 3/5; 92/240] START max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.0001
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver newton-cg supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver newton-cg supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver newton-cg supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 3/5; 92/240] END max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.0001;, score=nan total time=   0.0s
[CV 4/5; 92/240] START max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.0001
[CV 4/5; 92/240] END max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.0001;, score=nan total time=   0.0s
[CV 5/5; 92/240] START max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.0001
[CV 5/5; 92/240] END max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.0001;, score=nan total time=   0.0s
[CV 1/5; 93/240] START max_iter=100, penalty=elasticnet, solver=newton-cg, tol=1e-05</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver newton-cg supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver newton-cg supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver newton-cg supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>
[CV 1/5; 93/240] END max_iter=100, penalty=elasticnet, solver=newton-cg, tol=1e-05;, score=nan total time=   0.0s
[CV 2/5; 93/240] START max_iter=100, penalty=elasticnet, solver=newton-cg, tol=1e-05
[CV 2/5; 93/240] END max_iter=100, penalty=elasticnet, solver=newton-cg, tol=1e-05;, score=nan total time=   0.0s
[CV 3/5; 93/240] START max_iter=100, penalty=elasticnet, solver=newton-cg, tol=1e-05
[CV 3/5; 93/240] END max_iter=100, penalty=elasticnet, solver=newton-cg, tol=1e-05;, score=nan total time=   0.0s
[CV 4/5; 93/240] START max_iter=100, penalty=elasticnet, solver=newton-cg, tol=1e-05
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver newton-cg supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver newton-cg supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 4/5; 93/240] END max_iter=100, penalty=elasticnet, solver=newton-cg, tol=1e-05;, score=nan total time=   0.0s
[CV 5/5; 93/240] START max_iter=100, penalty=elasticnet, solver=newton-cg, tol=1e-05
[CV 5/5; 93/240] END max_iter=100, penalty=elasticnet, solver=newton-cg, tol=1e-05;, score=nan total time=   0.0s
[CV 1/5; 94/240] START max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.001
[CV 1/5; 94/240] END max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.001;, score=nan total time=   0.0s
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 2/5; 94/240] START max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.001
[CV 2/5; 94/240] END max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.001;, score=nan total time=   0.0s
[CV 3/5; 94/240] START max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.001
[CV 3/5; 94/240] END max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.001;, score=nan total time=   0.0s
[CV 4/5; 94/240] START max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.001
[CV 4/5; 94/240] END max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.001;, score=nan total time=   0.0s
[CV 5/5; 94/240] START max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.001</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>
[CV 5/5; 94/240] END max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.001;, score=nan total time=   0.0s
[CV 1/5; 95/240] START max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.0001
[CV 1/5; 95/240] END max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.0001;, score=nan total time=   0.0s
[CV 2/5; 95/240] START max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.0001
[CV 2/5; 95/240] END max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.0001;, score=nan total time=   0.0s
[CV 3/5; 95/240] START max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.0001
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 3/5; 95/240] END max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.0001;, score=nan total time=   0.0s
[CV 4/5; 95/240] START max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.0001
[CV 4/5; 95/240] END max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.0001;, score=nan total time=   0.0s
[CV 5/5; 95/240] START max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.0001
[CV 5/5; 95/240] END max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.0001;, score=nan total time=   0.0s
[CV 1/5; 96/240] START max_iter=100, penalty=elasticnet, solver=lbfgs, tol=1e-05
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 1/5; 96/240] END max_iter=100, penalty=elasticnet, solver=lbfgs, tol=1e-05;, score=nan total time=   0.0s
[CV 2/5; 96/240] START max_iter=100, penalty=elasticnet, solver=lbfgs, tol=1e-05
[CV 2/5; 96/240] END max_iter=100, penalty=elasticnet, solver=lbfgs, tol=1e-05;, score=nan total time=   0.0s
[CV 3/5; 96/240] START max_iter=100, penalty=elasticnet, solver=lbfgs, tol=1e-05
[CV 3/5; 96/240] END max_iter=100, penalty=elasticnet, solver=lbfgs, tol=1e-05;, score=nan total time=   0.0s
[CV 4/5; 96/240] START max_iter=100, penalty=elasticnet, solver=lbfgs, tol=1e-05
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 450, in _check_solver
    raise ValueError(&#34;Only &#39;saga&#39; solver supports elasticnet penalty,&#34;
ValueError: Only &#39;saga&#39; solver supports elasticnet penalty, got solver=liblinear.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 4/5; 96/240] END max_iter=100, penalty=elasticnet, solver=lbfgs, tol=1e-05;, score=nan total time=   0.0s
[CV 5/5; 96/240] START max_iter=100, penalty=elasticnet, solver=lbfgs, tol=1e-05
[CV 5/5; 96/240] END max_iter=100, penalty=elasticnet, solver=lbfgs, tol=1e-05;, score=nan total time=   0.0s
[CV 1/5; 97/240] START max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.001
[CV 1/5; 97/240] END max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.001;, score=nan total time=   0.0s
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 450, in _check_solver
    raise ValueError(&#34;Only &#39;saga&#39; solver supports elasticnet penalty,&#34;
ValueError: Only &#39;saga&#39; solver supports elasticnet penalty, got solver=liblinear.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 450, in _check_solver
    raise ValueError(&#34;Only &#39;saga&#39; solver supports elasticnet penalty,&#34;
ValueError: Only &#39;saga&#39; solver supports elasticnet penalty, got solver=liblinear.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 450, in _check_solver
    raise ValueError(&#34;Only &#39;saga&#39; solver supports elasticnet penalty,&#34;
ValueError: Only &#39;saga&#39; solver supports elasticnet penalty, got solver=liblinear.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 2/5; 97/240] START max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.001
[CV 2/5; 97/240] END max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.001;, score=nan total time=   0.0s
[CV 3/5; 97/240] START max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.001
[CV 3/5; 97/240] END max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.001;, score=nan total time=   0.0s
[CV 4/5; 97/240] START max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.001
[CV 4/5; 97/240] END max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.001;, score=nan total time=   0.0s
[CV 5/5; 97/240] START max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.001
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 450, in _check_solver
    raise ValueError(&#34;Only &#39;saga&#39; solver supports elasticnet penalty,&#34;
ValueError: Only &#39;saga&#39; solver supports elasticnet penalty, got solver=liblinear.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 450, in _check_solver
    raise ValueError(&#34;Only &#39;saga&#39; solver supports elasticnet penalty,&#34;
ValueError: Only &#39;saga&#39; solver supports elasticnet penalty, got solver=liblinear.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 450, in _check_solver
    raise ValueError(&#34;Only &#39;saga&#39; solver supports elasticnet penalty,&#34;
ValueError: Only &#39;saga&#39; solver supports elasticnet penalty, got solver=liblinear.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 5/5; 97/240] END max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.001;, score=nan total time=   0.0s
[CV 1/5; 98/240] START max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.0001
[CV 1/5; 98/240] END max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.0001;, score=nan total time=   0.0s
[CV 2/5; 98/240] START max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.0001
[CV 2/5; 98/240] END max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.0001;, score=nan total time=   0.0s
[CV 3/5; 98/240] START max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.0001
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 450, in _check_solver
    raise ValueError(&#34;Only &#39;saga&#39; solver supports elasticnet penalty,&#34;
ValueError: Only &#39;saga&#39; solver supports elasticnet penalty, got solver=liblinear.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 450, in _check_solver
    raise ValueError(&#34;Only &#39;saga&#39; solver supports elasticnet penalty,&#34;
ValueError: Only &#39;saga&#39; solver supports elasticnet penalty, got solver=liblinear.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 450, in _check_solver
    raise ValueError(&#34;Only &#39;saga&#39; solver supports elasticnet penalty,&#34;
ValueError: Only &#39;saga&#39; solver supports elasticnet penalty, got solver=liblinear.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 3/5; 98/240] END max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.0001;, score=nan total time=   0.0s
[CV 4/5; 98/240] START max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.0001
[CV 4/5; 98/240] END max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.0001;, score=nan total time=   0.0s
[CV 5/5; 98/240] START max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.0001
[CV 5/5; 98/240] END max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.0001;, score=nan total time=   0.0s
[CV 1/5; 99/240] START max_iter=100, penalty=elasticnet, solver=liblinear, tol=1e-05
[CV 1/5; 99/240] END max_iter=100, penalty=elasticnet, solver=liblinear, tol=1e-05;, score=nan total time=   0.0s
[CV 2/5; 99/240] START max_iter=100, penalty=elasticnet, solver=liblinear, tol=1e-05
[CV 2/5; 99/240] END max_iter=100, penalty=elasticnet, solver=liblinear, tol=1e-05;, score=nan total time=   0.0s
[CV 3/5; 99/240] START max_iter=100, penalty=elasticnet, solver=liblinear, tol=1e-05
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 450, in _check_solver
    raise ValueError(&#34;Only &#39;saga&#39; solver supports elasticnet penalty,&#34;
ValueError: Only &#39;saga&#39; solver supports elasticnet penalty, got solver=liblinear.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 450, in _check_solver
    raise ValueError(&#34;Only &#39;saga&#39; solver supports elasticnet penalty,&#34;
ValueError: Only &#39;saga&#39; solver supports elasticnet penalty, got solver=liblinear.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 450, in _check_solver
    raise ValueError(&#34;Only &#39;saga&#39; solver supports elasticnet penalty,&#34;
ValueError: Only &#39;saga&#39; solver supports elasticnet penalty, got solver=liblinear.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 3/5; 99/240] END max_iter=100, penalty=elasticnet, solver=liblinear, tol=1e-05;, score=nan total time=   0.0s
[CV 4/5; 99/240] START max_iter=100, penalty=elasticnet, solver=liblinear, tol=1e-05
[CV 4/5; 99/240] END max_iter=100, penalty=elasticnet, solver=liblinear, tol=1e-05;, score=nan total time=   0.0s
[CV 5/5; 99/240] START max_iter=100, penalty=elasticnet, solver=liblinear, tol=1e-05
[CV 5/5; 99/240] END max_iter=100, penalty=elasticnet, solver=liblinear, tol=1e-05;, score=nan total time=   0.0s
[CV 1/5; 100/240] START max_iter=100, penalty=elasticnet, solver=sag, tol=0.001.</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 450, in _check_solver
    raise ValueError(&#34;Only &#39;saga&#39; solver supports elasticnet penalty,&#34;
ValueError: Only &#39;saga&#39; solver supports elasticnet penalty, got solver=liblinear.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 450, in _check_solver
    raise ValueError(&#34;Only &#39;saga&#39; solver supports elasticnet penalty,&#34;
ValueError: Only &#39;saga&#39; solver supports elasticnet penalty, got solver=liblinear.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver sag supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>
[CV 1/5; 100/240] END max_iter=100, penalty=elasticnet, solver=sag, tol=0.001;, score=nan total time=   0.0s
[CV 2/5; 100/240] START max_iter=100, penalty=elasticnet, solver=sag, tol=0.001.
[CV 2/5; 100/240] END max_iter=100, penalty=elasticnet, solver=sag, tol=0.001;, score=nan total time=   0.0s
[CV 3/5; 100/240] START max_iter=100, penalty=elasticnet, solver=sag, tol=0.001.</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver sag supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver sag supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver sag supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>
[CV 3/5; 100/240] END max_iter=100, penalty=elasticnet, solver=sag, tol=0.001;, score=nan total time=   0.0s
[CV 4/5; 100/240] START max_iter=100, penalty=elasticnet, solver=sag, tol=0.001.
[CV 4/5; 100/240] END max_iter=100, penalty=elasticnet, solver=sag, tol=0.001;, score=nan total time=   0.0s
[CV 5/5; 100/240] START max_iter=100, penalty=elasticnet, solver=sag, tol=0.001.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver sag supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver sag supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver sag supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 5/5; 100/240] END max_iter=100, penalty=elasticnet, solver=sag, tol=0.001;, score=nan total time=   0.0s
[CV 1/5; 101/240] START max_iter=100, penalty=elasticnet, solver=sag, tol=0.0001
[CV 1/5; 101/240] END max_iter=100, penalty=elasticnet, solver=sag, tol=0.0001;, score=nan total time=   0.0s
[CV 2/5; 101/240] START max_iter=100, penalty=elasticnet, solver=sag, tol=0.0001
[CV 2/5; 101/240] END max_iter=100, penalty=elasticnet, solver=sag, tol=0.0001;, score=nan total time=   0.0s
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver sag supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver sag supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver sag supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 3/5; 101/240] START max_iter=100, penalty=elasticnet, solver=sag, tol=0.0001
[CV 3/5; 101/240] END max_iter=100, penalty=elasticnet, solver=sag, tol=0.0001;, score=nan total time=   0.0s
[CV 4/5; 101/240] START max_iter=100, penalty=elasticnet, solver=sag, tol=0.0001
[CV 4/5; 101/240] END max_iter=100, penalty=elasticnet, solver=sag, tol=0.0001;, score=nan total time=   0.0s
[CV 5/5; 101/240] START max_iter=100, penalty=elasticnet, solver=sag, tol=0.0001
[CV 5/5; 101/240] END max_iter=100, penalty=elasticnet, solver=sag, tol=0.0001;, score=nan total time=   0.0s
[CV 1/5; 102/240] START max_iter=100, penalty=elasticnet, solver=sag, tol=1e-05.
[CV 1/5; 102/240] END max_iter=100, penalty=elasticnet, solver=sag, tol=1e-05;, score=nan total time=   0.0s
[CV 2/5; 102/240] START max_iter=100, penalty=elasticnet, solver=sag, tol=1e-05.
[CV 2/5; 102/240] END max_iter=100, penalty=elasticnet, solver=sag, tol=1e-05;, score=nan total time=   0.0s
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver sag supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver sag supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver sag supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 3/5; 102/240] START max_iter=100, penalty=elasticnet, solver=sag, tol=1e-05.
[CV 3/5; 102/240] END max_iter=100, penalty=elasticnet, solver=sag, tol=1e-05;, score=nan total time=   0.0s
[CV 4/5; 102/240] START max_iter=100, penalty=elasticnet, solver=sag, tol=1e-05.
[CV 4/5; 102/240] END max_iter=100, penalty=elasticnet, solver=sag, tol=1e-05;, score=nan total time=   0.0s
[CV 5/5; 102/240] START max_iter=100, penalty=elasticnet, solver=sag, tol=1e-05.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver sag supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver sag supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1314, in fit
    raise ValueError(&#34;l1_ratio must be between 0 and 1;&#34;
ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 5/5; 102/240] END max_iter=100, penalty=elasticnet, solver=sag, tol=1e-05;, score=nan total time=   0.0s
[CV 1/5; 103/240] START max_iter=100, penalty=elasticnet, solver=saga, tol=0.001
[CV 1/5; 103/240] END max_iter=100, penalty=elasticnet, solver=saga, tol=0.001;, score=nan total time=   0.0s
[CV 2/5; 103/240] START max_iter=100, penalty=elasticnet, solver=saga, tol=0.001
[CV 2/5; 103/240] END max_iter=100, penalty=elasticnet, solver=saga, tol=0.001;, score=nan total time=   0.0s
[CV 3/5; 103/240] START max_iter=100, penalty=elasticnet, solver=saga, tol=0.001
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1314, in fit
    raise ValueError(&#34;l1_ratio must be between 0 and 1;&#34;
ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1314, in fit
    raise ValueError(&#34;l1_ratio must be between 0 and 1;&#34;
ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1314, in fit
    raise ValueError(&#34;l1_ratio must be between 0 and 1;&#34;
ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 3/5; 103/240] END max_iter=100, penalty=elasticnet, solver=saga, tol=0.001;, score=nan total time=   0.0s
[CV 4/5; 103/240] START max_iter=100, penalty=elasticnet, solver=saga, tol=0.001
[CV 4/5; 103/240] END max_iter=100, penalty=elasticnet, solver=saga, tol=0.001;, score=nan total time=   0.0s
[CV 5/5; 103/240] START max_iter=100, penalty=elasticnet, solver=saga, tol=0.001
[CV 5/5; 103/240] END max_iter=100, penalty=elasticnet, solver=saga, tol=0.001;, score=nan total time=   0.0s
[CV 1/5; 104/240] START max_iter=100, penalty=elasticnet, solver=saga, tol=0.0001
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1314, in fit
    raise ValueError(&#34;l1_ratio must be between 0 and 1;&#34;
ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1314, in fit
    raise ValueError(&#34;l1_ratio must be between 0 and 1;&#34;
ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1314, in fit
    raise ValueError(&#34;l1_ratio must be between 0 and 1;&#34;
ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 1/5; 104/240] END max_iter=100, penalty=elasticnet, solver=saga, tol=0.0001;, score=nan total time=   0.0s
[CV 2/5; 104/240] START max_iter=100, penalty=elasticnet, solver=saga, tol=0.0001
[CV 2/5; 104/240] END max_iter=100, penalty=elasticnet, solver=saga, tol=0.0001;, score=nan total time=   0.0s
[CV 3/5; 104/240] START max_iter=100, penalty=elasticnet, solver=saga, tol=0.0001
[CV 3/5; 104/240] END max_iter=100, penalty=elasticnet, solver=saga, tol=0.0001;, score=nan total time=   0.0s
[CV 4/5; 104/240] START max_iter=100, penalty=elasticnet, solver=saga, tol=0.0001</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1314, in fit
    raise ValueError(&#34;l1_ratio must be between 0 and 1;&#34;
ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1314, in fit
    raise ValueError(&#34;l1_ratio must be between 0 and 1;&#34;
ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1314, in fit
    raise ValueError(&#34;l1_ratio must be between 0 and 1;&#34;
ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>
[CV 4/5; 104/240] END max_iter=100, penalty=elasticnet, solver=saga, tol=0.0001;, score=nan total time=   0.0s
[CV 5/5; 104/240] START max_iter=100, penalty=elasticnet, solver=saga, tol=0.0001
[CV 5/5; 104/240] END max_iter=100, penalty=elasticnet, solver=saga, tol=0.0001;, score=nan total time=   0.0s
[CV 1/5; 105/240] START max_iter=100, penalty=elasticnet, solver=saga, tol=1e-05
[CV 1/5; 105/240] END max_iter=100, penalty=elasticnet, solver=saga, tol=1e-05;, score=nan total time=   0.0s
[CV 2/5; 105/240] START max_iter=100, penalty=elasticnet, solver=saga, tol=1e-05
[CV 2/5; 105/240] END max_iter=100, penalty=elasticnet, solver=saga, tol=1e-05;, score=nan total time=   0.0s
[CV 3/5; 105/240] START max_iter=100, penalty=elasticnet, solver=saga, tol=1e-05
[CV 3/5; 105/240] END max_iter=100, penalty=elasticnet, solver=saga, tol=1e-05;, score=nan total time=   0.0s
[CV 4/5; 105/240] START max_iter=100, penalty=elasticnet, solver=saga, tol=1e-05
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1314, in fit
    raise ValueError(&#34;l1_ratio must be between 0 and 1;&#34;
ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1314, in fit
    raise ValueError(&#34;l1_ratio must be between 0 and 1;&#34;
ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1314, in fit
    raise ValueError(&#34;l1_ratio must be between 0 and 1;&#34;
ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1314, in fit
    raise ValueError(&#34;l1_ratio must be between 0 and 1;&#34;
ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1314, in fit
    raise ValueError(&#34;l1_ratio must be between 0 and 1;&#34;
ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 4/5; 105/240] END max_iter=100, penalty=elasticnet, solver=saga, tol=1e-05;, score=nan total time=   0.0s
[CV 5/5; 105/240] START max_iter=100, penalty=elasticnet, solver=saga, tol=1e-05
[CV 5/5; 105/240] END max_iter=100, penalty=elasticnet, solver=saga, tol=1e-05;, score=nan total time=   0.0s
[CV 1/5; 106/240] START max_iter=100, penalty=none, solver=newton-cg, tol=0.001.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\utils\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.
  warnings.warn(&#34;newton-cg failed to converge. Increase the &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 1/5; 106/240] END max_iter=100, penalty=none, solver=newton-cg, tol=0.001;, score=0.497 total time= 5.0min
[CV 2/5; 106/240] START max_iter=100, penalty=none, solver=newton-cg, tol=0.001.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\utils\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.
  warnings.warn(&#34;newton-cg failed to converge. Increase the &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 2/5; 106/240] END max_iter=100, penalty=none, solver=newton-cg, tol=0.001;, score=0.500 total time= 5.0min
[CV 3/5; 106/240] START max_iter=100, penalty=none, solver=newton-cg, tol=0.001.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\utils\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.
  warnings.warn(&#34;newton-cg failed to converge. Increase the &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 3/5; 106/240] END max_iter=100, penalty=none, solver=newton-cg, tol=0.001;, score=0.499 total time= 4.9min
[CV 4/5; 106/240] START max_iter=100, penalty=none, solver=newton-cg, tol=0.001.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\utils\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.
  warnings.warn(&#34;newton-cg failed to converge. Increase the &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 4/5; 106/240] END max_iter=100, penalty=none, solver=newton-cg, tol=0.001;, score=0.499 total time= 4.7min
[CV 5/5; 106/240] START max_iter=100, penalty=none, solver=newton-cg, tol=0.001.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\utils\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.
  warnings.warn(&#34;newton-cg failed to converge. Increase the &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 5/5; 106/240] END max_iter=100, penalty=none, solver=newton-cg, tol=0.001;, score=0.500 total time= 4.9min
[CV 1/5; 107/240] START max_iter=100, penalty=none, solver=newton-cg, tol=0.0001
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\utils\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.
  warnings.warn(&#34;newton-cg failed to converge. Increase the &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 1/5; 107/240] END max_iter=100, penalty=none, solver=newton-cg, tol=0.0001;, score=0.497 total time= 4.4min
[CV 2/5; 107/240] START max_iter=100, penalty=none, solver=newton-cg, tol=0.0001
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\utils\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.
  warnings.warn(&#34;newton-cg failed to converge. Increase the &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 2/5; 107/240] END max_iter=100, penalty=none, solver=newton-cg, tol=0.0001;, score=0.500 total time= 3.4min
[CV 3/5; 107/240] START max_iter=100, penalty=none, solver=newton-cg, tol=0.0001
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\utils\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.
  warnings.warn(&#34;newton-cg failed to converge. Increase the &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 3/5; 107/240] END max_iter=100, penalty=none, solver=newton-cg, tol=0.0001;, score=0.499 total time= 3.3min
[CV 4/5; 107/240] START max_iter=100, penalty=none, solver=newton-cg, tol=0.0001
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\utils\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.
  warnings.warn(&#34;newton-cg failed to converge. Increase the &#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 4/5; 107/240] END max_iter=100, penalty=none, solver=newton-cg, tol=0.0001;, score=0.499 total time= 3.1min
[CV 5/5; 107/240] START max_iter=100, penalty=none, solver=newton-cg, tol=0.0001
</pre>
</div>
</div>

</div>

</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Logistic regression didn't have good result on the dataset. It doesn't converge.</p>

</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[18]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">penalty</span><span class="o">=</span><span class="s1">&#39;l2&#39;</span><span class="p">,</span> <span class="n">solver</span><span class="o">=</span><span class="s1">&#39;lbfgs&#39;</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mf">0.0001</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">predicted</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

</div>

</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>As we are not getting the wanted result let's check the <code>learning curve</code>.</p>
<p>We will check it for KNN.</p>

</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[24]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">yellowbrick.model_selection</span> <span class="kn">import</span> <span class="n">learning_curve</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">leaf_size</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="s1">&#39;uniform&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">learning_curve</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;accuracy&#39;</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">learning_curve</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;balanced_accuracy&#39;</span><span class="p">))</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedImage jp-OutputArea-output ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>
<span class="ansi-red-intense-fg ansi-bold">---------------------------------------------------------------------------</span>
<span class="ansi-red-intense-fg ansi-bold">ValueError</span>                                Traceback (most recent call last)
<span class="ansi-green-intense-fg ansi-bold">&lt;ipython-input-24-43bacc7f4e84&gt;</span> in <span class="ansi-cyan-fg">&lt;module&gt;</span>
<span class="ansi-green-fg">      2</span> 
<span class="ansi-green-fg">      3</span> model <span class="ansi-yellow-intense-fg ansi-bold">=</span> KNeighborsClassifier<span class="ansi-yellow-intense-fg ansi-bold">(</span>n_neighbors<span class="ansi-yellow-intense-fg ansi-bold">=</span><span class="ansi-cyan-intense-fg ansi-bold">5</span><span class="ansi-yellow-intense-fg ansi-bold">,</span> leaf_size<span class="ansi-yellow-intense-fg ansi-bold">=</span><span class="ansi-cyan-intense-fg ansi-bold">20</span><span class="ansi-yellow-intense-fg ansi-bold">,</span> weights<span class="ansi-yellow-intense-fg ansi-bold">=</span><span class="ansi-blue-intense-fg ansi-bold">&#39;uniform&#39;</span><span class="ansi-yellow-intense-fg ansi-bold">)</span>
<span class="ansi-green-intense-fg ansi-bold">----&gt; 4</span><span class="ansi-yellow-intense-fg ansi-bold"> </span>print<span class="ansi-yellow-intense-fg ansi-bold">(</span>learning_curve<span class="ansi-yellow-intense-fg ansi-bold">(</span>model<span class="ansi-yellow-intense-fg ansi-bold">,</span> X_train<span class="ansi-yellow-intense-fg ansi-bold">,</span> y_train<span class="ansi-yellow-intense-fg ansi-bold">,</span> cv<span class="ansi-yellow-intense-fg ansi-bold">=</span><span class="ansi-cyan-intense-fg ansi-bold">10</span><span class="ansi-yellow-intense-fg ansi-bold">,</span> scoring<span class="ansi-yellow-intense-fg ansi-bold">=</span><span class="ansi-blue-intense-fg ansi-bold">&#39;accuracy&#39;</span><span class="ansi-yellow-intense-fg ansi-bold">)</span><span class="ansi-yellow-intense-fg ansi-bold">)</span>
<span class="ansi-green-fg">      5</span> print<span class="ansi-yellow-intense-fg ansi-bold">(</span>learning_curve<span class="ansi-yellow-intense-fg ansi-bold">(</span>model<span class="ansi-yellow-intense-fg ansi-bold">,</span> X_train<span class="ansi-yellow-intense-fg ansi-bold">,</span> y_train<span class="ansi-yellow-intense-fg ansi-bold">,</span> cv<span class="ansi-yellow-intense-fg ansi-bold">=</span><span class="ansi-cyan-intense-fg ansi-bold">10</span><span class="ansi-yellow-intense-fg ansi-bold">,</span> scoring<span class="ansi-yellow-intense-fg ansi-bold">=</span><span class="ansi-blue-intense-fg ansi-bold">&#39;balanced_accuracy&#39;</span><span class="ansi-yellow-intense-fg ansi-bold">)</span><span class="ansi-yellow-intense-fg ansi-bold">)</span>

<span class="ansi-green-intense-fg ansi-bold">~\anaconda3\lib\site-packages\sklearn\base.py</span> in <span class="ansi-cyan-fg">__repr__</span><span class="ansi-blue-intense-fg ansi-bold">(self, N_CHAR_MAX)</span>
<span class="ansi-green-fg">    258</span>             n_max_elements_to_show=N_MAX_ELEMENTS_TO_SHOW)
<span class="ansi-green-fg">    259</span> 
<span class="ansi-green-intense-fg ansi-bold">--&gt; 260</span><span class="ansi-yellow-intense-fg ansi-bold">         </span>repr_ <span class="ansi-yellow-intense-fg ansi-bold">=</span> pp<span class="ansi-yellow-intense-fg ansi-bold">.</span>pformat<span class="ansi-yellow-intense-fg ansi-bold">(</span>self<span class="ansi-yellow-intense-fg ansi-bold">)</span>
<span class="ansi-green-fg">    261</span> 
<span class="ansi-green-fg">    262</span>         <span class="ansi-red-intense-fg ansi-bold"># Use bruteforce ellipsis when there are a lot of non-blank characters</span>

<span class="ansi-green-intense-fg ansi-bold">~\anaconda3\lib\pprint.py</span> in <span class="ansi-cyan-fg">pformat</span><span class="ansi-blue-intense-fg ansi-bold">(self, object)</span>
<span class="ansi-green-fg">    151</span>     <span class="ansi-green-intense-fg ansi-bold">def</span> pformat<span class="ansi-yellow-intense-fg ansi-bold">(</span>self<span class="ansi-yellow-intense-fg ansi-bold">,</span> object<span class="ansi-yellow-intense-fg ansi-bold">)</span><span class="ansi-yellow-intense-fg ansi-bold">:</span>
<span class="ansi-green-fg">    152</span>         sio <span class="ansi-yellow-intense-fg ansi-bold">=</span> _StringIO<span class="ansi-yellow-intense-fg ansi-bold">(</span><span class="ansi-yellow-intense-fg ansi-bold">)</span>
<span class="ansi-green-intense-fg ansi-bold">--&gt; 153</span><span class="ansi-yellow-intense-fg ansi-bold">         </span>self<span class="ansi-yellow-intense-fg ansi-bold">.</span>_format<span class="ansi-yellow-intense-fg ansi-bold">(</span>object<span class="ansi-yellow-intense-fg ansi-bold">,</span> sio<span class="ansi-yellow-intense-fg ansi-bold">,</span> <span class="ansi-cyan-intense-fg ansi-bold">0</span><span class="ansi-yellow-intense-fg ansi-bold">,</span> <span class="ansi-cyan-intense-fg ansi-bold">0</span><span class="ansi-yellow-intense-fg ansi-bold">,</span> <span class="ansi-yellow-intense-fg ansi-bold">{</span><span class="ansi-yellow-intense-fg ansi-bold">}</span><span class="ansi-yellow-intense-fg ansi-bold">,</span> <span class="ansi-cyan-intense-fg ansi-bold">0</span><span class="ansi-yellow-intense-fg ansi-bold">)</span>
<span class="ansi-green-fg">    154</span>         <span class="ansi-green-intense-fg ansi-bold">return</span> sio<span class="ansi-yellow-intense-fg ansi-bold">.</span>getvalue<span class="ansi-yellow-intense-fg ansi-bold">(</span><span class="ansi-yellow-intense-fg ansi-bold">)</span>
<span class="ansi-green-fg">    155</span> 

<span class="ansi-green-intense-fg ansi-bold">~\anaconda3\lib\pprint.py</span> in <span class="ansi-cyan-fg">_format</span><span class="ansi-blue-intense-fg ansi-bold">(self, object, stream, indent, allowance, context, level)</span>
<span class="ansi-green-fg">    168</span>             self<span class="ansi-yellow-intense-fg ansi-bold">.</span>_readable <span class="ansi-yellow-intense-fg ansi-bold">=</span> <span class="ansi-green-intense-fg ansi-bold">False</span>
<span class="ansi-green-fg">    169</span>             <span class="ansi-green-intense-fg ansi-bold">return</span>
<span class="ansi-green-intense-fg ansi-bold">--&gt; 170</span><span class="ansi-yellow-intense-fg ansi-bold">         </span>rep <span class="ansi-yellow-intense-fg ansi-bold">=</span> self<span class="ansi-yellow-intense-fg ansi-bold">.</span>_repr<span class="ansi-yellow-intense-fg ansi-bold">(</span>object<span class="ansi-yellow-intense-fg ansi-bold">,</span> context<span class="ansi-yellow-intense-fg ansi-bold">,</span> level<span class="ansi-yellow-intense-fg ansi-bold">)</span>
<span class="ansi-green-fg">    171</span>         max_width <span class="ansi-yellow-intense-fg ansi-bold">=</span> self<span class="ansi-yellow-intense-fg ansi-bold">.</span>_width <span class="ansi-yellow-intense-fg ansi-bold">-</span> indent <span class="ansi-yellow-intense-fg ansi-bold">-</span> allowance
<span class="ansi-green-fg">    172</span>         <span class="ansi-green-intense-fg ansi-bold">if</span> len<span class="ansi-yellow-intense-fg ansi-bold">(</span>rep<span class="ansi-yellow-intense-fg ansi-bold">)</span> <span class="ansi-yellow-intense-fg ansi-bold">&gt;</span> max_width<span class="ansi-yellow-intense-fg ansi-bold">:</span>

<span class="ansi-green-intense-fg ansi-bold">~\anaconda3\lib\pprint.py</span> in <span class="ansi-cyan-fg">_repr</span><span class="ansi-blue-intense-fg ansi-bold">(self, object, context, level)</span>
<span class="ansi-green-fg">    402</span> 
<span class="ansi-green-fg">    403</span>     <span class="ansi-green-intense-fg ansi-bold">def</span> _repr<span class="ansi-yellow-intense-fg ansi-bold">(</span>self<span class="ansi-yellow-intense-fg ansi-bold">,</span> object<span class="ansi-yellow-intense-fg ansi-bold">,</span> context<span class="ansi-yellow-intense-fg ansi-bold">,</span> level<span class="ansi-yellow-intense-fg ansi-bold">)</span><span class="ansi-yellow-intense-fg ansi-bold">:</span>
<span class="ansi-green-intense-fg ansi-bold">--&gt; 404</span><span class="ansi-yellow-intense-fg ansi-bold">         repr, readable, recursive = self.format(object, context.copy(),
</span><span class="ansi-green-fg">    405</span>                                                 self._depth, level)
<span class="ansi-green-fg">    406</span>         <span class="ansi-green-intense-fg ansi-bold">if</span> <span class="ansi-green-intense-fg ansi-bold">not</span> readable<span class="ansi-yellow-intense-fg ansi-bold">:</span>

<span class="ansi-green-intense-fg ansi-bold">~\anaconda3\lib\site-packages\sklearn\utils\_pprint.py</span> in <span class="ansi-cyan-fg">format</span><span class="ansi-blue-intense-fg ansi-bold">(self, object, context, maxlevels, level)</span>
<span class="ansi-green-fg">    178</span> 
<span class="ansi-green-fg">    179</span>     <span class="ansi-green-intense-fg ansi-bold">def</span> format<span class="ansi-yellow-intense-fg ansi-bold">(</span>self<span class="ansi-yellow-intense-fg ansi-bold">,</span> object<span class="ansi-yellow-intense-fg ansi-bold">,</span> context<span class="ansi-yellow-intense-fg ansi-bold">,</span> maxlevels<span class="ansi-yellow-intense-fg ansi-bold">,</span> level<span class="ansi-yellow-intense-fg ansi-bold">)</span><span class="ansi-yellow-intense-fg ansi-bold">:</span>
<span class="ansi-green-intense-fg ansi-bold">--&gt; 180</span><span class="ansi-yellow-intense-fg ansi-bold">         return _safe_repr(object, context, maxlevels, level,
</span><span class="ansi-green-fg">    181</span>                           changed_only=self._changed_only)
<span class="ansi-green-fg">    182</span> 

<span class="ansi-green-intense-fg ansi-bold">~\anaconda3\lib\site-packages\sklearn\utils\_pprint.py</span> in <span class="ansi-cyan-fg">_safe_repr</span><span class="ansi-blue-intense-fg ansi-bold">(object, context, maxlevels, level, changed_only)</span>
<span class="ansi-green-fg">    423</span>         recursive <span class="ansi-yellow-intense-fg ansi-bold">=</span> <span class="ansi-green-intense-fg ansi-bold">False</span>
<span class="ansi-green-fg">    424</span>         <span class="ansi-green-intense-fg ansi-bold">if</span> changed_only<span class="ansi-yellow-intense-fg ansi-bold">:</span>
<span class="ansi-green-intense-fg ansi-bold">--&gt; 425</span><span class="ansi-yellow-intense-fg ansi-bold">             </span>params <span class="ansi-yellow-intense-fg ansi-bold">=</span> _changed_params<span class="ansi-yellow-intense-fg ansi-bold">(</span>object<span class="ansi-yellow-intense-fg ansi-bold">)</span>
<span class="ansi-green-fg">    426</span>         <span class="ansi-green-intense-fg ansi-bold">else</span><span class="ansi-yellow-intense-fg ansi-bold">:</span>
<span class="ansi-green-fg">    427</span>             params <span class="ansi-yellow-intense-fg ansi-bold">=</span> object<span class="ansi-yellow-intense-fg ansi-bold">.</span>get_params<span class="ansi-yellow-intense-fg ansi-bold">(</span>deep<span class="ansi-yellow-intense-fg ansi-bold">=</span><span class="ansi-green-intense-fg ansi-bold">False</span><span class="ansi-yellow-intense-fg ansi-bold">)</span>

<span class="ansi-green-intense-fg ansi-bold">~\anaconda3\lib\site-packages\sklearn\utils\_pprint.py</span> in <span class="ansi-cyan-fg">_changed_params</span><span class="ansi-blue-intense-fg ansi-bold">(estimator)</span>
<span class="ansi-green-fg">    110</span>         <span class="ansi-green-intense-fg ansi-bold">return</span> <span class="ansi-green-intense-fg ansi-bold">False</span>
<span class="ansi-green-fg">    111</span> 
<span class="ansi-green-intense-fg ansi-bold">--&gt; 112</span><span class="ansi-yellow-intense-fg ansi-bold">     </span><span class="ansi-green-intense-fg ansi-bold">return</span> <span class="ansi-yellow-intense-fg ansi-bold">{</span>k<span class="ansi-yellow-intense-fg ansi-bold">:</span> v <span class="ansi-green-intense-fg ansi-bold">for</span> k<span class="ansi-yellow-intense-fg ansi-bold">,</span> v <span class="ansi-green-intense-fg ansi-bold">in</span> params<span class="ansi-yellow-intense-fg ansi-bold">.</span>items<span class="ansi-yellow-intense-fg ansi-bold">(</span><span class="ansi-yellow-intense-fg ansi-bold">)</span> <span class="ansi-green-intense-fg ansi-bold">if</span> has_changed<span class="ansi-yellow-intense-fg ansi-bold">(</span>k<span class="ansi-yellow-intense-fg ansi-bold">,</span> v<span class="ansi-yellow-intense-fg ansi-bold">)</span><span class="ansi-yellow-intense-fg ansi-bold">}</span>
<span class="ansi-green-fg">    113</span> 
<span class="ansi-green-fg">    114</span> 

<span class="ansi-green-intense-fg ansi-bold">~\anaconda3\lib\site-packages\sklearn\utils\_pprint.py</span> in <span class="ansi-cyan-fg">&lt;dictcomp&gt;</span><span class="ansi-blue-intense-fg ansi-bold">(.0)</span>
<span class="ansi-green-fg">    110</span>         <span class="ansi-green-intense-fg ansi-bold">return</span> <span class="ansi-green-intense-fg ansi-bold">False</span>
<span class="ansi-green-fg">    111</span> 
<span class="ansi-green-intense-fg ansi-bold">--&gt; 112</span><span class="ansi-yellow-intense-fg ansi-bold">     </span><span class="ansi-green-intense-fg ansi-bold">return</span> <span class="ansi-yellow-intense-fg ansi-bold">{</span>k<span class="ansi-yellow-intense-fg ansi-bold">:</span> v <span class="ansi-green-intense-fg ansi-bold">for</span> k<span class="ansi-yellow-intense-fg ansi-bold">,</span> v <span class="ansi-green-intense-fg ansi-bold">in</span> params<span class="ansi-yellow-intense-fg ansi-bold">.</span>items<span class="ansi-yellow-intense-fg ansi-bold">(</span><span class="ansi-yellow-intense-fg ansi-bold">)</span> <span class="ansi-green-intense-fg ansi-bold">if</span> has_changed<span class="ansi-yellow-intense-fg ansi-bold">(</span>k<span class="ansi-yellow-intense-fg ansi-bold">,</span> v<span class="ansi-yellow-intense-fg ansi-bold">)</span><span class="ansi-yellow-intense-fg ansi-bold">}</span>
<span class="ansi-green-fg">    113</span> 
<span class="ansi-green-fg">    114</span> 

<span class="ansi-green-intense-fg ansi-bold">~\anaconda3\lib\site-packages\sklearn\utils\_pprint.py</span> in <span class="ansi-cyan-fg">has_changed</span><span class="ansi-blue-intense-fg ansi-bold">(k, v)</span>
<span class="ansi-green-fg">     98</span>         <span class="ansi-green-intense-fg ansi-bold">if</span> k <span class="ansi-green-intense-fg ansi-bold">not</span> <span class="ansi-green-intense-fg ansi-bold">in</span> init_params<span class="ansi-yellow-intense-fg ansi-bold">:</span>  <span class="ansi-red-intense-fg ansi-bold"># happens if k is part of a **kwargs</span>
<span class="ansi-green-fg">     99</span>             <span class="ansi-green-intense-fg ansi-bold">return</span> <span class="ansi-green-intense-fg ansi-bold">True</span>
<span class="ansi-green-intense-fg ansi-bold">--&gt; 100</span><span class="ansi-yellow-intense-fg ansi-bold">         </span><span class="ansi-green-intense-fg ansi-bold">if</span> init_params<span class="ansi-yellow-intense-fg ansi-bold">[</span>k<span class="ansi-yellow-intense-fg ansi-bold">]</span> <span class="ansi-yellow-intense-fg ansi-bold">==</span> inspect<span class="ansi-yellow-intense-fg ansi-bold">.</span>_empty<span class="ansi-yellow-intense-fg ansi-bold">:</span>  <span class="ansi-red-intense-fg ansi-bold"># k has no default value</span>
<span class="ansi-green-fg">    101</span>             <span class="ansi-green-intense-fg ansi-bold">return</span> <span class="ansi-green-intense-fg ansi-bold">True</span>
<span class="ansi-green-fg">    102</span>         <span class="ansi-red-intense-fg ansi-bold"># try to avoid calling repr on nested estimators</span>

<span class="ansi-red-intense-fg ansi-bold">ValueError</span>: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[28]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">keras</span>
<span class="kn">from</span> <span class="nn">keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>
<span class="kn">from</span> <span class="nn">keras.layers</span> <span class="kn">import</span> <span class="n">Dense</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">input_dim</span><span class="o">=</span><span class="mi">931</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">60</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">45</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">30</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">))</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[63]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;binary_crossentropy&#39;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;adam&#39;</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[41]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">OneHotEncoder</span>

<span class="n">ohe</span> <span class="o">=</span> <span class="n">OneHotEncoder</span><span class="p">()</span>

<span class="n">y_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">y_train</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">y_test</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>

<span class="n">y_train</span> <span class="o">=</span> <span class="n">ohe</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">y_train</span><span class="p">)</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">ohe</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">y_test</span><span class="p">)</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[64]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Epoch 1/100
504/504 [==============================] - 2s 1ms/step - loss: 10.8064 - accuracy: 0.7126
Epoch 2/100
504/504 [==============================] - 1s 1ms/step - loss: 0.6040 - accuracy: 0.7409
Epoch 3/100
504/504 [==============================] - 1s 1ms/step - loss: 0.5759 - accuracy: 0.7462
Epoch 4/100
504/504 [==============================] - 1s 1ms/step - loss: 0.5683 - accuracy: 0.7465
Epoch 5/100
504/504 [==============================] - 1s 1ms/step - loss: 0.5687 - accuracy: 0.7444
Epoch 6/100
504/504 [==============================] - 1s 1ms/step - loss: 0.5685 - accuracy: 0.7444
Epoch 7/100
504/504 [==============================] - 1s 1ms/step - loss: 0.5676 - accuracy: 0.7452
Epoch 8/100
504/504 [==============================] - 1s 1ms/step - loss: 0.5661 - accuracy: 0.7466
Epoch 9/100
504/504 [==============================] - 1s 1ms/step - loss: 0.5725 - accuracy: 0.7406
Epoch 10/100
504/504 [==============================] - 1s 1ms/step - loss: 0.5675 - accuracy: 0.7453
Epoch 11/100
504/504 [==============================] - 1s 1ms/step - loss: 0.5711 - accuracy: 0.7418
Epoch 12/100
504/504 [==============================] - 1s 1ms/step - loss: 0.5735 - accuracy: 0.7396
Epoch 13/100
504/504 [==============================] - 1s 1ms/step - loss: 0.5666 - accuracy: 0.7461
Epoch 14/100
504/504 [==============================] - 1s 1ms/step - loss: 0.5644 - accuracy: 0.7482
Epoch 15/100
504/504 [==============================] - 1s 1ms/step - loss: 0.5702 - accuracy: 0.7427
Epoch 16/100
504/504 [==============================] - 1s 1ms/step - loss: 0.5654 - accuracy: 0.7472
Epoch 17/100
504/504 [==============================] - 1s 1ms/step - loss: 0.5713 - accuracy: 0.7416
Epoch 18/100
504/504 [==============================] - 1s 1ms/step - loss: 0.5674 - accuracy: 0.7453
Epoch 19/100
504/504 [==============================] - 1s 1ms/step - loss: 0.5662 - accuracy: 0.7465
Epoch 20/100
504/504 [==============================] - 1s 1ms/step - loss: 0.5679 - accuracy: 0.7449
Epoch 21/100
504/504 [==============================] - 1s 1ms/step - loss: 0.5675 - accuracy: 0.7453
Epoch 22/100
504/504 [==============================] - 1s 1ms/step - loss: 0.5679 - accuracy: 0.7449
Epoch 23/100
504/504 [==============================] - 1s 1ms/step - loss: 0.5688 - accuracy: 0.7440
Epoch 24/100
504/504 [==============================] - 1s 1ms/step - loss: 0.5714 - accuracy: 0.7416
Epoch 25/100
504/504 [==============================] - 1s 1ms/step - loss: 0.5665 - accuracy: 0.7462
Epoch 26/100
504/504 [==============================] - 1s 1ms/step - loss: 0.5711 - accuracy: 0.7419
Epoch 27/100
504/504 [==============================] - 1s 1ms/step - loss: 0.5718 - accuracy: 0.7412
Epoch 28/100
504/504 [==============================] - 1s 1ms/step - loss: 0.5686 - accuracy: 0.7443
Epoch 29/100
504/504 [==============================] - 1s 1ms/step - loss: 0.5687 - accuracy: 0.7441
Epoch 30/100
504/504 [==============================] - 1s 1ms/step - loss: 0.5680 - accuracy: 0.7448
Epoch 31/100
504/504 [==============================] - 1s 1ms/step - loss: 0.5695 - accuracy: 0.7434
Epoch 32/100
504/504 [==============================] - 1s 1ms/step - loss: 0.5695 - accuracy: 0.7434
Epoch 33/100
504/504 [==============================] - 1s 1ms/step - loss: 0.5687 - accuracy: 0.7442
Epoch 34/100
504/504 [==============================] - 1s 1ms/step - loss: 0.5677 - accuracy: 0.7451
Epoch 35/100
504/504 [==============================] - 1s 1ms/step - loss: 0.5672 - accuracy: 0.7456
Epoch 36/100
504/504 [==============================] - 1s 1ms/step - loss: 0.5717 - accuracy: 0.7414
Epoch 37/100
504/504 [==============================] - 1s 1ms/step - loss: 0.5664 - accuracy: 0.7462
Epoch 38/100
504/504 [==============================] - 1s 1ms/step - loss: 0.5687 - accuracy: 0.7441
Epoch 39/100
504/504 [==============================] - 1s 1ms/step - loss: 0.5683 - accuracy: 0.7445
Epoch 40/100
504/504 [==============================] - 1s 1ms/step - loss: 0.5701 - accuracy: 0.7429
Epoch 41/100
504/504 [==============================] - 1s 1ms/step - loss: 0.5659 - accuracy: 0.7468
Epoch 42/100
504/504 [==============================] - 1s 1ms/step - loss: 0.5697 - accuracy: 0.7432
Epoch 43/100
504/504 [==============================] - 1s 1ms/step - loss: 0.5668 - accuracy: 0.7460
Epoch 44/100
504/504 [==============================] - 1s 1ms/step - loss: 0.5703 - accuracy: 0.7426
Epoch 45/100
504/504 [==============================] - 1s 1ms/step - loss: 0.5676 - accuracy: 0.7452
Epoch 46/100
504/504 [==============================] - 1s 1ms/step - loss: 0.5685 - accuracy: 0.7443
Epoch 47/100
504/504 [==============================] - 1s 1ms/step - loss: 0.5721 - accuracy: 0.7409
Epoch 48/100
504/504 [==============================] - 1s 1ms/step - loss: 0.5693 - accuracy: 0.7435
Epoch 49/100
504/504 [==============================] - 1s 1ms/step - loss: 0.5658 - accuracy: 0.7469
Epoch 50/100
504/504 [==============================] - 1s 1ms/step - loss: 0.5694 - accuracy: 0.7434
Epoch 51/100
504/504 [==============================] - 1s 1ms/step - loss: 0.5692 - accuracy: 0.7437
Epoch 52/100
504/504 [==============================] - 1s 1ms/step - loss: 0.5708 - accuracy: 0.7422
Epoch 53/100
504/504 [==============================] - 1s 1ms/step - loss: 0.5701 - accuracy: 0.7428
Epoch 54/100
504/504 [==============================] - 1s 1ms/step - loss: 0.5703 - accuracy: 0.7426
Epoch 55/100
504/504 [==============================] - 1s 1ms/step - loss: 0.5666 - accuracy: 0.7461
Epoch 56/100
504/504 [==============================] - 1s 1ms/step - loss: 0.5690 - accuracy: 0.7438
Epoch 57/100
504/504 [==============================] - 1s 1ms/step - loss: 0.5657 - accuracy: 0.7469
Epoch 58/100
504/504 [==============================] - 1s 1ms/step - loss: 0.5757 - accuracy: 0.7375
Epoch 59/100
504/504 [==============================] - 1s 1ms/step - loss: 0.5683 - accuracy: 0.7445
Epoch 60/100
504/504 [==============================] - 1s 1ms/step - loss: 0.5717 - accuracy: 0.7413
Epoch 61/100
504/504 [==============================] - 1s 1ms/step - loss: 0.5696 - accuracy: 0.7433
Epoch 62/100
504/504 [==============================] - 1s 1ms/step - loss: 0.5699 - accuracy: 0.7430
Epoch 63/100
504/504 [==============================] - 1s 1ms/step - loss: 0.5705 - accuracy: 0.7424
Epoch 64/100
504/504 [==============================] - 1s 1ms/step - loss: 0.5717 - accuracy: 0.7413
Epoch 65/100
504/504 [==============================] - 1s 1ms/step - loss: 0.5721 - accuracy: 0.7409
Epoch 66/100
504/504 [==============================] - 1s 1ms/step - loss: 0.5689 - accuracy: 0.7439
Epoch 67/100
504/504 [==============================] - 1s 1ms/step - loss: 0.5660 - accuracy: 0.7466
Epoch 68/100
504/504 [==============================] - 1s 1ms/step - loss: 0.5640 - accuracy: 0.7485
Epoch 69/100
504/504 [==============================] - 1s 1ms/step - loss: 0.5671 - accuracy: 0.7456
Epoch 70/100
504/504 [==============================] - 1s 1ms/step - loss: 0.5690 - accuracy: 0.7438
Epoch 71/100
504/504 [==============================] - 1s 1ms/step - loss: 0.5719 - accuracy: 0.7411
Epoch 72/100
504/504 [==============================] - 1s 1ms/step - loss: 0.5708 - accuracy: 0.7421
Epoch 73/100
504/504 [==============================] - 1s 1ms/step - loss: 0.5720 - accuracy: 0.7410
Epoch 74/100
504/504 [==============================] - 1s 1ms/step - loss: 0.5685 - accuracy: 0.7444
Epoch 75/100
504/504 [==============================] - 1s 1ms/step - loss: 0.5708 - accuracy: 0.7421
Epoch 76/100
504/504 [==============================] - 1s 1ms/step - loss: 0.5654 - accuracy: 0.7472
Epoch 77/100
504/504 [==============================] - 1s 1ms/step - loss: 0.5708 - accuracy: 0.7422
Epoch 78/100
504/504 [==============================] - 1s 1ms/step - loss: 0.5680 - accuracy: 0.7448
Epoch 79/100
504/504 [==============================] - 1s 1ms/step - loss: 0.5725 - accuracy: 0.7405
Epoch 80/100
504/504 [==============================] - 1s 1ms/step - loss: 0.5656 - accuracy: 0.7470
Epoch 81/100
504/504 [==============================] - 1s 1ms/step - loss: 0.5730 - accuracy: 0.7401: 0s - loss: 0.5742 - accuracy
Epoch 82/100
504/504 [==============================] - 1s 1ms/step - loss: 0.5674 - accuracy: 0.7453
Epoch 83/100
504/504 [==============================] - 1s 1ms/step - loss: 0.5690 - accuracy: 0.7438
Epoch 84/100
504/504 [==============================] - 1s 1ms/step - loss: 0.5656 - accuracy: 0.7470
Epoch 85/100
504/504 [==============================] - 1s 1ms/step - loss: 0.5711 - accuracy: 0.7419
Epoch 86/100
504/504 [==============================] - 1s 1ms/step - loss: 0.5710 - accuracy: 0.7419
Epoch 87/100
504/504 [==============================] - 1s 1ms/step - loss: 0.5641 - accuracy: 0.7484
Epoch 88/100
504/504 [==============================] - 1s 1ms/step - loss: 0.5686 - accuracy: 0.7442
Epoch 89/100
504/504 [==============================] - 1s 1ms/step - loss: 0.5741 - accuracy: 0.7390
Epoch 90/100
504/504 [==============================] - 1s 1ms/step - loss: 0.5700 - accuracy: 0.7429
Epoch 91/100
504/504 [==============================] - 1s 1ms/step - loss: 0.5718 - accuracy: 0.7412
Epoch 92/100
504/504 [==============================] - 1s 1ms/step - loss: 0.5716 - accuracy: 0.7414
Epoch 93/100
504/504 [==============================] - 1s 1ms/step - loss: 0.5687 - accuracy: 0.7441
Epoch 94/100
504/504 [==============================] - 1s 1ms/step - loss: 0.5691 - accuracy: 0.7438
Epoch 95/100
504/504 [==============================] - 1s 1ms/step - loss: 0.5735 - accuracy: 0.7396
Epoch 96/100
504/504 [==============================] - 1s 1ms/step - loss: 0.5697 - accuracy: 0.7432
Epoch 97/100
504/504 [==============================] - 1s 1ms/step - loss: 0.5739 - accuracy: 0.7392
Epoch 98/100
504/504 [==============================] - 1s 1ms/step - loss: 0.5716 - accuracy: 0.7414
Epoch 99/100
504/504 [==============================] - 1s 1ms/step - loss: 0.5669 - accuracy: 0.7458
Epoch 100/100
504/504 [==============================] - 1s 1ms/step - loss: 0.5677 - accuracy: 0.7451
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[70]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_parquet</span><span class="p">(</span><span class="n">DATA_DIR</span><span class="p">,</span> <span class="n">engine</span><span class="o">=</span><span class="s2">&quot;pyarrow&quot;</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s2">&quot;birth_year&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;birth_year&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">uint</span><span class="p">)</span>
<span class="n">valid_birth_year</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;birth_year&quot;</span><span class="p">][</span><span class="n">df</span><span class="p">[</span><span class="s2">&quot;birth_year&quot;</span><span class="p">]</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">]</span>
<span class="n">mean_birth_year</span> <span class="o">=</span> <span class="nb">round</span><span class="p">(</span><span class="n">valid_birth_year</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>
<span class="n">df</span><span class="p">[</span><span class="s2">&quot;birth_year&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;birth_year&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">mean_birth_year</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s2">&quot;gender&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;gender&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">({</span><span class="s1">&#39;M&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;F&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">})</span>
<span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;birth_year&#39;</span><span class="p">],</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt">Out[70]:</div>



<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/html">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>queries</th>
      <th>apps</th>
      <th>games</th>
      <th>gender</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>[216, 359, 12329, 3, 45, 4002, 2066, 32, 3931,...</td>
      <td>[4, 4, 25, 7, 30, 58, 16, 19, 17, 21, 10, 10, ...</td>
      <td>[9151, 208]</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>[]</td>
      <td>[129, 71, 9, 8, 11, 25, 18, 58, 6, 16, 125, 12...</td>
      <td>[460, 4939, 14, 232, 6387, 1758, 5834, 3, 2]</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>[23463, 18831]</td>
      <td>[9, 174, 65, 8, 63, 97, 62, 103, 61, 116, 59, ...</td>
      <td>[448, 723, 267, 9064, 10634, 166, 782, 224, 27...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>[1634, 3609, 654]</td>
      <td>[99, 73, 9, 8, 59, 37, 131, 3, 89, 6, 24, 16, ...</td>
      <td>[78, 2607, 478, 435, 9, 192]</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>[11064, 227, 623, 1301, 43999, 35411, 2492, 11...</td>
      <td>[9, 8, 17, 54, 3, 25, 22, 6, 21, 7, 14, 5, 817...</td>
      <td>[1702, 1, 53]</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[71]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">df</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">&#39;apps&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">),</span> <span class="n">df</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">df</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">&#39;games&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">),</span> <span class="n">df</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">df</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">&#39;queries&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">),</span> <span class="n">df</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span>  <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;gender&quot;</span><span class="p">]),</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;gender&quot;</span><span class="p">]</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[72]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt">Out[72]:</div>




<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain">
<pre>(32216, 930)</pre>
</div>

</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[81]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">input_dim</span><span class="o">=</span><span class="mi">930</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">60</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">45</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">30</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">))</span>

<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;binary_crossentropy&#39;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;adam&#39;</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[74]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">ohe</span> <span class="o">=</span> <span class="n">OneHotEncoder</span><span class="p">()</span>

<span class="n">y_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">y_train</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">y_test</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>

<span class="n">y_train</span> <span class="o">=</span> <span class="n">ohe</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">y_train</span><span class="p">)</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">ohe</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">y_test</span><span class="p">)</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[82]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">validation_split</span><span class="o">=</span><span class="mf">0.33</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Epoch 1/100
338/338 [==============================] - 2s 2ms/step - loss: 25.7407 - accuracy: 0.6838 - val_loss: 0.6485 - val_accuracy: 0.7368
Epoch 2/100
338/338 [==============================] - 1s 2ms/step - loss: 0.6222 - accuracy: 0.7432 - val_loss: 0.6089 - val_accuracy: 0.7369
Epoch 3/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5889 - accuracy: 0.7503 - val_loss: 0.5943 - val_accuracy: 0.7369
Epoch 4/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5735 - accuracy: 0.7485 - val_loss: 0.5882 - val_accuracy: 0.7369
Epoch 5/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5721 - accuracy: 0.7433 - val_loss: 0.5863 - val_accuracy: 0.7369
Epoch 6/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5668 - accuracy: 0.7467 - val_loss: 0.5858 - val_accuracy: 0.7369
Epoch 7/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5663 - accuracy: 0.7466 - val_loss: 0.5859 - val_accuracy: 0.7369
Epoch 8/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5662 - accuracy: 0.7465 - val_loss: 0.5859 - val_accuracy: 0.7369
Epoch 9/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5602 - accuracy: 0.7520 - val_loss: 0.5860 - val_accuracy: 0.7369
Epoch 10/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5650 - accuracy: 0.7476 - val_loss: 0.5859 - val_accuracy: 0.7369
Epoch 11/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5612 - accuracy: 0.7511 - val_loss: 0.5859 - val_accuracy: 0.7369
Epoch 12/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5649 - accuracy: 0.7476 - val_loss: 0.5860 - val_accuracy: 0.7369
Epoch 13/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5684 - accuracy: 0.7444 - val_loss: 0.5860 - val_accuracy: 0.7369
Epoch 14/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5652 - accuracy: 0.7473 - val_loss: 0.5859 - val_accuracy: 0.7369
Epoch 15/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5642 - accuracy: 0.7483 - val_loss: 0.5859 - val_accuracy: 0.7369
Epoch 16/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5656 - accuracy: 0.7470 - val_loss: 0.5859 - val_accuracy: 0.7369
Epoch 17/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5713 - accuracy: 0.7419 - val_loss: 0.5842 - val_accuracy: 0.7370
Epoch 18/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5636 - accuracy: 0.7489 - val_loss: 0.5839 - val_accuracy: 0.7370
Epoch 19/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5666 - accuracy: 0.7461 - val_loss: 0.5840 - val_accuracy: 0.7370
Epoch 20/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5685 - accuracy: 0.7443 - val_loss: 0.5840 - val_accuracy: 0.7370
Epoch 21/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5665 - accuracy: 0.7462 - val_loss: 0.5840 - val_accuracy: 0.7370
Epoch 22/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5651 - accuracy: 0.7475 - val_loss: 0.5840 - val_accuracy: 0.7370
Epoch 23/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5633 - accuracy: 0.7491 - val_loss: 0.5839 - val_accuracy: 0.7370
Epoch 24/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5614 - accuracy: 0.7509 - val_loss: 0.5839 - val_accuracy: 0.7370
Epoch 25/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5675 - accuracy: 0.7453 - val_loss: 0.5840 - val_accuracy: 0.7370
Epoch 26/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5644 - accuracy: 0.7482 - val_loss: 0.5840 - val_accuracy: 0.7370
Epoch 27/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5689 - accuracy: 0.7440 - val_loss: 0.5840 - val_accuracy: 0.7370
Epoch 28/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5654 - accuracy: 0.7472 - val_loss: 0.5840 - val_accuracy: 0.7370
Epoch 29/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5670 - accuracy: 0.7457 - val_loss: 0.5840 - val_accuracy: 0.7370
Epoch 30/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5736 - accuracy: 0.7396 - val_loss: 0.5840 - val_accuracy: 0.7370
Epoch 31/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5664 - accuracy: 0.7463 - val_loss: 0.5840 - val_accuracy: 0.7370
Epoch 32/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5688 - accuracy: 0.7440 - val_loss: 0.5840 - val_accuracy: 0.7370
Epoch 33/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5576 - accuracy: 0.7543 - val_loss: 0.5839 - val_accuracy: 0.7370
Epoch 34/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5572 - accuracy: 0.7548 - val_loss: 0.5839 - val_accuracy: 0.7370
Epoch 35/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5634 - accuracy: 0.7491 - val_loss: 0.5839 - val_accuracy: 0.7370
Epoch 36/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5717 - accuracy: 0.7413 - val_loss: 0.5840 - val_accuracy: 0.7370
Epoch 37/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5657 - accuracy: 0.7469 - val_loss: 0.5840 - val_accuracy: 0.7370
Epoch 38/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5664 - accuracy: 0.7463 - val_loss: 0.5840 - val_accuracy: 0.7370
Epoch 39/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5639 - accuracy: 0.7486 - val_loss: 0.5839 - val_accuracy: 0.7370
Epoch 40/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5659 - accuracy: 0.7467 - val_loss: 0.5839 - val_accuracy: 0.7370
Epoch 41/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5711 - accuracy: 0.7420 - val_loss: 0.5840 - val_accuracy: 0.7370
Epoch 42/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5642 - accuracy: 0.7483 - val_loss: 0.5840 - val_accuracy: 0.7370
Epoch 43/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5651 - accuracy: 0.7475 - val_loss: 0.5840 - val_accuracy: 0.7370
Epoch 44/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5653 - accuracy: 0.7473 - val_loss: 0.5840 - val_accuracy: 0.7370
Epoch 45/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5619 - accuracy: 0.7504 - val_loss: 0.5839 - val_accuracy: 0.7370
Epoch 46/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5642 - accuracy: 0.7483 - val_loss: 0.5840 - val_accuracy: 0.7370
Epoch 47/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5638 - accuracy: 0.7487 - val_loss: 0.5839 - val_accuracy: 0.7370
Epoch 48/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5675 - accuracy: 0.7452 - val_loss: 0.5840 - val_accuracy: 0.7370
Epoch 49/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5677 - accuracy: 0.7451 - val_loss: 0.5840 - val_accuracy: 0.7370
Epoch 50/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5642 - accuracy: 0.7483 - val_loss: 0.5840 - val_accuracy: 0.7370
Epoch 51/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5656 - accuracy: 0.7470 - val_loss: 0.5840 - val_accuracy: 0.7370
Epoch 52/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5654 - accuracy: 0.7472 - val_loss: 0.5840 - val_accuracy: 0.7370
Epoch 53/100
338/338 [==============================] - 1s 1ms/step - loss: 0.5656 - accuracy: 0.7470 - val_loss: 0.5840 - val_accuracy: 0.7370
Epoch 54/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5665 - accuracy: 0.7462 - val_loss: 0.5840 - val_accuracy: 0.7370
Epoch 55/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5694 - accuracy: 0.7435 - val_loss: 0.5840 - val_accuracy: 0.7370
Epoch 56/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5689 - accuracy: 0.7440 - val_loss: 0.5840 - val_accuracy: 0.7370
Epoch 57/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5655 - accuracy: 0.7471 - val_loss: 0.5840 - val_accuracy: 0.7370
Epoch 58/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5628 - accuracy: 0.7496 - val_loss: 0.5840 - val_accuracy: 0.7370
Epoch 59/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5699 - accuracy: 0.7431 - val_loss: 0.5840 - val_accuracy: 0.7370
Epoch 60/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5691 - accuracy: 0.7437 - val_loss: 0.5840 - val_accuracy: 0.7370
Epoch 61/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5645 - accuracy: 0.7481 - val_loss: 0.5840 - val_accuracy: 0.7370
Epoch 62/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5637 - accuracy: 0.7488 - val_loss: 0.5840 - val_accuracy: 0.7370
Epoch 63/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5680 - accuracy: 0.7448 - val_loss: 0.5840 - val_accuracy: 0.7370
Epoch 64/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5714 - accuracy: 0.7417 - val_loss: 0.5841 - val_accuracy: 0.7370
Epoch 65/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5657 - accuracy: 0.7469 - val_loss: 0.5840 - val_accuracy: 0.7370
Epoch 66/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5657 - accuracy: 0.7469 - val_loss: 0.5840 - val_accuracy: 0.7370
Epoch 67/100
338/338 [==============================] - 1s 1ms/step - loss: 0.5672 - accuracy: 0.7456 - val_loss: 0.5840 - val_accuracy: 0.7370
Epoch 68/100
338/338 [==============================] - 1s 1ms/step - loss: 0.5656 - accuracy: 0.7470 - val_loss: 0.5840 - val_accuracy: 0.7370
Epoch 69/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5619 - accuracy: 0.7504 - val_loss: 0.5840 - val_accuracy: 0.7370
Epoch 70/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5662 - accuracy: 0.7465 - val_loss: 0.5840 - val_accuracy: 0.7370
Epoch 71/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5643 - accuracy: 0.7483 - val_loss: 0.5839 - val_accuracy: 0.7370
Epoch 72/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5712 - accuracy: 0.7418 - val_loss: 0.5840 - val_accuracy: 0.7370
Epoch 73/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5663 - accuracy: 0.7464 - val_loss: 0.5840 - val_accuracy: 0.7370
Epoch 74/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5620 - accuracy: 0.7503 - val_loss: 0.5840 - val_accuracy: 0.7370
Epoch 75/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5667 - accuracy: 0.7460 - val_loss: 0.5840 - val_accuracy: 0.7370
Epoch 76/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5676 - accuracy: 0.7452 - val_loss: 0.5840 - val_accuracy: 0.7370
Epoch 77/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5666 - accuracy: 0.7461 - val_loss: 0.5840 - val_accuracy: 0.7370
Epoch 78/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5661 - accuracy: 0.7465 - val_loss: 0.5840 - val_accuracy: 0.7370
Epoch 79/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5683 - accuracy: 0.7445 - val_loss: 0.5840 - val_accuracy: 0.7370
Epoch 80/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5700 - accuracy: 0.7429 - val_loss: 0.5840 - val_accuracy: 0.7370
Epoch 81/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5662 - accuracy: 0.7465 - val_loss: 0.5840 - val_accuracy: 0.7370
Epoch 82/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5659 - accuracy: 0.7467 - val_loss: 0.5840 - val_accuracy: 0.7370
Epoch 83/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5655 - accuracy: 0.7471 - val_loss: 0.5840 - val_accuracy: 0.7370
Epoch 84/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5628 - accuracy: 0.7497 - val_loss: 0.5839 - val_accuracy: 0.7370
Epoch 85/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5644 - accuracy: 0.7482 - val_loss: 0.5839 - val_accuracy: 0.7370
Epoch 86/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5663 - accuracy: 0.7464 - val_loss: 0.5839 - val_accuracy: 0.7370
Epoch 87/100
338/338 [==============================] - 1s 1ms/step - loss: 0.5621 - accuracy: 0.7503 - val_loss: 0.5839 - val_accuracy: 0.7370
Epoch 88/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5667 - accuracy: 0.7460 - val_loss: 0.5840 - val_accuracy: 0.7370
Epoch 89/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5678 - accuracy: 0.7450 - val_loss: 0.5840 - val_accuracy: 0.7370
Epoch 90/100
338/338 [==============================] - 1s 1ms/step - loss: 0.5657 - accuracy: 0.7469 - val_loss: 0.5840 - val_accuracy: 0.7370
Epoch 91/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5645 - accuracy: 0.7481 - val_loss: 0.5840 - val_accuracy: 0.7370
Epoch 92/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5679 - accuracy: 0.7449 - val_loss: 0.5840 - val_accuracy: 0.7370
Epoch 93/100
338/338 [==============================] - 1s 1ms/step - loss: 0.5665 - accuracy: 0.7462 - val_loss: 0.5840 - val_accuracy: 0.7370
Epoch 94/100
338/338 [==============================] - 1s 1ms/step - loss: 0.5692 - accuracy: 0.7437 - val_loss: 0.5840 - val_accuracy: 0.7370
Epoch 95/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5638 - accuracy: 0.7487 - val_loss: 0.5840 - val_accuracy: 0.7370
Epoch 96/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5670 - accuracy: 0.7458 - val_loss: 0.5840 - val_accuracy: 0.7370
Epoch 97/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5649 - accuracy: 0.7476 - val_loss: 0.5839 - val_accuracy: 0.7370
Epoch 98/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5659 - accuracy: 0.7467 - val_loss: 0.5840 - val_accuracy: 0.7370
Epoch 99/100
338/338 [==============================] - 1s 1ms/step - loss: 0.5669 - accuracy: 0.7458 - val_loss: 0.5840 - val_accuracy: 0.7370
Epoch 100/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5606 - accuracy: 0.7517 - val_loss: 0.5839 - val_accuracy: 0.7370
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[83]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_accuracy&#39;</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;model accuracy&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;accuracy&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;epoch&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s1">&#39;train&#39;</span><span class="p">,</span> <span class="s1">&#39;test&#39;</span><span class="p">],</span> <span class="n">loc</span><span class="o">=</span><span class="s1">&#39;upper left&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedImage jp-OutputArea-output ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[84]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;model loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;epoch&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s1">&#39;train&#39;</span><span class="p">,</span> <span class="s1">&#39;test&#39;</span><span class="p">],</span> <span class="n">loc</span><span class="o">=</span><span class="s1">&#39;upper left&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedImage jp-OutputArea-output ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[85]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_parquet</span><span class="p">(</span><span class="n">DATA_DIR</span><span class="p">,</span> <span class="n">engine</span><span class="o">=</span><span class="s2">&quot;pyarrow&quot;</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s2">&quot;birth_year&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;birth_year&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">uint</span><span class="p">)</span>
<span class="n">valid_birth_year</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;birth_year&quot;</span><span class="p">][</span><span class="n">df</span><span class="p">[</span><span class="s2">&quot;birth_year&quot;</span><span class="p">]</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">]</span>
<span class="n">mean_birth_year</span> <span class="o">=</span> <span class="nb">round</span><span class="p">(</span><span class="n">valid_birth_year</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>
<span class="n">df</span><span class="p">[</span><span class="s2">&quot;birth_year&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;birth_year&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">mean_birth_year</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s2">&quot;gender&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;gender&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">({</span><span class="s1">&#39;M&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;F&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">})</span>
<span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;birth_year&#39;</span><span class="p">,</span> <span class="s1">&#39;queries&#39;</span><span class="p">],</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt">Out[85]:</div>



<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/html">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>apps</th>
      <th>games</th>
      <th>gender</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>[4, 4, 25, 7, 30, 58, 16, 19, 17, 21, 10, 10, ...</td>
      <td>[9151, 208]</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>[129, 71, 9, 8, 11, 25, 18, 58, 6, 16, 125, 12...</td>
      <td>[460, 4939, 14, 232, 6387, 1758, 5834, 3, 2]</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>[9, 174, 65, 8, 63, 97, 62, 103, 61, 116, 59, ...</td>
      <td>[448, 723, 267, 9064, 10634, 166, 782, 224, 27...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>[99, 73, 9, 8, 59, 37, 131, 3, 89, 6, 24, 16, ...</td>
      <td>[78, 2607, 478, 435, 9, 192]</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>[9, 8, 17, 54, 3, 25, 22, 6, 21, 7, 14, 5, 817...</td>
      <td>[1702, 1, 53]</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[86]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">df</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">&#39;apps&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">),</span> <span class="n">df</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">df</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">&#39;games&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">),</span> <span class="n">df</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span>  <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;gender&quot;</span><span class="p">]),</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;gender&quot;</span><span class="p">]</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[88]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">input_dim</span><span class="o">=</span><span class="mi">834</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">60</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">45</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">30</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">))</span>

<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;binary_crossentropy&#39;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;adam&#39;</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[89]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">ohe</span> <span class="o">=</span> <span class="n">OneHotEncoder</span><span class="p">()</span>

<span class="n">y_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">y_train</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">y_test</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>

<span class="n">y_train</span> <span class="o">=</span> <span class="n">ohe</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">y_train</span><span class="p">)</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">ohe</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">y_test</span><span class="p">)</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[90]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">validation_split</span><span class="o">=</span><span class="mf">0.33</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Epoch 1/100
338/338 [==============================] - 2s 2ms/step - loss: 28.8057 - accuracy: 0.6787 - val_loss: 0.9474 - val_accuracy: 0.7367
Epoch 2/100
338/338 [==============================] - 0s 1ms/step - loss: 0.7826 - accuracy: 0.7343 - val_loss: 0.6396 - val_accuracy: 0.7371
Epoch 3/100
338/338 [==============================] - 1s 2ms/step - loss: 0.7634 - accuracy: 0.7271 - val_loss: 0.7065 - val_accuracy: 0.7369
Epoch 4/100
338/338 [==============================] - 1s 2ms/step - loss: 0.6757 - accuracy: 0.7304 - val_loss: 0.6433 - val_accuracy: 0.7369
Epoch 5/100
338/338 [==============================] - 0s 1ms/step - loss: 0.6375 - accuracy: 0.7367 - val_loss: 0.7294 - val_accuracy: 0.7369
Epoch 6/100
338/338 [==============================] - 0s 1ms/step - loss: 0.6136 - accuracy: 0.7345 - val_loss: 0.5884 - val_accuracy: 0.7366
Epoch 7/100
338/338 [==============================] - 1s 2ms/step - loss: 0.6386 - accuracy: 0.7371 - val_loss: 0.6286 - val_accuracy: 0.7370
Epoch 8/100
338/338 [==============================] - 1s 1ms/step - loss: 0.6176 - accuracy: 0.7410 - val_loss: 0.6603 - val_accuracy: 0.6810
Epoch 9/100
338/338 [==============================] - 0s 1ms/step - loss: 0.6648 - accuracy: 0.7324 - val_loss: 0.6140 - val_accuracy: 0.7255
Epoch 10/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5806 - accuracy: 0.7411 - val_loss: 1.0220 - val_accuracy: 0.5456
Epoch 11/100
338/338 [==============================] - 1s 2ms/step - loss: 0.6374 - accuracy: 0.7344 - val_loss: 0.6814 - val_accuracy: 0.7369
Epoch 12/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5931 - accuracy: 0.7449 - val_loss: 0.5968 - val_accuracy: 0.7314
Epoch 13/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5811 - accuracy: 0.7423 - val_loss: 0.6049 - val_accuracy: 0.7149
Epoch 14/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5807 - accuracy: 0.7418 - val_loss: 0.6300 - val_accuracy: 0.7369
Epoch 15/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5794 - accuracy: 0.7447 - val_loss: 1.4932 - val_accuracy: 0.6118
Epoch 16/100
338/338 [==============================] - 0s 1ms/step - loss: 0.6762 - accuracy: 0.7344 - val_loss: 0.5778 - val_accuracy: 0.7369
Epoch 17/100
338/338 [==============================] - 1s 1ms/step - loss: 0.5970 - accuracy: 0.7453 - val_loss: 0.5764 - val_accuracy: 0.7370
Epoch 18/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5726 - accuracy: 0.7407 - val_loss: 0.5766 - val_accuracy: 0.7370
Epoch 19/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5696 - accuracy: 0.7433 - val_loss: 0.5765 - val_accuracy: 0.7370
Epoch 20/100
338/338 [==============================] - 1s 1ms/step - loss: 0.5664 - accuracy: 0.7463 - val_loss: 0.5764 - val_accuracy: 0.7370
Epoch 21/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5630 - accuracy: 0.7493 - val_loss: 0.5764 - val_accuracy: 0.7370
Epoch 22/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5702 - accuracy: 0.7428 - val_loss: 0.5766 - val_accuracy: 0.7370
Epoch 23/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5688 - accuracy: 0.7443 - val_loss: 0.5766 - val_accuracy: 0.7369
Epoch 24/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5702 - accuracy: 0.7429 - val_loss: 0.5765 - val_accuracy: 0.7370
Epoch 25/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5673 - accuracy: 0.7455 - val_loss: 0.5765 - val_accuracy: 0.7369
Epoch 26/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5682 - accuracy: 0.7446 - val_loss: 0.5764 - val_accuracy: 0.7370
Epoch 27/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5624 - accuracy: 0.7508 - val_loss: 0.5763 - val_accuracy: 0.7370
Epoch 28/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5637 - accuracy: 0.7488 - val_loss: 0.5767 - val_accuracy: 0.7368
Epoch 29/100
338/338 [==============================] - 1s 1ms/step - loss: 0.5636 - accuracy: 0.7490 - val_loss: 0.5763 - val_accuracy: 0.7370
Epoch 30/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5677 - accuracy: 0.7451 - val_loss: 0.5765 - val_accuracy: 0.7370
Epoch 31/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5655 - accuracy: 0.7471 - val_loss: 0.5764 - val_accuracy: 0.7370
Epoch 32/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5666 - accuracy: 0.7461 - val_loss: 0.5764 - val_accuracy: 0.7370
Epoch 33/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5697 - accuracy: 0.7432 - val_loss: 0.5765 - val_accuracy: 0.7370
Epoch 34/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5670 - accuracy: 0.7458 - val_loss: 0.5765 - val_accuracy: 0.7370
Epoch 35/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5665 - accuracy: 0.7462 - val_loss: 0.5763 - val_accuracy: 0.7370
Epoch 36/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5652 - accuracy: 0.7474 - val_loss: 0.5763 - val_accuracy: 0.7370
Epoch 37/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5641 - accuracy: 0.7484 - val_loss: 0.5763 - val_accuracy: 0.7370
Epoch 38/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5637 - accuracy: 0.7488 - val_loss: 0.5763 - val_accuracy: 0.7370
Epoch 39/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5667 - accuracy: 0.7460 - val_loss: 0.5764 - val_accuracy: 0.7370
Epoch 40/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5624 - accuracy: 0.7500 - val_loss: 0.5763 - val_accuracy: 0.7370
Epoch 41/100
338/338 [==============================] - 1s 1ms/step - loss: 0.5685 - accuracy: 0.7444 - val_loss: 0.5767 - val_accuracy: 0.7370
Epoch 42/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5633 - accuracy: 0.7492 - val_loss: 0.5764 - val_accuracy: 0.7370
Epoch 43/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5657 - accuracy: 0.7469 - val_loss: 0.5762 - val_accuracy: 0.7370
Epoch 44/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5664 - accuracy: 0.7462 - val_loss: 0.5764 - val_accuracy: 0.7370
Epoch 45/100
338/338 [==============================] - 1s 1ms/step - loss: 0.5696 - accuracy: 0.7433 - val_loss: 0.5767 - val_accuracy: 0.7370
Epoch 46/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5640 - accuracy: 0.7485 - val_loss: 0.5763 - val_accuracy: 0.7370
Epoch 47/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5740 - accuracy: 0.7391 - val_loss: 0.5768 - val_accuracy: 0.7370
Epoch 48/100
338/338 [==============================] - 1s 1ms/step - loss: 0.5657 - accuracy: 0.7469 - val_loss: 0.5764 - val_accuracy: 0.7370
Epoch 49/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5680 - accuracy: 0.7447 - val_loss: 0.5763 - val_accuracy: 0.7370
Epoch 50/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5620 - accuracy: 0.7505 - val_loss: 0.5763 - val_accuracy: 0.7370
Epoch 51/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5663 - accuracy: 0.7464 - val_loss: 0.5765 - val_accuracy: 0.7370
Epoch 52/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5668 - accuracy: 0.7459 - val_loss: 0.5764 - val_accuracy: 0.7370
Epoch 53/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5700 - accuracy: 0.7430 - val_loss: 0.5764 - val_accuracy: 0.7370
Epoch 54/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5686 - accuracy: 0.7442 - val_loss: 0.5765 - val_accuracy: 0.7370
Epoch 55/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5644 - accuracy: 0.7482 - val_loss: 0.5764 - val_accuracy: 0.7370
Epoch 56/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5640 - accuracy: 0.7485 - val_loss: 0.5762 - val_accuracy: 0.7370
Epoch 57/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5642 - accuracy: 0.7484 - val_loss: 0.5763 - val_accuracy: 0.7370
Epoch 58/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5723 - accuracy: 0.7408 - val_loss: 0.5765 - val_accuracy: 0.7370
Epoch 59/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5660 - accuracy: 0.7468 - val_loss: 0.5763 - val_accuracy: 0.7370
Epoch 60/100
338/338 [==============================] - 1s 1ms/step - loss: 0.5642 - accuracy: 0.7484 - val_loss: 0.5763 - val_accuracy: 0.7370
Epoch 61/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5711 - accuracy: 0.7418 - val_loss: 0.5769 - val_accuracy: 0.7370
Epoch 62/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5686 - accuracy: 0.7444 - val_loss: 0.5765 - val_accuracy: 0.7370
Epoch 63/100
338/338 [==============================] - 1s 1ms/step - loss: 0.5630 - accuracy: 0.7494 - val_loss: 0.5763 - val_accuracy: 0.7370
Epoch 64/100
338/338 [==============================] - 1s 1ms/step - loss: 0.5651 - accuracy: 0.7475 - val_loss: 0.5763 - val_accuracy: 0.7370
Epoch 65/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5699 - accuracy: 0.7430 - val_loss: 0.5765 - val_accuracy: 0.7370
Epoch 66/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5657 - accuracy: 0.7469 - val_loss: 0.5764 - val_accuracy: 0.7370
Epoch 67/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5677 - accuracy: 0.7451 - val_loss: 0.5764 - val_accuracy: 0.7370
Epoch 68/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5656 - accuracy: 0.7477 - val_loss: 0.6131 - val_accuracy: 0.7365
Epoch 69/100
338/338 [==============================] - 1s 1ms/step - loss: 0.5736 - accuracy: 0.7476 - val_loss: 0.5763 - val_accuracy: 0.7370
Epoch 70/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5631 - accuracy: 0.7494 - val_loss: 0.5762 - val_accuracy: 0.7370
Epoch 71/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5642 - accuracy: 0.7484 - val_loss: 0.5763 - val_accuracy: 0.7370
Epoch 72/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5622 - accuracy: 0.7502 - val_loss: 0.5763 - val_accuracy: 0.7370
Epoch 73/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5672 - accuracy: 0.7456 - val_loss: 0.5765 - val_accuracy: 0.7370
Epoch 74/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5686 - accuracy: 0.7442 - val_loss: 0.5766 - val_accuracy: 0.7370
Epoch 75/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5626 - accuracy: 0.7498 - val_loss: 0.5762 - val_accuracy: 0.7370
Epoch 76/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5691 - accuracy: 0.7438 - val_loss: 0.5764 - val_accuracy: 0.7370
Epoch 77/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5710 - accuracy: 0.7421 - val_loss: 0.5764 - val_accuracy: 0.7370
Epoch 78/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5632 - accuracy: 0.7492 - val_loss: 0.5763 - val_accuracy: 0.7370
Epoch 79/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5650 - accuracy: 0.7477 - val_loss: 0.5763 - val_accuracy: 0.7370
Epoch 80/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5704 - accuracy: 0.7426 - val_loss: 0.5766 - val_accuracy: 0.7370
Epoch 81/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5681 - accuracy: 0.7448 - val_loss: 0.5763 - val_accuracy: 0.7370
Epoch 82/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5673 - accuracy: 0.7454 - val_loss: 0.5763 - val_accuracy: 0.7370
Epoch 83/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5639 - accuracy: 0.7485 - val_loss: 0.5762 - val_accuracy: 0.7370
Epoch 84/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5651 - accuracy: 0.7475 - val_loss: 0.5764 - val_accuracy: 0.7370
Epoch 85/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5645 - accuracy: 0.7481 - val_loss: 0.5763 - val_accuracy: 0.7370
Epoch 86/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5663 - accuracy: 0.7464 - val_loss: 0.5764 - val_accuracy: 0.7370
Epoch 87/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5668 - accuracy: 0.7460 - val_loss: 0.5767 - val_accuracy: 0.7370
Epoch 88/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5764 - val_accuracy: 0.7370
Epoch 89/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5760 - accuracy: 0.7472 - val_loss: 0.5763 - val_accuracy: 0.7370
Epoch 90/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5683 - accuracy: 0.7445 - val_loss: 0.5764 - val_accuracy: 0.7370
Epoch 91/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5687 - accuracy: 0.7442 - val_loss: 0.5767 - val_accuracy: 0.7370
Epoch 92/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5676 - accuracy: 0.7452 - val_loss: 0.5764 - val_accuracy: 0.7370
Epoch 93/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5656 - accuracy: 0.7470 - val_loss: 0.5763 - val_accuracy: 0.7370
Epoch 94/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5737 - accuracy: 0.7395 - val_loss: 0.5766 - val_accuracy: 0.7370
Epoch 95/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5614 - accuracy: 0.7509 - val_loss: 0.5763 - val_accuracy: 0.7370
Epoch 96/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5705 - accuracy: 0.7424 - val_loss: 0.5766 - val_accuracy: 0.7370
Epoch 97/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5630 - accuracy: 0.7494 - val_loss: 0.5764 - val_accuracy: 0.7370
Epoch 98/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5658 - accuracy: 0.7469 - val_loss: 0.5763 - val_accuracy: 0.7370
Epoch 99/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5655 - accuracy: 0.7471 - val_loss: 0.5765 - val_accuracy: 0.7370
Epoch 100/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5640 - accuracy: 0.7485 - val_loss: 0.5764 - val_accuracy: 0.7370
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[91]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_accuracy&#39;</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;model accuracy&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;accuracy&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;epoch&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s1">&#39;train&#39;</span><span class="p">,</span> <span class="s1">&#39;test&#39;</span><span class="p">],</span> <span class="n">loc</span><span class="o">=</span><span class="s1">&#39;upper left&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedImage jp-OutputArea-output ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[92]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;model loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;epoch&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s1">&#39;train&#39;</span><span class="p">,</span> <span class="s1">&#39;test&#39;</span><span class="p">],</span> <span class="n">loc</span><span class="o">=</span><span class="s1">&#39;upper left&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedImage jp-OutputArea-output ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[93]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">X_train</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt">Out[93]:</div>



<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/html">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
      <th>1</th>
      <th>2</th>
      <th>3</th>
      <th>4</th>
      <th>5</th>
      <th>6</th>
      <th>7</th>
      <th>8</th>
      <th>9</th>
      <th>...</th>
      <th>411</th>
      <th>412</th>
      <th>413</th>
      <th>414</th>
      <th>415</th>
      <th>416</th>
      <th>417</th>
      <th>418</th>
      <th>419</th>
      <th>420</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>9391</th>
      <td>336.0</td>
      <td>822.0</td>
      <td>14.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>36089</th>
      <td>1.0</td>
      <td>145.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>38820</th>
      <td>78.0</td>
      <td>11.0</td>
      <td>122.0</td>
      <td>113.0</td>
      <td>192.0</td>
      <td>2726.0</td>
      <td>34.0</td>
      <td>44.0</td>
      <td>17.0</td>
      <td>4.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>33815</th>
      <td>771.0</td>
      <td>3198.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>31187</th>
      <td>689.0</td>
      <td>45.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>6265</th>
      <td>23.0</td>
      <td>947.0</td>
      <td>35.0</td>
      <td>435.0</td>
      <td>1327.0</td>
      <td>2694.0</td>
      <td>2.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>11284</th>
      <td>64.0</td>
      <td>361.0</td>
      <td>2093.0</td>
      <td>2708.0</td>
      <td>1228.0</td>
      <td>318.0</td>
      <td>711.0</td>
      <td>1844.0</td>
      <td>2392.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>38158</th>
      <td>35.0</td>
      <td>4697.0</td>
      <td>3.0</td>
      <td>47.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>860</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>15795</th>
      <td>2.0</td>
      <td>889.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
  </tbody>
</table>
<p>32216 rows  834 columns</p>
</div>
</div>

</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[94]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">preprocessing</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">values</span>
<span class="n">min_max_scaler</span> <span class="o">=</span> <span class="n">preprocessing</span><span class="o">.</span><span class="n">MinMaxScaler</span><span class="p">()</span>
<span class="n">x_scaled</span> <span class="o">=</span> <span class="n">min_max_scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">x_scaled</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt">Out[94]:</div>



<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/html">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
      <th>1</th>
      <th>2</th>
      <th>3</th>
      <th>4</th>
      <th>5</th>
      <th>6</th>
      <th>7</th>
      <th>8</th>
      <th>9</th>
      <th>...</th>
      <th>825</th>
      <th>826</th>
      <th>827</th>
      <th>828</th>
      <th>829</th>
      <th>830</th>
      <th>831</th>
      <th>832</th>
      <th>833</th>
      <th>834</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.184073</td>
      <td>0.004199</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.009253</td>
      <td>0.099703</td>
      <td>0.000280</td>
      <td>0.004739</td>
      <td>0.130517</td>
      <td>0.035448</td>
      <td>0.124714</td>
      <td>0.000060</td>
      <td>0.000040</td>
      <td>0.000000</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.009012</td>
      <td>0.014595</td>
      <td>0.005346</td>
      <td>0.185161</td>
      <td>0.217304</td>
      <td>0.003347</td>
      <td>0.016717</td>
      <td>0.004492</td>
      <td>0.005472</td>
      <td>0.082066</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.001569</td>
      <td>0.052627</td>
      <td>0.009570</td>
      <td>0.008886</td>
      <td>0.000184</td>
      <td>0.003871</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.034236</td>
      <td>0.000020</td>
      <td>0.001061</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
    </tr>
  </tbody>
</table>
<p>5 rows  835 columns</p>
</div>
</div>

</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[95]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">input_dim</span><span class="o">=</span><span class="mi">834</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">60</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">45</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">30</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">))</span>

<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;binary_crossentropy&#39;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;adam&#39;</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[96]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">ohe</span> <span class="o">=</span> <span class="n">OneHotEncoder</span><span class="p">()</span>

<span class="n">y_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">y_train</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">y_test</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>

<span class="n">y_train</span> <span class="o">=</span> <span class="n">ohe</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">y_train</span><span class="p">)</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">ohe</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">y_test</span><span class="p">)</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[97]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">validation_split</span><span class="o">=</span><span class="mf">0.33</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Epoch 1/100
338/338 [==============================] - 2s 2ms/step - loss: 5.5669 - accuracy: 0.4944 - val_loss: 0.7017 - val_accuracy: 0.5006
Epoch 2/100
338/338 [==============================] - 0s 1ms/step - loss: 0.6940 - accuracy: 0.5091 - val_loss: 0.6960 - val_accuracy: 0.5001
Epoch 3/100
338/338 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.4909 - val_loss: 0.6961 - val_accuracy: 0.4999
Epoch 4/100
338/338 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5028 - val_loss: 0.6959 - val_accuracy: 0.5001
Epoch 5/100
338/338 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.4974 - val_loss: 0.6951 - val_accuracy: 0.4999
Epoch 6/100
338/338 [==============================] - 0s 1ms/step - loss: 0.6937 - accuracy: 0.4955 - val_loss: 0.6984 - val_accuracy: 0.4999
Epoch 7/100
338/338 [==============================] - 1s 1ms/step - loss: 0.6930 - accuracy: 0.5008 - val_loss: 0.6986 - val_accuracy: 0.5000
Epoch 8/100
338/338 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.4978 - val_loss: 0.7126 - val_accuracy: 0.4998
Epoch 9/100
338/338 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.4986 - val_loss: 0.7127 - val_accuracy: 0.5002
Epoch 10/100
338/338 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5004 - val_loss: 0.7126 - val_accuracy: 0.5001
Epoch 11/100
338/338 [==============================] - 0s 1ms/step - loss: 0.6930 - accuracy: 0.4994 - val_loss: 0.7110 - val_accuracy: 0.5001
Epoch 12/100
338/338 [==============================] - 1s 2ms/step - loss: 0.6929 - accuracy: 0.4948 - val_loss: 0.7149 - val_accuracy: 0.5001
Epoch 13/100
338/338 [==============================] - 1s 2ms/step - loss: 0.6931 - accuracy: 0.5009 - val_loss: 0.7183 - val_accuracy: 0.4998
Epoch 14/100
338/338 [==============================] - 0s 1ms/step - loss: 0.6930 - accuracy: 0.4956 - val_loss: 0.7045 - val_accuracy: 0.4999
Epoch 15/100
338/338 [==============================] - 1s 2ms/step - loss: 0.6929 - accuracy: 0.4952 - val_loss: 0.6931 - val_accuracy: 0.5000
Epoch 16/100
338/338 [==============================] - 1s 2ms/step - loss: 0.6930 - accuracy: 0.5042 - val_loss: 0.6931 - val_accuracy: 0.5002
Epoch 17/100
338/338 [==============================] - 1s 2ms/step - loss: 0.6930 - accuracy: 0.4992 - val_loss: 0.6961 - val_accuracy: 0.5000
Epoch 18/100
338/338 [==============================] - 1s 2ms/step - loss: 0.6932 - accuracy: 0.5020 - val_loss: 0.6961 - val_accuracy: 0.5000
Epoch 19/100
338/338 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5064 - val_loss: 0.6961 - val_accuracy: 0.4999
Epoch 20/100
338/338 [==============================] - 1s 2ms/step - loss: 0.6932 - accuracy: 0.5023 - val_loss: 0.6961 - val_accuracy: 0.5000
Epoch 21/100
338/338 [==============================] - 1s 1ms/step - loss: 0.6932 - accuracy: 0.5021 - val_loss: 0.6961 - val_accuracy: 0.4999
Epoch 22/100
338/338 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.4905 - val_loss: 0.6961 - val_accuracy: 0.4999
Epoch 23/100
338/338 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.4987 - val_loss: 0.6961 - val_accuracy: 0.4999
Epoch 24/100
338/338 [==============================] - 1s 2ms/step - loss: 0.6932 - accuracy: 0.4929 - val_loss: 0.6961 - val_accuracy: 0.4999
Epoch 25/100
338/338 [==============================] - 1s 1ms/step - loss: 0.6931 - accuracy: 0.5060 - val_loss: 0.6961 - val_accuracy: 0.5000
Epoch 26/100
338/338 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5028 - val_loss: 0.6961 - val_accuracy: 0.4999
Epoch 27/100
338/338 [==============================] - 1s 1ms/step - loss: 0.6932 - accuracy: 0.4939 - val_loss: 0.6961 - val_accuracy: 0.4999
Epoch 28/100
338/338 [==============================] - 1s 1ms/step - loss: 0.6932 - accuracy: 0.5048 - val_loss: 0.6961 - val_accuracy: 0.5000
Epoch 29/100
338/338 [==============================] - 1s 2ms/step - loss: 0.6932 - accuracy: 0.5012 - val_loss: 0.6961 - val_accuracy: 0.4999
Epoch 30/100
338/338 [==============================] - 1s 1ms/step - loss: 0.6932 - accuracy: 0.5023 - val_loss: 0.6961 - val_accuracy: 0.4999
Epoch 31/100
338/338 [==============================] - 1s 2ms/step - loss: 0.6932 - accuracy: 0.5021 - val_loss: 0.6961 - val_accuracy: 0.5000
Epoch 32/100
338/338 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.4950 - val_loss: 0.6961 - val_accuracy: 0.5000
Epoch 33/100
338/338 [==============================] - 1s 1ms/step - loss: 0.6932 - accuracy: 0.5015 - val_loss: 0.6961 - val_accuracy: 0.4999
Epoch 34/100
338/338 [==============================] - 1s 1ms/step - loss: 0.6932 - accuracy: 0.4935 - val_loss: 0.6961 - val_accuracy: 0.4999
Epoch 35/100
338/338 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.4956 - val_loss: 0.6961 - val_accuracy: 0.5000
Epoch 36/100
338/338 [==============================] - 1s 2ms/step - loss: 0.6932 - accuracy: 0.4973 - val_loss: 0.6961 - val_accuracy: 0.4999
Epoch 37/100
338/338 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5010 - val_loss: 0.6961 - val_accuracy: 0.4999
Epoch 38/100
338/338 [==============================] - 1s 2ms/step - loss: 0.6932 - accuracy: 0.4947 - val_loss: 0.6961 - val_accuracy: 0.4999
Epoch 39/100
338/338 [==============================] - 1s 1ms/step - loss: 0.6932 - accuracy: 0.5019 - val_loss: 0.6961 - val_accuracy: 0.5000
Epoch 40/100
338/338 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5004 - val_loss: 0.6961 - val_accuracy: 0.5000
Epoch 41/100
338/338 [==============================] - 1s 1ms/step - loss: 0.6932 - accuracy: 0.5003 - val_loss: 0.6961 - val_accuracy: 0.5000
Epoch 42/100
338/338 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.4955 - val_loss: 0.6961 - val_accuracy: 0.4999
Epoch 43/100
338/338 [==============================] - 1s 2ms/step - loss: 0.6932 - accuracy: 0.5008 - val_loss: 0.6961 - val_accuracy: 0.4999
Epoch 44/100
338/338 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.4972 - val_loss: 0.6961 - val_accuracy: 0.4999
Epoch 45/100
338/338 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.4844 - val_loss: 0.6961 - val_accuracy: 0.4999
Epoch 46/100
338/338 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.4935 - val_loss: 0.6961 - val_accuracy: 0.4999
Epoch 47/100
338/338 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5034 - val_loss: 0.6961 - val_accuracy: 0.4999
Epoch 48/100
338/338 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5041 - val_loss: 0.6961 - val_accuracy: 0.5000
Epoch 49/100
338/338 [==============================] - 1s 2ms/step - loss: 0.6932 - accuracy: 0.4934 - val_loss: 0.6961 - val_accuracy: 0.4999
Epoch 50/100
338/338 [==============================] - 1s 2ms/step - loss: 0.6932 - accuracy: 0.5004 - val_loss: 0.6961 - val_accuracy: 0.4999
Epoch 51/100
338/338 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5029 - val_loss: 0.6961 - val_accuracy: 0.5000
Epoch 52/100
338/338 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5058 - val_loss: 0.6961 - val_accuracy: 0.4999
Epoch 53/100
338/338 [==============================] - 1s 1ms/step - loss: 0.6932 - accuracy: 0.4957 - val_loss: 0.6961 - val_accuracy: 0.4999
Epoch 54/100
338/338 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.4965 - val_loss: 0.6961 - val_accuracy: 0.4999
Epoch 55/100
338/338 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.4944 - val_loss: 0.6961 - val_accuracy: 0.5000
Epoch 56/100
338/338 [==============================] - 1s 1ms/step - loss: 0.6931 - accuracy: 0.5051 - val_loss: 0.6961 - val_accuracy: 0.4999
Epoch 57/100
338/338 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5083 - val_loss: 0.6961 - val_accuracy: 0.5000
Epoch 58/100
338/338 [==============================] - 1s 1ms/step - loss: 0.6931 - accuracy: 0.5063 - val_loss: 0.6961 - val_accuracy: 0.4999
Epoch 59/100
338/338 [==============================] - 1s 2ms/step - loss: 0.6931 - accuracy: 0.5027 - val_loss: 0.6961 - val_accuracy: 0.5000
Epoch 60/100
338/338 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.4942 - val_loss: 0.6961 - val_accuracy: 0.5000
Epoch 61/100
338/338 [==============================] - 1s 1ms/step - loss: 0.6932 - accuracy: 0.5024 - val_loss: 0.6961 - val_accuracy: 0.5000
Epoch 62/100
338/338 [==============================] - 1s 1ms/step - loss: 0.6932 - accuracy: 0.4975 - val_loss: 0.6961 - val_accuracy: 0.5000
Epoch 63/100
338/338 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.4947 - val_loss: 0.6961 - val_accuracy: 0.4999
Epoch 64/100
338/338 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.4956 - val_loss: 0.6961 - val_accuracy: 0.4999
Epoch 65/100
338/338 [==============================] - 1s 2ms/step - loss: 0.6932 - accuracy: 0.4970 - val_loss: 0.6961 - val_accuracy: 0.4999
Epoch 66/100
338/338 [==============================] - 1s 2ms/step - loss: 0.6932 - accuracy: 0.5002 - val_loss: 0.6961 - val_accuracy: 0.5000
Epoch 67/100
338/338 [==============================] - 1s 2ms/step - loss: 0.6932 - accuracy: 0.5024 - val_loss: 0.6961 - val_accuracy: 0.4999
Epoch 68/100
338/338 [==============================] - 1s 2ms/step - loss: 0.6932 - accuracy: 0.5017 - val_loss: 0.6961 - val_accuracy: 0.4999
Epoch 69/100
338/338 [==============================] - 1s 1ms/step - loss: 0.6932 - accuracy: 0.4998 - val_loss: 0.6961 - val_accuracy: 0.5000
Epoch 70/100
338/338 [==============================] - 1s 2ms/step - loss: 0.6932 - accuracy: 0.4979 - val_loss: 0.6961 - val_accuracy: 0.5000
Epoch 71/100
338/338 [==============================] - 1s 2ms/step - loss: 0.6932 - accuracy: 0.5025 - val_loss: 0.6961 - val_accuracy: 0.4999
Epoch 72/100
338/338 [==============================] - 1s 2ms/step - loss: 0.6931 - accuracy: 0.5051 - val_loss: 0.6961 - val_accuracy: 0.5000
Epoch 73/100
338/338 [==============================] - 1s 2ms/step - loss: 0.6932 - accuracy: 0.4985 - val_loss: 0.6961 - val_accuracy: 0.5000
Epoch 74/100
338/338 [==============================] - 1s 1ms/step - loss: 0.6932 - accuracy: 0.4994 - val_loss: 0.6961 - val_accuracy: 0.5000
Epoch 75/100
338/338 [==============================] - 1s 2ms/step - loss: 0.6932 - accuracy: 0.4985 - val_loss: 0.6961 - val_accuracy: 0.5000
Epoch 76/100
338/338 [==============================] - 1s 2ms/step - loss: 0.6932 - accuracy: 0.4947 - val_loss: 0.6961 - val_accuracy: 0.5000
Epoch 77/100
338/338 [==============================] - 1s 2ms/step - loss: 0.6932 - accuracy: 0.5015 - val_loss: 0.6961 - val_accuracy: 0.5000
Epoch 78/100
338/338 [==============================] - 1s 2ms/step - loss: 0.6932 - accuracy: 0.4968 - val_loss: 0.6961 - val_accuracy: 0.5000
Epoch 79/100
338/338 [==============================] - 1s 2ms/step - loss: 0.6932 - accuracy: 0.4966 - val_loss: 0.6961 - val_accuracy: 0.5000
Epoch 80/100
338/338 [==============================] - 1s 2ms/step - loss: 0.6932 - accuracy: 0.4911 - val_loss: 0.6961 - val_accuracy: 0.5000
Epoch 81/100
338/338 [==============================] - 1s 2ms/step - loss: 0.6932 - accuracy: 0.4995 - val_loss: 0.6961 - val_accuracy: 0.5000
Epoch 82/100
338/338 [==============================] - 1s 2ms/step - loss: 0.6931 - accuracy: 0.5100 - val_loss: 0.6961 - val_accuracy: 0.4999
Epoch 83/100
338/338 [==============================] - 1s 2ms/step - loss: 0.6932 - accuracy: 0.4889 - val_loss: 0.6961 - val_accuracy: 0.4999
Epoch 84/100
338/338 [==============================] - 1s 2ms/step - loss: 0.6932 - accuracy: 0.4972 - val_loss: 0.6961 - val_accuracy: 0.4999
Epoch 85/100
338/338 [==============================] - 1s 2ms/step - loss: 0.6932 - accuracy: 0.4974 - val_loss: 0.6961 - val_accuracy: 0.4999
Epoch 86/100
338/338 [==============================] - 1s 1ms/step - loss: 0.6932 - accuracy: 0.4966 - val_loss: 0.6961 - val_accuracy: 0.5000
Epoch 87/100
338/338 [==============================] - 1s 1ms/step - loss: 0.6932 - accuracy: 0.4970 - val_loss: 0.6961 - val_accuracy: 0.5000
Epoch 88/100
338/338 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.4986 - val_loss: 0.6961 - val_accuracy: 0.5000
Epoch 89/100
338/338 [==============================] - 1s 1ms/step - loss: 0.6932 - accuracy: 0.4965 - val_loss: 0.6961 - val_accuracy: 0.5000
Epoch 90/100
338/338 [==============================] - 1s 2ms/step - loss: 0.6932 - accuracy: 0.5036 - val_loss: 0.6961 - val_accuracy: 0.5000
Epoch 91/100
338/338 [==============================] - 1s 2ms/step - loss: 0.6932 - accuracy: 0.4970 - val_loss: 0.6961 - val_accuracy: 0.5000
Epoch 92/100
338/338 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5015 - val_loss: 0.6961 - val_accuracy: 0.4999
Epoch 93/100
338/338 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.4960 - val_loss: 0.6961 - val_accuracy: 0.4999
Epoch 94/100
338/338 [==============================] - 1s 2ms/step - loss: 0.6932 - accuracy: 0.4980 - val_loss: 0.6961 - val_accuracy: 0.5000
Epoch 95/100
338/338 [==============================] - 1s 2ms/step - loss: 0.6932 - accuracy: 0.5003 - val_loss: 0.6961 - val_accuracy: 0.5000
Epoch 96/100
338/338 [==============================] - 1s 1ms/step - loss: 0.6932 - accuracy: 0.5015 - val_loss: 0.6961 - val_accuracy: 0.4999
Epoch 97/100
338/338 [==============================] - 1s 2ms/step - loss: 0.6931 - accuracy: 0.5041 - val_loss: 0.6961 - val_accuracy: 0.5000
Epoch 98/100
338/338 [==============================] - 1s 2ms/step - loss: 0.6932 - accuracy: 0.4968 - val_loss: 0.6961 - val_accuracy: 0.5000
Epoch 99/100
338/338 [==============================] - 1s 2ms/step - loss: 0.6932 - accuracy: 0.4958 - val_loss: 0.6961 - val_accuracy: 0.5000
Epoch 100/100
338/338 [==============================] - 1s 2ms/step - loss: 0.6932 - accuracy: 0.4974 - val_loss: 0.6961 - val_accuracy: 0.4999
</pre>
</div>
</div>

</div>

</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>As it was expected it is not a good idea to normalize columns.</p>

</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[101]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">((</span><span class="n">X_train</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">())</span>
<span class="nb">print</span><span class="p">((</span><span class="n">X_train</span><span class="p">[</span><span class="mi">10</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">())</span>
<span class="nb">print</span><span class="p">((</span><span class="n">X_train</span><span class="p">[</span><span class="mi">100</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">())</span>
<span class="nb">print</span><span class="p">((</span><span class="n">X_train</span><span class="p">[</span><span class="mi">400</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">())</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>0    6813
0       0
dtype: int64
10    28302
10       28
dtype: int64
100    32171
100    30621
dtype: int64
400    32215
400    32215
dtype: int64
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[34]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_parquet</span><span class="p">(</span><span class="n">DATA_DIR</span><span class="p">,</span> <span class="n">engine</span><span class="o">=</span><span class="s2">&quot;pyarrow&quot;</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s2">&quot;birth_year&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;birth_year&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">uint</span><span class="p">)</span>
<span class="n">valid_birth_year</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;birth_year&quot;</span><span class="p">][</span><span class="n">df</span><span class="p">[</span><span class="s2">&quot;birth_year&quot;</span><span class="p">]</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">]</span>
<span class="n">mean_birth_year</span> <span class="o">=</span> <span class="nb">round</span><span class="p">(</span><span class="n">valid_birth_year</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>
<span class="n">df</span><span class="p">[</span><span class="s2">&quot;birth_year&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;birth_year&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">mean_birth_year</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s2">&quot;gender&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;gender&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">({</span><span class="s1">&#39;M&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;F&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">})</span>
<span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;birth_year&#39;</span><span class="p">],</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt">Out[34]:</div>



<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/html">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>queries</th>
      <th>apps</th>
      <th>games</th>
      <th>gender</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>[216, 359, 12329, 3, 45, 4002, 2066, 32, 3931,...</td>
      <td>[4, 4, 25, 7, 30, 58, 16, 19, 17, 21, 10, 10, ...</td>
      <td>[9151, 208]</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>[]</td>
      <td>[129, 71, 9, 8, 11, 25, 18, 58, 6, 16, 125, 12...</td>
      <td>[460, 4939, 14, 232, 6387, 1758, 5834, 3, 2]</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>[23463, 18831]</td>
      <td>[9, 174, 65, 8, 63, 97, 62, 103, 61, 116, 59, ...</td>
      <td>[448, 723, 267, 9064, 10634, 166, 782, 224, 27...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>[1634, 3609, 654]</td>
      <td>[99, 73, 9, 8, 59, 37, 131, 3, 89, 6, 24, 16, ...</td>
      <td>[78, 2607, 478, 435, 9, 192]</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>[11064, 227, 623, 1301, 43999, 35411, 2492, 11...</td>
      <td>[9, 8, 17, 54, 3, 25, 22, 6, 21, 7, 14, 5, 817...</td>
      <td>[1702, 1, 53]</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[35]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">df</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">&#39;apps&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">),</span> <span class="n">df</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">df</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">&#39;games&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">),</span> <span class="n">df</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">df</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">&#39;queries&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">),</span> <span class="n">df</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[36]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt">Out[36]:</div>



<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/html">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
      <th>1</th>
      <th>2</th>
      <th>3</th>
      <th>4</th>
      <th>5</th>
      <th>6</th>
      <th>7</th>
      <th>8</th>
      <th>9</th>
      <th>...</th>
      <th>412</th>
      <th>413</th>
      <th>414</th>
      <th>415</th>
      <th>416</th>
      <th>417</th>
      <th>418</th>
      <th>419</th>
      <th>420</th>
      <th>gender</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>216.0</td>
      <td>359.0</td>
      <td>12329.0</td>
      <td>3.0</td>
      <td>45.0</td>
      <td>4002.0</td>
      <td>2066.0</td>
      <td>32.0</td>
      <td>3931.0</td>
      <td>17104.0</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>23463.0</td>
      <td>18831.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1634.0</td>
      <td>3609.0</td>
      <td>654.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>11064.0</td>
      <td>227.0</td>
      <td>623.0</td>
      <td>1301.0</td>
      <td>43999.0</td>
      <td>35411.0</td>
      <td>2492.0</td>
      <td>112.0</td>
      <td>1652.0</td>
      <td>27068.0</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
<p>5 rows  931 columns</p>
</div>
</div>

</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[37]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt">Out[37]:</div>




<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain">
<pre>0         0.017407
1         0.041643
2         0.070373
3         0.098036
4         0.127312
            ...   
417       0.999975
418       0.999975
419       0.999975
420       0.999975
gender    0.000000
Length: 931, dtype: float64</pre>
</div>

</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[38]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="n">df</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span> <span class="o">&lt;</span> <span class="mf">0.8</span><span class="p">]</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt">Out[38]:</div>




<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain">
<pre>Index([       0,        1,        2,        3,        4,        5,        6,
              7,        8,        9,
       ...
             62,       63,       64,       65,       66,       67,       68,
             69,       70, &#39;gender&#39;],
      dtype=&#39;object&#39;, length=119)</pre>
</div>

</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[39]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="n">df</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span> <span class="o">&lt;</span> <span class="mf">0.8</span><span class="p">]]</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[40]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt">Out[40]:</div>




<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain">
<pre>(40271, 355)</pre>
</div>

</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[50]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[51]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span>  <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;gender&quot;</span><span class="p">]),</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;gender&quot;</span><span class="p">]</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[52]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">ohe</span> <span class="o">=</span> <span class="n">OneHotEncoder</span><span class="p">()</span>

<span class="n">y_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">y_train</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">y_test</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>

<span class="n">y_train</span> <span class="o">=</span> <span class="n">ohe</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">y_train</span><span class="p">)</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">ohe</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">y_test</span><span class="p">)</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[53]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">input_dim</span><span class="o">=</span><span class="mi">354</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">60</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">45</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">30</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">))</span>

<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;binary_crossentropy&#39;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;adam&#39;</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[55]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">validation_split</span><span class="o">=</span><span class="mf">0.33</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Epoch 1/100
338/338 [==============================] - 2s 2ms/step - loss: 18.2793 - accuracy: 0.7150 - val_loss: 0.6518 - val_accuracy: 0.7369
Epoch 2/100
338/338 [==============================] - 1s 1ms/step - loss: 0.6233 - accuracy: 0.7420 - val_loss: 0.6184 - val_accuracy: 0.7369
Epoch 3/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5895 - accuracy: 0.7486 - val_loss: 0.6030 - val_accuracy: 0.7369
Epoch 4/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5746 - accuracy: 0.7490 - val_loss: 0.5927 - val_accuracy: 0.7370
Epoch 5/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5723 - accuracy: 0.7436 - val_loss: 0.5894 - val_accuracy: 0.7369
Epoch 6/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5683 - accuracy: 0.7454 - val_loss: 0.5888 - val_accuracy: 0.7369
Epoch 7/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5630 - accuracy: 0.7497 - val_loss: 0.5888 - val_accuracy: 0.7369
Epoch 8/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5674 - accuracy: 0.7454 - val_loss: 0.5889 - val_accuracy: 0.7369
Epoch 9/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5691 - accuracy: 0.7437 - val_loss: 0.5889 - val_accuracy: 0.7369
Epoch 10/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5698 - accuracy: 0.7431 - val_loss: 0.5890 - val_accuracy: 0.7369
Epoch 11/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5658 - accuracy: 0.7468 - val_loss: 0.5890 - val_accuracy: 0.7369
Epoch 12/100
338/338 [==============================] - 1s 1ms/step - loss: 0.5639 - accuracy: 0.7486 - val_loss: 0.5889 - val_accuracy: 0.7369
Epoch 13/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5638 - accuracy: 0.7486 - val_loss: 0.5890 - val_accuracy: 0.7369
Epoch 14/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5693 - accuracy: 0.7436 - val_loss: 0.5890 - val_accuracy: 0.7369
Epoch 15/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5659 - accuracy: 0.7467 - val_loss: 0.5890 - val_accuracy: 0.7369
Epoch 16/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5647 - accuracy: 0.7478 - val_loss: 0.5890 - val_accuracy: 0.7369
Epoch 17/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5663 - accuracy: 0.7464 - val_loss: 0.5890 - val_accuracy: 0.7369
Epoch 18/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5669 - accuracy: 0.7457 - val_loss: 0.5890 - val_accuracy: 0.7369
Epoch 19/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5627 - accuracy: 0.7497 - val_loss: 0.5890 - val_accuracy: 0.7369
Epoch 20/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5697 - accuracy: 0.7432 - val_loss: 0.5890 - val_accuracy: 0.7369
Epoch 21/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5613 - accuracy: 0.7509 - val_loss: 0.5890 - val_accuracy: 0.7369
Epoch 22/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5663 - accuracy: 0.7463 - val_loss: 0.5889 - val_accuracy: 0.7369
Epoch 23/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5641 - accuracy: 0.7484 - val_loss: 0.5890 - val_accuracy: 0.7369
Epoch 24/100
338/338 [==============================] - 1s 1ms/step - loss: 0.5672 - accuracy: 0.7455 - val_loss: 0.5890 - val_accuracy: 0.7369
Epoch 25/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5680 - accuracy: 0.7448 - val_loss: 0.5890 - val_accuracy: 0.7369
Epoch 26/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5672 - accuracy: 0.7455 - val_loss: 0.5890 - val_accuracy: 0.7369
Epoch 27/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5629 - accuracy: 0.7495 - val_loss: 0.5890 - val_accuracy: 0.7369
Epoch 28/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5684 - accuracy: 0.7444 - val_loss: 0.5890 - val_accuracy: 0.7369
Epoch 29/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5694 - accuracy: 0.7435 - val_loss: 0.5890 - val_accuracy: 0.7369
Epoch 30/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5674 - accuracy: 0.7453 - val_loss: 0.5890 - val_accuracy: 0.7369
Epoch 31/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5664 - accuracy: 0.7463 - val_loss: 0.5890 - val_accuracy: 0.7369
Epoch 32/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5678 - accuracy: 0.7450 - val_loss: 0.5890 - val_accuracy: 0.7369
Epoch 33/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5625 - accuracy: 0.7499 - val_loss: 0.5890 - val_accuracy: 0.7369
Epoch 34/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5674 - accuracy: 0.7453 - val_loss: 0.5890 - val_accuracy: 0.7369
Epoch 35/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5675 - accuracy: 0.7453 - val_loss: 0.5890 - val_accuracy: 0.7369
Epoch 36/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5632 - accuracy: 0.7492 - val_loss: 0.5890 - val_accuracy: 0.7369
Epoch 37/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5634 - accuracy: 0.7490 - val_loss: 0.5890 - val_accuracy: 0.7369
Epoch 38/100
338/338 [==============================] - 1s 1ms/step - loss: 0.5610 - accuracy: 0.7513 - val_loss: 0.5890 - val_accuracy: 0.7369
Epoch 39/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5654 - accuracy: 0.7471 - val_loss: 0.5890 - val_accuracy: 0.7369
Epoch 40/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5656 - accuracy: 0.7470 - val_loss: 0.5890 - val_accuracy: 0.7369
Epoch 41/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5634 - accuracy: 0.7491 - val_loss: 0.5890 - val_accuracy: 0.7369
Epoch 42/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5645 - accuracy: 0.7480 - val_loss: 0.5889 - val_accuracy: 0.7369
Epoch 43/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5572 - accuracy: 0.7548 - val_loss: 0.5889 - val_accuracy: 0.7369
Epoch 44/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5679 - accuracy: 0.7448 - val_loss: 0.5889 - val_accuracy: 0.7369
Epoch 45/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5684 - accuracy: 0.7444 - val_loss: 0.5890 - val_accuracy: 0.7369
Epoch 46/100
338/338 [==============================] - 1s 1ms/step - loss: 0.5666 - accuracy: 0.7461 - val_loss: 0.5890 - val_accuracy: 0.7369
Epoch 47/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5705 - accuracy: 0.7425 - val_loss: 0.5890 - val_accuracy: 0.7369
Epoch 48/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5681 - accuracy: 0.7447 - val_loss: 0.5890 - val_accuracy: 0.7369
Epoch 49/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5654 - accuracy: 0.7471 - val_loss: 0.5890 - val_accuracy: 0.7369
Epoch 50/100
338/338 [==============================] - 1s 1ms/step - loss: 0.5611 - accuracy: 0.7511 - val_loss: 0.5890 - val_accuracy: 0.7369
Epoch 51/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5643 - accuracy: 0.7481 - val_loss: 0.5890 - val_accuracy: 0.7369
Epoch 52/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5691 - accuracy: 0.7437 - val_loss: 0.5890 - val_accuracy: 0.7369
Epoch 53/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5654 - accuracy: 0.7472 - val_loss: 0.5890 - val_accuracy: 0.7369
Epoch 54/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5654 - accuracy: 0.7472 - val_loss: 0.5890 - val_accuracy: 0.7369
Epoch 55/100
338/338 [==============================] - 1s 1ms/step - loss: 0.5661 - accuracy: 0.7466 - val_loss: 0.5890 - val_accuracy: 0.7369
Epoch 56/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5672 - accuracy: 0.7455 - val_loss: 0.5890 - val_accuracy: 0.7369
Epoch 57/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5612 - accuracy: 0.7510 - val_loss: 0.5889 - val_accuracy: 0.7369
Epoch 58/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5696 - accuracy: 0.7432 - val_loss: 0.5890 - val_accuracy: 0.7369
Epoch 59/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5603 - accuracy: 0.7519 - val_loss: 0.5889 - val_accuracy: 0.7369
Epoch 60/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5606 - accuracy: 0.7516 - val_loss: 0.5889 - val_accuracy: 0.7369
Epoch 61/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5664 - accuracy: 0.7463 - val_loss: 0.5890 - val_accuracy: 0.7369
Epoch 62/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5647 - accuracy: 0.7478 - val_loss: 0.5889 - val_accuracy: 0.7369
Epoch 63/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5684 - accuracy: 0.7443 - val_loss: 0.5890 - val_accuracy: 0.7369
Epoch 64/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5645 - accuracy: 0.7481 - val_loss: 0.5890 - val_accuracy: 0.7369
Epoch 65/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5679 - accuracy: 0.7448 - val_loss: 0.5890 - val_accuracy: 0.7369
Epoch 66/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5660 - accuracy: 0.7466 - val_loss: 0.5890 - val_accuracy: 0.7369
Epoch 67/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5659 - accuracy: 0.7467 - val_loss: 0.5890 - val_accuracy: 0.7369
Epoch 68/100
338/338 [==============================] - 1s 1ms/step - loss: 0.5622 - accuracy: 0.7501 - val_loss: 0.5890 - val_accuracy: 0.7369
Epoch 69/100
338/338 [==============================] - 1s 1ms/step - loss: 0.5635 - accuracy: 0.7489 - val_loss: 0.5890 - val_accuracy: 0.7369
Epoch 70/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5665 - accuracy: 0.7462 - val_loss: 0.5889 - val_accuracy: 0.7369
Epoch 71/100
338/338 [==============================] - 1s 1ms/step - loss: 0.5690 - accuracy: 0.7438 - val_loss: 0.5890 - val_accuracy: 0.7369
Epoch 72/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5685 - accuracy: 0.7442 - val_loss: 0.5890 - val_accuracy: 0.7369
Epoch 73/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5730 - accuracy: 0.7402 - val_loss: 0.5890 - val_accuracy: 0.7369
Epoch 74/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5652 - accuracy: 0.7473 - val_loss: 0.5890 - val_accuracy: 0.7369
Epoch 75/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5653 - accuracy: 0.7472 - val_loss: 0.5890 - val_accuracy: 0.7369
Epoch 76/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5702 - accuracy: 0.7427 - val_loss: 0.5890 - val_accuracy: 0.7369
Epoch 77/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5656 - accuracy: 0.7470 - val_loss: 0.5890 - val_accuracy: 0.7369
Epoch 78/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5716 - accuracy: 0.7415 - val_loss: 0.5890 - val_accuracy: 0.7369
Epoch 79/100
338/338 [==============================] - 1s 1ms/step - loss: 0.5683 - accuracy: 0.7445 - val_loss: 0.5890 - val_accuracy: 0.7369
Epoch 80/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5681 - accuracy: 0.7446 - val_loss: 0.5890 - val_accuracy: 0.7369
Epoch 81/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5625 - accuracy: 0.7498 - val_loss: 0.5890 - val_accuracy: 0.7369
Epoch 82/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5632 - accuracy: 0.7492 - val_loss: 0.5890 - val_accuracy: 0.7369
Epoch 83/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5666 - accuracy: 0.7461 - val_loss: 0.5889 - val_accuracy: 0.7369
Epoch 84/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5667 - accuracy: 0.7460 - val_loss: 0.5890 - val_accuracy: 0.7369
Epoch 85/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5567 - accuracy: 0.7552 - val_loss: 0.5889 - val_accuracy: 0.7369
Epoch 86/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5704 - accuracy: 0.7425 - val_loss: 0.5890 - val_accuracy: 0.7369
Epoch 87/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5658 - accuracy: 0.7468 - val_loss: 0.5890 - val_accuracy: 0.7369
Epoch 88/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5572 - accuracy: 0.7547 - val_loss: 0.5889 - val_accuracy: 0.7369
Epoch 89/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5658 - accuracy: 0.7467 - val_loss: 0.5890 - val_accuracy: 0.7369
Epoch 90/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5666 - accuracy: 0.7461 - val_loss: 0.5890 - val_accuracy: 0.7369
Epoch 91/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5664 - accuracy: 0.7462 - val_loss: 0.5890 - val_accuracy: 0.7369
Epoch 92/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5603 - accuracy: 0.7519 - val_loss: 0.5889 - val_accuracy: 0.7369
Epoch 93/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5598 - accuracy: 0.7524 - val_loss: 0.5889 - val_accuracy: 0.7369
Epoch 94/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5630 - accuracy: 0.7494 - val_loss: 0.5889 - val_accuracy: 0.7369
Epoch 95/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5609 - accuracy: 0.7513 - val_loss: 0.5889 - val_accuracy: 0.7369
Epoch 96/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5679 - accuracy: 0.7448 - val_loss: 0.5889 - val_accuracy: 0.7369
Epoch 97/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5594 - accuracy: 0.7527 - val_loss: 0.5889 - val_accuracy: 0.7369
Epoch 98/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5700 - accuracy: 0.7429 - val_loss: 0.5890 - val_accuracy: 0.7369
Epoch 99/100
338/338 [==============================] - 1s 1ms/step - loss: 0.5667 - accuracy: 0.7460 - val_loss: 0.5890 - val_accuracy: 0.7369
Epoch 100/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5643 - accuracy: 0.7481 - val_loss: 0.5889 - val_accuracy: 0.7369
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[56]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_parquet</span><span class="p">(</span><span class="n">DATA_DIR</span><span class="p">,</span> <span class="n">engine</span><span class="o">=</span><span class="s2">&quot;pyarrow&quot;</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s2">&quot;birth_year&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;birth_year&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">uint</span><span class="p">)</span>
<span class="n">valid_birth_year</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;birth_year&quot;</span><span class="p">][</span><span class="n">df</span><span class="p">[</span><span class="s2">&quot;birth_year&quot;</span><span class="p">]</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">]</span>
<span class="n">mean_birth_year</span> <span class="o">=</span> <span class="nb">round</span><span class="p">(</span><span class="n">valid_birth_year</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>
<span class="n">df</span><span class="p">[</span><span class="s2">&quot;birth_year&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;birth_year&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">mean_birth_year</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s2">&quot;gender&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;gender&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">({</span><span class="s1">&#39;M&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;F&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">})</span>
<span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;birth_year&#39;</span><span class="p">],</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt">Out[56]:</div>



<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/html">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>queries</th>
      <th>apps</th>
      <th>games</th>
      <th>gender</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>[216, 359, 12329, 3, 45, 4002, 2066, 32, 3931,...</td>
      <td>[4, 4, 25, 7, 30, 58, 16, 19, 17, 21, 10, 10, ...</td>
      <td>[9151, 208]</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>[]</td>
      <td>[129, 71, 9, 8, 11, 25, 18, 58, 6, 16, 125, 12...</td>
      <td>[460, 4939, 14, 232, 6387, 1758, 5834, 3, 2]</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>[23463, 18831]</td>
      <td>[9, 174, 65, 8, 63, 97, 62, 103, 61, 116, 59, ...</td>
      <td>[448, 723, 267, 9064, 10634, 166, 782, 224, 27...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>[1634, 3609, 654]</td>
      <td>[99, 73, 9, 8, 59, 37, 131, 3, 89, 6, 24, 16, ...</td>
      <td>[78, 2607, 478, 435, 9, 192]</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>[11064, 227, 623, 1301, 43999, 35411, 2492, 11...</td>
      <td>[9, 8, 17, 54, 3, 25, 22, 6, 21, 7, 14, 5, 817...</td>
      <td>[1702, 1, 53]</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[57]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">df</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">&#39;apps&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">),</span> <span class="n">df</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">df</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">&#39;games&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">),</span> <span class="n">df</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">df</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">&#39;queries&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">),</span> <span class="n">df</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[58]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="n">df</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span> <span class="o">&lt;</span> <span class="mf">0.7</span><span class="p">]]</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[59]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[60]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span>  <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;gender&quot;</span><span class="p">]),</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;gender&quot;</span><span class="p">]</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[61]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">ohe</span> <span class="o">=</span> <span class="n">OneHotEncoder</span><span class="p">()</span>

<span class="n">y_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">y_train</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">y_test</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>

<span class="n">y_train</span> <span class="o">=</span> <span class="n">ohe</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">y_train</span><span class="p">)</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">ohe</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">y_test</span><span class="p">)</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[63]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">input_dim</span><span class="o">=</span><span class="mi">291</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">60</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">45</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">30</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">))</span>

<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;binary_crossentropy&#39;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;adam&#39;</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[64]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">validation_split</span><span class="o">=</span><span class="mf">0.33</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Epoch 1/100
338/338 [==============================] - 2s 2ms/step - loss: 30.9248 - accuracy: 0.6959 - val_loss: 0.6455 - val_accuracy: 0.7371
Epoch 2/100
338/338 [==============================] - 0s 1ms/step - loss: 0.6248 - accuracy: 0.7446 - val_loss: 0.6125 - val_accuracy: 0.7372
Epoch 3/100
338/338 [==============================] - 1s 1ms/step - loss: 0.5937 - accuracy: 0.7395 - val_loss: 0.5944 - val_accuracy: 0.7370
Epoch 4/100
338/338 [==============================] - 1s 1ms/step - loss: 0.5756 - accuracy: 0.7455 - val_loss: 0.5870 - val_accuracy: 0.7370
Epoch 5/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5740 - accuracy: 0.7409 - val_loss: 0.5862 - val_accuracy: 0.7371
Epoch 6/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5637 - accuracy: 0.7499 - val_loss: 0.5763 - val_accuracy: 0.7370
Epoch 7/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5628 - accuracy: 0.7501 - val_loss: 0.5770 - val_accuracy: 0.7371
Epoch 8/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5679 - accuracy: 0.7454 - val_loss: 0.5764 - val_accuracy: 0.7370
Epoch 9/100
338/338 [==============================] - 1s 1ms/step - loss: 0.5610 - accuracy: 0.7512 - val_loss: 0.5770 - val_accuracy: 0.7370
Epoch 10/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5664 - accuracy: 0.7462 - val_loss: 0.5783 - val_accuracy: 0.7370
Epoch 11/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5680 - accuracy: 0.7446 - val_loss: 0.5765 - val_accuracy: 0.7371
Epoch 12/100
338/338 [==============================] - 1s 1ms/step - loss: 0.5690 - accuracy: 0.7438 - val_loss: 0.5766 - val_accuracy: 0.7371
Epoch 13/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5684 - accuracy: 0.7444 - val_loss: 0.5766 - val_accuracy: 0.7371
Epoch 14/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5673 - accuracy: 0.7454 - val_loss: 0.5766 - val_accuracy: 0.7371
Epoch 15/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5701 - accuracy: 0.7428 - val_loss: 0.5766 - val_accuracy: 0.7371
Epoch 16/100
338/338 [==============================] - 1s 1ms/step - loss: 0.5668 - accuracy: 0.7459 - val_loss: 0.5766 - val_accuracy: 0.7371
Epoch 17/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5714 - accuracy: 0.7417 - val_loss: 0.5766 - val_accuracy: 0.7371
Epoch 18/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5662 - accuracy: 0.7465 - val_loss: 0.5765 - val_accuracy: 0.7371
Epoch 19/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5643 - accuracy: 0.7482 - val_loss: 0.5765 - val_accuracy: 0.7371
Epoch 20/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5697 - accuracy: 0.7432 - val_loss: 0.5765 - val_accuracy: 0.7371
Epoch 21/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5663 - accuracy: 0.7463 - val_loss: 0.5765 - val_accuracy: 0.7371
Epoch 22/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5664 - accuracy: 0.7462 - val_loss: 0.5765 - val_accuracy: 0.7371
Epoch 23/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5668 - accuracy: 0.7459 - val_loss: 0.5765 - val_accuracy: 0.7371
Epoch 24/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5652 - accuracy: 0.7474 - val_loss: 0.5765 - val_accuracy: 0.7371
Epoch 25/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5684 - accuracy: 0.7444 - val_loss: 0.5765 - val_accuracy: 0.7371
Epoch 26/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5704 - accuracy: 0.7426 - val_loss: 0.5766 - val_accuracy: 0.7371
Epoch 27/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5669 - accuracy: 0.7458 - val_loss: 0.5765 - val_accuracy: 0.7371
Epoch 28/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5666 - accuracy: 0.7461 - val_loss: 0.5765 - val_accuracy: 0.7371
Epoch 29/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5647 - accuracy: 0.7478 - val_loss: 0.5765 - val_accuracy: 0.7371
Epoch 30/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5638 - accuracy: 0.7487 - val_loss: 0.5765 - val_accuracy: 0.7371
Epoch 31/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5659 - accuracy: 0.7467 - val_loss: 0.5765 - val_accuracy: 0.7371
Epoch 32/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5660 - accuracy: 0.7467 - val_loss: 0.5765 - val_accuracy: 0.7371
Epoch 33/100
338/338 [==============================] - 1s 1ms/step - loss: 0.5694 - accuracy: 0.7435 - val_loss: 0.5766 - val_accuracy: 0.7371
Epoch 34/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5633 - accuracy: 0.7491 - val_loss: 0.5765 - val_accuracy: 0.7371
Epoch 35/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5597 - accuracy: 0.7525 - val_loss: 0.5765 - val_accuracy: 0.7371
Epoch 36/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5668 - accuracy: 0.7459 - val_loss: 0.5765 - val_accuracy: 0.7371
Epoch 37/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5703 - accuracy: 0.7426 - val_loss: 0.5766 - val_accuracy: 0.7371
Epoch 38/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5673 - accuracy: 0.7455 - val_loss: 0.5765 - val_accuracy: 0.7371
Epoch 39/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5603 - accuracy: 0.7519 - val_loss: 0.5765 - val_accuracy: 0.7371
Epoch 40/100
338/338 [==============================] - 1s 1ms/step - loss: 0.5665 - accuracy: 0.7461 - val_loss: 0.5765 - val_accuracy: 0.7371
Epoch 41/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5677 - accuracy: 0.7451 - val_loss: 0.5765 - val_accuracy: 0.7371
Epoch 42/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5685 - accuracy: 0.7443 - val_loss: 0.5766 - val_accuracy: 0.7371
Epoch 43/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5642 - accuracy: 0.7483 - val_loss: 0.5766 - val_accuracy: 0.7371
Epoch 44/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5671 - accuracy: 0.7456 - val_loss: 0.5766 - val_accuracy: 0.7371
Epoch 45/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5618 - accuracy: 0.7505 - val_loss: 0.5765 - val_accuracy: 0.7371
Epoch 46/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5649 - accuracy: 0.7477 - val_loss: 0.5765 - val_accuracy: 0.7371
Epoch 47/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5663 - accuracy: 0.7464 - val_loss: 0.5765 - val_accuracy: 0.7371
Epoch 48/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5663 - accuracy: 0.7463 - val_loss: 0.5765 - val_accuracy: 0.7371
Epoch 49/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5696 - accuracy: 0.7433 - val_loss: 0.5765 - val_accuracy: 0.7371
Epoch 50/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5654 - accuracy: 0.7472 - val_loss: 0.5765 - val_accuracy: 0.7371
Epoch 51/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5620 - accuracy: 0.7503 - val_loss: 0.5765 - val_accuracy: 0.7371
Epoch 52/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5677 - accuracy: 0.7451 - val_loss: 0.5765 - val_accuracy: 0.7371
Epoch 53/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5712 - accuracy: 0.7418 - val_loss: 0.5766 - val_accuracy: 0.7371
Epoch 54/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5677 - accuracy: 0.7450 - val_loss: 0.5765 - val_accuracy: 0.7371
Epoch 55/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5654 - accuracy: 0.7472 - val_loss: 0.5765 - val_accuracy: 0.7371
Epoch 56/100
338/338 [==============================] - 1s 1ms/step - loss: 0.5718 - accuracy: 0.7413 - val_loss: 0.5766 - val_accuracy: 0.7371
Epoch 57/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5616 - accuracy: 0.7507 - val_loss: 0.5765 - val_accuracy: 0.7371
Epoch 58/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5702 - accuracy: 0.7428 - val_loss: 0.5766 - val_accuracy: 0.7371
Epoch 59/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5680 - accuracy: 0.7447 - val_loss: 0.5765 - val_accuracy: 0.7371
Epoch 60/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5699 - accuracy: 0.7430 - val_loss: 0.5766 - val_accuracy: 0.7371
Epoch 61/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5661 - accuracy: 0.7466 - val_loss: 0.5765 - val_accuracy: 0.7371
Epoch 62/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5676 - accuracy: 0.7451 - val_loss: 0.5765 - val_accuracy: 0.7371
Epoch 63/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5691 - accuracy: 0.7437 - val_loss: 0.5765 - val_accuracy: 0.7371
Epoch 64/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5689 - accuracy: 0.7440 - val_loss: 0.5765 - val_accuracy: 0.7371
Epoch 65/100
338/338 [==============================] - 1s 1ms/step - loss: 0.5683 - accuracy: 0.7445 - val_loss: 0.5766 - val_accuracy: 0.7371
Epoch 66/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5700 - accuracy: 0.7429 - val_loss: 0.5766 - val_accuracy: 0.7371
Epoch 67/100
338/338 [==============================] - 1s 1ms/step - loss: 0.5635 - accuracy: 0.7489 - val_loss: 0.5766 - val_accuracy: 0.7371
Epoch 68/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5685 - accuracy: 0.7443 - val_loss: 0.5766 - val_accuracy: 0.7371
Epoch 69/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5594 - accuracy: 0.7528 - val_loss: 0.5765 - val_accuracy: 0.7371
Epoch 70/100
338/338 [==============================] - 1s 1ms/step - loss: 0.5652 - accuracy: 0.7474 - val_loss: 0.5765 - val_accuracy: 0.7371
Epoch 71/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5658 - accuracy: 0.7469 - val_loss: 0.5765 - val_accuracy: 0.7371
Epoch 72/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5669 - accuracy: 0.7458 - val_loss: 0.5766 - val_accuracy: 0.7371
Epoch 73/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5641 - accuracy: 0.7484 - val_loss: 0.5765 - val_accuracy: 0.7371
Epoch 74/100
338/338 [==============================] - 1s 1ms/step - loss: 0.5685 - accuracy: 0.7443 - val_loss: 0.5766 - val_accuracy: 0.7371
Epoch 75/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5650 - accuracy: 0.7476 - val_loss: 0.5765 - val_accuracy: 0.7371
Epoch 76/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5691 - accuracy: 0.7438 - val_loss: 0.5765 - val_accuracy: 0.7371
Epoch 77/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5639 - accuracy: 0.7486 - val_loss: 0.5765 - val_accuracy: 0.7371
Epoch 78/100
338/338 [==============================] - 1s 1ms/step - loss: 0.5649 - accuracy: 0.7476 - val_loss: 0.5765 - val_accuracy: 0.7371
Epoch 79/100
338/338 [==============================] - 1s 1ms/step - loss: 0.5691 - accuracy: 0.7438 - val_loss: 0.5766 - val_accuracy: 0.7371
Epoch 80/100
338/338 [==============================] - 1s 1ms/step - loss: 0.5648 - accuracy: 0.7478 - val_loss: 0.5765 - val_accuracy: 0.7371
Epoch 81/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5675 - accuracy: 0.7452 - val_loss: 0.5765 - val_accuracy: 0.7371
Epoch 82/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5659 - accuracy: 0.7467 - val_loss: 0.5765 - val_accuracy: 0.7371
Epoch 83/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5625 - accuracy: 0.7499 - val_loss: 0.5765 - val_accuracy: 0.7371
Epoch 84/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5718 - accuracy: 0.7413 - val_loss: 0.5766 - val_accuracy: 0.7371
Epoch 85/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5618 - accuracy: 0.7505 - val_loss: 0.5765 - val_accuracy: 0.7371
Epoch 86/100
338/338 [==============================] - 1s 1ms/step - loss: 0.5658 - accuracy: 0.7468 - val_loss: 0.5765 - val_accuracy: 0.7371
Epoch 87/100
338/338 [==============================] - 1s 2ms/step - loss: 0.5657 - accuracy: 0.7469 - val_loss: 0.5765 - val_accuracy: 0.7371
Epoch 88/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5663 - accuracy: 0.7464 - val_loss: 0.5766 - val_accuracy: 0.7371
Epoch 89/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5689 - accuracy: 0.7439 - val_loss: 0.5766 - val_accuracy: 0.7371
Epoch 90/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5617 - accuracy: 0.7506 - val_loss: 0.5765 - val_accuracy: 0.7371
Epoch 91/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5669 - accuracy: 0.7458 - val_loss: 0.5765 - val_accuracy: 0.7371
Epoch 92/100
338/338 [==============================] - 1s 1ms/step - loss: 0.5674 - accuracy: 0.7453 - val_loss: 0.5765 - val_accuracy: 0.7371
Epoch 93/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5646 - accuracy: 0.7479 - val_loss: 0.5765 - val_accuracy: 0.7371
Epoch 94/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5666 - accuracy: 0.7461 - val_loss: 0.5765 - val_accuracy: 0.7371
Epoch 95/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5706 - accuracy: 0.7424 - val_loss: 0.5765 - val_accuracy: 0.7371
Epoch 96/100
338/338 [==============================] - 1s 1ms/step - loss: 0.5609 - accuracy: 0.7514 - val_loss: 0.5765 - val_accuracy: 0.7371
Epoch 97/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5639 - accuracy: 0.7486 - val_loss: 0.5765 - val_accuracy: 0.7371
Epoch 98/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5676 - accuracy: 0.7452 - val_loss: 0.5765 - val_accuracy: 0.7371
Epoch 99/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5685 - accuracy: 0.7443 - val_loss: 0.5765 - val_accuracy: 0.7371
Epoch 100/100
338/338 [==============================] - 0s 1ms/step - loss: 0.5681 - accuracy: 0.7447 - val_loss: 0.5766 - val_accuracy: 0.7371
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[65]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;model loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;epoch&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s1">&#39;train&#39;</span><span class="p">,</span> <span class="s1">&#39;test&#39;</span><span class="p">],</span> <span class="n">loc</span><span class="o">=</span><span class="s1">&#39;upper left&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedImage jp-OutputArea-output ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>

</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>It seems that my model has lot of problem. Let's find it out:</p>

</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[69]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span>  <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;gender&quot;</span><span class="p">]),</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;gender&quot;</span><span class="p">]</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[75]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">kerastuner.engine.hyperparameters</span> <span class="kn">import</span> <span class="n">HyperParameters</span>
<span class="kn">from</span> <span class="nn">kerastuner.tuners</span> <span class="kn">import</span> <span class="n">RandomSearch</span>
<span class="kn">import</span> <span class="nn">time</span>

<span class="n">LOG_DIR</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="nb">int</span><span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">())</span><span class="si">}</span><span class="s2">&quot;</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[83]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">tensorflow</span> <span class="kn">import</span> <span class="n">keras</span>

<span class="k">def</span> <span class="nf">build_model</span><span class="p">(</span><span class="n">hp</span><span class="p">):</span>
    
    <span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>
    
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="n">hp</span><span class="o">.</span><span class="n">Int</span><span class="p">(</span><span class="s2">&quot;input_units&quot;</span><span class="p">,</span> <span class="n">min_value</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">max_value</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mi">20</span><span class="p">),</span> <span class="n">input_dim</span><span class="o">=</span><span class="mi">291</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
    
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">hp</span><span class="o">.</span><span class="n">Int</span><span class="p">(</span><span class="s1">&#39;n_layers&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">)):</span>
        <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="n">hp</span><span class="o">.</span><span class="n">Int</span><span class="p">(</span><span class="s2">&quot;dense_units&quot;</span><span class="p">,</span> <span class="n">min_value</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">max_value</span><span class="o">=</span><span class="mi">300</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mi">10</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
    
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;sigmoid&#39;</span><span class="p">))</span>
    
    <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;binary_crossentropy&#39;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;adam&#39;</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>
    
    <span class="k">return</span> <span class="n">model</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[84]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tuner</span> <span class="o">=</span> <span class="n">RandomSearch</span><span class="p">(</span>
    <span class="n">build_model</span><span class="p">,</span>
    <span class="n">objective</span> <span class="o">=</span> <span class="s2">&quot;val_accuracy&quot;</span><span class="p">,</span>
    <span class="n">max_trials</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">executions_per_trial</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">directory</span> <span class="o">=</span> <span class="n">LOG_DIR</span>
<span class="p">)</span>

<span class="n">tuner</span><span class="o">.</span><span class="n">search</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y_train</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span><span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">))</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Trial 1 Complete [00h 06m 05s]
val_accuracy: 0.741651177406311

Best val_accuracy So Far: 0.741651177406311
Total elapsed time: 00h 06m 05s
INFO:tensorflow:Oracle triggered exit
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[85]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">pickle</span>

<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;tuner_</span><span class="si">{</span><span class="nb">int</span><span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">())</span><span class="si">}</span><span class="s2">.pkl&quot;</span><span class="p">,</span> <span class="s2">&quot;wb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">tuner</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[87]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tuner</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="nb">open</span><span class="p">(</span><span class="s2">&quot;tuner_1627669198.pkl&quot;</span><span class="p">,</span> <span class="s2">&quot;rb&quot;</span><span class="p">))</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[89]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">tuner</span><span class="o">.</span><span class="n">get_best_hyperparameters</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">tuner</span><span class="o">.</span><span class="n">results_summary</span><span class="p">())</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;input_units&#39;: 260, &#39;n_layers&#39;: 3, &#39;dense_units&#39;: 110}
Results summary
Results in 1627666980\untitled_project
Showing 10 best trials
Objective(name=&#39;val_accuracy&#39;, direction=&#39;max&#39;)
Trial summary
Hyperparameters:
input_units: 260
n_layers: 3
dense_units: 110
Score: 0.741651177406311
None
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[93]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">tuner</span><span class="o">.</span><span class="n">get_best_models</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">validation_split</span><span class="o">=</span><span class="mf">0.33</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate
WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-0._module.kernel
WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-0._module.bias
WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-1._module.kernel
WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-1._module.bias
WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-2._module.kernel
WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-2._module.bias
WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-3._module.kernel
WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-3._module.bias
WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-4._module.kernel
WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-4._module.bias
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer&#39;s state &#39;m&#39; for (root).layer_with_weights-0._module.kernel
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer&#39;s state &#39;m&#39; for (root).layer_with_weights-0._module.bias
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer&#39;s state &#39;m&#39; for (root).layer_with_weights-1._module.kernel
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer&#39;s state &#39;m&#39; for (root).layer_with_weights-1._module.bias
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer&#39;s state &#39;m&#39; for (root).layer_with_weights-2._module.kernel
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer&#39;s state &#39;m&#39; for (root).layer_with_weights-2._module.bias
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer&#39;s state &#39;m&#39; for (root).layer_with_weights-3._module.kernel
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer&#39;s state &#39;m&#39; for (root).layer_with_weights-3._module.bias
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer&#39;s state &#39;m&#39; for (root).layer_with_weights-4._module.kernel
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer&#39;s state &#39;m&#39; for (root).layer_with_weights-4._module.bias
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer&#39;s state &#39;v&#39; for (root).layer_with_weights-0._module.kernel
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer&#39;s state &#39;v&#39; for (root).layer_with_weights-0._module.bias
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer&#39;s state &#39;v&#39; for (root).layer_with_weights-1._module.kernel
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer&#39;s state &#39;v&#39; for (root).layer_with_weights-1._module.bias
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer&#39;s state &#39;v&#39; for (root).layer_with_weights-2._module.kernel
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer&#39;s state &#39;v&#39; for (root).layer_with_weights-2._module.bias
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer&#39;s state &#39;v&#39; for (root).layer_with_weights-3._module.kernel
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer&#39;s state &#39;v&#39; for (root).layer_with_weights-3._module.bias
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer&#39;s state &#39;v&#39; for (root).layer_with_weights-4._module.kernel
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer&#39;s state &#39;v&#39; for (root).layer_with_weights-4._module.bias
WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.
Epoch 1/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.6063 - accuracy: 0.7459 - val_loss: 0.5990 - val_accuracy: 0.7366
Epoch 2/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5933 - accuracy: 0.7462 - val_loss: 0.5815 - val_accuracy: 0.7371
Epoch 3/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5813 - val_accuracy: 0.7371
Epoch 4/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.6328 - accuracy: 0.7460 - val_loss: 0.5855 - val_accuracy: 0.7368
Epoch 5/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5790 - accuracy: 0.7463 - val_loss: 0.5761 - val_accuracy: 0.7370
Epoch 6/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5666 - accuracy: 0.7464 - val_loss: 0.5765 - val_accuracy: 0.7370
Epoch 7/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5668 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370
Epoch 8/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5667 - accuracy: 0.7464 - val_loss: 0.5768 - val_accuracy: 0.7370
Epoch 9/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5667 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370
Epoch 10/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5666 - accuracy: 0.7464 - val_loss: 0.5764 - val_accuracy: 0.7370
Epoch 11/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370
Epoch 12/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5772 - val_accuracy: 0.7370
Epoch 13/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5667 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370
Epoch 14/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5764 - val_accuracy: 0.7370
Epoch 15/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5775 - val_accuracy: 0.7370
Epoch 16/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5666 - accuracy: 0.7464 - val_loss: 0.5772 - val_accuracy: 0.7370
Epoch 17/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370
Epoch 18/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5666 - accuracy: 0.7464 - val_loss: 0.5763 - val_accuracy: 0.7370
Epoch 19/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5666 - accuracy: 0.7464 - val_loss: 0.5771 - val_accuracy: 0.7370
Epoch 20/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5666 - accuracy: 0.7464 - val_loss: 0.5773 - val_accuracy: 0.7370
Epoch 21/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370
Epoch 22/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5666 - accuracy: 0.7464 - val_loss: 0.5766 - val_accuracy: 0.7370
Epoch 23/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5666 - accuracy: 0.7464 - val_loss: 0.5765 - val_accuracy: 0.7370
Epoch 24/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5667 - accuracy: 0.7464 - val_loss: 0.5766 - val_accuracy: 0.7370
Epoch 25/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5768 - val_accuracy: 0.7370
Epoch 26/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370
Epoch 27/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5766 - val_accuracy: 0.7370
Epoch 28/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5764 - val_accuracy: 0.7370
Epoch 29/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5764 - val_accuracy: 0.7370
Epoch 30/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370
Epoch 31/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5769 - val_accuracy: 0.7370
Epoch 32/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5663 - accuracy: 0.7464 - val_loss: 0.5763 - val_accuracy: 0.7370
Epoch 33/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5767 - val_accuracy: 0.7370
Epoch 34/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5773 - val_accuracy: 0.7370
Epoch 35/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5764 - val_accuracy: 0.7370
Epoch 36/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370
Epoch 37/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370
Epoch 38/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370
Epoch 39/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5761 - val_accuracy: 0.7370
Epoch 40/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5764 - val_accuracy: 0.7370
Epoch 41/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5767 - val_accuracy: 0.7370
Epoch 42/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5763 - val_accuracy: 0.7370
Epoch 43/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370
Epoch 44/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370
Epoch 45/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5765 - val_accuracy: 0.7370
Epoch 46/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5770 - val_accuracy: 0.7370
Epoch 47/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370
Epoch 48/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370
Epoch 49/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5763 - val_accuracy: 0.7370
Epoch 50/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370
Epoch 51/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5663 - accuracy: 0.7464 - val_loss: 0.5768 - val_accuracy: 0.7370
Epoch 52/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5770 - val_accuracy: 0.7370
Epoch 53/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5770 - val_accuracy: 0.7370
Epoch 54/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370
Epoch 55/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370
Epoch 56/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5765 - val_accuracy: 0.7370
Epoch 57/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5768 - val_accuracy: 0.7370
Epoch 58/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5775 - val_accuracy: 0.7370
Epoch 59/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370
Epoch 60/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5666 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370
Epoch 61/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5761 - val_accuracy: 0.7370
Epoch 62/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370
Epoch 63/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5765 - val_accuracy: 0.7370
Epoch 64/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5663 - accuracy: 0.7464 - val_loss: 0.5770 - val_accuracy: 0.7370
Epoch 65/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5763 - val_accuracy: 0.7370
Epoch 66/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5767 - val_accuracy: 0.7370
Epoch 67/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5764 - val_accuracy: 0.7370
Epoch 68/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5761 - val_accuracy: 0.7370
Epoch 69/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5765 - val_accuracy: 0.7370
Epoch 70/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5776 - val_accuracy: 0.7370
Epoch 71/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5662 - accuracy: 0.7464 - val_loss: 0.5767 - val_accuracy: 0.7370
Epoch 72/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5763 - val_accuracy: 0.7370
Epoch 73/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5767 - val_accuracy: 0.7370
Epoch 74/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370
Epoch 75/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5764 - val_accuracy: 0.7370
Epoch 76/100
2159/2159 [==============================] - 3s 2ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5767 - val_accuracy: 0.7370
Epoch 77/100
2159/2159 [==============================] - 4s 2ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370
Epoch 78/100
2159/2159 [==============================] - 4s 2ms/step - loss: 0.5663 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370
Epoch 79/100
2159/2159 [==============================] - 4s 2ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5766 - val_accuracy: 0.7370
Epoch 80/100
2159/2159 [==============================] - 4s 2ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370
Epoch 81/100
2159/2159 [==============================] - 4s 2ms/step - loss: 0.5663 - accuracy: 0.7464 - val_loss: 0.5775 - val_accuracy: 0.7370
Epoch 82/100
2159/2159 [==============================] - 4s 2ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370
Epoch 83/100
2159/2159 [==============================] - 4s 2ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5766 - val_accuracy: 0.7370
Epoch 84/100
2159/2159 [==============================] - 4s 2ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5767 - val_accuracy: 0.7370
Epoch 85/100
2159/2159 [==============================] - 4s 2ms/step - loss: 0.5663 - accuracy: 0.7464 - val_loss: 0.5773 - val_accuracy: 0.7370
Epoch 86/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370
Epoch 87/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5663 - accuracy: 0.7464 - val_loss: 0.5771 - val_accuracy: 0.7370
Epoch 88/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5663 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370
Epoch 89/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5767 - val_accuracy: 0.7370
Epoch 90/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5663 - accuracy: 0.7464 - val_loss: 0.5763 - val_accuracy: 0.7370
Epoch 91/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5768 - val_accuracy: 0.7370
Epoch 92/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5764 - val_accuracy: 0.7370
Epoch 93/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370
Epoch 94/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5764 - val_accuracy: 0.7370
Epoch 95/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5763 - val_accuracy: 0.7370
Epoch 96/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370
Epoch 97/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5763 - val_accuracy: 0.7370
Epoch 98/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5761 - val_accuracy: 0.7370
Epoch 99/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5767 - val_accuracy: 0.7370
Epoch 100/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5773 - val_accuracy: 0.7370
</pre>
</div>
</div>

</div>

</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Accuracy is not changing one reason can be because of <code>optimizer</code></p>

</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[100]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">tensorflow.keras.optimizers</span> <span class="kn">import</span> <span class="n">SGD</span>
<span class="n">opt</span> <span class="o">=</span> <span class="n">SGD</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">build_model2</span><span class="p">(</span><span class="n">hp</span><span class="p">):</span>
    
    <span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>
    
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="n">hp</span><span class="o">.</span><span class="n">Int</span><span class="p">(</span><span class="s2">&quot;input_units&quot;</span><span class="p">,</span> <span class="n">min_value</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">max_value</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mi">20</span><span class="p">),</span> <span class="n">input_dim</span><span class="o">=</span><span class="mi">291</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
    
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">hp</span><span class="o">.</span><span class="n">Int</span><span class="p">(</span><span class="s1">&#39;n_layers&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">)):</span>
        <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="n">hp</span><span class="o">.</span><span class="n">Int</span><span class="p">(</span><span class="s2">&quot;dense_units&quot;</span><span class="p">,</span> <span class="n">min_value</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">max_value</span><span class="o">=</span><span class="mi">300</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mi">10</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
    
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;sigmoid&#39;</span><span class="p">))</span>
    
    <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;binary_crossentropy&#39;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">opt</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>
    
    <span class="k">return</span> <span class="n">model</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[102]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">LOG_DIR</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="nb">int</span><span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">())</span><span class="si">}</span><span class="s2">&quot;</span>

<span class="n">tuner</span> <span class="o">=</span> <span class="n">RandomSearch</span><span class="p">(</span>
    <span class="n">build_model</span><span class="p">,</span>
    <span class="n">objective</span> <span class="o">=</span> <span class="s2">&quot;val_accuracy&quot;</span><span class="p">,</span>
    <span class="n">max_trials</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">executions_per_trial</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">directory</span> <span class="o">=</span> <span class="n">LOG_DIR</span>
<span class="p">)</span>

<span class="n">tuner</span><span class="o">.</span><span class="n">search</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y_train</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span><span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">))</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Trial 1 Complete [00h 06m 33s]
val_accuracy: 0.741651177406311

Best val_accuracy So Far: 0.741651177406311
Total elapsed time: 00h 06m 33s
INFO:tensorflow:Oracle triggered exit
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[103]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;tuner_</span><span class="si">{</span><span class="nb">int</span><span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">())</span><span class="si">}</span><span class="s2">.pkl&quot;</span><span class="p">,</span> <span class="s2">&quot;wb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">tuner</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[104]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tuner</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="nb">open</span><span class="p">(</span><span class="s2">&quot;tuner_1627670879.pkl&quot;</span><span class="p">,</span> <span class="s2">&quot;rb&quot;</span><span class="p">))</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[105]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">tuner</span><span class="o">.</span><span class="n">get_best_hyperparameters</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">tuner</span><span class="o">.</span><span class="n">results_summary</span><span class="p">())</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;input_units&#39;: 140, &#39;n_layers&#39;: 3, &#39;dense_units&#39;: 170}
Results summary
Results in 1627670169\untitled_project
Showing 10 best trials
Objective(name=&#39;val_accuracy&#39;, direction=&#39;max&#39;)
Trial summary
Hyperparameters:
input_units: 140
n_layers: 3
dense_units: 170
Score: 0.741651177406311
None
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[119]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">tuner</span><span class="o">.</span><span class="n">get_best_models</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">validation_split</span><span class="o">=</span><span class="mf">0.33</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Epoch 1/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5675 - accuracy: 0.7463 - val_loss: 0.5761 - val_accuracy: 0.7371
Epoch 2/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5686 - accuracy: 0.7463 - val_loss: 0.5762 - val_accuracy: 0.7371
Epoch 3/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5704 - accuracy: 0.7462 - val_loss: 0.5762 - val_accuracy: 0.7370
Epoch 4/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5711 - accuracy: 0.7463 - val_loss: 0.5763 - val_accuracy: 0.7370
Epoch 5/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5666 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370
Epoch 6/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5668 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370
Epoch 7/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5668 - accuracy: 0.7464 - val_loss: 0.5763 - val_accuracy: 0.7370
Epoch 8/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5666 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370
Epoch 9/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5667 - accuracy: 0.7464 - val_loss: 0.5763 - val_accuracy: 0.7370
Epoch 10/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5668 - accuracy: 0.7464 - val_loss: 0.5765 - val_accuracy: 0.7370
Epoch 11/100
2159/2159 [==============================] - 3s 2ms/step - loss: 0.5667 - accuracy: 0.7464 - val_loss: 0.5768 - val_accuracy: 0.7370
Epoch 12/100
2159/2159 [==============================] - 4s 2ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5773 - val_accuracy: 0.7370
Epoch 13/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5763 - val_accuracy: 0.7370
Epoch 14/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5667 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370
Epoch 15/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5667 - accuracy: 0.7464 - val_loss: 0.5766 - val_accuracy: 0.7370
Epoch 16/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5666 - accuracy: 0.7464 - val_loss: 0.5768 - val_accuracy: 0.7370
Epoch 17/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5666 - accuracy: 0.7464 - val_loss: 0.5764 - val_accuracy: 0.7370
Epoch 18/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5663 - accuracy: 0.7464 - val_loss: 0.5770 - val_accuracy: 0.7370
Epoch 19/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5666 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370
Epoch 20/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5667 - accuracy: 0.7464 - val_loss: 0.5766 - val_accuracy: 0.7370
Epoch 21/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5666 - accuracy: 0.7464 - val_loss: 0.5773 - val_accuracy: 0.7370
Epoch 22/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5775 - val_accuracy: 0.7370
Epoch 23/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5666 - accuracy: 0.7464 - val_loss: 0.5766 - val_accuracy: 0.7370
Epoch 24/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5666 - accuracy: 0.7464 - val_loss: 0.5764 - val_accuracy: 0.7370
Epoch 25/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370
Epoch 26/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5794 - val_accuracy: 0.7370
Epoch 27/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5666 - accuracy: 0.7464 - val_loss: 0.5783 - val_accuracy: 0.7370
Epoch 28/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5767 - val_accuracy: 0.7370
Epoch 29/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5666 - accuracy: 0.7464 - val_loss: 0.5763 - val_accuracy: 0.7370
Epoch 30/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5770 - val_accuracy: 0.7370
Epoch 31/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5666 - accuracy: 0.7464 - val_loss: 0.5764 - val_accuracy: 0.7370
Epoch 32/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5666 - accuracy: 0.7464 - val_loss: 0.5761 - val_accuracy: 0.7370
Epoch 33/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370
Epoch 34/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370
Epoch 35/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5666 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370
Epoch 36/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5763 - val_accuracy: 0.7370
Epoch 37/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5666 - accuracy: 0.7464 - val_loss: 0.5765 - val_accuracy: 0.7370
Epoch 38/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5666 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370
Epoch 39/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5765 - val_accuracy: 0.7370
Epoch 40/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5666 - accuracy: 0.7464 - val_loss: 0.5765 - val_accuracy: 0.7370
Epoch 41/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370
Epoch 42/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5666 - accuracy: 0.7464 - val_loss: 0.5766 - val_accuracy: 0.7370
Epoch 43/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5768 - val_accuracy: 0.7370
Epoch 44/100
2159/2159 [==============================] - 3s 2ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5775 - val_accuracy: 0.7370
Epoch 45/100
2159/2159 [==============================] - 4s 2ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5770 - val_accuracy: 0.7370
Epoch 46/100
2159/2159 [==============================] - 4s 2ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5779 - val_accuracy: 0.7370
Epoch 47/100
2159/2159 [==============================] - 4s 2ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370
Epoch 48/100
2159/2159 [==============================] - 4s 2ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370
Epoch 49/100
2159/2159 [==============================] - 3s 2ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5769 - val_accuracy: 0.7370
Epoch 50/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370
Epoch 51/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5773 - val_accuracy: 0.7370
Epoch 52/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5767 - val_accuracy: 0.7370
Epoch 53/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370
Epoch 54/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5663 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370
Epoch 55/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370
Epoch 56/100
2159/2159 [==============================] - 3s 2ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5769 - val_accuracy: 0.7370
Epoch 57/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5765 - val_accuracy: 0.7370
Epoch 58/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5764 - val_accuracy: 0.7370
Epoch 59/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5763 - val_accuracy: 0.7370
Epoch 60/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5766 - val_accuracy: 0.7370
Epoch 61/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5663 - accuracy: 0.7464 - val_loss: 0.5765 - val_accuracy: 0.7370
Epoch 62/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5763 - val_accuracy: 0.7370
Epoch 63/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5663 - accuracy: 0.7464 - val_loss: 0.5770 - val_accuracy: 0.7370
Epoch 64/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5769 - val_accuracy: 0.7370
Epoch 65/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5663 - accuracy: 0.7464 - val_loss: 0.5765 - val_accuracy: 0.7370
Epoch 66/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5764 - val_accuracy: 0.7370
Epoch 67/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370
Epoch 68/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370
Epoch 69/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5663 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370
Epoch 70/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370
Epoch 71/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5768 - val_accuracy: 0.7370
Epoch 72/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5763 - val_accuracy: 0.7370
Epoch 73/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370
Epoch 74/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5769 - val_accuracy: 0.7370
Epoch 75/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5765 - val_accuracy: 0.7370
Epoch 76/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5773 - val_accuracy: 0.7370
Epoch 77/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5768 - val_accuracy: 0.7370
Epoch 78/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370
Epoch 79/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5764 - val_accuracy: 0.7370
Epoch 80/100
2159/2159 [==============================] - 3s 2ms/step - loss: 0.5663 - accuracy: 0.7464 - val_loss: 0.5769 - val_accuracy: 0.7370
Epoch 81/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5766 - val_accuracy: 0.7370
Epoch 82/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370
Epoch 83/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5767 - val_accuracy: 0.7370
Epoch 84/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5663 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370
Epoch 85/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5663 - accuracy: 0.7464 - val_loss: 0.5764 - val_accuracy: 0.7370
Epoch 86/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5766 - val_accuracy: 0.7370
Epoch 87/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5663 - accuracy: 0.7464 - val_loss: 0.5763 - val_accuracy: 0.7370
Epoch 88/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5763 - val_accuracy: 0.7370
Epoch 89/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5767 - val_accuracy: 0.7370
Epoch 90/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5765 - val_accuracy: 0.7370
Epoch 91/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5763 - val_accuracy: 0.7370
Epoch 92/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370
Epoch 93/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370
Epoch 94/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5663 - accuracy: 0.7464 - val_loss: 0.5773 - val_accuracy: 0.7370
Epoch 95/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5766 - val_accuracy: 0.7370
Epoch 96/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370
Epoch 97/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370
Epoch 98/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370
Epoch 99/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5767 - val_accuracy: 0.7370
Epoch 100/100
2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5771 - val_accuracy: 0.7370
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[126]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">predicted</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_classes</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">evaluate</span><span class="p">(</span><span class="n">predicted</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\tensorflow\python\keras\engine\sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) &gt; 0.5).astype(&#34;int32&#34;)`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).
  warnings.warn(&#39;`model.predict_classes()` is deprecated and &#39;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Accuracy:  0.741651148355059
Balanced Accuracy:  0.5
Precision:  0.741651148355059
Recall:  1.0
F1:  0.8516644094375936
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[127]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">count_0_predicted</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">count_1_predicted</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">count_0_actual</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">count_1_actual</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">predicted</span><span class="p">)):</span>
    <span class="k">if</span> <span class="n">predicted</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">count_0_predicted</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">count_1_predicted</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="k">if</span> <span class="n">y_test</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">count_0_actual</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">count_1_actual</span> <span class="o">+=</span> <span class="mi">1</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;There </span><span class="si">{</span><span class="n">count_0_predicted</span><span class="si">}</span><span class="s2"> 0 values in prediction.&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;There </span><span class="si">{</span><span class="n">count_1_predicted</span><span class="si">}</span><span class="s2"> 1 values in prediction.&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;There </span><span class="si">{</span><span class="n">count_0_actual</span><span class="si">}</span><span class="s2"> 0 values in test dataset.&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;There </span><span class="si">{</span><span class="n">count_1_actual</span><span class="si">}</span><span class="s2"> 1 values in test dataset.&quot;</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>There 0 0 values in prediction.
There 8055 1 values in prediction.
There 2081 0 values in test dataset.
There 5974 1 values in test dataset.
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[109]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">max_depth</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">min_samples_leaf</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">min_samples_split</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="n">cross_val_score</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt">Out[109]:</div>




<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain">
<pre>array([0.74301676, 0.74518932, 0.74239603, 0.74239603, 0.74332713,
       0.74208566, 0.74262651, 0.74293698, 0.74293698, 0.74138466])</pre>
</div>

</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[110]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">predicted</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[113]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">evaluate</span><span class="p">(</span><span class="n">predicted</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Accuracy:  0.7415270018621974
Balanced Accuracy:  0.5017951810078175
Precision:  0.7423412204234122
Recall:  0.9978239035821895
F1:  0.8513281919451585
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[118]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">count_0_predicted</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">count_1_predicted</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">count_0_actual</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">count_1_actual</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">predicted</span><span class="p">)):</span>
    <span class="k">if</span> <span class="n">predicted</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">count_0_predicted</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">count_1_predicted</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="k">if</span> <span class="n">y_test</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">count_0_actual</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">count_1_actual</span> <span class="o">+=</span> <span class="mi">1</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;There </span><span class="si">{</span><span class="n">count_0_predicted</span><span class="si">}</span><span class="s2"> 0 values in prediction.&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;There </span><span class="si">{</span><span class="n">count_1_predicted</span><span class="si">}</span><span class="s2"> 1 values in prediction.&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;There </span><span class="si">{</span><span class="n">count_0_actual</span><span class="si">}</span><span class="s2"> 0 values in test dataset.&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;There </span><span class="si">{</span><span class="n">count_1_actual</span><span class="si">}</span><span class="s2"> 1 values in test dataset.&quot;</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>There 25 0 values in prediction.
There 8030 1 values in prediction.
There 2081 0 values in test dataset.
There 5974 1 values in test dataset.
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[7]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;birth_year&#39;</span><span class="p">],</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s2">&quot;gender&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;gender&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">({</span><span class="s1">&#39;M&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;F&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">})</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt">Out[7]:</div>



<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/html">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>queries</th>
      <th>apps</th>
      <th>games</th>
      <th>gender</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>[216, 359, 12329, 3, 45, 4002, 2066, 32, 3931,...</td>
      <td>[4, 4, 25, 7, 30, 58, 16, 19, 17, 21, 10, 10, ...</td>
      <td>[9151, 208]</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>[]</td>
      <td>[129, 71, 9, 8, 11, 25, 18, 58, 6, 16, 125, 12...</td>
      <td>[460, 4939, 14, 232, 6387, 1758, 5834, 3, 2]</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>[23463, 18831]</td>
      <td>[9, 174, 65, 8, 63, 97, 62, 103, 61, 116, 59, ...</td>
      <td>[448, 723, 267, 9064, 10634, 166, 782, 224, 27...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>[1634, 3609, 654]</td>
      <td>[99, 73, 9, 8, 59, 37, 131, 3, 89, 6, 24, 16, ...</td>
      <td>[78, 2607, 478, 435, 9, 192]</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>[11064, 227, 623, 1301, 43999, 35411, 2492, 11...</td>
      <td>[9, 8, 17, 54, 3, 25, 22, 6, 21, 7, 14, 5, 817...</td>
      <td>[1702, 1, 53]</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[6]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>

<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span>  <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;gender&quot;</span><span class="p">]),</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;gender&quot;</span><span class="p">]</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[7]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">X_train</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt">Out[7]:</div>



<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/html">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>queries</th>
      <th>apps</th>
      <th>games</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>9391</th>
      <td>[2504, 30655, 32035, 3, 4]</td>
      <td>[9, 10, 10, 39, 17, 3, 21, 12, 7, 41, 58, 6, 1...</td>
      <td>[336, 822, 14]</td>
    </tr>
    <tr>
      <th>36089</th>
      <td>[1400, 4, 9, 18236, 16200, 10739, 9713, 70, 14...</td>
      <td>[9, 8, 10, 10, 39, 17, 48, 54, 3, 25, 22, 6, 2...</td>
      <td>[1, 145]</td>
    </tr>
    <tr>
      <th>38820</th>
      <td>[5327, 12, 3, 10462, 30102, 921, 1247, 6869, 7...</td>
      <td>[9, 17, 3, 25, 22, 6, 21, 7, 14, 23, 2, 19, 10...</td>
      <td>[78, 11, 122, 113, 192, 2726, 34, 44, 17, 4, 9...</td>
    </tr>
    <tr>
      <th>33815</th>
      <td>[479, 1717, 1205, 875, 3570, 4]</td>
      <td>[73, 9, 8, 59, 37, 131, 3, 89, 6, 16, 85, 12, ...</td>
      <td>[771, 3198]</td>
    </tr>
    <tr>
      <th>31187</th>
      <td>[163, 18284, 143, 1082, 258, 28721]</td>
      <td>[25, 71, 125, 16, 7, 5, 10, 10, 48, 3, 79, 47,...</td>
      <td>[689, 45]</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>6265</th>
      <td>[824, 197, 42, 259, 4127, 894, 719, 344]</td>
      <td>[9, 8, 105, 10, 10, 17, 54, 3, 25, 95, 22, 6, ...</td>
      <td>[23, 947, 35, 435, 1327, 2694, 2]</td>
    </tr>
    <tr>
      <th>11284</th>
      <td>[1565, 712, 24838, 39622, 20862, 22, 238, 599,...</td>
      <td>[9, 8, 105, 10, 10, 39, 17, 3, 25, 22, 6, 24, ...</td>
      <td>[64, 361, 2093, 2708, 1228, 318, 711, 1844, 2392]</td>
    </tr>
    <tr>
      <th>38158</th>
      <td>[4118, 12355, 723, 41687, 1678, 30560, 184, 85...</td>
      <td>[9, 8, 17, 3, 25, 22, 6, 21, 7, 14, 5, 23, 2, ...</td>
      <td>[35, 4697, 3, 47]</td>
    </tr>
    <tr>
      <th>860</th>
      <td>[134, 12, 16458, 459, 118, 13249, 241, 10469, ...</td>
      <td>[9, 8, 17, 3, 25, 22, 6, 24, 21, 7, 14, 5, 23,...</td>
      <td>[]</td>
    </tr>
    <tr>
      <th>15795</th>
      <td>[12904, 2555, 39, 976, 3716, 10283, 10193, 102...</td>
      <td>[9, 8, 105, 10, 10, 39, 17, 3, 25, 22, 6, 24, ...</td>
      <td>[2, 889]</td>
    </tr>
  </tbody>
</table>
<p>32216 rows  3 columns</p>
</div>
</div>

</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[26]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">max_depth</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">min_samples_leaf</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">min_samples_split</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>
<span class="ansi-red-intense-fg ansi-bold">---------------------------------------------------------------------------</span>
<span class="ansi-red-intense-fg ansi-bold">TypeError</span>                                 Traceback (most recent call last)
<span class="ansi-red-intense-fg ansi-bold">TypeError</span>: only size-1 arrays can be converted to Python scalars

The above exception was the direct cause of the following exception:

<span class="ansi-red-intense-fg ansi-bold">ValueError</span>                                Traceback (most recent call last)
<span class="ansi-green-intense-fg ansi-bold">&lt;ipython-input-26-866bb70b5a7c&gt;</span> in <span class="ansi-cyan-fg">&lt;module&gt;</span>
<span class="ansi-green-fg">      3</span> 
<span class="ansi-green-fg">      4</span> model <span class="ansi-yellow-intense-fg ansi-bold">=</span> RandomForestClassifier<span class="ansi-yellow-intense-fg ansi-bold">(</span>random_state<span class="ansi-yellow-intense-fg ansi-bold">=</span><span class="ansi-cyan-intense-fg ansi-bold">0</span><span class="ansi-yellow-intense-fg ansi-bold">,</span> max_depth<span class="ansi-yellow-intense-fg ansi-bold">=</span><span class="ansi-cyan-intense-fg ansi-bold">20</span><span class="ansi-yellow-intense-fg ansi-bold">,</span> min_samples_leaf<span class="ansi-yellow-intense-fg ansi-bold">=</span><span class="ansi-cyan-intense-fg ansi-bold">1</span><span class="ansi-yellow-intense-fg ansi-bold">,</span> min_samples_split<span class="ansi-yellow-intense-fg ansi-bold">=</span><span class="ansi-cyan-intense-fg ansi-bold">2</span><span class="ansi-yellow-intense-fg ansi-bold">,</span> n_estimators<span class="ansi-yellow-intense-fg ansi-bold">=</span><span class="ansi-cyan-intense-fg ansi-bold">100</span><span class="ansi-yellow-intense-fg ansi-bold">)</span>
<span class="ansi-green-intense-fg ansi-bold">----&gt; 5</span><span class="ansi-yellow-intense-fg ansi-bold"> </span>model<span class="ansi-yellow-intense-fg ansi-bold">.</span>fit<span class="ansi-yellow-intense-fg ansi-bold">(</span>X_train<span class="ansi-yellow-intense-fg ansi-bold">,</span> y_train<span class="ansi-yellow-intense-fg ansi-bold">)</span>

<span class="ansi-green-intense-fg ansi-bold">~\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py</span> in <span class="ansi-cyan-fg">fit</span><span class="ansi-blue-intense-fg ansi-bold">(self, X, y, sample_weight)</span>
<span class="ansi-green-fg">    302</span>                 <span class="ansi-blue-intense-fg ansi-bold">&#34;sparse multilabel-indicator for y is not supported.&#34;</span>
<span class="ansi-green-fg">    303</span>             )
<span class="ansi-green-intense-fg ansi-bold">--&gt; 304</span><span class="ansi-yellow-intense-fg ansi-bold">         X, y = self._validate_data(X, y, multi_output=True,
</span><span class="ansi-green-fg">    305</span>                                    accept_sparse=&#34;csc&#34;, dtype=DTYPE)
<span class="ansi-green-fg">    306</span>         <span class="ansi-green-intense-fg ansi-bold">if</span> sample_weight <span class="ansi-green-intense-fg ansi-bold">is</span> <span class="ansi-green-intense-fg ansi-bold">not</span> <span class="ansi-green-intense-fg ansi-bold">None</span><span class="ansi-yellow-intense-fg ansi-bold">:</span>

<span class="ansi-green-intense-fg ansi-bold">~\anaconda3\lib\site-packages\sklearn\base.py</span> in <span class="ansi-cyan-fg">_validate_data</span><span class="ansi-blue-intense-fg ansi-bold">(self, X, y, reset, validate_separately, **check_params)</span>
<span class="ansi-green-fg">    431</span>                 y <span class="ansi-yellow-intense-fg ansi-bold">=</span> check_array<span class="ansi-yellow-intense-fg ansi-bold">(</span>y<span class="ansi-yellow-intense-fg ansi-bold">,</span> <span class="ansi-yellow-intense-fg ansi-bold">**</span>check_y_params<span class="ansi-yellow-intense-fg ansi-bold">)</span>
<span class="ansi-green-fg">    432</span>             <span class="ansi-green-intense-fg ansi-bold">else</span><span class="ansi-yellow-intense-fg ansi-bold">:</span>
<span class="ansi-green-intense-fg ansi-bold">--&gt; 433</span><span class="ansi-yellow-intense-fg ansi-bold">                 </span>X<span class="ansi-yellow-intense-fg ansi-bold">,</span> y <span class="ansi-yellow-intense-fg ansi-bold">=</span> check_X_y<span class="ansi-yellow-intense-fg ansi-bold">(</span>X<span class="ansi-yellow-intense-fg ansi-bold">,</span> y<span class="ansi-yellow-intense-fg ansi-bold">,</span> <span class="ansi-yellow-intense-fg ansi-bold">**</span>check_params<span class="ansi-yellow-intense-fg ansi-bold">)</span>
<span class="ansi-green-fg">    434</span>             out <span class="ansi-yellow-intense-fg ansi-bold">=</span> X<span class="ansi-yellow-intense-fg ansi-bold">,</span> y
<span class="ansi-green-fg">    435</span> 

<span class="ansi-green-intense-fg ansi-bold">~\anaconda3\lib\site-packages\sklearn\utils\validation.py</span> in <span class="ansi-cyan-fg">inner_f</span><span class="ansi-blue-intense-fg ansi-bold">(*args, **kwargs)</span>
<span class="ansi-green-fg">     61</span>             extra_args <span class="ansi-yellow-intense-fg ansi-bold">=</span> len<span class="ansi-yellow-intense-fg ansi-bold">(</span>args<span class="ansi-yellow-intense-fg ansi-bold">)</span> <span class="ansi-yellow-intense-fg ansi-bold">-</span> len<span class="ansi-yellow-intense-fg ansi-bold">(</span>all_args<span class="ansi-yellow-intense-fg ansi-bold">)</span>
<span class="ansi-green-fg">     62</span>             <span class="ansi-green-intense-fg ansi-bold">if</span> extra_args <span class="ansi-yellow-intense-fg ansi-bold">&lt;=</span> <span class="ansi-cyan-intense-fg ansi-bold">0</span><span class="ansi-yellow-intense-fg ansi-bold">:</span>
<span class="ansi-green-intense-fg ansi-bold">---&gt; 63</span><span class="ansi-yellow-intense-fg ansi-bold">                 </span><span class="ansi-green-intense-fg ansi-bold">return</span> f<span class="ansi-yellow-intense-fg ansi-bold">(</span><span class="ansi-yellow-intense-fg ansi-bold">*</span>args<span class="ansi-yellow-intense-fg ansi-bold">,</span> <span class="ansi-yellow-intense-fg ansi-bold">**</span>kwargs<span class="ansi-yellow-intense-fg ansi-bold">)</span>
<span class="ansi-green-fg">     64</span> 
<span class="ansi-green-fg">     65</span>             <span class="ansi-red-intense-fg ansi-bold"># extra_args &gt; 0</span>

<span class="ansi-green-intense-fg ansi-bold">~\anaconda3\lib\site-packages\sklearn\utils\validation.py</span> in <span class="ansi-cyan-fg">check_X_y</span><span class="ansi-blue-intense-fg ansi-bold">(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)</span>
<span class="ansi-green-fg">    869</span>         <span class="ansi-green-intense-fg ansi-bold">raise</span> ValueError<span class="ansi-yellow-intense-fg ansi-bold">(</span><span class="ansi-blue-intense-fg ansi-bold">&#34;y cannot be None&#34;</span><span class="ansi-yellow-intense-fg ansi-bold">)</span>
<span class="ansi-green-fg">    870</span> 
<span class="ansi-green-intense-fg ansi-bold">--&gt; 871</span><span class="ansi-yellow-intense-fg ansi-bold">     X = check_array(X, accept_sparse=accept_sparse,
</span><span class="ansi-green-fg">    872</span>                     accept_large_sparse<span class="ansi-yellow-intense-fg ansi-bold">=</span>accept_large_sparse<span class="ansi-yellow-intense-fg ansi-bold">,</span>
<span class="ansi-green-fg">    873</span>                     dtype<span class="ansi-yellow-intense-fg ansi-bold">=</span>dtype<span class="ansi-yellow-intense-fg ansi-bold">,</span> order<span class="ansi-yellow-intense-fg ansi-bold">=</span>order<span class="ansi-yellow-intense-fg ansi-bold">,</span> copy<span class="ansi-yellow-intense-fg ansi-bold">=</span>copy<span class="ansi-yellow-intense-fg ansi-bold">,</span>

<span class="ansi-green-intense-fg ansi-bold">~\anaconda3\lib\site-packages\sklearn\utils\validation.py</span> in <span class="ansi-cyan-fg">inner_f</span><span class="ansi-blue-intense-fg ansi-bold">(*args, **kwargs)</span>
<span class="ansi-green-fg">     61</span>             extra_args <span class="ansi-yellow-intense-fg ansi-bold">=</span> len<span class="ansi-yellow-intense-fg ansi-bold">(</span>args<span class="ansi-yellow-intense-fg ansi-bold">)</span> <span class="ansi-yellow-intense-fg ansi-bold">-</span> len<span class="ansi-yellow-intense-fg ansi-bold">(</span>all_args<span class="ansi-yellow-intense-fg ansi-bold">)</span>
<span class="ansi-green-fg">     62</span>             <span class="ansi-green-intense-fg ansi-bold">if</span> extra_args <span class="ansi-yellow-intense-fg ansi-bold">&lt;=</span> <span class="ansi-cyan-intense-fg ansi-bold">0</span><span class="ansi-yellow-intense-fg ansi-bold">:</span>
<span class="ansi-green-intense-fg ansi-bold">---&gt; 63</span><span class="ansi-yellow-intense-fg ansi-bold">                 </span><span class="ansi-green-intense-fg ansi-bold">return</span> f<span class="ansi-yellow-intense-fg ansi-bold">(</span><span class="ansi-yellow-intense-fg ansi-bold">*</span>args<span class="ansi-yellow-intense-fg ansi-bold">,</span> <span class="ansi-yellow-intense-fg ansi-bold">**</span>kwargs<span class="ansi-yellow-intense-fg ansi-bold">)</span>
<span class="ansi-green-fg">     64</span> 
<span class="ansi-green-fg">     65</span>             <span class="ansi-red-intense-fg ansi-bold"># extra_args &gt; 0</span>

<span class="ansi-green-intense-fg ansi-bold">~\anaconda3\lib\site-packages\sklearn\utils\validation.py</span> in <span class="ansi-cyan-fg">check_array</span><span class="ansi-blue-intense-fg ansi-bold">(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)</span>
<span class="ansi-green-fg">    671</span>                     array <span class="ansi-yellow-intense-fg ansi-bold">=</span> array<span class="ansi-yellow-intense-fg ansi-bold">.</span>astype<span class="ansi-yellow-intense-fg ansi-bold">(</span>dtype<span class="ansi-yellow-intense-fg ansi-bold">,</span> casting<span class="ansi-yellow-intense-fg ansi-bold">=</span><span class="ansi-blue-intense-fg ansi-bold">&#34;unsafe&#34;</span><span class="ansi-yellow-intense-fg ansi-bold">,</span> copy<span class="ansi-yellow-intense-fg ansi-bold">=</span><span class="ansi-green-intense-fg ansi-bold">False</span><span class="ansi-yellow-intense-fg ansi-bold">)</span>
<span class="ansi-green-fg">    672</span>                 <span class="ansi-green-intense-fg ansi-bold">else</span><span class="ansi-yellow-intense-fg ansi-bold">:</span>
<span class="ansi-green-intense-fg ansi-bold">--&gt; 673</span><span class="ansi-yellow-intense-fg ansi-bold">                     </span>array <span class="ansi-yellow-intense-fg ansi-bold">=</span> np<span class="ansi-yellow-intense-fg ansi-bold">.</span>asarray<span class="ansi-yellow-intense-fg ansi-bold">(</span>array<span class="ansi-yellow-intense-fg ansi-bold">,</span> order<span class="ansi-yellow-intense-fg ansi-bold">=</span>order<span class="ansi-yellow-intense-fg ansi-bold">,</span> dtype<span class="ansi-yellow-intense-fg ansi-bold">=</span>dtype<span class="ansi-yellow-intense-fg ansi-bold">)</span>
<span class="ansi-green-fg">    674</span>             <span class="ansi-green-intense-fg ansi-bold">except</span> ComplexWarning <span class="ansi-green-intense-fg ansi-bold">as</span> complex_warning<span class="ansi-yellow-intense-fg ansi-bold">:</span>
<span class="ansi-green-fg">    675</span>                 raise ValueError(&#34;Complex data not supported\n&#34;

<span class="ansi-green-intense-fg ansi-bold">~\anaconda3\lib\site-packages\numpy\core\_asarray.py</span> in <span class="ansi-cyan-fg">asarray</span><span class="ansi-blue-intense-fg ansi-bold">(a, dtype, order)</span>
<span class="ansi-green-fg">     81</span> 
<span class="ansi-green-fg">     82</span>     &#34;&#34;&#34;
<span class="ansi-green-intense-fg ansi-bold">---&gt; 83</span><span class="ansi-yellow-intense-fg ansi-bold">     </span><span class="ansi-green-intense-fg ansi-bold">return</span> array<span class="ansi-yellow-intense-fg ansi-bold">(</span>a<span class="ansi-yellow-intense-fg ansi-bold">,</span> dtype<span class="ansi-yellow-intense-fg ansi-bold">,</span> copy<span class="ansi-yellow-intense-fg ansi-bold">=</span><span class="ansi-green-intense-fg ansi-bold">False</span><span class="ansi-yellow-intense-fg ansi-bold">,</span> order<span class="ansi-yellow-intense-fg ansi-bold">=</span>order<span class="ansi-yellow-intense-fg ansi-bold">)</span>
<span class="ansi-green-fg">     84</span> 
<span class="ansi-green-fg">     85</span> 

<span class="ansi-green-intense-fg ansi-bold">~\anaconda3\lib\site-packages\pandas\core\generic.py</span> in <span class="ansi-cyan-fg">__array__</span><span class="ansi-blue-intense-fg ansi-bold">(self, dtype)</span>
<span class="ansi-green-fg">   1988</span> 
<span class="ansi-green-fg">   1989</span>     <span class="ansi-green-intense-fg ansi-bold">def</span> __array__<span class="ansi-yellow-intense-fg ansi-bold">(</span>self<span class="ansi-yellow-intense-fg ansi-bold">,</span> dtype<span class="ansi-yellow-intense-fg ansi-bold">:</span> NpDtype <span class="ansi-yellow-intense-fg ansi-bold">|</span> <span class="ansi-green-intense-fg ansi-bold">None</span> <span class="ansi-yellow-intense-fg ansi-bold">=</span> <span class="ansi-green-intense-fg ansi-bold">None</span><span class="ansi-yellow-intense-fg ansi-bold">)</span> <span class="ansi-yellow-intense-fg ansi-bold">-&gt;</span> np<span class="ansi-yellow-intense-fg ansi-bold">.</span>ndarray<span class="ansi-yellow-intense-fg ansi-bold">:</span>
<span class="ansi-green-intense-fg ansi-bold">-&gt; 1990</span><span class="ansi-yellow-intense-fg ansi-bold">         </span><span class="ansi-green-intense-fg ansi-bold">return</span> np<span class="ansi-yellow-intense-fg ansi-bold">.</span>asarray<span class="ansi-yellow-intense-fg ansi-bold">(</span>self<span class="ansi-yellow-intense-fg ansi-bold">.</span>_values<span class="ansi-yellow-intense-fg ansi-bold">,</span> dtype<span class="ansi-yellow-intense-fg ansi-bold">=</span>dtype<span class="ansi-yellow-intense-fg ansi-bold">)</span>
<span class="ansi-green-fg">   1991</span> 
<span class="ansi-green-fg">   1992</span>     def __array_wrap__(

<span class="ansi-green-intense-fg ansi-bold">~\anaconda3\lib\site-packages\numpy\core\_asarray.py</span> in <span class="ansi-cyan-fg">asarray</span><span class="ansi-blue-intense-fg ansi-bold">(a, dtype, order)</span>
<span class="ansi-green-fg">     81</span> 
<span class="ansi-green-fg">     82</span>     &#34;&#34;&#34;
<span class="ansi-green-intense-fg ansi-bold">---&gt; 83</span><span class="ansi-yellow-intense-fg ansi-bold">     </span><span class="ansi-green-intense-fg ansi-bold">return</span> array<span class="ansi-yellow-intense-fg ansi-bold">(</span>a<span class="ansi-yellow-intense-fg ansi-bold">,</span> dtype<span class="ansi-yellow-intense-fg ansi-bold">,</span> copy<span class="ansi-yellow-intense-fg ansi-bold">=</span><span class="ansi-green-intense-fg ansi-bold">False</span><span class="ansi-yellow-intense-fg ansi-bold">,</span> order<span class="ansi-yellow-intense-fg ansi-bold">=</span>order<span class="ansi-yellow-intense-fg ansi-bold">)</span>
<span class="ansi-green-fg">     84</span> 
<span class="ansi-green-fg">     85</span> 

<span class="ansi-red-intense-fg ansi-bold">ValueError</span>: setting an array element with a sequence.</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[5]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">to_1D</span><span class="p">(</span><span class="n">series</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">([</span><span class="n">x</span> <span class="k">for</span> <span class="n">_list</span> <span class="ow">in</span> <span class="n">series</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">_list</span><span class="p">])</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[6]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">queries</span> <span class="o">=</span> <span class="n">to_1D</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;queries&#39;</span><span class="p">])</span>
<span class="n">apps</span> <span class="o">=</span> <span class="n">to_1D</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;apps&#39;</span><span class="p">])</span>
<span class="n">games</span> <span class="o">=</span> <span class="n">to_1D</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;games&#39;</span><span class="p">])</span>

<span class="n">queries_value_count</span> <span class="o">=</span> <span class="n">queries</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
<span class="n">games_value_count</span> <span class="o">=</span> <span class="n">games</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
<span class="n">apps_value_count</span> <span class="o">=</span> <span class="n">apps</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[10]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">features</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>

<span class="k">for</span> <span class="n">query</span> <span class="ow">in</span> <span class="n">queries</span><span class="p">:</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">queries_value_count</span><span class="p">[</span><span class="n">query</span><span class="p">]</span> <span class="o">&gt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.05</span><span class="p">):</span>
        <span class="n">features</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;q</span><span class="si">{</span><span class="n">query</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span> 
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Queries completed&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">app</span> <span class="ow">in</span> <span class="n">apps</span><span class="p">:</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">apps_value_count</span><span class="p">[</span><span class="n">app</span><span class="p">]</span> <span class="o">&gt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.05</span><span class="p">):</span>
        <span class="n">features</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;a</span><span class="si">{</span><span class="n">app</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Apps completed&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">game</span> <span class="ow">in</span> <span class="n">games</span><span class="p">:</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">games_value_count</span><span class="p">[</span><span class="n">game</span><span class="p">]</span> <span class="o">&gt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.05</span><span class="p">):</span>
        <span class="n">features</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;g</span><span class="si">{</span><span class="n">game</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Games completed&quot;</span><span class="p">)</span>
    
<span class="n">features</span><span class="p">[</span><span class="s2">&quot;gender&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Queries completed
Apps completed
Games completed
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[7]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">check_key</span><span class="p">(</span><span class="nb">dict</span><span class="p">,</span> <span class="n">key</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">key</span> <span class="ow">in</span> <span class="nb">dict</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
        <span class="k">return</span> <span class="kc">True</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">False</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[12]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">copy</span>
<span class="kn">from</span> <span class="nn">tqdm</span> <span class="kn">import</span> <span class="n">tqdm</span>

<span class="n">new_dataset</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">iterrows</span><span class="p">(),</span> <span class="n">total</span><span class="o">=</span><span class="n">df</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
    <span class="n">new_item</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">query</span> <span class="ow">in</span> <span class="n">row</span><span class="p">[</span><span class="s1">&#39;queries&#39;</span><span class="p">]:</span>
        <span class="k">if</span> <span class="n">check_key</span><span class="p">(</span><span class="n">new_item</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;q</span><span class="si">{</span><span class="n">query</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">):</span>
            <span class="n">new_item</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;q</span><span class="si">{</span><span class="n">query</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">for</span> <span class="n">game</span> <span class="ow">in</span> <span class="n">row</span><span class="p">[</span><span class="s1">&#39;games&#39;</span><span class="p">]:</span>
        <span class="k">if</span> <span class="n">check_key</span><span class="p">(</span><span class="n">new_item</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;g</span><span class="si">{</span><span class="n">game</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">):</span>
            <span class="n">new_item</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;g</span><span class="si">{</span><span class="n">game</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">for</span> <span class="n">app</span> <span class="ow">in</span> <span class="n">row</span><span class="p">[</span><span class="s1">&#39;apps&#39;</span><span class="p">]:</span>
        <span class="k">if</span> <span class="n">check_key</span><span class="p">(</span><span class="n">new_item</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;a</span><span class="si">{</span><span class="n">app</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">):</span>
            <span class="n">new_item</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;a</span><span class="si">{</span><span class="n">app</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">new_item</span><span class="p">[</span><span class="s1">&#39;gender&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">row</span><span class="p">[</span><span class="s1">&#39;gender&#39;</span><span class="p">]</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">new_item</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">features</span><span class="p">),</span> <span class="s2">&quot;Featues count error&quot;</span>
    <span class="n">new_dataset</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">copy</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">new_item</span><span class="p">))</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>100%|| 40271/40271 [00:05&lt;00:00, 8037.25it/s]
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[13]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">new_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="o">.</span><span class="n">from_dict</span><span class="p">(</span><span class="n">new_dataset</span><span class="p">,</span> <span class="n">orient</span><span class="o">=</span><span class="s1">&#39;columns&#39;</span><span class="p">)</span>
<span class="n">new_df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt">Out[13]:</div>



<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/html">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>q3</th>
      <th>q1</th>
      <th>q15</th>
      <th>q2</th>
      <th>q12</th>
      <th>q8</th>
      <th>q40</th>
      <th>q21</th>
      <th>q27</th>
      <th>q13</th>
      <th>...</th>
      <th>a33</th>
      <th>a152</th>
      <th>g3</th>
      <th>g2</th>
      <th>g9</th>
      <th>g1</th>
      <th>g16</th>
      <th>g4</th>
      <th>g5</th>
      <th>gender</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
<p>5 rows  220 columns</p>
</div>
</div>

</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[14]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>

<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span>  <span class="n">new_df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;gender&quot;</span><span class="p">]),</span> <span class="n">new_df</span><span class="p">[</span><span class="s2">&quot;gender&quot;</span><span class="p">]</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[14]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">max_depth</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">min_samples_leaf</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">min_samples_split</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="n">cross_val_score</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt">Out[14]:</div>




<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain">
<pre>array([0.80633147, 0.81315953, 0.81750466, 0.80726257, 0.80819367,
       0.82091868, 0.80565042, 0.81527476, 0.81837939, 0.80844458])</pre>
</div>

</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[15]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">predicted</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[18]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">evaluate</span><span class="p">(</span><span class="n">predicted</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Accuracy:  0.8120422098075729
Balanced Accuracy:  0.6615974203126249
Precision:  0.8112786152987158
Recall:  0.9728824907934382
F1:  0.8847617597807885
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[18]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">tensorflow</span> <span class="kn">import</span> <span class="n">keras</span>
<span class="kn">from</span> <span class="nn">keras.layers</span> <span class="kn">import</span> <span class="n">Dense</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.optimizers</span> <span class="kn">import</span> <span class="n">SGD</span>
<span class="n">opt</span> <span class="o">=</span> <span class="n">SGD</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">build_model</span><span class="p">(</span><span class="n">hp</span><span class="p">):</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>
    
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="n">hp</span><span class="o">.</span><span class="n">Int</span><span class="p">(</span><span class="s2">&quot;input_units&quot;</span><span class="p">,</span> <span class="n">min_value</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">max_value</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mi">20</span><span class="p">),</span> <span class="n">input_dim</span><span class="o">=</span><span class="mi">219</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
    
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">hp</span><span class="o">.</span><span class="n">Int</span><span class="p">(</span><span class="s1">&#39;n_layers&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">)):</span>
        <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="n">hp</span><span class="o">.</span><span class="n">Int</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;dense_units_</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">min_value</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">max_value</span><span class="o">=</span><span class="mi">300</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mi">10</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
    
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;sigmoid&#39;</span><span class="p">))</span>
    
    <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;binary_crossentropy&#39;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">opt</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>
    
    <span class="k">return</span> <span class="n">model</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[20]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">kerastuner.engine.hyperparameters</span> <span class="kn">import</span> <span class="n">HyperParameters</span>
<span class="kn">from</span> <span class="nn">kerastuner.tuners</span> <span class="kn">import</span> <span class="n">RandomSearch</span>
<span class="kn">import</span> <span class="nn">time</span>

<span class="n">LOG_DIR</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="nb">int</span><span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">())</span><span class="si">}</span><span class="s2">&quot;</span>

<span class="n">tuner</span> <span class="o">=</span> <span class="n">RandomSearch</span><span class="p">(</span>
    <span class="n">build_model</span><span class="p">,</span>
    <span class="n">objective</span> <span class="o">=</span> <span class="s2">&quot;val_accuracy&quot;</span><span class="p">,</span>
    <span class="n">max_trials</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">executions_per_trial</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">directory</span> <span class="o">=</span> <span class="n">LOG_DIR</span>
<span class="p">)</span>

<span class="n">tuner</span><span class="o">.</span><span class="n">search</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y_train</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span><span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">))</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Trial 1 Complete [00h 04m 54s]
val_accuracy: 0.8227187991142273

Best val_accuracy So Far: 0.8227187991142273
Total elapsed time: 00h 04m 54s
INFO:tensorflow:Oracle triggered exit
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[23]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;tuner_</span><span class="si">{</span><span class="nb">int</span><span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">())</span><span class="si">}</span><span class="s2">.pkl&quot;</span><span class="p">,</span> <span class="s2">&quot;wb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">tuner</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[19]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tuner</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="nb">open</span><span class="p">(</span><span class="s2">&quot;tuner_1627738330.pkl&quot;</span><span class="p">,</span> <span class="s2">&quot;rb&quot;</span><span class="p">))</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[20]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">tuner</span><span class="o">.</span><span class="n">get_best_hyperparameters</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">tuner</span><span class="o">.</span><span class="n">results_summary</span><span class="p">())</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;input_units&#39;: 280, &#39;n_layers&#39;: 8, &#39;dense_units_0&#39;: 30, &#39;dense_units_1&#39;: 10, &#39;dense_units_2&#39;: 10, &#39;dense_units_3&#39;: 10, &#39;dense_units_4&#39;: 10, &#39;dense_units_5&#39;: 10, &#39;dense_units_6&#39;: 10, &#39;dense_units_7&#39;: 10}
Results summary
Results in 1627737908\untitled_project
Showing 10 best trials
Objective(name=&#39;val_accuracy&#39;, direction=&#39;max&#39;)
Trial summary
Hyperparameters:
input_units: 280
n_layers: 8
dense_units_0: 30
dense_units_1: 10
dense_units_2: 10
dense_units_3: 10
dense_units_4: 10
dense_units_5: 10
dense_units_6: 10
dense_units_7: 10
Score: 0.8227187991142273
None
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[37]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">callback</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">EarlyStopping</span><span class="p">(</span><span class="n">monitor</span><span class="o">=</span><span class="s1">&#39;val_loss&#39;</span><span class="p">,</span> <span class="n">patience</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">tuner</span><span class="o">.</span><span class="n">get_best_models</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">validation_split</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">callback</span><span class="p">])</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Epoch 1/100
2900/2900 [==============================] - 3s 869us/step - loss: 0.3878 - accuracy: 0.8319 - val_loss: 0.3908 - val_accuracy: 0.8312
Epoch 2/100
2900/2900 [==============================] - 2s 827us/step - loss: 0.3822 - accuracy: 0.8360 - val_loss: 0.3909 - val_accuracy: 0.8274
Epoch 3/100
2900/2900 [==============================] - 2s 843us/step - loss: 0.3769 - accuracy: 0.8384 - val_loss: 0.4322 - val_accuracy: 0.8060
Epoch 4/100
2900/2900 [==============================] - 2s 831us/step - loss: 0.3697 - accuracy: 0.8432 - val_loss: 0.4084 - val_accuracy: 0.8191
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[38]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;model loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;epoch&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s1">&#39;train&#39;</span><span class="p">,</span> <span class="s1">&#39;test&#39;</span><span class="p">],</span> <span class="n">loc</span><span class="o">=</span><span class="s1">&#39;upper left&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedImage jp-OutputArea-output ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[39]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">predicted</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_classes</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">evaluate</span><span class="p">(</span><span class="n">predicted</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\tensorflow\python\keras\engine\sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) &gt; 0.5).astype(&#34;int32&#34;)`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).
  warnings.warn(&#39;`model.predict_classes()` is deprecated and &#39;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Accuracy:  0.810552451893234
Balanced Accuracy:  0.7355915759899496
Precision:  0.8590571520826606
Recall:  0.8906930030130565
F1:  0.8745890861275476
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[32]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">count_0_predicted</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">count_1_predicted</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">count_0_actual</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">count_1_actual</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">predicted</span><span class="p">)):</span>
    <span class="k">if</span> <span class="n">predicted</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">count_0_predicted</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">count_1_predicted</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="k">if</span> <span class="n">y_test</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">count_0_actual</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">count_1_actual</span> <span class="o">+=</span> <span class="mi">1</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;There </span><span class="si">{</span><span class="n">count_0_predicted</span><span class="si">}</span><span class="s2"> 0 values in prediction.&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;There </span><span class="si">{</span><span class="n">count_1_predicted</span><span class="si">}</span><span class="s2"> 1 values in prediction.&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;There </span><span class="si">{</span><span class="n">count_0_actual</span><span class="si">}</span><span class="s2"> 0 values in test dataset.&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;There </span><span class="si">{</span><span class="n">count_1_actual</span><span class="si">}</span><span class="s2"> 1 values in test dataset.&quot;</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>There 1969 0 values in prediction.
There 6086 1 values in prediction.
There 2081 0 values in test dataset.
There 5974 1 values in test dataset.
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[33]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">GridSearchCV</span>
<span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsClassifier</span>

<span class="n">parameters</span> <span class="o">=</span> <span class="p">{</span> <span class="s1">&#39;n_neighbors&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">19</span><span class="p">,</span> <span class="mi">25</span><span class="p">,</span> <span class="mi">35</span><span class="p">,</span> <span class="mi">55</span><span class="p">,</span><span class="mi">75</span><span class="p">,</span> <span class="mi">99</span><span class="p">],</span>
                <span class="s1">&#39;leaf_size&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">20</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">70</span><span class="p">],</span>
              <span class="s1">&#39;weights&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;uniform&#39;</span><span class="p">,</span> <span class="s1">&#39;distance&#39;</span><span class="p">]</span>
                 <span class="p">}</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">()</span>

<span class="n">grid_search</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">estimator</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">param_grid</span><span class="o">=</span><span class="n">parameters</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s2">&quot;balanced_accuracy&quot;</span><span class="p">)</span>
<span class="n">grid_search</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Fitting 5 folds for each of 88 candidates, totalling 440 fits
[CV 1/5; 1/88] START leaf_size=20, n_neighbors=3, weights=uniform...............
[CV 1/5; 1/88] END leaf_size=20, n_neighbors=3, weights=uniform;, score=0.589 total time=   2.1s
[CV 2/5; 1/88] START leaf_size=20, n_neighbors=3, weights=uniform...............
[CV 2/5; 1/88] END leaf_size=20, n_neighbors=3, weights=uniform;, score=0.581 total time=   2.1s
[CV 3/5; 1/88] START leaf_size=20, n_neighbors=3, weights=uniform...............
[CV 3/5; 1/88] END leaf_size=20, n_neighbors=3, weights=uniform;, score=0.589 total time=   2.1s
[CV 4/5; 1/88] START leaf_size=20, n_neighbors=3, weights=uniform...............
[CV 4/5; 1/88] END leaf_size=20, n_neighbors=3, weights=uniform;, score=0.590 total time=   2.1s
[CV 5/5; 1/88] START leaf_size=20, n_neighbors=3, weights=uniform...............
[CV 5/5; 1/88] END leaf_size=20, n_neighbors=3, weights=uniform;, score=0.581 total time=   2.0s
[CV 1/5; 2/88] START leaf_size=20, n_neighbors=3, weights=distance..............
[CV 1/5; 2/88] END leaf_size=20, n_neighbors=3, weights=distance;, score=0.589 total time=   1.9s
[CV 2/5; 2/88] START leaf_size=20, n_neighbors=3, weights=distance..............
[CV 2/5; 2/88] END leaf_size=20, n_neighbors=3, weights=distance;, score=0.581 total time=   2.0s
[CV 3/5; 2/88] START leaf_size=20, n_neighbors=3, weights=distance..............
[CV 3/5; 2/88] END leaf_size=20, n_neighbors=3, weights=distance;, score=0.589 total time=   1.9s
[CV 4/5; 2/88] START leaf_size=20, n_neighbors=3, weights=distance..............
[CV 4/5; 2/88] END leaf_size=20, n_neighbors=3, weights=distance;, score=0.590 total time=   1.9s
[CV 5/5; 2/88] START leaf_size=20, n_neighbors=3, weights=distance..............
[CV 5/5; 2/88] END leaf_size=20, n_neighbors=3, weights=distance;, score=0.581 total time=   2.0s
[CV 1/5; 3/88] START leaf_size=20, n_neighbors=5, weights=uniform...............
[CV 1/5; 3/88] END leaf_size=20, n_neighbors=5, weights=uniform;, score=0.592 total time=   2.6s
[CV 2/5; 3/88] START leaf_size=20, n_neighbors=5, weights=uniform...............
[CV 2/5; 3/88] END leaf_size=20, n_neighbors=5, weights=uniform;, score=0.577 total time=   2.5s
[CV 3/5; 3/88] START leaf_size=20, n_neighbors=5, weights=uniform...............
[CV 3/5; 3/88] END leaf_size=20, n_neighbors=5, weights=uniform;, score=0.589 total time=   2.7s
[CV 4/5; 3/88] START leaf_size=20, n_neighbors=5, weights=uniform...............
[CV 4/5; 3/88] END leaf_size=20, n_neighbors=5, weights=uniform;, score=0.588 total time=   2.6s
[CV 5/5; 3/88] START leaf_size=20, n_neighbors=5, weights=uniform...............
[CV 5/5; 3/88] END leaf_size=20, n_neighbors=5, weights=uniform;, score=0.585 total time=   2.7s
[CV 1/5; 4/88] START leaf_size=20, n_neighbors=5, weights=distance..............
[CV 1/5; 4/88] END leaf_size=20, n_neighbors=5, weights=distance;, score=0.592 total time=   2.5s
[CV 2/5; 4/88] START leaf_size=20, n_neighbors=5, weights=distance..............
[CV 2/5; 4/88] END leaf_size=20, n_neighbors=5, weights=distance;, score=0.577 total time=   2.4s
[CV 3/5; 4/88] START leaf_size=20, n_neighbors=5, weights=distance..............
[CV 3/5; 4/88] END leaf_size=20, n_neighbors=5, weights=distance;, score=0.589 total time=   2.6s
[CV 4/5; 4/88] START leaf_size=20, n_neighbors=5, weights=distance..............
[CV 4/5; 4/88] END leaf_size=20, n_neighbors=5, weights=distance;, score=0.588 total time=   2.5s
[CV 5/5; 4/88] START leaf_size=20, n_neighbors=5, weights=distance..............
[CV 5/5; 4/88] END leaf_size=20, n_neighbors=5, weights=distance;, score=0.585 total time=   2.6s
[CV 1/5; 5/88] START leaf_size=20, n_neighbors=7, weights=uniform...............
[CV 1/5; 5/88] END leaf_size=20, n_neighbors=7, weights=uniform;, score=0.582 total time=   2.7s
[CV 2/5; 5/88] START leaf_size=20, n_neighbors=7, weights=uniform...............
[CV 2/5; 5/88] END leaf_size=20, n_neighbors=7, weights=uniform;, score=0.574 total time=   2.6s
[CV 3/5; 5/88] START leaf_size=20, n_neighbors=7, weights=uniform...............
[CV 3/5; 5/88] END leaf_size=20, n_neighbors=7, weights=uniform;, score=0.581 total time=   2.7s
[CV 4/5; 5/88] START leaf_size=20, n_neighbors=7, weights=uniform...............
[CV 4/5; 5/88] END leaf_size=20, n_neighbors=7, weights=uniform;, score=0.584 total time=   2.7s
[CV 5/5; 5/88] START leaf_size=20, n_neighbors=7, weights=uniform...............
[CV 5/5; 5/88] END leaf_size=20, n_neighbors=7, weights=uniform;, score=0.583 total time=   2.7s
[CV 1/5; 6/88] START leaf_size=20, n_neighbors=7, weights=distance..............
[CV 1/5; 6/88] END leaf_size=20, n_neighbors=7, weights=distance;, score=0.582 total time=   2.6s
[CV 2/5; 6/88] START leaf_size=20, n_neighbors=7, weights=distance..............
[CV 2/5; 6/88] END leaf_size=20, n_neighbors=7, weights=distance;, score=0.574 total time=   2.5s
[CV 3/5; 6/88] START leaf_size=20, n_neighbors=7, weights=distance..............
[CV 3/5; 6/88] END leaf_size=20, n_neighbors=7, weights=distance;, score=0.581 total time=   2.8s
[CV 4/5; 6/88] START leaf_size=20, n_neighbors=7, weights=distance..............
[CV 4/5; 6/88] END leaf_size=20, n_neighbors=7, weights=distance;, score=0.585 total time=   2.7s
[CV 5/5; 6/88] START leaf_size=20, n_neighbors=7, weights=distance..............
[CV 5/5; 6/88] END leaf_size=20, n_neighbors=7, weights=distance;, score=0.583 total time=   2.5s
[CV 1/5; 7/88] START leaf_size=20, n_neighbors=9, weights=uniform...............
[CV 1/5; 7/88] END leaf_size=20, n_neighbors=9, weights=uniform;, score=0.575 total time=   2.6s
[CV 2/5; 7/88] START leaf_size=20, n_neighbors=9, weights=uniform...............
[CV 2/5; 7/88] END leaf_size=20, n_neighbors=9, weights=uniform;, score=0.572 total time=   2.5s
[CV 3/5; 7/88] START leaf_size=20, n_neighbors=9, weights=uniform...............
[CV 3/5; 7/88] END leaf_size=20, n_neighbors=9, weights=uniform;, score=0.581 total time=   2.7s
[CV 4/5; 7/88] START leaf_size=20, n_neighbors=9, weights=uniform...............
[CV 4/5; 7/88] END leaf_size=20, n_neighbors=9, weights=uniform;, score=0.584 total time=   2.7s
[CV 5/5; 7/88] START leaf_size=20, n_neighbors=9, weights=uniform...............
[CV 5/5; 7/88] END leaf_size=20, n_neighbors=9, weights=uniform;, score=0.580 total time=   2.7s
[CV 1/5; 8/88] START leaf_size=20, n_neighbors=9, weights=distance..............
[CV 1/5; 8/88] END leaf_size=20, n_neighbors=9, weights=distance;, score=0.575 total time=   2.5s
[CV 2/5; 8/88] START leaf_size=20, n_neighbors=9, weights=distance..............
[CV 2/5; 8/88] END leaf_size=20, n_neighbors=9, weights=distance;, score=0.572 total time=   2.5s
[CV 3/5; 8/88] START leaf_size=20, n_neighbors=9, weights=distance..............
[CV 3/5; 8/88] END leaf_size=20, n_neighbors=9, weights=distance;, score=0.581 total time=   2.6s
[CV 4/5; 8/88] START leaf_size=20, n_neighbors=9, weights=distance..............
[CV 4/5; 8/88] END leaf_size=20, n_neighbors=9, weights=distance;, score=0.584 total time=   2.6s
[CV 5/5; 8/88] START leaf_size=20, n_neighbors=9, weights=distance..............
[CV 5/5; 8/88] END leaf_size=20, n_neighbors=9, weights=distance;, score=0.580 total time=   2.7s
[CV 1/5; 9/88] START leaf_size=20, n_neighbors=15, weights=uniform..............
[CV 1/5; 9/88] END leaf_size=20, n_neighbors=15, weights=uniform;, score=0.569 total time=   2.8s
[CV 2/5; 9/88] START leaf_size=20, n_neighbors=15, weights=uniform..............
[CV 2/5; 9/88] END leaf_size=20, n_neighbors=15, weights=uniform;, score=0.563 total time=   2.5s
[CV 3/5; 9/88] START leaf_size=20, n_neighbors=15, weights=uniform..............
[CV 3/5; 9/88] END leaf_size=20, n_neighbors=15, weights=uniform;, score=0.578 total time=   2.6s
[CV 4/5; 9/88] START leaf_size=20, n_neighbors=15, weights=uniform..............
[CV 4/5; 9/88] END leaf_size=20, n_neighbors=15, weights=uniform;, score=0.568 total time=   2.8s
[CV 5/5; 9/88] START leaf_size=20, n_neighbors=15, weights=uniform..............
[CV 5/5; 9/88] END leaf_size=20, n_neighbors=15, weights=uniform;, score=0.567 total time=   2.8s
[CV 1/5; 10/88] START leaf_size=20, n_neighbors=15, weights=distance............
[CV 1/5; 10/88] END leaf_size=20, n_neighbors=15, weights=distance;, score=0.569 total time=   2.5s
[CV 2/5; 10/88] START leaf_size=20, n_neighbors=15, weights=distance............
[CV 2/5; 10/88] END leaf_size=20, n_neighbors=15, weights=distance;, score=0.563 total time=   2.4s
[CV 3/5; 10/88] START leaf_size=20, n_neighbors=15, weights=distance............
[CV 3/5; 10/88] END leaf_size=20, n_neighbors=15, weights=distance;, score=0.578 total time=   2.6s
[CV 4/5; 10/88] START leaf_size=20, n_neighbors=15, weights=distance............
[CV 4/5; 10/88] END leaf_size=20, n_neighbors=15, weights=distance;, score=0.568 total time=   2.7s
[CV 5/5; 10/88] START leaf_size=20, n_neighbors=15, weights=distance............
[CV 5/5; 10/88] END leaf_size=20, n_neighbors=15, weights=distance;, score=0.567 total time=   2.8s
[CV 1/5; 11/88] START leaf_size=20, n_neighbors=19, weights=uniform.............
[CV 1/5; 11/88] END leaf_size=20, n_neighbors=19, weights=uniform;, score=0.560 total time=   2.7s
[CV 2/5; 11/88] START leaf_size=20, n_neighbors=19, weights=uniform.............
[CV 2/5; 11/88] END leaf_size=20, n_neighbors=19, weights=uniform;, score=0.556 total time=   2.6s
[CV 3/5; 11/88] START leaf_size=20, n_neighbors=19, weights=uniform.............
[CV 3/5; 11/88] END leaf_size=20, n_neighbors=19, weights=uniform;, score=0.567 total time=   2.7s
[CV 4/5; 11/88] START leaf_size=20, n_neighbors=19, weights=uniform.............
[CV 4/5; 11/88] END leaf_size=20, n_neighbors=19, weights=uniform;, score=0.563 total time=   2.7s
[CV 5/5; 11/88] START leaf_size=20, n_neighbors=19, weights=uniform.............
[CV 5/5; 11/88] END leaf_size=20, n_neighbors=19, weights=uniform;, score=0.560 total time=   2.7s
[CV 1/5; 12/88] START leaf_size=20, n_neighbors=19, weights=distance............
[CV 1/5; 12/88] END leaf_size=20, n_neighbors=19, weights=distance;, score=0.560 total time=   2.5s
[CV 2/5; 12/88] START leaf_size=20, n_neighbors=19, weights=distance............
[CV 2/5; 12/88] END leaf_size=20, n_neighbors=19, weights=distance;, score=0.556 total time=   2.4s
[CV 3/5; 12/88] START leaf_size=20, n_neighbors=19, weights=distance............
[CV 3/5; 12/88] END leaf_size=20, n_neighbors=19, weights=distance;, score=0.567 total time=   2.6s
[CV 4/5; 12/88] START leaf_size=20, n_neighbors=19, weights=distance............
[CV 4/5; 12/88] END leaf_size=20, n_neighbors=19, weights=distance;, score=0.563 total time=   2.5s
[CV 5/5; 12/88] START leaf_size=20, n_neighbors=19, weights=distance............
[CV 5/5; 12/88] END leaf_size=20, n_neighbors=19, weights=distance;, score=0.560 total time=   2.6s
[CV 1/5; 13/88] START leaf_size=20, n_neighbors=25, weights=uniform.............
[CV 1/5; 13/88] END leaf_size=20, n_neighbors=25, weights=uniform;, score=0.556 total time=   2.8s
[CV 2/5; 13/88] START leaf_size=20, n_neighbors=25, weights=uniform.............
[CV 2/5; 13/88] END leaf_size=20, n_neighbors=25, weights=uniform;, score=0.550 total time=   2.7s
[CV 3/5; 13/88] START leaf_size=20, n_neighbors=25, weights=uniform.............
[CV 3/5; 13/88] END leaf_size=20, n_neighbors=25, weights=uniform;, score=0.563 total time=   2.9s
[CV 4/5; 13/88] START leaf_size=20, n_neighbors=25, weights=uniform.............
[CV 4/5; 13/88] END leaf_size=20, n_neighbors=25, weights=uniform;, score=0.560 total time=   2.8s
[CV 5/5; 13/88] START leaf_size=20, n_neighbors=25, weights=uniform.............
[CV 5/5; 13/88] END leaf_size=20, n_neighbors=25, weights=uniform;, score=0.557 total time=   2.8s
[CV 1/5; 14/88] START leaf_size=20, n_neighbors=25, weights=distance............
[CV 1/5; 14/88] END leaf_size=20, n_neighbors=25, weights=distance;, score=0.556 total time=   2.6s
[CV 2/5; 14/88] START leaf_size=20, n_neighbors=25, weights=distance............
[CV 2/5; 14/88] END leaf_size=20, n_neighbors=25, weights=distance;, score=0.550 total time=   2.5s
[CV 3/5; 14/88] START leaf_size=20, n_neighbors=25, weights=distance............
[CV 3/5; 14/88] END leaf_size=20, n_neighbors=25, weights=distance;, score=0.563 total time=   2.6s
[CV 4/5; 14/88] START leaf_size=20, n_neighbors=25, weights=distance............
[CV 4/5; 14/88] END leaf_size=20, n_neighbors=25, weights=distance;, score=0.560 total time=   2.5s
[CV 5/5; 14/88] START leaf_size=20, n_neighbors=25, weights=distance............
[CV 5/5; 14/88] END leaf_size=20, n_neighbors=25, weights=distance;, score=0.557 total time=   2.6s
[CV 1/5; 15/88] START leaf_size=20, n_neighbors=35, weights=uniform.............
[CV 1/5; 15/88] END leaf_size=20, n_neighbors=35, weights=uniform;, score=0.547 total time=   2.7s
[CV 2/5; 15/88] START leaf_size=20, n_neighbors=35, weights=uniform.............
[CV 2/5; 15/88] END leaf_size=20, n_neighbors=35, weights=uniform;, score=0.546 total time=   2.6s
[CV 3/5; 15/88] START leaf_size=20, n_neighbors=35, weights=uniform.............
[CV 3/5; 15/88] END leaf_size=20, n_neighbors=35, weights=uniform;, score=0.553 total time=   2.8s
[CV 4/5; 15/88] START leaf_size=20, n_neighbors=35, weights=uniform.............
[CV 4/5; 15/88] END leaf_size=20, n_neighbors=35, weights=uniform;, score=0.547 total time=   2.7s
[CV 5/5; 15/88] START leaf_size=20, n_neighbors=35, weights=uniform.............
[CV 5/5; 15/88] END leaf_size=20, n_neighbors=35, weights=uniform;, score=0.550 total time=   2.8s
[CV 1/5; 16/88] START leaf_size=20, n_neighbors=35, weights=distance............
[CV 1/5; 16/88] END leaf_size=20, n_neighbors=35, weights=distance;, score=0.547 total time=   2.5s
[CV 2/5; 16/88] START leaf_size=20, n_neighbors=35, weights=distance............
[CV 2/5; 16/88] END leaf_size=20, n_neighbors=35, weights=distance;, score=0.546 total time=   2.5s
[CV 3/5; 16/88] START leaf_size=20, n_neighbors=35, weights=distance............
[CV 3/5; 16/88] END leaf_size=20, n_neighbors=35, weights=distance;, score=0.554 total time=   2.6s
[CV 4/5; 16/88] START leaf_size=20, n_neighbors=35, weights=distance............
[CV 4/5; 16/88] END leaf_size=20, n_neighbors=35, weights=distance;, score=0.547 total time=   2.6s
[CV 5/5; 16/88] START leaf_size=20, n_neighbors=35, weights=distance............
[CV 5/5; 16/88] END leaf_size=20, n_neighbors=35, weights=distance;, score=0.550 total time=   2.6s
[CV 1/5; 17/88] START leaf_size=20, n_neighbors=55, weights=uniform.............
[CV 1/5; 17/88] END leaf_size=20, n_neighbors=55, weights=uniform;, score=0.533 total time=   2.7s
[CV 2/5; 17/88] START leaf_size=20, n_neighbors=55, weights=uniform.............
[CV 2/5; 17/88] END leaf_size=20, n_neighbors=55, weights=uniform;, score=0.535 total time=   2.6s
[CV 3/5; 17/88] START leaf_size=20, n_neighbors=55, weights=uniform.............
[CV 3/5; 17/88] END leaf_size=20, n_neighbors=55, weights=uniform;, score=0.540 total time=   2.7s
[CV 4/5; 17/88] START leaf_size=20, n_neighbors=55, weights=uniform.............
[CV 4/5; 17/88] END leaf_size=20, n_neighbors=55, weights=uniform;, score=0.538 total time=   2.7s
[CV 5/5; 17/88] START leaf_size=20, n_neighbors=55, weights=uniform.............
[CV 5/5; 17/88] END leaf_size=20, n_neighbors=55, weights=uniform;, score=0.532 total time=   2.7s
[CV 1/5; 18/88] START leaf_size=20, n_neighbors=55, weights=distance............
[CV 1/5; 18/88] END leaf_size=20, n_neighbors=55, weights=distance;, score=0.533 total time=   2.6s
[CV 2/5; 18/88] START leaf_size=20, n_neighbors=55, weights=distance............
[CV 2/5; 18/88] END leaf_size=20, n_neighbors=55, weights=distance;, score=0.535 total time=   2.5s
[CV 3/5; 18/88] START leaf_size=20, n_neighbors=55, weights=distance............
[CV 3/5; 18/88] END leaf_size=20, n_neighbors=55, weights=distance;, score=0.540 total time=   2.6s
[CV 4/5; 18/88] START leaf_size=20, n_neighbors=55, weights=distance............
[CV 4/5; 18/88] END leaf_size=20, n_neighbors=55, weights=distance;, score=0.538 total time=   2.6s
[CV 5/5; 18/88] START leaf_size=20, n_neighbors=55, weights=distance............
[CV 5/5; 18/88] END leaf_size=20, n_neighbors=55, weights=distance;, score=0.532 total time=   2.6s
[CV 1/5; 19/88] START leaf_size=20, n_neighbors=75, weights=uniform.............
[CV 1/5; 19/88] END leaf_size=20, n_neighbors=75, weights=uniform;, score=0.528 total time=   2.7s
[CV 2/5; 19/88] START leaf_size=20, n_neighbors=75, weights=uniform.............
[CV 2/5; 19/88] END leaf_size=20, n_neighbors=75, weights=uniform;, score=0.525 total time=   2.6s
[CV 3/5; 19/88] START leaf_size=20, n_neighbors=75, weights=uniform.............
[CV 3/5; 19/88] END leaf_size=20, n_neighbors=75, weights=uniform;, score=0.529 total time=   2.7s
[CV 4/5; 19/88] START leaf_size=20, n_neighbors=75, weights=uniform.............
[CV 4/5; 19/88] END leaf_size=20, n_neighbors=75, weights=uniform;, score=0.533 total time=   2.8s
[CV 5/5; 19/88] START leaf_size=20, n_neighbors=75, weights=uniform.............
[CV 5/5; 19/88] END leaf_size=20, n_neighbors=75, weights=uniform;, score=0.524 total time=   2.7s
[CV 1/5; 20/88] START leaf_size=20, n_neighbors=75, weights=distance............
[CV 1/5; 20/88] END leaf_size=20, n_neighbors=75, weights=distance;, score=0.528 total time=   2.6s
[CV 2/5; 20/88] START leaf_size=20, n_neighbors=75, weights=distance............
[CV 2/5; 20/88] END leaf_size=20, n_neighbors=75, weights=distance;, score=0.525 total time=   2.6s
[CV 3/5; 20/88] START leaf_size=20, n_neighbors=75, weights=distance............
[CV 3/5; 20/88] END leaf_size=20, n_neighbors=75, weights=distance;, score=0.529 total time=   2.8s
[CV 4/5; 20/88] START leaf_size=20, n_neighbors=75, weights=distance............
[CV 4/5; 20/88] END leaf_size=20, n_neighbors=75, weights=distance;, score=0.533 total time=   2.7s
[CV 5/5; 20/88] START leaf_size=20, n_neighbors=75, weights=distance............
[CV 5/5; 20/88] END leaf_size=20, n_neighbors=75, weights=distance;, score=0.525 total time=   3.1s
[CV 1/5; 21/88] START leaf_size=20, n_neighbors=99, weights=uniform.............
[CV 1/5; 21/88] END leaf_size=20, n_neighbors=99, weights=uniform;, score=0.523 total time=   3.2s
[CV 2/5; 21/88] START leaf_size=20, n_neighbors=99, weights=uniform.............
[CV 2/5; 21/88] END leaf_size=20, n_neighbors=99, weights=uniform;, score=0.523 total time=   3.0s
[CV 3/5; 21/88] START leaf_size=20, n_neighbors=99, weights=uniform.............
[CV 3/5; 21/88] END leaf_size=20, n_neighbors=99, weights=uniform;, score=0.523 total time=   3.0s
[CV 4/5; 21/88] START leaf_size=20, n_neighbors=99, weights=uniform.............
[CV 4/5; 21/88] END leaf_size=20, n_neighbors=99, weights=uniform;, score=0.526 total time=   2.9s
[CV 5/5; 21/88] START leaf_size=20, n_neighbors=99, weights=uniform.............
[CV 5/5; 21/88] END leaf_size=20, n_neighbors=99, weights=uniform;, score=0.520 total time=   2.9s
[CV 1/5; 22/88] START leaf_size=20, n_neighbors=99, weights=distance............
[CV 1/5; 22/88] END leaf_size=20, n_neighbors=99, weights=distance;, score=0.524 total time=   2.8s
[CV 2/5; 22/88] START leaf_size=20, n_neighbors=99, weights=distance............
[CV 2/5; 22/88] END leaf_size=20, n_neighbors=99, weights=distance;, score=0.523 total time=   2.9s
[CV 3/5; 22/88] START leaf_size=20, n_neighbors=99, weights=distance............
[CV 3/5; 22/88] END leaf_size=20, n_neighbors=99, weights=distance;, score=0.523 total time=   3.1s
[CV 4/5; 22/88] START leaf_size=20, n_neighbors=99, weights=distance............
[CV 4/5; 22/88] END leaf_size=20, n_neighbors=99, weights=distance;, score=0.527 total time=   3.1s
[CV 5/5; 22/88] START leaf_size=20, n_neighbors=99, weights=distance............
[CV 5/5; 22/88] END leaf_size=20, n_neighbors=99, weights=distance;, score=0.521 total time=   2.8s
[CV 1/5; 23/88] START leaf_size=30, n_neighbors=3, weights=uniform..............
[CV 1/5; 23/88] END leaf_size=30, n_neighbors=3, weights=uniform;, score=0.589 total time=   2.2s
[CV 2/5; 23/88] START leaf_size=30, n_neighbors=3, weights=uniform..............
[CV 2/5; 23/88] END leaf_size=30, n_neighbors=3, weights=uniform;, score=0.581 total time=   2.2s
[CV 3/5; 23/88] START leaf_size=30, n_neighbors=3, weights=uniform..............
[CV 3/5; 23/88] END leaf_size=30, n_neighbors=3, weights=uniform;, score=0.589 total time=   2.2s
[CV 4/5; 23/88] START leaf_size=30, n_neighbors=3, weights=uniform..............
[CV 4/5; 23/88] END leaf_size=30, n_neighbors=3, weights=uniform;, score=0.590 total time=   2.2s
[CV 5/5; 23/88] START leaf_size=30, n_neighbors=3, weights=uniform..............
[CV 5/5; 23/88] END leaf_size=30, n_neighbors=3, weights=uniform;, score=0.581 total time=   2.2s
[CV 1/5; 24/88] START leaf_size=30, n_neighbors=3, weights=distance.............
[CV 1/5; 24/88] END leaf_size=30, n_neighbors=3, weights=distance;, score=0.589 total time=   2.0s
[CV 2/5; 24/88] START leaf_size=30, n_neighbors=3, weights=distance.............
[CV 2/5; 24/88] END leaf_size=30, n_neighbors=3, weights=distance;, score=0.581 total time=   2.0s
[CV 3/5; 24/88] START leaf_size=30, n_neighbors=3, weights=distance.............
[CV 3/5; 24/88] END leaf_size=30, n_neighbors=3, weights=distance;, score=0.589 total time=   2.0s
[CV 4/5; 24/88] START leaf_size=30, n_neighbors=3, weights=distance.............
[CV 4/5; 24/88] END leaf_size=30, n_neighbors=3, weights=distance;, score=0.590 total time=   2.1s
[CV 5/5; 24/88] START leaf_size=30, n_neighbors=3, weights=distance.............
[CV 5/5; 24/88] END leaf_size=30, n_neighbors=3, weights=distance;, score=0.581 total time=   2.0s
[CV 1/5; 25/88] START leaf_size=30, n_neighbors=5, weights=uniform..............
[CV 1/5; 25/88] END leaf_size=30, n_neighbors=5, weights=uniform;, score=0.592 total time=   2.9s
[CV 2/5; 25/88] START leaf_size=30, n_neighbors=5, weights=uniform..............
[CV 2/5; 25/88] END leaf_size=30, n_neighbors=5, weights=uniform;, score=0.577 total time=   2.9s
[CV 3/5; 25/88] START leaf_size=30, n_neighbors=5, weights=uniform..............
[CV 3/5; 25/88] END leaf_size=30, n_neighbors=5, weights=uniform;, score=0.589 total time=   2.8s
[CV 4/5; 25/88] START leaf_size=30, n_neighbors=5, weights=uniform..............
[CV 4/5; 25/88] END leaf_size=30, n_neighbors=5, weights=uniform;, score=0.588 total time=   2.7s
[CV 5/5; 25/88] START leaf_size=30, n_neighbors=5, weights=uniform..............
[CV 5/5; 25/88] END leaf_size=30, n_neighbors=5, weights=uniform;, score=0.585 total time=   2.7s
[CV 1/5; 26/88] START leaf_size=30, n_neighbors=5, weights=distance.............
[CV 1/5; 26/88] END leaf_size=30, n_neighbors=5, weights=distance;, score=0.592 total time=   2.5s
[CV 2/5; 26/88] START leaf_size=30, n_neighbors=5, weights=distance.............
[CV 2/5; 26/88] END leaf_size=30, n_neighbors=5, weights=distance;, score=0.577 total time=   2.3s
[CV 3/5; 26/88] START leaf_size=30, n_neighbors=5, weights=distance.............
[CV 3/5; 26/88] END leaf_size=30, n_neighbors=5, weights=distance;, score=0.589 total time=   2.5s
[CV 4/5; 26/88] START leaf_size=30, n_neighbors=5, weights=distance.............
[CV 4/5; 26/88] END leaf_size=30, n_neighbors=5, weights=distance;, score=0.588 total time=   2.5s
[CV 5/5; 26/88] START leaf_size=30, n_neighbors=5, weights=distance.............
[CV 5/5; 26/88] END leaf_size=30, n_neighbors=5, weights=distance;, score=0.585 total time=   2.6s
[CV 1/5; 27/88] START leaf_size=30, n_neighbors=7, weights=uniform..............
[CV 1/5; 27/88] END leaf_size=30, n_neighbors=7, weights=uniform;, score=0.582 total time=   2.7s
[CV 2/5; 27/88] START leaf_size=30, n_neighbors=7, weights=uniform..............
[CV 2/5; 27/88] END leaf_size=30, n_neighbors=7, weights=uniform;, score=0.574 total time=   2.7s
[CV 3/5; 27/88] START leaf_size=30, n_neighbors=7, weights=uniform..............
[CV 3/5; 27/88] END leaf_size=30, n_neighbors=7, weights=uniform;, score=0.581 total time=   2.9s
[CV 4/5; 27/88] START leaf_size=30, n_neighbors=7, weights=uniform..............
[CV 4/5; 27/88] END leaf_size=30, n_neighbors=7, weights=uniform;, score=0.584 total time=   2.9s
[CV 5/5; 27/88] START leaf_size=30, n_neighbors=7, weights=uniform..............
[CV 5/5; 27/88] END leaf_size=30, n_neighbors=7, weights=uniform;, score=0.583 total time=   2.8s
[CV 1/5; 28/88] START leaf_size=30, n_neighbors=7, weights=distance.............
[CV 1/5; 28/88] END leaf_size=30, n_neighbors=7, weights=distance;, score=0.582 total time=   2.5s
[CV 2/5; 28/88] START leaf_size=30, n_neighbors=7, weights=distance.............
[CV 2/5; 28/88] END leaf_size=30, n_neighbors=7, weights=distance;, score=0.574 total time=   2.4s
[CV 3/5; 28/88] START leaf_size=30, n_neighbors=7, weights=distance.............
[CV 3/5; 28/88] END leaf_size=30, n_neighbors=7, weights=distance;, score=0.581 total time=   2.6s
[CV 4/5; 28/88] START leaf_size=30, n_neighbors=7, weights=distance.............
[CV 4/5; 28/88] END leaf_size=30, n_neighbors=7, weights=distance;, score=0.585 total time=   2.5s
[CV 5/5; 28/88] START leaf_size=30, n_neighbors=7, weights=distance.............
[CV 5/5; 28/88] END leaf_size=30, n_neighbors=7, weights=distance;, score=0.583 total time=   2.6s
[CV 1/5; 29/88] START leaf_size=30, n_neighbors=9, weights=uniform..............
[CV 1/5; 29/88] END leaf_size=30, n_neighbors=9, weights=uniform;, score=0.575 total time=   2.7s
[CV 2/5; 29/88] START leaf_size=30, n_neighbors=9, weights=uniform..............
[CV 2/5; 29/88] END leaf_size=30, n_neighbors=9, weights=uniform;, score=0.572 total time=   2.5s
[CV 3/5; 29/88] START leaf_size=30, n_neighbors=9, weights=uniform..............
[CV 3/5; 29/88] END leaf_size=30, n_neighbors=9, weights=uniform;, score=0.581 total time=   2.7s
[CV 4/5; 29/88] START leaf_size=30, n_neighbors=9, weights=uniform..............
[CV 4/5; 29/88] END leaf_size=30, n_neighbors=9, weights=uniform;, score=0.584 total time=   2.6s
[CV 5/5; 29/88] START leaf_size=30, n_neighbors=9, weights=uniform..............
[CV 5/5; 29/88] END leaf_size=30, n_neighbors=9, weights=uniform;, score=0.580 total time=   2.8s
[CV 1/5; 30/88] START leaf_size=30, n_neighbors=9, weights=distance.............
[CV 1/5; 30/88] END leaf_size=30, n_neighbors=9, weights=distance;, score=0.575 total time=   2.7s
[CV 2/5; 30/88] START leaf_size=30, n_neighbors=9, weights=distance.............
[CV 2/5; 30/88] END leaf_size=30, n_neighbors=9, weights=distance;, score=0.572 total time=   2.5s
[CV 3/5; 30/88] START leaf_size=30, n_neighbors=9, weights=distance.............
[CV 3/5; 30/88] END leaf_size=30, n_neighbors=9, weights=distance;, score=0.581 total time=   2.5s
[CV 4/5; 30/88] START leaf_size=30, n_neighbors=9, weights=distance.............
[CV 4/5; 30/88] END leaf_size=30, n_neighbors=9, weights=distance;, score=0.584 total time=   2.5s
[CV 5/5; 30/88] START leaf_size=30, n_neighbors=9, weights=distance.............
[CV 5/5; 30/88] END leaf_size=30, n_neighbors=9, weights=distance;, score=0.580 total time=   2.5s
[CV 1/5; 31/88] START leaf_size=30, n_neighbors=15, weights=uniform.............
[CV 1/5; 31/88] END leaf_size=30, n_neighbors=15, weights=uniform;, score=0.569 total time=   2.6s
[CV 2/5; 31/88] START leaf_size=30, n_neighbors=15, weights=uniform.............
[CV 2/5; 31/88] END leaf_size=30, n_neighbors=15, weights=uniform;, score=0.563 total time=   2.6s
[CV 3/5; 31/88] START leaf_size=30, n_neighbors=15, weights=uniform.............
[CV 3/5; 31/88] END leaf_size=30, n_neighbors=15, weights=uniform;, score=0.578 total time=   2.9s
[CV 4/5; 31/88] START leaf_size=30, n_neighbors=15, weights=uniform.............
[CV 4/5; 31/88] END leaf_size=30, n_neighbors=15, weights=uniform;, score=0.568 total time=   2.8s
[CV 5/5; 31/88] START leaf_size=30, n_neighbors=15, weights=uniform.............
[CV 5/5; 31/88] END leaf_size=30, n_neighbors=15, weights=uniform;, score=0.567 total time=   2.7s
[CV 1/5; 32/88] START leaf_size=30, n_neighbors=15, weights=distance............
[CV 1/5; 32/88] END leaf_size=30, n_neighbors=15, weights=distance;, score=0.569 total time=   2.6s
[CV 2/5; 32/88] START leaf_size=30, n_neighbors=15, weights=distance............
[CV 2/5; 32/88] END leaf_size=30, n_neighbors=15, weights=distance;, score=0.563 total time=   2.4s
[CV 3/5; 32/88] START leaf_size=30, n_neighbors=15, weights=distance............
[CV 3/5; 32/88] END leaf_size=30, n_neighbors=15, weights=distance;, score=0.578 total time=   2.5s
[CV 4/5; 32/88] START leaf_size=30, n_neighbors=15, weights=distance............
[CV 4/5; 32/88] END leaf_size=30, n_neighbors=15, weights=distance;, score=0.568 total time=   2.5s
[CV 5/5; 32/88] START leaf_size=30, n_neighbors=15, weights=distance............
[CV 5/5; 32/88] END leaf_size=30, n_neighbors=15, weights=distance;, score=0.567 total time=   2.5s
[CV 1/5; 33/88] START leaf_size=30, n_neighbors=19, weights=uniform.............
[CV 1/5; 33/88] END leaf_size=30, n_neighbors=19, weights=uniform;, score=0.560 total time=   2.6s
[CV 2/5; 33/88] START leaf_size=30, n_neighbors=19, weights=uniform.............
[CV 2/5; 33/88] END leaf_size=30, n_neighbors=19, weights=uniform;, score=0.556 total time=   2.5s
[CV 3/5; 33/88] START leaf_size=30, n_neighbors=19, weights=uniform.............
[CV 3/5; 33/88] END leaf_size=30, n_neighbors=19, weights=uniform;, score=0.567 total time=   2.7s
[CV 4/5; 33/88] START leaf_size=30, n_neighbors=19, weights=uniform.............
[CV 4/5; 33/88] END leaf_size=30, n_neighbors=19, weights=uniform;, score=0.563 total time=   2.9s
[CV 5/5; 33/88] START leaf_size=30, n_neighbors=19, weights=uniform.............
[CV 5/5; 33/88] END leaf_size=30, n_neighbors=19, weights=uniform;, score=0.560 total time=   2.8s
[CV 1/5; 34/88] START leaf_size=30, n_neighbors=19, weights=distance............
[CV 1/5; 34/88] END leaf_size=30, n_neighbors=19, weights=distance;, score=0.560 total time=   2.6s
[CV 2/5; 34/88] START leaf_size=30, n_neighbors=19, weights=distance............
[CV 2/5; 34/88] END leaf_size=30, n_neighbors=19, weights=distance;, score=0.556 total time=   2.5s
[CV 3/5; 34/88] START leaf_size=30, n_neighbors=19, weights=distance............
[CV 3/5; 34/88] END leaf_size=30, n_neighbors=19, weights=distance;, score=0.567 total time=   2.6s
[CV 4/5; 34/88] START leaf_size=30, n_neighbors=19, weights=distance............
[CV 4/5; 34/88] END leaf_size=30, n_neighbors=19, weights=distance;, score=0.563 total time=   2.5s
[CV 5/5; 34/88] START leaf_size=30, n_neighbors=19, weights=distance............
[CV 5/5; 34/88] END leaf_size=30, n_neighbors=19, weights=distance;, score=0.560 total time=   2.7s
[CV 1/5; 35/88] START leaf_size=30, n_neighbors=25, weights=uniform.............
[CV 1/5; 35/88] END leaf_size=30, n_neighbors=25, weights=uniform;, score=0.556 total time=   2.8s
[CV 2/5; 35/88] START leaf_size=30, n_neighbors=25, weights=uniform.............
[CV 2/5; 35/88] END leaf_size=30, n_neighbors=25, weights=uniform;, score=0.550 total time=   2.6s
[CV 3/5; 35/88] START leaf_size=30, n_neighbors=25, weights=uniform.............
[CV 3/5; 35/88] END leaf_size=30, n_neighbors=25, weights=uniform;, score=0.563 total time=   2.7s
[CV 4/5; 35/88] START leaf_size=30, n_neighbors=25, weights=uniform.............
[CV 4/5; 35/88] END leaf_size=30, n_neighbors=25, weights=uniform;, score=0.560 total time=   2.7s
[CV 5/5; 35/88] START leaf_size=30, n_neighbors=25, weights=uniform.............
[CV 5/5; 35/88] END leaf_size=30, n_neighbors=25, weights=uniform;, score=0.557 total time=   2.9s
[CV 1/5; 36/88] START leaf_size=30, n_neighbors=25, weights=distance............
[CV 1/5; 36/88] END leaf_size=30, n_neighbors=25, weights=distance;, score=0.556 total time=   2.9s
[CV 2/5; 36/88] START leaf_size=30, n_neighbors=25, weights=distance............
[CV 2/5; 36/88] END leaf_size=30, n_neighbors=25, weights=distance;, score=0.550 total time=   2.8s
[CV 3/5; 36/88] START leaf_size=30, n_neighbors=25, weights=distance............
[CV 3/5; 36/88] END leaf_size=30, n_neighbors=25, weights=distance;, score=0.563 total time=   3.2s
[CV 4/5; 36/88] START leaf_size=30, n_neighbors=25, weights=distance............
[CV 4/5; 36/88] END leaf_size=30, n_neighbors=25, weights=distance;, score=0.560 total time=   2.8s
[CV 5/5; 36/88] START leaf_size=30, n_neighbors=25, weights=distance............
[CV 5/5; 36/88] END leaf_size=30, n_neighbors=25, weights=distance;, score=0.557 total time=   3.0s
[CV 1/5; 37/88] START leaf_size=30, n_neighbors=35, weights=uniform.............
[CV 1/5; 37/88] END leaf_size=30, n_neighbors=35, weights=uniform;, score=0.547 total time=   3.1s
[CV 2/5; 37/88] START leaf_size=30, n_neighbors=35, weights=uniform.............
[CV 2/5; 37/88] END leaf_size=30, n_neighbors=35, weights=uniform;, score=0.546 total time=   2.9s
[CV 3/5; 37/88] START leaf_size=30, n_neighbors=35, weights=uniform.............
[CV 3/5; 37/88] END leaf_size=30, n_neighbors=35, weights=uniform;, score=0.553 total time=   3.0s
[CV 4/5; 37/88] START leaf_size=30, n_neighbors=35, weights=uniform.............
[CV 4/5; 37/88] END leaf_size=30, n_neighbors=35, weights=uniform;, score=0.547 total time=   2.8s
[CV 5/5; 37/88] START leaf_size=30, n_neighbors=35, weights=uniform.............
[CV 5/5; 37/88] END leaf_size=30, n_neighbors=35, weights=uniform;, score=0.550 total time=   2.8s
[CV 1/5; 38/88] START leaf_size=30, n_neighbors=35, weights=distance............
[CV 1/5; 38/88] END leaf_size=30, n_neighbors=35, weights=distance;, score=0.547 total time=   2.7s
[CV 2/5; 38/88] START leaf_size=30, n_neighbors=35, weights=distance............
[CV 2/5; 38/88] END leaf_size=30, n_neighbors=35, weights=distance;, score=0.546 total time=   2.6s
[CV 3/5; 38/88] START leaf_size=30, n_neighbors=35, weights=distance............
[CV 3/5; 38/88] END leaf_size=30, n_neighbors=35, weights=distance;, score=0.554 total time=   2.6s
[CV 4/5; 38/88] START leaf_size=30, n_neighbors=35, weights=distance............
[CV 4/5; 38/88] END leaf_size=30, n_neighbors=35, weights=distance;, score=0.547 total time=   2.6s
[CV 5/5; 38/88] START leaf_size=30, n_neighbors=35, weights=distance............
[CV 5/5; 38/88] END leaf_size=30, n_neighbors=35, weights=distance;, score=0.550 total time=   2.7s
[CV 1/5; 39/88] START leaf_size=30, n_neighbors=55, weights=uniform.............
[CV 1/5; 39/88] END leaf_size=30, n_neighbors=55, weights=uniform;, score=0.533 total time=   2.7s
[CV 2/5; 39/88] START leaf_size=30, n_neighbors=55, weights=uniform.............
[CV 2/5; 39/88] END leaf_size=30, n_neighbors=55, weights=uniform;, score=0.535 total time=   2.7s
[CV 3/5; 39/88] START leaf_size=30, n_neighbors=55, weights=uniform.............
[CV 3/5; 39/88] END leaf_size=30, n_neighbors=55, weights=uniform;, score=0.540 total time=   2.9s
[CV 4/5; 39/88] START leaf_size=30, n_neighbors=55, weights=uniform.............
[CV 4/5; 39/88] END leaf_size=30, n_neighbors=55, weights=uniform;, score=0.538 total time=   2.8s
[CV 5/5; 39/88] START leaf_size=30, n_neighbors=55, weights=uniform.............
[CV 5/5; 39/88] END leaf_size=30, n_neighbors=55, weights=uniform;, score=0.532 total time=   2.7s
[CV 1/5; 40/88] START leaf_size=30, n_neighbors=55, weights=distance............
[CV 1/5; 40/88] END leaf_size=30, n_neighbors=55, weights=distance;, score=0.533 total time=   2.6s
[CV 2/5; 40/88] START leaf_size=30, n_neighbors=55, weights=distance............
[CV 2/5; 40/88] END leaf_size=30, n_neighbors=55, weights=distance;, score=0.535 total time=   2.5s
[CV 3/5; 40/88] START leaf_size=30, n_neighbors=55, weights=distance............
[CV 3/5; 40/88] END leaf_size=30, n_neighbors=55, weights=distance;, score=0.540 total time=   2.6s
[CV 4/5; 40/88] START leaf_size=30, n_neighbors=55, weights=distance............
[CV 4/5; 40/88] END leaf_size=30, n_neighbors=55, weights=distance;, score=0.538 total time=   2.6s
[CV 5/5; 40/88] START leaf_size=30, n_neighbors=55, weights=distance............
[CV 5/5; 40/88] END leaf_size=30, n_neighbors=55, weights=distance;, score=0.532 total time=   2.6s
[CV 1/5; 41/88] START leaf_size=30, n_neighbors=75, weights=uniform.............
[CV 1/5; 41/88] END leaf_size=30, n_neighbors=75, weights=uniform;, score=0.528 total time=   2.7s
[CV 2/5; 41/88] START leaf_size=30, n_neighbors=75, weights=uniform.............
[CV 2/5; 41/88] END leaf_size=30, n_neighbors=75, weights=uniform;, score=0.525 total time=   2.7s
[CV 3/5; 41/88] START leaf_size=30, n_neighbors=75, weights=uniform.............
[CV 3/5; 41/88] END leaf_size=30, n_neighbors=75, weights=uniform;, score=0.529 total time=   2.9s
[CV 4/5; 41/88] START leaf_size=30, n_neighbors=75, weights=uniform.............
[CV 4/5; 41/88] END leaf_size=30, n_neighbors=75, weights=uniform;, score=0.533 total time=   2.8s
[CV 5/5; 41/88] START leaf_size=30, n_neighbors=75, weights=uniform.............
[CV 5/5; 41/88] END leaf_size=30, n_neighbors=75, weights=uniform;, score=0.524 total time=   3.0s
[CV 1/5; 42/88] START leaf_size=30, n_neighbors=75, weights=distance............
[CV 1/5; 42/88] END leaf_size=30, n_neighbors=75, weights=distance;, score=0.528 total time=   2.7s
[CV 2/5; 42/88] START leaf_size=30, n_neighbors=75, weights=distance............
[CV 2/5; 42/88] END leaf_size=30, n_neighbors=75, weights=distance;, score=0.525 total time=   2.5s
[CV 3/5; 42/88] START leaf_size=30, n_neighbors=75, weights=distance............
[CV 3/5; 42/88] END leaf_size=30, n_neighbors=75, weights=distance;, score=0.529 total time=   2.8s
[CV 4/5; 42/88] START leaf_size=30, n_neighbors=75, weights=distance............
[CV 4/5; 42/88] END leaf_size=30, n_neighbors=75, weights=distance;, score=0.533 total time=   2.8s
[CV 5/5; 42/88] START leaf_size=30, n_neighbors=75, weights=distance............
[CV 5/5; 42/88] END leaf_size=30, n_neighbors=75, weights=distance;, score=0.525 total time=   2.7s
[CV 1/5; 43/88] START leaf_size=30, n_neighbors=99, weights=uniform.............
[CV 1/5; 43/88] END leaf_size=30, n_neighbors=99, weights=uniform;, score=0.523 total time=   2.8s
[CV 2/5; 43/88] START leaf_size=30, n_neighbors=99, weights=uniform.............
[CV 2/5; 43/88] END leaf_size=30, n_neighbors=99, weights=uniform;, score=0.523 total time=   2.8s
[CV 3/5; 43/88] START leaf_size=30, n_neighbors=99, weights=uniform.............
[CV 3/5; 43/88] END leaf_size=30, n_neighbors=99, weights=uniform;, score=0.523 total time=   2.7s
[CV 4/5; 43/88] START leaf_size=30, n_neighbors=99, weights=uniform.............
[CV 4/5; 43/88] END leaf_size=30, n_neighbors=99, weights=uniform;, score=0.526 total time=   2.7s
[CV 5/5; 43/88] START leaf_size=30, n_neighbors=99, weights=uniform.............
[CV 5/5; 43/88] END leaf_size=30, n_neighbors=99, weights=uniform;, score=0.520 total time=   2.8s
[CV 1/5; 44/88] START leaf_size=30, n_neighbors=99, weights=distance............
[CV 1/5; 44/88] END leaf_size=30, n_neighbors=99, weights=distance;, score=0.524 total time=   2.9s
[CV 2/5; 44/88] START leaf_size=30, n_neighbors=99, weights=distance............
[CV 2/5; 44/88] END leaf_size=30, n_neighbors=99, weights=distance;, score=0.523 total time=   2.7s
[CV 3/5; 44/88] START leaf_size=30, n_neighbors=99, weights=distance............
[CV 3/5; 44/88] END leaf_size=30, n_neighbors=99, weights=distance;, score=0.523 total time=   3.0s
[CV 4/5; 44/88] START leaf_size=30, n_neighbors=99, weights=distance............
[CV 4/5; 44/88] END leaf_size=30, n_neighbors=99, weights=distance;, score=0.527 total time=   2.8s
[CV 5/5; 44/88] START leaf_size=30, n_neighbors=99, weights=distance............
[CV 5/5; 44/88] END leaf_size=30, n_neighbors=99, weights=distance;, score=0.521 total time=   2.8s
[CV 1/5; 45/88] START leaf_size=50, n_neighbors=3, weights=uniform..............
[CV 1/5; 45/88] END leaf_size=50, n_neighbors=3, weights=uniform;, score=0.589 total time=   2.2s
[CV 2/5; 45/88] START leaf_size=50, n_neighbors=3, weights=uniform..............
[CV 2/5; 45/88] END leaf_size=50, n_neighbors=3, weights=uniform;, score=0.581 total time=   2.5s
[CV 3/5; 45/88] START leaf_size=50, n_neighbors=3, weights=uniform..............
[CV 3/5; 45/88] END leaf_size=50, n_neighbors=3, weights=uniform;, score=0.589 total time=   2.3s
[CV 4/5; 45/88] START leaf_size=50, n_neighbors=3, weights=uniform..............
[CV 4/5; 45/88] END leaf_size=50, n_neighbors=3, weights=uniform;, score=0.590 total time=   2.2s
[CV 5/5; 45/88] START leaf_size=50, n_neighbors=3, weights=uniform..............
[CV 5/5; 45/88] END leaf_size=50, n_neighbors=3, weights=uniform;, score=0.581 total time=   2.2s
[CV 1/5; 46/88] START leaf_size=50, n_neighbors=3, weights=distance.............
[CV 1/5; 46/88] END leaf_size=50, n_neighbors=3, weights=distance;, score=0.589 total time=   2.0s
[CV 2/5; 46/88] START leaf_size=50, n_neighbors=3, weights=distance.............
[CV 2/5; 46/88] END leaf_size=50, n_neighbors=3, weights=distance;, score=0.581 total time=   2.1s
[CV 3/5; 46/88] START leaf_size=50, n_neighbors=3, weights=distance.............
[CV 3/5; 46/88] END leaf_size=50, n_neighbors=3, weights=distance;, score=0.589 total time=   2.0s
[CV 4/5; 46/88] START leaf_size=50, n_neighbors=3, weights=distance.............
[CV 4/5; 46/88] END leaf_size=50, n_neighbors=3, weights=distance;, score=0.590 total time=   2.0s
[CV 5/5; 46/88] START leaf_size=50, n_neighbors=3, weights=distance.............
[CV 5/5; 46/88] END leaf_size=50, n_neighbors=3, weights=distance;, score=0.581 total time=   2.1s
[CV 1/5; 47/88] START leaf_size=50, n_neighbors=5, weights=uniform..............
[CV 1/5; 47/88] END leaf_size=50, n_neighbors=5, weights=uniform;, score=0.592 total time=   2.7s
[CV 2/5; 47/88] START leaf_size=50, n_neighbors=5, weights=uniform..............
[CV 2/5; 47/88] END leaf_size=50, n_neighbors=5, weights=uniform;, score=0.577 total time=   2.6s
[CV 3/5; 47/88] START leaf_size=50, n_neighbors=5, weights=uniform..............
[CV 3/5; 47/88] END leaf_size=50, n_neighbors=5, weights=uniform;, score=0.589 total time=   2.7s
[CV 4/5; 47/88] START leaf_size=50, n_neighbors=5, weights=uniform..............
[CV 4/5; 47/88] END leaf_size=50, n_neighbors=5, weights=uniform;, score=0.588 total time=   2.7s
[CV 5/5; 47/88] START leaf_size=50, n_neighbors=5, weights=uniform..............
[CV 5/5; 47/88] END leaf_size=50, n_neighbors=5, weights=uniform;, score=0.585 total time=   2.7s
[CV 1/5; 48/88] START leaf_size=50, n_neighbors=5, weights=distance.............
[CV 1/5; 48/88] END leaf_size=50, n_neighbors=5, weights=distance;, score=0.592 total time=   2.5s
[CV 2/5; 48/88] START leaf_size=50, n_neighbors=5, weights=distance.............
[CV 2/5; 48/88] END leaf_size=50, n_neighbors=5, weights=distance;, score=0.577 total time=   2.4s
[CV 3/5; 48/88] START leaf_size=50, n_neighbors=5, weights=distance.............
[CV 3/5; 48/88] END leaf_size=50, n_neighbors=5, weights=distance;, score=0.589 total time=   2.6s
[CV 4/5; 48/88] START leaf_size=50, n_neighbors=5, weights=distance.............
[CV 4/5; 48/88] END leaf_size=50, n_neighbors=5, weights=distance;, score=0.588 total time=   2.5s
[CV 5/5; 48/88] START leaf_size=50, n_neighbors=5, weights=distance.............
[CV 5/5; 48/88] END leaf_size=50, n_neighbors=5, weights=distance;, score=0.585 total time=   2.6s
[CV 1/5; 49/88] START leaf_size=50, n_neighbors=7, weights=uniform..............
[CV 1/5; 49/88] END leaf_size=50, n_neighbors=7, weights=uniform;, score=0.582 total time=   2.8s
[CV 2/5; 49/88] START leaf_size=50, n_neighbors=7, weights=uniform..............
[CV 2/5; 49/88] END leaf_size=50, n_neighbors=7, weights=uniform;, score=0.574 total time=   2.7s
[CV 3/5; 49/88] START leaf_size=50, n_neighbors=7, weights=uniform..............
[CV 3/5; 49/88] END leaf_size=50, n_neighbors=7, weights=uniform;, score=0.581 total time=   2.8s
[CV 4/5; 49/88] START leaf_size=50, n_neighbors=7, weights=uniform..............
[CV 4/5; 49/88] END leaf_size=50, n_neighbors=7, weights=uniform;, score=0.584 total time=   2.7s
[CV 5/5; 49/88] START leaf_size=50, n_neighbors=7, weights=uniform..............
[CV 5/5; 49/88] END leaf_size=50, n_neighbors=7, weights=uniform;, score=0.583 total time=   2.9s
[CV 1/5; 50/88] START leaf_size=50, n_neighbors=7, weights=distance.............
[CV 1/5; 50/88] END leaf_size=50, n_neighbors=7, weights=distance;, score=0.582 total time=   2.6s
[CV 2/5; 50/88] START leaf_size=50, n_neighbors=7, weights=distance.............
[CV 2/5; 50/88] END leaf_size=50, n_neighbors=7, weights=distance;, score=0.574 total time=   2.4s
[CV 3/5; 50/88] START leaf_size=50, n_neighbors=7, weights=distance.............
[CV 3/5; 50/88] END leaf_size=50, n_neighbors=7, weights=distance;, score=0.581 total time=   2.6s
[CV 4/5; 50/88] START leaf_size=50, n_neighbors=7, weights=distance.............
[CV 4/5; 50/88] END leaf_size=50, n_neighbors=7, weights=distance;, score=0.585 total time=   2.7s
[CV 5/5; 50/88] START leaf_size=50, n_neighbors=7, weights=distance.............
[CV 5/5; 50/88] END leaf_size=50, n_neighbors=7, weights=distance;, score=0.583 total time=   2.6s
[CV 1/5; 51/88] START leaf_size=50, n_neighbors=9, weights=uniform..............
[CV 1/5; 51/88] END leaf_size=50, n_neighbors=9, weights=uniform;, score=0.575 total time=   3.2s
[CV 2/5; 51/88] START leaf_size=50, n_neighbors=9, weights=uniform..............
[CV 2/5; 51/88] END leaf_size=50, n_neighbors=9, weights=uniform;, score=0.572 total time=   2.7s
[CV 3/5; 51/88] START leaf_size=50, n_neighbors=9, weights=uniform..............
[CV 3/5; 51/88] END leaf_size=50, n_neighbors=9, weights=uniform;, score=0.581 total time=   2.8s
[CV 4/5; 51/88] START leaf_size=50, n_neighbors=9, weights=uniform..............
[CV 4/5; 51/88] END leaf_size=50, n_neighbors=9, weights=uniform;, score=0.584 total time=   2.7s
[CV 5/5; 51/88] START leaf_size=50, n_neighbors=9, weights=uniform..............
[CV 5/5; 51/88] END leaf_size=50, n_neighbors=9, weights=uniform;, score=0.580 total time=   2.7s
[CV 1/5; 52/88] START leaf_size=50, n_neighbors=9, weights=distance.............
[CV 1/5; 52/88] END leaf_size=50, n_neighbors=9, weights=distance;, score=0.575 total time=   2.6s
[CV 2/5; 52/88] START leaf_size=50, n_neighbors=9, weights=distance.............
[CV 2/5; 52/88] END leaf_size=50, n_neighbors=9, weights=distance;, score=0.572 total time=   2.5s
[CV 3/5; 52/88] START leaf_size=50, n_neighbors=9, weights=distance.............
[CV 3/5; 52/88] END leaf_size=50, n_neighbors=9, weights=distance;, score=0.581 total time=   2.6s
[CV 4/5; 52/88] START leaf_size=50, n_neighbors=9, weights=distance.............
[CV 4/5; 52/88] END leaf_size=50, n_neighbors=9, weights=distance;, score=0.584 total time=   2.6s
[CV 5/5; 52/88] START leaf_size=50, n_neighbors=9, weights=distance.............
[CV 5/5; 52/88] END leaf_size=50, n_neighbors=9, weights=distance;, score=0.580 total time=   2.7s
[CV 1/5; 53/88] START leaf_size=50, n_neighbors=15, weights=uniform.............
[CV 1/5; 53/88] END leaf_size=50, n_neighbors=15, weights=uniform;, score=0.569 total time=   2.7s
[CV 2/5; 53/88] START leaf_size=50, n_neighbors=15, weights=uniform.............
[CV 2/5; 53/88] END leaf_size=50, n_neighbors=15, weights=uniform;, score=0.563 total time=   2.6s
[CV 3/5; 53/88] START leaf_size=50, n_neighbors=15, weights=uniform.............
[CV 3/5; 53/88] END leaf_size=50, n_neighbors=15, weights=uniform;, score=0.578 total time=   2.8s
[CV 4/5; 53/88] START leaf_size=50, n_neighbors=15, weights=uniform.............
[CV 4/5; 53/88] END leaf_size=50, n_neighbors=15, weights=uniform;, score=0.568 total time=   2.8s
[CV 5/5; 53/88] START leaf_size=50, n_neighbors=15, weights=uniform.............
[CV 5/5; 53/88] END leaf_size=50, n_neighbors=15, weights=uniform;, score=0.567 total time=   3.0s
[CV 1/5; 54/88] START leaf_size=50, n_neighbors=15, weights=distance............
[CV 1/5; 54/88] END leaf_size=50, n_neighbors=15, weights=distance;, score=0.569 total time=   2.7s
[CV 2/5; 54/88] START leaf_size=50, n_neighbors=15, weights=distance............
[CV 2/5; 54/88] END leaf_size=50, n_neighbors=15, weights=distance;, score=0.563 total time=   2.6s
[CV 3/5; 54/88] START leaf_size=50, n_neighbors=15, weights=distance............
[CV 3/5; 54/88] END leaf_size=50, n_neighbors=15, weights=distance;, score=0.578 total time=   2.7s
[CV 4/5; 54/88] START leaf_size=50, n_neighbors=15, weights=distance............
[CV 4/5; 54/88] END leaf_size=50, n_neighbors=15, weights=distance;, score=0.568 total time=   2.7s
[CV 5/5; 54/88] START leaf_size=50, n_neighbors=15, weights=distance............
[CV 5/5; 54/88] END leaf_size=50, n_neighbors=15, weights=distance;, score=0.567 total time=   2.8s
[CV 1/5; 55/88] START leaf_size=50, n_neighbors=19, weights=uniform.............
[CV 1/5; 55/88] END leaf_size=50, n_neighbors=19, weights=uniform;, score=0.560 total time=   2.7s
[CV 2/5; 55/88] START leaf_size=50, n_neighbors=19, weights=uniform.............
[CV 2/5; 55/88] END leaf_size=50, n_neighbors=19, weights=uniform;, score=0.556 total time=   2.6s
[CV 3/5; 55/88] START leaf_size=50, n_neighbors=19, weights=uniform.............
[CV 3/5; 55/88] END leaf_size=50, n_neighbors=19, weights=uniform;, score=0.567 total time=   2.8s
[CV 4/5; 55/88] START leaf_size=50, n_neighbors=19, weights=uniform.............
[CV 4/5; 55/88] END leaf_size=50, n_neighbors=19, weights=uniform;, score=0.563 total time=   2.7s
[CV 5/5; 55/88] START leaf_size=50, n_neighbors=19, weights=uniform.............
[CV 5/5; 55/88] END leaf_size=50, n_neighbors=19, weights=uniform;, score=0.560 total time=   2.7s
[CV 1/5; 56/88] START leaf_size=50, n_neighbors=19, weights=distance............
[CV 1/5; 56/88] END leaf_size=50, n_neighbors=19, weights=distance;, score=0.560 total time=   2.6s
[CV 2/5; 56/88] START leaf_size=50, n_neighbors=19, weights=distance............
[CV 2/5; 56/88] END leaf_size=50, n_neighbors=19, weights=distance;, score=0.556 total time=   2.6s
[CV 3/5; 56/88] START leaf_size=50, n_neighbors=19, weights=distance............
[CV 3/5; 56/88] END leaf_size=50, n_neighbors=19, weights=distance;, score=0.567 total time=   2.9s
[CV 4/5; 56/88] START leaf_size=50, n_neighbors=19, weights=distance............
[CV 4/5; 56/88] END leaf_size=50, n_neighbors=19, weights=distance;, score=0.563 total time=   3.0s
[CV 5/5; 56/88] START leaf_size=50, n_neighbors=19, weights=distance............
[CV 5/5; 56/88] END leaf_size=50, n_neighbors=19, weights=distance;, score=0.560 total time=   2.9s
[CV 1/5; 57/88] START leaf_size=50, n_neighbors=25, weights=uniform.............
[CV 1/5; 57/88] END leaf_size=50, n_neighbors=25, weights=uniform;, score=0.556 total time=   2.8s
[CV 2/5; 57/88] START leaf_size=50, n_neighbors=25, weights=uniform.............
[CV 2/5; 57/88] END leaf_size=50, n_neighbors=25, weights=uniform;, score=0.550 total time=   2.7s
[CV 3/5; 57/88] START leaf_size=50, n_neighbors=25, weights=uniform.............
[CV 3/5; 57/88] END leaf_size=50, n_neighbors=25, weights=uniform;, score=0.563 total time=   2.9s
[CV 4/5; 57/88] START leaf_size=50, n_neighbors=25, weights=uniform.............
[CV 4/5; 57/88] END leaf_size=50, n_neighbors=25, weights=uniform;, score=0.560 total time=   2.8s
[CV 5/5; 57/88] START leaf_size=50, n_neighbors=25, weights=uniform.............
[CV 5/5; 57/88] END leaf_size=50, n_neighbors=25, weights=uniform;, score=0.557 total time=   2.9s
[CV 1/5; 58/88] START leaf_size=50, n_neighbors=25, weights=distance............
[CV 1/5; 58/88] END leaf_size=50, n_neighbors=25, weights=distance;, score=0.556 total time=   2.6s
[CV 2/5; 58/88] START leaf_size=50, n_neighbors=25, weights=distance............
[CV 2/5; 58/88] END leaf_size=50, n_neighbors=25, weights=distance;, score=0.550 total time=   2.5s
[CV 3/5; 58/88] START leaf_size=50, n_neighbors=25, weights=distance............
[CV 3/5; 58/88] END leaf_size=50, n_neighbors=25, weights=distance;, score=0.563 total time=   2.9s
[CV 4/5; 58/88] START leaf_size=50, n_neighbors=25, weights=distance............
[CV 4/5; 58/88] END leaf_size=50, n_neighbors=25, weights=distance;, score=0.560 total time=   2.8s
[CV 5/5; 58/88] START leaf_size=50, n_neighbors=25, weights=distance............
[CV 5/5; 58/88] END leaf_size=50, n_neighbors=25, weights=distance;, score=0.557 total time=   2.7s
[CV 1/5; 59/88] START leaf_size=50, n_neighbors=35, weights=uniform.............
[CV 1/5; 59/88] END leaf_size=50, n_neighbors=35, weights=uniform;, score=0.547 total time=   2.7s
[CV 2/5; 59/88] START leaf_size=50, n_neighbors=35, weights=uniform.............
[CV 2/5; 59/88] END leaf_size=50, n_neighbors=35, weights=uniform;, score=0.546 total time=   2.7s
[CV 3/5; 59/88] START leaf_size=50, n_neighbors=35, weights=uniform.............
[CV 3/5; 59/88] END leaf_size=50, n_neighbors=35, weights=uniform;, score=0.553 total time=   2.8s
[CV 4/5; 59/88] START leaf_size=50, n_neighbors=35, weights=uniform.............
[CV 4/5; 59/88] END leaf_size=50, n_neighbors=35, weights=uniform;, score=0.547 total time=   2.8s
[CV 5/5; 59/88] START leaf_size=50, n_neighbors=35, weights=uniform.............
[CV 5/5; 59/88] END leaf_size=50, n_neighbors=35, weights=uniform;, score=0.550 total time=   2.8s
[CV 1/5; 60/88] START leaf_size=50, n_neighbors=35, weights=distance............
[CV 1/5; 60/88] END leaf_size=50, n_neighbors=35, weights=distance;, score=0.547 total time=   2.7s
[CV 2/5; 60/88] START leaf_size=50, n_neighbors=35, weights=distance............
[CV 2/5; 60/88] END leaf_size=50, n_neighbors=35, weights=distance;, score=0.546 total time=   2.5s
[CV 3/5; 60/88] START leaf_size=50, n_neighbors=35, weights=distance............
[CV 3/5; 60/88] END leaf_size=50, n_neighbors=35, weights=distance;, score=0.554 total time=   2.7s
[CV 4/5; 60/88] START leaf_size=50, n_neighbors=35, weights=distance............
[CV 4/5; 60/88] END leaf_size=50, n_neighbors=35, weights=distance;, score=0.547 total time=   2.7s
[CV 5/5; 60/88] START leaf_size=50, n_neighbors=35, weights=distance............
[CV 5/5; 60/88] END leaf_size=50, n_neighbors=35, weights=distance;, score=0.550 total time=   2.7s
[CV 1/5; 61/88] START leaf_size=50, n_neighbors=55, weights=uniform.............
[CV 1/5; 61/88] END leaf_size=50, n_neighbors=55, weights=uniform;, score=0.533 total time=   2.8s
[CV 2/5; 61/88] START leaf_size=50, n_neighbors=55, weights=uniform.............
[CV 2/5; 61/88] END leaf_size=50, n_neighbors=55, weights=uniform;, score=0.535 total time=   2.6s
[CV 3/5; 61/88] START leaf_size=50, n_neighbors=55, weights=uniform.............
[CV 3/5; 61/88] END leaf_size=50, n_neighbors=55, weights=uniform;, score=0.540 total time=   2.8s
[CV 4/5; 61/88] START leaf_size=50, n_neighbors=55, weights=uniform.............
[CV 4/5; 61/88] END leaf_size=50, n_neighbors=55, weights=uniform;, score=0.538 total time=   2.7s
[CV 5/5; 61/88] START leaf_size=50, n_neighbors=55, weights=uniform.............
[CV 5/5; 61/88] END leaf_size=50, n_neighbors=55, weights=uniform;, score=0.532 total time=   2.8s
[CV 1/5; 62/88] START leaf_size=50, n_neighbors=55, weights=distance............
[CV 1/5; 62/88] END leaf_size=50, n_neighbors=55, weights=distance;, score=0.533 total time=   2.6s
[CV 2/5; 62/88] START leaf_size=50, n_neighbors=55, weights=distance............
[CV 2/5; 62/88] END leaf_size=50, n_neighbors=55, weights=distance;, score=0.535 total time=   2.5s
[CV 3/5; 62/88] START leaf_size=50, n_neighbors=55, weights=distance............
[CV 3/5; 62/88] END leaf_size=50, n_neighbors=55, weights=distance;, score=0.540 total time=   2.7s
[CV 4/5; 62/88] START leaf_size=50, n_neighbors=55, weights=distance............
[CV 4/5; 62/88] END leaf_size=50, n_neighbors=55, weights=distance;, score=0.538 total time=   2.6s
[CV 5/5; 62/88] START leaf_size=50, n_neighbors=55, weights=distance............
[CV 5/5; 62/88] END leaf_size=50, n_neighbors=55, weights=distance;, score=0.532 total time=   2.6s
[CV 1/5; 63/88] START leaf_size=50, n_neighbors=75, weights=uniform.............
[CV 1/5; 63/88] END leaf_size=50, n_neighbors=75, weights=uniform;, score=0.528 total time=   2.8s
[CV 2/5; 63/88] START leaf_size=50, n_neighbors=75, weights=uniform.............
[CV 2/5; 63/88] END leaf_size=50, n_neighbors=75, weights=uniform;, score=0.525 total time=   2.8s
[CV 3/5; 63/88] START leaf_size=50, n_neighbors=75, weights=uniform.............
[CV 3/5; 63/88] END leaf_size=50, n_neighbors=75, weights=uniform;, score=0.529 total time=   2.9s
[CV 4/5; 63/88] START leaf_size=50, n_neighbors=75, weights=uniform.............
[CV 4/5; 63/88] END leaf_size=50, n_neighbors=75, weights=uniform;, score=0.533 total time=   2.8s
[CV 5/5; 63/88] START leaf_size=50, n_neighbors=75, weights=uniform.............
[CV 5/5; 63/88] END leaf_size=50, n_neighbors=75, weights=uniform;, score=0.524 total time=   2.8s
[CV 1/5; 64/88] START leaf_size=50, n_neighbors=75, weights=distance............
[CV 1/5; 64/88] END leaf_size=50, n_neighbors=75, weights=distance;, score=0.528 total time=   2.6s
[CV 2/5; 64/88] START leaf_size=50, n_neighbors=75, weights=distance............
[CV 2/5; 64/88] END leaf_size=50, n_neighbors=75, weights=distance;, score=0.525 total time=   2.5s
[CV 3/5; 64/88] START leaf_size=50, n_neighbors=75, weights=distance............
[CV 3/5; 64/88] END leaf_size=50, n_neighbors=75, weights=distance;, score=0.529 total time=   2.7s
[CV 4/5; 64/88] START leaf_size=50, n_neighbors=75, weights=distance............
[CV 4/5; 64/88] END leaf_size=50, n_neighbors=75, weights=distance;, score=0.533 total time=   2.7s
[CV 5/5; 64/88] START leaf_size=50, n_neighbors=75, weights=distance............
[CV 5/5; 64/88] END leaf_size=50, n_neighbors=75, weights=distance;, score=0.525 total time=   2.7s
[CV 1/5; 65/88] START leaf_size=50, n_neighbors=99, weights=uniform.............
[CV 1/5; 65/88] END leaf_size=50, n_neighbors=99, weights=uniform;, score=0.523 total time=   2.8s
[CV 2/5; 65/88] START leaf_size=50, n_neighbors=99, weights=uniform.............
[CV 2/5; 65/88] END leaf_size=50, n_neighbors=99, weights=uniform;, score=0.523 total time=   2.7s
[CV 3/5; 65/88] START leaf_size=50, n_neighbors=99, weights=uniform.............
[CV 3/5; 65/88] END leaf_size=50, n_neighbors=99, weights=uniform;, score=0.523 total time=   2.8s
[CV 4/5; 65/88] START leaf_size=50, n_neighbors=99, weights=uniform.............
[CV 4/5; 65/88] END leaf_size=50, n_neighbors=99, weights=uniform;, score=0.526 total time=   2.9s
[CV 5/5; 65/88] START leaf_size=50, n_neighbors=99, weights=uniform.............
[CV 5/5; 65/88] END leaf_size=50, n_neighbors=99, weights=uniform;, score=0.520 total time=   2.8s
[CV 1/5; 66/88] START leaf_size=50, n_neighbors=99, weights=distance............
[CV 1/5; 66/88] END leaf_size=50, n_neighbors=99, weights=distance;, score=0.524 total time=   2.6s
[CV 2/5; 66/88] START leaf_size=50, n_neighbors=99, weights=distance............
[CV 2/5; 66/88] END leaf_size=50, n_neighbors=99, weights=distance;, score=0.523 total time=   2.6s
[CV 3/5; 66/88] START leaf_size=50, n_neighbors=99, weights=distance............
[CV 3/5; 66/88] END leaf_size=50, n_neighbors=99, weights=distance;, score=0.523 total time=   2.7s
[CV 4/5; 66/88] START leaf_size=50, n_neighbors=99, weights=distance............
[CV 4/5; 66/88] END leaf_size=50, n_neighbors=99, weights=distance;, score=0.527 total time=   2.7s
[CV 5/5; 66/88] START leaf_size=50, n_neighbors=99, weights=distance............
[CV 5/5; 66/88] END leaf_size=50, n_neighbors=99, weights=distance;, score=0.521 total time=   2.7s
[CV 1/5; 67/88] START leaf_size=70, n_neighbors=3, weights=uniform..............
[CV 1/5; 67/88] END leaf_size=70, n_neighbors=3, weights=uniform;, score=0.589 total time=   2.1s
[CV 2/5; 67/88] START leaf_size=70, n_neighbors=3, weights=uniform..............
[CV 2/5; 67/88] END leaf_size=70, n_neighbors=3, weights=uniform;, score=0.581 total time=   2.1s
[CV 3/5; 67/88] START leaf_size=70, n_neighbors=3, weights=uniform..............
[CV 3/5; 67/88] END leaf_size=70, n_neighbors=3, weights=uniform;, score=0.589 total time=   2.2s
[CV 4/5; 67/88] START leaf_size=70, n_neighbors=3, weights=uniform..............
[CV 4/5; 67/88] END leaf_size=70, n_neighbors=3, weights=uniform;, score=0.590 total time=   2.1s
[CV 5/5; 67/88] START leaf_size=70, n_neighbors=3, weights=uniform..............
[CV 5/5; 67/88] END leaf_size=70, n_neighbors=3, weights=uniform;, score=0.581 total time=   2.1s
[CV 1/5; 68/88] START leaf_size=70, n_neighbors=3, weights=distance.............
[CV 1/5; 68/88] END leaf_size=70, n_neighbors=3, weights=distance;, score=0.589 total time=   2.2s
[CV 2/5; 68/88] START leaf_size=70, n_neighbors=3, weights=distance.............
[CV 2/5; 68/88] END leaf_size=70, n_neighbors=3, weights=distance;, score=0.581 total time=   2.3s
[CV 3/5; 68/88] START leaf_size=70, n_neighbors=3, weights=distance.............
[CV 3/5; 68/88] END leaf_size=70, n_neighbors=3, weights=distance;, score=0.589 total time=   2.2s
[CV 4/5; 68/88] START leaf_size=70, n_neighbors=3, weights=distance.............
[CV 4/5; 68/88] END leaf_size=70, n_neighbors=3, weights=distance;, score=0.590 total time=   2.0s
[CV 5/5; 68/88] START leaf_size=70, n_neighbors=3, weights=distance.............
[CV 5/5; 68/88] END leaf_size=70, n_neighbors=3, weights=distance;, score=0.581 total time=   2.0s
[CV 1/5; 69/88] START leaf_size=70, n_neighbors=5, weights=uniform..............
[CV 1/5; 69/88] END leaf_size=70, n_neighbors=5, weights=uniform;, score=0.592 total time=   2.7s
[CV 2/5; 69/88] START leaf_size=70, n_neighbors=5, weights=uniform..............
[CV 2/5; 69/88] END leaf_size=70, n_neighbors=5, weights=uniform;, score=0.577 total time=   2.8s
[CV 3/5; 69/88] START leaf_size=70, n_neighbors=5, weights=uniform..............
[CV 3/5; 69/88] END leaf_size=70, n_neighbors=5, weights=uniform;, score=0.589 total time=   2.9s
[CV 4/5; 69/88] START leaf_size=70, n_neighbors=5, weights=uniform..............
[CV 4/5; 69/88] END leaf_size=70, n_neighbors=5, weights=uniform;, score=0.588 total time=   2.8s
[CV 5/5; 69/88] START leaf_size=70, n_neighbors=5, weights=uniform..............
[CV 5/5; 69/88] END leaf_size=70, n_neighbors=5, weights=uniform;, score=0.585 total time=   2.9s
[CV 1/5; 70/88] START leaf_size=70, n_neighbors=5, weights=distance.............
[CV 1/5; 70/88] END leaf_size=70, n_neighbors=5, weights=distance;, score=0.592 total time=   2.6s
[CV 2/5; 70/88] START leaf_size=70, n_neighbors=5, weights=distance.............
[CV 2/5; 70/88] END leaf_size=70, n_neighbors=5, weights=distance;, score=0.577 total time=   2.5s
[CV 3/5; 70/88] START leaf_size=70, n_neighbors=5, weights=distance.............
[CV 3/5; 70/88] END leaf_size=70, n_neighbors=5, weights=distance;, score=0.589 total time=   2.7s
[CV 4/5; 70/88] START leaf_size=70, n_neighbors=5, weights=distance.............
[CV 4/5; 70/88] END leaf_size=70, n_neighbors=5, weights=distance;, score=0.588 total time=   2.7s
[CV 5/5; 70/88] START leaf_size=70, n_neighbors=5, weights=distance.............
[CV 5/5; 70/88] END leaf_size=70, n_neighbors=5, weights=distance;, score=0.585 total time=   2.7s
[CV 1/5; 71/88] START leaf_size=70, n_neighbors=7, weights=uniform..............
[CV 1/5; 71/88] END leaf_size=70, n_neighbors=7, weights=uniform;, score=0.582 total time=   2.7s
[CV 2/5; 71/88] START leaf_size=70, n_neighbors=7, weights=uniform..............
[CV 2/5; 71/88] END leaf_size=70, n_neighbors=7, weights=uniform;, score=0.574 total time=   2.7s
[CV 3/5; 71/88] START leaf_size=70, n_neighbors=7, weights=uniform..............
[CV 3/5; 71/88] END leaf_size=70, n_neighbors=7, weights=uniform;, score=0.581 total time=   2.9s
[CV 4/5; 71/88] START leaf_size=70, n_neighbors=7, weights=uniform..............
[CV 4/5; 71/88] END leaf_size=70, n_neighbors=7, weights=uniform;, score=0.584 total time=   2.7s
[CV 5/5; 71/88] START leaf_size=70, n_neighbors=7, weights=uniform..............
[CV 5/5; 71/88] END leaf_size=70, n_neighbors=7, weights=uniform;, score=0.583 total time=   2.7s
[CV 1/5; 72/88] START leaf_size=70, n_neighbors=7, weights=distance.............
[CV 1/5; 72/88] END leaf_size=70, n_neighbors=7, weights=distance;, score=0.582 total time=   2.5s
[CV 2/5; 72/88] START leaf_size=70, n_neighbors=7, weights=distance.............
[CV 2/5; 72/88] END leaf_size=70, n_neighbors=7, weights=distance;, score=0.574 total time=   2.4s
[CV 3/5; 72/88] START leaf_size=70, n_neighbors=7, weights=distance.............
[CV 3/5; 72/88] END leaf_size=70, n_neighbors=7, weights=distance;, score=0.581 total time=   2.6s
[CV 4/5; 72/88] START leaf_size=70, n_neighbors=7, weights=distance.............
[CV 4/5; 72/88] END leaf_size=70, n_neighbors=7, weights=distance;, score=0.585 total time=   2.5s
[CV 5/5; 72/88] START leaf_size=70, n_neighbors=7, weights=distance.............
[CV 5/5; 72/88] END leaf_size=70, n_neighbors=7, weights=distance;, score=0.583 total time=   2.6s
[CV 1/5; 73/88] START leaf_size=70, n_neighbors=9, weights=uniform..............
[CV 1/5; 73/88] END leaf_size=70, n_neighbors=9, weights=uniform;, score=0.575 total time=   2.8s
[CV 2/5; 73/88] START leaf_size=70, n_neighbors=9, weights=uniform..............
[CV 2/5; 73/88] END leaf_size=70, n_neighbors=9, weights=uniform;, score=0.572 total time=   2.8s
[CV 3/5; 73/88] START leaf_size=70, n_neighbors=9, weights=uniform..............
[CV 3/5; 73/88] END leaf_size=70, n_neighbors=9, weights=uniform;, score=0.581 total time=   3.0s
[CV 4/5; 73/88] START leaf_size=70, n_neighbors=9, weights=uniform..............
[CV 4/5; 73/88] END leaf_size=70, n_neighbors=9, weights=uniform;, score=0.584 total time=   2.8s
[CV 5/5; 73/88] START leaf_size=70, n_neighbors=9, weights=uniform..............
[CV 5/5; 73/88] END leaf_size=70, n_neighbors=9, weights=uniform;, score=0.580 total time=   2.8s
[CV 1/5; 74/88] START leaf_size=70, n_neighbors=9, weights=distance.............
[CV 1/5; 74/88] END leaf_size=70, n_neighbors=9, weights=distance;, score=0.575 total time=   2.7s
[CV 2/5; 74/88] START leaf_size=70, n_neighbors=9, weights=distance.............
[CV 2/5; 74/88] END leaf_size=70, n_neighbors=9, weights=distance;, score=0.572 total time=   2.6s
[CV 3/5; 74/88] START leaf_size=70, n_neighbors=9, weights=distance.............
[CV 3/5; 74/88] END leaf_size=70, n_neighbors=9, weights=distance;, score=0.581 total time=   2.8s
[CV 4/5; 74/88] START leaf_size=70, n_neighbors=9, weights=distance.............
[CV 4/5; 74/88] END leaf_size=70, n_neighbors=9, weights=distance;, score=0.584 total time=   2.8s
[CV 5/5; 74/88] START leaf_size=70, n_neighbors=9, weights=distance.............
[CV 5/5; 74/88] END leaf_size=70, n_neighbors=9, weights=distance;, score=0.580 total time=   2.6s
[CV 1/5; 75/88] START leaf_size=70, n_neighbors=15, weights=uniform.............
[CV 1/5; 75/88] END leaf_size=70, n_neighbors=15, weights=uniform;, score=0.569 total time=   2.8s
[CV 2/5; 75/88] START leaf_size=70, n_neighbors=15, weights=uniform.............
[CV 2/5; 75/88] END leaf_size=70, n_neighbors=15, weights=uniform;, score=0.563 total time=   2.8s
[CV 3/5; 75/88] START leaf_size=70, n_neighbors=15, weights=uniform.............
[CV 3/5; 75/88] END leaf_size=70, n_neighbors=15, weights=uniform;, score=0.578 total time=   2.8s
[CV 4/5; 75/88] START leaf_size=70, n_neighbors=15, weights=uniform.............
[CV 4/5; 75/88] END leaf_size=70, n_neighbors=15, weights=uniform;, score=0.568 total time=   2.7s
[CV 5/5; 75/88] START leaf_size=70, n_neighbors=15, weights=uniform.............
[CV 5/5; 75/88] END leaf_size=70, n_neighbors=15, weights=uniform;, score=0.567 total time=   2.8s
[CV 1/5; 76/88] START leaf_size=70, n_neighbors=15, weights=distance............
[CV 1/5; 76/88] END leaf_size=70, n_neighbors=15, weights=distance;, score=0.569 total time=   2.6s
[CV 2/5; 76/88] START leaf_size=70, n_neighbors=15, weights=distance............
[CV 2/5; 76/88] END leaf_size=70, n_neighbors=15, weights=distance;, score=0.563 total time=   2.5s
[CV 3/5; 76/88] START leaf_size=70, n_neighbors=15, weights=distance............
[CV 3/5; 76/88] END leaf_size=70, n_neighbors=15, weights=distance;, score=0.578 total time=   2.6s
[CV 4/5; 76/88] START leaf_size=70, n_neighbors=15, weights=distance............
[CV 4/5; 76/88] END leaf_size=70, n_neighbors=15, weights=distance;, score=0.568 total time=   2.6s
[CV 5/5; 76/88] START leaf_size=70, n_neighbors=15, weights=distance............
[CV 5/5; 76/88] END leaf_size=70, n_neighbors=15, weights=distance;, score=0.567 total time=   2.7s
[CV 1/5; 77/88] START leaf_size=70, n_neighbors=19, weights=uniform.............
[CV 1/5; 77/88] END leaf_size=70, n_neighbors=19, weights=uniform;, score=0.560 total time=   2.8s
[CV 2/5; 77/88] START leaf_size=70, n_neighbors=19, weights=uniform.............
[CV 2/5; 77/88] END leaf_size=70, n_neighbors=19, weights=uniform;, score=0.556 total time=   2.7s
[CV 3/5; 77/88] START leaf_size=70, n_neighbors=19, weights=uniform.............
[CV 3/5; 77/88] END leaf_size=70, n_neighbors=19, weights=uniform;, score=0.567 total time=   2.8s
[CV 4/5; 77/88] START leaf_size=70, n_neighbors=19, weights=uniform.............
[CV 4/5; 77/88] END leaf_size=70, n_neighbors=19, weights=uniform;, score=0.563 total time=   3.0s
[CV 5/5; 77/88] START leaf_size=70, n_neighbors=19, weights=uniform.............
[CV 5/5; 77/88] END leaf_size=70, n_neighbors=19, weights=uniform;, score=0.560 total time=   2.9s
[CV 1/5; 78/88] START leaf_size=70, n_neighbors=19, weights=distance............
[CV 1/5; 78/88] END leaf_size=70, n_neighbors=19, weights=distance;, score=0.560 total time=   2.6s
[CV 2/5; 78/88] START leaf_size=70, n_neighbors=19, weights=distance............
[CV 2/5; 78/88] END leaf_size=70, n_neighbors=19, weights=distance;, score=0.556 total time=   2.5s
[CV 3/5; 78/88] START leaf_size=70, n_neighbors=19, weights=distance............
[CV 3/5; 78/88] END leaf_size=70, n_neighbors=19, weights=distance;, score=0.567 total time=   2.7s
[CV 4/5; 78/88] START leaf_size=70, n_neighbors=19, weights=distance............
[CV 4/5; 78/88] END leaf_size=70, n_neighbors=19, weights=distance;, score=0.563 total time=   2.6s
[CV 5/5; 78/88] START leaf_size=70, n_neighbors=19, weights=distance............
[CV 5/5; 78/88] END leaf_size=70, n_neighbors=19, weights=distance;, score=0.560 total time=   2.7s
[CV 1/5; 79/88] START leaf_size=70, n_neighbors=25, weights=uniform.............
[CV 1/5; 79/88] END leaf_size=70, n_neighbors=25, weights=uniform;, score=0.556 total time=   2.8s
[CV 2/5; 79/88] START leaf_size=70, n_neighbors=25, weights=uniform.............
[CV 2/5; 79/88] END leaf_size=70, n_neighbors=25, weights=uniform;, score=0.550 total time=   2.6s
[CV 3/5; 79/88] START leaf_size=70, n_neighbors=25, weights=uniform.............
[CV 3/5; 79/88] END leaf_size=70, n_neighbors=25, weights=uniform;, score=0.563 total time=   2.8s
[CV 4/5; 79/88] START leaf_size=70, n_neighbors=25, weights=uniform.............
[CV 4/5; 79/88] END leaf_size=70, n_neighbors=25, weights=uniform;, score=0.560 total time=   2.8s
[CV 5/5; 79/88] START leaf_size=70, n_neighbors=25, weights=uniform.............
[CV 5/5; 79/88] END leaf_size=70, n_neighbors=25, weights=uniform;, score=0.557 total time=   2.8s
[CV 1/5; 80/88] START leaf_size=70, n_neighbors=25, weights=distance............
[CV 1/5; 80/88] END leaf_size=70, n_neighbors=25, weights=distance;, score=0.556 total time=   2.6s
[CV 2/5; 80/88] START leaf_size=70, n_neighbors=25, weights=distance............
[CV 2/5; 80/88] END leaf_size=70, n_neighbors=25, weights=distance;, score=0.550 total time=   2.5s
[CV 3/5; 80/88] START leaf_size=70, n_neighbors=25, weights=distance............
[CV 3/5; 80/88] END leaf_size=70, n_neighbors=25, weights=distance;, score=0.563 total time=   2.7s
[CV 4/5; 80/88] START leaf_size=70, n_neighbors=25, weights=distance............
[CV 4/5; 80/88] END leaf_size=70, n_neighbors=25, weights=distance;, score=0.560 total time=   2.6s
[CV 5/5; 80/88] START leaf_size=70, n_neighbors=25, weights=distance............
[CV 5/5; 80/88] END leaf_size=70, n_neighbors=25, weights=distance;, score=0.557 total time=   2.7s
[CV 1/5; 81/88] START leaf_size=70, n_neighbors=35, weights=uniform.............
[CV 1/5; 81/88] END leaf_size=70, n_neighbors=35, weights=uniform;, score=0.547 total time=   2.7s
[CV 2/5; 81/88] START leaf_size=70, n_neighbors=35, weights=uniform.............
[CV 2/5; 81/88] END leaf_size=70, n_neighbors=35, weights=uniform;, score=0.546 total time=   2.6s
[CV 3/5; 81/88] START leaf_size=70, n_neighbors=35, weights=uniform.............
[CV 3/5; 81/88] END leaf_size=70, n_neighbors=35, weights=uniform;, score=0.553 total time=   2.8s
[CV 4/5; 81/88] START leaf_size=70, n_neighbors=35, weights=uniform.............
[CV 4/5; 81/88] END leaf_size=70, n_neighbors=35, weights=uniform;, score=0.547 total time=   2.7s
[CV 5/5; 81/88] START leaf_size=70, n_neighbors=35, weights=uniform.............
[CV 5/5; 81/88] END leaf_size=70, n_neighbors=35, weights=uniform;, score=0.550 total time=   2.8s
[CV 1/5; 82/88] START leaf_size=70, n_neighbors=35, weights=distance............
[CV 1/5; 82/88] END leaf_size=70, n_neighbors=35, weights=distance;, score=0.547 total time=   2.6s
[CV 2/5; 82/88] START leaf_size=70, n_neighbors=35, weights=distance............
[CV 2/5; 82/88] END leaf_size=70, n_neighbors=35, weights=distance;, score=0.546 total time=   2.7s
[CV 3/5; 82/88] START leaf_size=70, n_neighbors=35, weights=distance............
[CV 3/5; 82/88] END leaf_size=70, n_neighbors=35, weights=distance;, score=0.554 total time=   2.8s
[CV 4/5; 82/88] START leaf_size=70, n_neighbors=35, weights=distance............
[CV 4/5; 82/88] END leaf_size=70, n_neighbors=35, weights=distance;, score=0.547 total time=   2.7s
[CV 5/5; 82/88] START leaf_size=70, n_neighbors=35, weights=distance............
[CV 5/5; 82/88] END leaf_size=70, n_neighbors=35, weights=distance;, score=0.550 total time=   2.8s
[CV 1/5; 83/88] START leaf_size=70, n_neighbors=55, weights=uniform.............
[CV 1/5; 83/88] END leaf_size=70, n_neighbors=55, weights=uniform;, score=0.533 total time=   2.9s
[CV 2/5; 83/88] START leaf_size=70, n_neighbors=55, weights=uniform.............
[CV 2/5; 83/88] END leaf_size=70, n_neighbors=55, weights=uniform;, score=0.535 total time=   2.9s
[CV 3/5; 83/88] START leaf_size=70, n_neighbors=55, weights=uniform.............
[CV 3/5; 83/88] END leaf_size=70, n_neighbors=55, weights=uniform;, score=0.540 total time=   2.9s
[CV 4/5; 83/88] START leaf_size=70, n_neighbors=55, weights=uniform.............
[CV 4/5; 83/88] END leaf_size=70, n_neighbors=55, weights=uniform;, score=0.538 total time=   2.8s
[CV 5/5; 83/88] START leaf_size=70, n_neighbors=55, weights=uniform.............
[CV 5/5; 83/88] END leaf_size=70, n_neighbors=55, weights=uniform;, score=0.532 total time=   2.8s
[CV 1/5; 84/88] START leaf_size=70, n_neighbors=55, weights=distance............
[CV 1/5; 84/88] END leaf_size=70, n_neighbors=55, weights=distance;, score=0.533 total time=   2.7s
[CV 2/5; 84/88] START leaf_size=70, n_neighbors=55, weights=distance............
[CV 2/5; 84/88] END leaf_size=70, n_neighbors=55, weights=distance;, score=0.535 total time=   2.5s
[CV 3/5; 84/88] START leaf_size=70, n_neighbors=55, weights=distance............
[CV 3/5; 84/88] END leaf_size=70, n_neighbors=55, weights=distance;, score=0.540 total time=   2.7s
[CV 4/5; 84/88] START leaf_size=70, n_neighbors=55, weights=distance............
[CV 4/5; 84/88] END leaf_size=70, n_neighbors=55, weights=distance;, score=0.538 total time=   2.7s
[CV 5/5; 84/88] START leaf_size=70, n_neighbors=55, weights=distance............
[CV 5/5; 84/88] END leaf_size=70, n_neighbors=55, weights=distance;, score=0.532 total time=   2.8s
[CV 1/5; 85/88] START leaf_size=70, n_neighbors=75, weights=uniform.............
[CV 1/5; 85/88] END leaf_size=70, n_neighbors=75, weights=uniform;, score=0.528 total time=   2.7s
[CV 2/5; 85/88] START leaf_size=70, n_neighbors=75, weights=uniform.............
[CV 2/5; 85/88] END leaf_size=70, n_neighbors=75, weights=uniform;, score=0.525 total time=   2.7s
[CV 3/5; 85/88] START leaf_size=70, n_neighbors=75, weights=uniform.............
[CV 3/5; 85/88] END leaf_size=70, n_neighbors=75, weights=uniform;, score=0.529 total time=   2.7s
[CV 4/5; 85/88] START leaf_size=70, n_neighbors=75, weights=uniform.............
[CV 4/5; 85/88] END leaf_size=70, n_neighbors=75, weights=uniform;, score=0.533 total time=   2.7s
[CV 5/5; 85/88] START leaf_size=70, n_neighbors=75, weights=uniform.............
[CV 5/5; 85/88] END leaf_size=70, n_neighbors=75, weights=uniform;, score=0.524 total time=   2.7s
[CV 1/5; 86/88] START leaf_size=70, n_neighbors=75, weights=distance............
[CV 1/5; 86/88] END leaf_size=70, n_neighbors=75, weights=distance;, score=0.528 total time=   2.6s
[CV 2/5; 86/88] START leaf_size=70, n_neighbors=75, weights=distance............
[CV 2/5; 86/88] END leaf_size=70, n_neighbors=75, weights=distance;, score=0.525 total time=   2.5s
[CV 3/5; 86/88] START leaf_size=70, n_neighbors=75, weights=distance............
[CV 3/5; 86/88] END leaf_size=70, n_neighbors=75, weights=distance;, score=0.529 total time=   2.6s
[CV 4/5; 86/88] START leaf_size=70, n_neighbors=75, weights=distance............
[CV 4/5; 86/88] END leaf_size=70, n_neighbors=75, weights=distance;, score=0.533 total time=   2.7s
[CV 5/5; 86/88] START leaf_size=70, n_neighbors=75, weights=distance............
[CV 5/5; 86/88] END leaf_size=70, n_neighbors=75, weights=distance;, score=0.525 total time=   2.9s
[CV 1/5; 87/88] START leaf_size=70, n_neighbors=99, weights=uniform.............
[CV 1/5; 87/88] END leaf_size=70, n_neighbors=99, weights=uniform;, score=0.523 total time=   3.2s
[CV 2/5; 87/88] START leaf_size=70, n_neighbors=99, weights=uniform.............
[CV 2/5; 87/88] END leaf_size=70, n_neighbors=99, weights=uniform;, score=0.523 total time=   2.9s
[CV 3/5; 87/88] START leaf_size=70, n_neighbors=99, weights=uniform.............
[CV 3/5; 87/88] END leaf_size=70, n_neighbors=99, weights=uniform;, score=0.523 total time=   3.0s
[CV 4/5; 87/88] START leaf_size=70, n_neighbors=99, weights=uniform.............
[CV 4/5; 87/88] END leaf_size=70, n_neighbors=99, weights=uniform;, score=0.526 total time=   3.2s
[CV 5/5; 87/88] START leaf_size=70, n_neighbors=99, weights=uniform.............
[CV 5/5; 87/88] END leaf_size=70, n_neighbors=99, weights=uniform;, score=0.520 total time=   2.9s
[CV 1/5; 88/88] START leaf_size=70, n_neighbors=99, weights=distance............
[CV 1/5; 88/88] END leaf_size=70, n_neighbors=99, weights=distance;, score=0.524 total time=   2.9s
[CV 2/5; 88/88] START leaf_size=70, n_neighbors=99, weights=distance............
[CV 2/5; 88/88] END leaf_size=70, n_neighbors=99, weights=distance;, score=0.523 total time=   2.6s
[CV 3/5; 88/88] START leaf_size=70, n_neighbors=99, weights=distance............
[CV 3/5; 88/88] END leaf_size=70, n_neighbors=99, weights=distance;, score=0.523 total time=   2.9s
[CV 4/5; 88/88] START leaf_size=70, n_neighbors=99, weights=distance............
[CV 4/5; 88/88] END leaf_size=70, n_neighbors=99, weights=distance;, score=0.527 total time=   2.7s
[CV 5/5; 88/88] START leaf_size=70, n_neighbors=99, weights=distance............
[CV 5/5; 88/88] END leaf_size=70, n_neighbors=99, weights=distance;, score=0.521 total time=   2.8s
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt">Out[33]:</div>




<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain">
<pre>GridSearchCV(estimator=KNeighborsClassifier(),
             param_grid={&#39;leaf_size&#39;: [20, 30, 50, 70],
                         &#39;n_neighbors&#39;: [3, 5, 7, 9, 15, 19, 25, 35, 55, 75,
                                         99],
                         &#39;weights&#39;: [&#39;uniform&#39;, &#39;distance&#39;]},
             scoring=&#39;balanced_accuracy&#39;, verbose=10)</pre>
</div>

</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[37]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">grid_search</span><span class="o">.</span><span class="n">best_params_</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt">Out[37]:</div>




<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain">
<pre>{&#39;leaf_size&#39;: 20, &#39;n_neighbors&#39;: 5, &#39;weights&#39;: &#39;distance&#39;}</pre>
</div>

</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[39]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">leaf_size</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">n_neighbors</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="s1">&#39;distance&#39;</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">predicted</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">evaluate</span><span class="p">(</span><span class="n">predicted</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Accuracy:  0.7340782122905027
Balanced Accuracy:  0.5893081134700795
Precision:  0.7822628167354154
Recall:  0.8888516906595246
F1:  0.8321579689703809
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[40]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">GridSearchCV</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>

<span class="n">parameters</span> <span class="o">=</span> <span class="p">{</span>  <span class="s1">&#39;penalty&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;l1&#39;</span><span class="p">,</span> <span class="s1">&#39;l2&#39;</span><span class="p">,</span> <span class="s1">&#39;elasticnet&#39;</span><span class="p">,</span> <span class="s1">&#39;none&#39;</span><span class="p">],</span>
                <span class="s1">&#39;tol&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">1e-3</span><span class="p">,</span> <span class="mf">1e-4</span><span class="p">,</span> <span class="mf">1e-5</span><span class="p">],</span>
                <span class="s1">&#39;max_iter&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">150</span><span class="p">,</span> <span class="mi">200</span><span class="p">]</span>
                 <span class="p">}</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">()</span>

<span class="n">grid_search</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">estimator</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">param_grid</span><span class="o">=</span><span class="n">parameters</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s2">&quot;balanced_accuracy&quot;</span><span class="p">)</span>
<span class="n">grid_search</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Fitting 5 folds for each of 48 candidates, totalling 240 fits
[CV 1/5; 1/48] START max_iter=50, penalty=l1, tol=0.001.........................
[CV 1/5; 1/48] END max_iter=50, penalty=l1, tol=0.001;, score=nan total time=   0.0s
[CV 2/5; 1/48] START max_iter=50, penalty=l1, tol=0.001.........................
[CV 2/5; 1/48] END max_iter=50, penalty=l1, tol=0.001;, score=nan total time=   0.0s
[CV 3/5; 1/48] START max_iter=50, penalty=l1, tol=0.001.........................
[CV 3/5; 1/48] END max_iter=50, penalty=l1, tol=0.001;, score=nan total time=   0.0s
[CV 4/5; 1/48] START max_iter=50, penalty=l1, tol=0.001.........................
[CV 4/5; 1/48] END max_iter=50, penalty=l1, tol=0.001;, score=nan total time=   0.0s
[CV 5/5; 1/48] START max_iter=50, penalty=l1, tol=0.001.........................
[CV 5/5; 1/48] END max_iter=50, penalty=l1, tol=0.001;, score=nan total time=   0.0s
[CV 1/5; 2/48] START max_iter=50, penalty=l1, tol=0.0001........................
[CV 1/5; 2/48] END max_iter=50, penalty=l1, tol=0.0001;, score=nan total time=   0.0s
[CV 2/5; 2/48] START max_iter=50, penalty=l1, tol=0.0001........................
[CV 2/5; 2/48] END max_iter=50, penalty=l1, tol=0.0001;, score=nan total time=   0.0s
[CV 3/5; 2/48] START max_iter=50, penalty=l1, tol=0.0001........................
[CV 3/5; 2/48] END max_iter=50, penalty=l1, tol=0.0001;, score=nan total time=   0.0s
[CV 4/5; 2/48] START max_iter=50, penalty=l1, tol=0.0001........................
[CV 4/5; 2/48] END max_iter=50, penalty=l1, tol=0.0001;, score=nan total time=   0.0s
[CV 5/5; 2/48] START max_iter=50, penalty=l1, tol=0.0001........................
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 5/5; 2/48] END max_iter=50, penalty=l1, tol=0.0001;, score=nan total time=   0.0s
[CV 1/5; 3/48] START max_iter=50, penalty=l1, tol=1e-05.........................
[CV 1/5; 3/48] END max_iter=50, penalty=l1, tol=1e-05;, score=nan total time=   0.0s
[CV 2/5; 3/48] START max_iter=50, penalty=l1, tol=1e-05.........................
[CV 2/5; 3/48] END max_iter=50, penalty=l1, tol=1e-05;, score=nan total time=   0.0s
[CV 3/5; 3/48] START max_iter=50, penalty=l1, tol=1e-05.........................
[CV 3/5; 3/48] END max_iter=50, penalty=l1, tol=1e-05;, score=nan total time=   0.0s
[CV 4/5; 3/48] START max_iter=50, penalty=l1, tol=1e-05.........................
[CV 4/5; 3/48] END max_iter=50, penalty=l1, tol=1e-05;, score=nan total time=   0.0s
[CV 5/5; 3/48] START max_iter=50, penalty=l1, tol=1e-05.........................
[CV 5/5; 3/48] END max_iter=50, penalty=l1, tol=1e-05;, score=nan total time=   0.0s
[CV 1/5; 4/48] START max_iter=50, penalty=l2, tol=0.001.........................
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 1/5; 4/48] END max_iter=50, penalty=l2, tol=0.001;, score=0.705 total time=   0.5s
[CV 2/5; 4/48] START max_iter=50, penalty=l2, tol=0.001.........................
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 2/5; 4/48] END max_iter=50, penalty=l2, tol=0.001;, score=0.727 total time=   0.3s
[CV 3/5; 4/48] START max_iter=50, penalty=l2, tol=0.001.........................
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 3/5; 4/48] END max_iter=50, penalty=l2, tol=0.001;, score=0.719 total time=   0.3s
[CV 4/5; 4/48] START max_iter=50, penalty=l2, tol=0.001.........................
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 4/5; 4/48] END max_iter=50, penalty=l2, tol=0.001;, score=0.713 total time=   0.3s
[CV 5/5; 4/48] START max_iter=50, penalty=l2, tol=0.001.........................
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 5/5; 4/48] END max_iter=50, penalty=l2, tol=0.001;, score=0.721 total time=   0.3s
[CV 1/5; 5/48] START max_iter=50, penalty=l2, tol=0.0001........................
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 1/5; 5/48] END max_iter=50, penalty=l2, tol=0.0001;, score=0.705 total time=   0.3s
[CV 2/5; 5/48] START max_iter=50, penalty=l2, tol=0.0001........................
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 2/5; 5/48] END max_iter=50, penalty=l2, tol=0.0001;, score=0.727 total time=   0.3s
[CV 3/5; 5/48] START max_iter=50, penalty=l2, tol=0.0001........................
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 3/5; 5/48] END max_iter=50, penalty=l2, tol=0.0001;, score=0.719 total time=   0.3s
[CV 4/5; 5/48] START max_iter=50, penalty=l2, tol=0.0001........................
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 4/5; 5/48] END max_iter=50, penalty=l2, tol=0.0001;, score=0.713 total time=   0.3s
[CV 5/5; 5/48] START max_iter=50, penalty=l2, tol=0.0001........................
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 5/5; 5/48] END max_iter=50, penalty=l2, tol=0.0001;, score=0.721 total time=   0.3s
[CV 1/5; 6/48] START max_iter=50, penalty=l2, tol=1e-05.........................
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 1/5; 6/48] END max_iter=50, penalty=l2, tol=1e-05;, score=0.705 total time=   0.3s
[CV 2/5; 6/48] START max_iter=50, penalty=l2, tol=1e-05.........................
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 2/5; 6/48] END max_iter=50, penalty=l2, tol=1e-05;, score=0.727 total time=   0.3s
[CV 3/5; 6/48] START max_iter=50, penalty=l2, tol=1e-05.........................
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 3/5; 6/48] END max_iter=50, penalty=l2, tol=1e-05;, score=0.719 total time=   0.3s
[CV 4/5; 6/48] START max_iter=50, penalty=l2, tol=1e-05.........................
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 4/5; 6/48] END max_iter=50, penalty=l2, tol=1e-05;, score=0.713 total time=   0.3s
[CV 5/5; 6/48] START max_iter=50, penalty=l2, tol=1e-05.........................
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 5/5; 6/48] END max_iter=50, penalty=l2, tol=1e-05;, score=0.721 total time=   0.3s
[CV 1/5; 7/48] START max_iter=50, penalty=elasticnet, tol=0.001.................
[CV 1/5; 7/48] END max_iter=50, penalty=elasticnet, tol=0.001;, score=nan total time=   0.0s
[CV 2/5; 7/48] START max_iter=50, penalty=elasticnet, tol=0.001.................
[CV 2/5; 7/48] END max_iter=50, penalty=elasticnet, tol=0.001;, score=nan total time=   0.0s
[CV 3/5; 7/48] START max_iter=50, penalty=elasticnet, tol=0.001.................
[CV 3/5; 7/48] END max_iter=50, penalty=elasticnet, tol=0.001;, score=nan total time=   0.0s
[CV 4/5; 7/48] START max_iter=50, penalty=elasticnet, tol=0.001.................
[CV 4/5; 7/48] END max_iter=50, penalty=elasticnet, tol=0.001;, score=nan total time=   0.0s
[CV 5/5; 7/48] START max_iter=50, penalty=elasticnet, tol=0.001.................
[CV 5/5; 7/48] END max_iter=50, penalty=elasticnet, tol=0.001;, score=nan total time=   0.0s
[CV 1/5; 8/48] START max_iter=50, penalty=elasticnet, tol=0.0001................
[CV 1/5; 8/48] END max_iter=50, penalty=elasticnet, tol=0.0001;, score=nan total time=   0.0s
[CV 2/5; 8/48] START max_iter=50, penalty=elasticnet, tol=0.0001................
[CV 2/5; 8/48] END max_iter=50, penalty=elasticnet, tol=0.0001;, score=nan total time=   0.0s
[CV 3/5; 8/48] START max_iter=50, penalty=elasticnet, tol=0.0001................
[CV 3/5; 8/48] END max_iter=50, penalty=elasticnet, tol=0.0001;, score=nan total time=   0.0s
[CV 4/5; 8/48] START max_iter=50, penalty=elasticnet, tol=0.0001................
[CV 4/5; 8/48] END max_iter=50, penalty=elasticnet, tol=0.0001;, score=nan total time=   0.0s
[CV 5/5; 8/48] START max_iter=50, penalty=elasticnet, tol=0.0001................
[CV 5/5; 8/48] END max_iter=50, penalty=elasticnet, tol=0.0001;, score=nan total time=   0.0s
[CV 1/5; 9/48] START max_iter=50, penalty=elasticnet, tol=1e-05.................
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 1/5; 9/48] END max_iter=50, penalty=elasticnet, tol=1e-05;, score=nan total time=   0.0s
[CV 2/5; 9/48] START max_iter=50, penalty=elasticnet, tol=1e-05.................
[CV 2/5; 9/48] END max_iter=50, penalty=elasticnet, tol=1e-05;, score=nan total time=   0.0s
[CV 3/5; 9/48] START max_iter=50, penalty=elasticnet, tol=1e-05.................
[CV 3/5; 9/48] END max_iter=50, penalty=elasticnet, tol=1e-05;, score=nan total time=   0.0s
[CV 4/5; 9/48] START max_iter=50, penalty=elasticnet, tol=1e-05.................
[CV 4/5; 9/48] END max_iter=50, penalty=elasticnet, tol=1e-05;, score=nan total time=   0.0s
[CV 5/5; 9/48] START max_iter=50, penalty=elasticnet, tol=1e-05.................
[CV 5/5; 9/48] END max_iter=50, penalty=elasticnet, tol=1e-05;, score=nan total time=   0.0s
[CV 1/5; 10/48] START max_iter=50, penalty=none, tol=0.001......................
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 1/5; 10/48] END max_iter=50, penalty=none, tol=0.001;, score=0.707 total time=   0.3s
[CV 2/5; 10/48] START max_iter=50, penalty=none, tol=0.001......................
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 2/5; 10/48] END max_iter=50, penalty=none, tol=0.001;, score=0.727 total time=   0.3s
[CV 3/5; 10/48] START max_iter=50, penalty=none, tol=0.001......................
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 3/5; 10/48] END max_iter=50, penalty=none, tol=0.001;, score=0.718 total time=   0.3s
[CV 4/5; 10/48] START max_iter=50, penalty=none, tol=0.001......................
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 4/5; 10/48] END max_iter=50, penalty=none, tol=0.001;, score=0.713 total time=   0.3s
[CV 5/5; 10/48] START max_iter=50, penalty=none, tol=0.001......................
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 5/5; 10/48] END max_iter=50, penalty=none, tol=0.001;, score=0.720 total time=   0.3s
[CV 1/5; 11/48] START max_iter=50, penalty=none, tol=0.0001.....................
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 1/5; 11/48] END max_iter=50, penalty=none, tol=0.0001;, score=0.707 total time=   0.3s
[CV 2/5; 11/48] START max_iter=50, penalty=none, tol=0.0001.....................
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 2/5; 11/48] END max_iter=50, penalty=none, tol=0.0001;, score=0.727 total time=   0.3s
[CV 3/5; 11/48] START max_iter=50, penalty=none, tol=0.0001.....................
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 3/5; 11/48] END max_iter=50, penalty=none, tol=0.0001;, score=0.718 total time=   0.3s
[CV 4/5; 11/48] START max_iter=50, penalty=none, tol=0.0001.....................
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 4/5; 11/48] END max_iter=50, penalty=none, tol=0.0001;, score=0.713 total time=   0.2s
[CV 5/5; 11/48] START max_iter=50, penalty=none, tol=0.0001.....................
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 5/5; 11/48] END max_iter=50, penalty=none, tol=0.0001;, score=0.720 total time=   0.3s
[CV 1/5; 12/48] START max_iter=50, penalty=none, tol=1e-05......................
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 1/5; 12/48] END max_iter=50, penalty=none, tol=1e-05;, score=0.707 total time=   0.3s
[CV 2/5; 12/48] START max_iter=50, penalty=none, tol=1e-05......................
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 2/5; 12/48] END max_iter=50, penalty=none, tol=1e-05;, score=0.727 total time=   0.3s
[CV 3/5; 12/48] START max_iter=50, penalty=none, tol=1e-05......................
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 3/5; 12/48] END max_iter=50, penalty=none, tol=1e-05;, score=0.718 total time=   0.4s
[CV 4/5; 12/48] START max_iter=50, penalty=none, tol=1e-05......................
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 4/5; 12/48] END max_iter=50, penalty=none, tol=1e-05;, score=0.713 total time=   0.3s
[CV 5/5; 12/48] START max_iter=50, penalty=none, tol=1e-05......................
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 5/5; 12/48] END max_iter=50, penalty=none, tol=1e-05;, score=0.720 total time=   0.3s
[CV 1/5; 13/48] START max_iter=100, penalty=l1, tol=0.001.......................
[CV 1/5; 13/48] END max_iter=100, penalty=l1, tol=0.001;, score=nan total time=   0.0s
[CV 2/5; 13/48] START max_iter=100, penalty=l1, tol=0.001.......................
[CV 2/5; 13/48] END max_iter=100, penalty=l1, tol=0.001;, score=nan total time=   0.0s
[CV 3/5; 13/48] START max_iter=100, penalty=l1, tol=0.001.......................
[CV 3/5; 13/48] END max_iter=100, penalty=l1, tol=0.001;, score=nan total time=   0.0s
[CV 4/5; 13/48] START max_iter=100, penalty=l1, tol=0.001.......................
[CV 4/5; 13/48] END max_iter=100, penalty=l1, tol=0.001;, score=nan total time=   0.0s
[CV 5/5; 13/48] START max_iter=100, penalty=l1, tol=0.001.......................
[CV 5/5; 13/48] END max_iter=100, penalty=l1, tol=0.001;, score=nan total time=   0.0s
[CV 1/5; 14/48] START max_iter=100, penalty=l1, tol=0.0001......................
[CV 1/5; 14/48] END max_iter=100, penalty=l1, tol=0.0001;, score=nan total time=   0.0s
[CV 2/5; 14/48] START max_iter=100, penalty=l1, tol=0.0001......................
[CV 2/5; 14/48] END max_iter=100, penalty=l1, tol=0.0001;, score=nan total time=   0.0s
[CV 3/5; 14/48] START max_iter=100, penalty=l1, tol=0.0001......................
[CV 3/5; 14/48] END max_iter=100, penalty=l1, tol=0.0001;, score=nan total time=   0.0s
[CV 4/5; 14/48] START max_iter=100, penalty=l1, tol=0.0001......................
[CV 4/5; 14/48] END max_iter=100, penalty=l1, tol=0.0001;, score=nan total time=   0.0s
[CV 5/5; 14/48] START max_iter=100, penalty=l1, tol=0.0001......................
[CV 5/5; 14/48] END max_iter=100, penalty=l1, tol=0.0001;, score=nan total time=   0.0s
[CV 1/5; 15/48] START max_iter=100, penalty=l1, tol=1e-05.......................</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>
[CV 1/5; 15/48] END max_iter=100, penalty=l1, tol=1e-05;, score=nan total time=   0.0s
[CV 2/5; 15/48] START max_iter=100, penalty=l1, tol=1e-05.......................
[CV 2/5; 15/48] END max_iter=100, penalty=l1, tol=1e-05;, score=nan total time=   0.0s
[CV 3/5; 15/48] START max_iter=100, penalty=l1, tol=1e-05.......................
[CV 3/5; 15/48] END max_iter=100, penalty=l1, tol=1e-05;, score=nan total time=   0.0s
[CV 4/5; 15/48] START max_iter=100, penalty=l1, tol=1e-05.......................
[CV 4/5; 15/48] END max_iter=100, penalty=l1, tol=1e-05;, score=nan total time=   0.0s
[CV 5/5; 15/48] START max_iter=100, penalty=l1, tol=1e-05.......................
[CV 5/5; 15/48] END max_iter=100, penalty=l1, tol=1e-05;, score=nan total time=   0.0s
[CV 1/5; 16/48] START max_iter=100, penalty=l2, tol=0.001.......................
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 1/5; 16/48] END max_iter=100, penalty=l2, tol=0.001;, score=0.706 total time=   0.6s
[CV 2/5; 16/48] START max_iter=100, penalty=l2, tol=0.001.......................
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 2/5; 16/48] END max_iter=100, penalty=l2, tol=0.001;, score=0.726 total time=   0.7s
[CV 3/5; 16/48] START max_iter=100, penalty=l2, tol=0.001.......................
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 3/5; 16/48] END max_iter=100, penalty=l2, tol=0.001;, score=0.717 total time=   0.6s
[CV 4/5; 16/48] START max_iter=100, penalty=l2, tol=0.001.......................
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 4/5; 16/48] END max_iter=100, penalty=l2, tol=0.001;, score=0.712 total time=   0.6s
[CV 5/5; 16/48] START max_iter=100, penalty=l2, tol=0.001.......................
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 5/5; 16/48] END max_iter=100, penalty=l2, tol=0.001;, score=0.721 total time=   0.6s
[CV 1/5; 17/48] START max_iter=100, penalty=l2, tol=0.0001......................
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 1/5; 17/48] END max_iter=100, penalty=l2, tol=0.0001;, score=0.706 total time=   0.7s
[CV 2/5; 17/48] START max_iter=100, penalty=l2, tol=0.0001......................
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 2/5; 17/48] END max_iter=100, penalty=l2, tol=0.0001;, score=0.726 total time=   0.6s
[CV 3/5; 17/48] START max_iter=100, penalty=l2, tol=0.0001......................
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 3/5; 17/48] END max_iter=100, penalty=l2, tol=0.0001;, score=0.717 total time=   0.5s
[CV 4/5; 17/48] START max_iter=100, penalty=l2, tol=0.0001......................
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 4/5; 17/48] END max_iter=100, penalty=l2, tol=0.0001;, score=0.712 total time=   0.6s
[CV 5/5; 17/48] START max_iter=100, penalty=l2, tol=0.0001......................
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 5/5; 17/48] END max_iter=100, penalty=l2, tol=0.0001;, score=0.721 total time=   0.7s
[CV 1/5; 18/48] START max_iter=100, penalty=l2, tol=1e-05.......................
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 1/5; 18/48] END max_iter=100, penalty=l2, tol=1e-05;, score=0.706 total time=   0.6s
[CV 2/5; 18/48] START max_iter=100, penalty=l2, tol=1e-05.......................
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 2/5; 18/48] END max_iter=100, penalty=l2, tol=1e-05;, score=0.726 total time=   0.7s
[CV 3/5; 18/48] START max_iter=100, penalty=l2, tol=1e-05.......................
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 3/5; 18/48] END max_iter=100, penalty=l2, tol=1e-05;, score=0.717 total time=   0.6s
[CV 4/5; 18/48] START max_iter=100, penalty=l2, tol=1e-05.......................
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 4/5; 18/48] END max_iter=100, penalty=l2, tol=1e-05;, score=0.712 total time=   0.6s
[CV 5/5; 18/48] START max_iter=100, penalty=l2, tol=1e-05.......................
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 5/5; 18/48] END max_iter=100, penalty=l2, tol=1e-05;, score=0.721 total time=   0.6s
[CV 1/5; 19/48] START max_iter=100, penalty=elasticnet, tol=0.001...............
[CV 1/5; 19/48] END max_iter=100, penalty=elasticnet, tol=0.001;, score=nan total time=   0.0s
[CV 2/5; 19/48] START max_iter=100, penalty=elasticnet, tol=0.001...............
[CV 2/5; 19/48] END max_iter=100, penalty=elasticnet, tol=0.001;, score=nan total time=   0.0s
[CV 3/5; 19/48] START max_iter=100, penalty=elasticnet, tol=0.001...............
[CV 3/5; 19/48] END max_iter=100, penalty=elasticnet, tol=0.001;, score=nan total time=   0.0s
[CV 4/5; 19/48] START max_iter=100, penalty=elasticnet, tol=0.001...............
[CV 4/5; 19/48] END max_iter=100, penalty=elasticnet, tol=0.001;, score=nan total time=   0.0s
[CV 5/5; 19/48] START max_iter=100, penalty=elasticnet, tol=0.001...............
[CV 5/5; 19/48] END max_iter=100, penalty=elasticnet, tol=0.001;, score=nan total time=   0.0s
[CV 1/5; 20/48] START max_iter=100, penalty=elasticnet, tol=0.0001..............
[CV 1/5; 20/48] END max_iter=100, penalty=elasticnet, tol=0.0001;, score=nan total time=   0.0s
[CV 2/5; 20/48] START max_iter=100, penalty=elasticnet, tol=0.0001..............
[CV 2/5; 20/48] END max_iter=100, penalty=elasticnet, tol=0.0001;, score=nan total time=   0.0s
[CV 3/5; 20/48] START max_iter=100, penalty=elasticnet, tol=0.0001..............
[CV 3/5; 20/48] END max_iter=100, penalty=elasticnet, tol=0.0001;, score=nan total time=   0.0s
[CV 4/5; 20/48] START max_iter=100, penalty=elasticnet, tol=0.0001..............
[CV 4/5; 20/48] END max_iter=100, penalty=elasticnet, tol=0.0001;, score=nan total time=   0.0s
[CV 5/5; 20/48] START max_iter=100, penalty=elasticnet, tol=0.0001..............
[CV 5/5; 20/48] END max_iter=100, penalty=elasticnet, tol=0.0001;, score=nan total time=   0.0s
[CV 1/5; 21/48] START max_iter=100, penalty=elasticnet, tol=1e-05...............
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 1/5; 21/48] END max_iter=100, penalty=elasticnet, tol=1e-05;, score=nan total time=   0.0s
[CV 2/5; 21/48] START max_iter=100, penalty=elasticnet, tol=1e-05...............
[CV 2/5; 21/48] END max_iter=100, penalty=elasticnet, tol=1e-05;, score=nan total time=   0.0s
[CV 3/5; 21/48] START max_iter=100, penalty=elasticnet, tol=1e-05...............
[CV 3/5; 21/48] END max_iter=100, penalty=elasticnet, tol=1e-05;, score=nan total time=   0.0s
[CV 4/5; 21/48] START max_iter=100, penalty=elasticnet, tol=1e-05...............
[CV 4/5; 21/48] END max_iter=100, penalty=elasticnet, tol=1e-05;, score=nan total time=   0.0s
[CV 5/5; 21/48] START max_iter=100, penalty=elasticnet, tol=1e-05...............
[CV 5/5; 21/48] END max_iter=100, penalty=elasticnet, tol=1e-05;, score=nan total time=   0.0s
[CV 1/5; 22/48] START max_iter=100, penalty=none, tol=0.001.....................
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 1/5; 22/48] END max_iter=100, penalty=none, tol=0.001;, score=0.706 total time=   0.6s
[CV 2/5; 22/48] START max_iter=100, penalty=none, tol=0.001.....................
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 2/5; 22/48] END max_iter=100, penalty=none, tol=0.001;, score=0.725 total time=   0.7s
[CV 3/5; 22/48] START max_iter=100, penalty=none, tol=0.001.....................
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 3/5; 22/48] END max_iter=100, penalty=none, tol=0.001;, score=0.719 total time=   0.7s
[CV 4/5; 22/48] START max_iter=100, penalty=none, tol=0.001.....................
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 4/5; 22/48] END max_iter=100, penalty=none, tol=0.001;, score=0.712 total time=   0.6s
[CV 5/5; 22/48] START max_iter=100, penalty=none, tol=0.001.....................
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 5/5; 22/48] END max_iter=100, penalty=none, tol=0.001;, score=0.721 total time=   0.7s
[CV 1/5; 23/48] START max_iter=100, penalty=none, tol=0.0001....................
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 1/5; 23/48] END max_iter=100, penalty=none, tol=0.0001;, score=0.706 total time=   0.6s
[CV 2/5; 23/48] START max_iter=100, penalty=none, tol=0.0001....................
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 2/5; 23/48] END max_iter=100, penalty=none, tol=0.0001;, score=0.725 total time=   0.7s
[CV 3/5; 23/48] START max_iter=100, penalty=none, tol=0.0001....................
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 3/5; 23/48] END max_iter=100, penalty=none, tol=0.0001;, score=0.719 total time=   0.7s
[CV 4/5; 23/48] START max_iter=100, penalty=none, tol=0.0001....................
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 4/5; 23/48] END max_iter=100, penalty=none, tol=0.0001;, score=0.712 total time=   0.7s
[CV 5/5; 23/48] START max_iter=100, penalty=none, tol=0.0001....................
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 5/5; 23/48] END max_iter=100, penalty=none, tol=0.0001;, score=0.721 total time=   0.6s
[CV 1/5; 24/48] START max_iter=100, penalty=none, tol=1e-05.....................
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 1/5; 24/48] END max_iter=100, penalty=none, tol=1e-05;, score=0.706 total time=   0.7s
[CV 2/5; 24/48] START max_iter=100, penalty=none, tol=1e-05.....................
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 2/5; 24/48] END max_iter=100, penalty=none, tol=1e-05;, score=0.725 total time=   0.6s
[CV 3/5; 24/48] START max_iter=100, penalty=none, tol=1e-05.....................
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 3/5; 24/48] END max_iter=100, penalty=none, tol=1e-05;, score=0.719 total time=   0.7s
[CV 4/5; 24/48] START max_iter=100, penalty=none, tol=1e-05.....................
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 4/5; 24/48] END max_iter=100, penalty=none, tol=1e-05;, score=0.712 total time=   0.6s
[CV 5/5; 24/48] START max_iter=100, penalty=none, tol=1e-05.....................
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 5/5; 24/48] END max_iter=100, penalty=none, tol=1e-05;, score=0.721 total time=   0.6s
[CV 1/5; 25/48] START max_iter=150, penalty=l1, tol=0.001.......................
[CV 1/5; 25/48] END max_iter=150, penalty=l1, tol=0.001;, score=nan total time=   0.0s
[CV 2/5; 25/48] START max_iter=150, penalty=l1, tol=0.001.......................
[CV 2/5; 25/48] END max_iter=150, penalty=l1, tol=0.001;, score=nan total time=   0.0s
[CV 3/5; 25/48] START max_iter=150, penalty=l1, tol=0.001.......................
[CV 3/5; 25/48] END max_iter=150, penalty=l1, tol=0.001;, score=nan total time=   0.0s
[CV 4/5; 25/48] START max_iter=150, penalty=l1, tol=0.001.......................
[CV 4/5; 25/48] END max_iter=150, penalty=l1, tol=0.001;, score=nan total time=   0.0s
[CV 5/5; 25/48] START max_iter=150, penalty=l1, tol=0.001.......................
[CV 5/5; 25/48] END max_iter=150, penalty=l1, tol=0.001;, score=nan total time=   0.0s
[CV 1/5; 26/48] START max_iter=150, penalty=l1, tol=0.0001......................
[CV 1/5; 26/48] END max_iter=150, penalty=l1, tol=0.0001;, score=nan total time=   0.0s
[CV 2/5; 26/48] START max_iter=150, penalty=l1, tol=0.0001......................
[CV 2/5; 26/48] END max_iter=150, penalty=l1, tol=0.0001;, score=nan total time=   0.0s
[CV 3/5; 26/48] START max_iter=150, penalty=l1, tol=0.0001......................
[CV 3/5; 26/48] END max_iter=150, penalty=l1, tol=0.0001;, score=nan total time=   0.0s
[CV 4/5; 26/48] START max_iter=150, penalty=l1, tol=0.0001......................
[CV 4/5; 26/48] END max_iter=150, penalty=l1, tol=0.0001;, score=nan total time=   0.0s
[CV 5/5; 26/48] START max_iter=150, penalty=l1, tol=0.0001......................
[CV 5/5; 26/48] END max_iter=150, penalty=l1, tol=0.0001;, score=nan total time=   0.0s
[CV 1/5; 27/48] START max_iter=150, penalty=l1, tol=1e-05.......................
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 1/5; 27/48] END max_iter=150, penalty=l1, tol=1e-05;, score=nan total time=   0.0s
[CV 2/5; 27/48] START max_iter=150, penalty=l1, tol=1e-05.......................
[CV 2/5; 27/48] END max_iter=150, penalty=l1, tol=1e-05;, score=nan total time=   0.0s
[CV 3/5; 27/48] START max_iter=150, penalty=l1, tol=1e-05.......................
[CV 3/5; 27/48] END max_iter=150, penalty=l1, tol=1e-05;, score=nan total time=   0.0s
[CV 4/5; 27/48] START max_iter=150, penalty=l1, tol=1e-05.......................
[CV 4/5; 27/48] END max_iter=150, penalty=l1, tol=1e-05;, score=nan total time=   0.0s
[CV 5/5; 27/48] START max_iter=150, penalty=l1, tol=1e-05.......................
[CV 5/5; 27/48] END max_iter=150, penalty=l1, tol=1e-05;, score=nan total time=   0.0s
[CV 1/5; 28/48] START max_iter=150, penalty=l2, tol=0.001.......................
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 1/5; 28/48] END max_iter=150, penalty=l2, tol=0.001;, score=0.705 total time=   0.9s
[CV 2/5; 28/48] START max_iter=150, penalty=l2, tol=0.001.......................
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 2/5; 28/48] END max_iter=150, penalty=l2, tol=0.001;, score=0.726 total time=   1.0s
[CV 3/5; 28/48] START max_iter=150, penalty=l2, tol=0.001.......................
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 3/5; 28/48] END max_iter=150, penalty=l2, tol=0.001;, score=0.718 total time=   0.9s
[CV 4/5; 28/48] START max_iter=150, penalty=l2, tol=0.001.......................
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 4/5; 28/48] END max_iter=150, penalty=l2, tol=0.001;, score=0.712 total time=   0.9s
[CV 5/5; 28/48] START max_iter=150, penalty=l2, tol=0.001.......................
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 5/5; 28/48] END max_iter=150, penalty=l2, tol=0.001;, score=0.722 total time=   1.1s
[CV 1/5; 29/48] START max_iter=150, penalty=l2, tol=0.0001......................
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 1/5; 29/48] END max_iter=150, penalty=l2, tol=0.0001;, score=0.705 total time=   0.9s
[CV 2/5; 29/48] START max_iter=150, penalty=l2, tol=0.0001......................
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 2/5; 29/48] END max_iter=150, penalty=l2, tol=0.0001;, score=0.726 total time=   0.8s
[CV 3/5; 29/48] START max_iter=150, penalty=l2, tol=0.0001......................
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 3/5; 29/48] END max_iter=150, penalty=l2, tol=0.0001;, score=0.718 total time=   0.9s
[CV 4/5; 29/48] START max_iter=150, penalty=l2, tol=0.0001......................
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 4/5; 29/48] END max_iter=150, penalty=l2, tol=0.0001;, score=0.712 total time=   0.9s
[CV 5/5; 29/48] START max_iter=150, penalty=l2, tol=0.0001......................
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 5/5; 29/48] END max_iter=150, penalty=l2, tol=0.0001;, score=0.722 total time=   1.0s
[CV 1/5; 30/48] START max_iter=150, penalty=l2, tol=1e-05.......................
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 1/5; 30/48] END max_iter=150, penalty=l2, tol=1e-05;, score=0.705 total time=   1.0s
[CV 2/5; 30/48] START max_iter=150, penalty=l2, tol=1e-05.......................
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 2/5; 30/48] END max_iter=150, penalty=l2, tol=1e-05;, score=0.726 total time=   1.0s
[CV 3/5; 30/48] START max_iter=150, penalty=l2, tol=1e-05.......................
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 3/5; 30/48] END max_iter=150, penalty=l2, tol=1e-05;, score=0.718 total time=   0.9s
[CV 4/5; 30/48] START max_iter=150, penalty=l2, tol=1e-05.......................
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 4/5; 30/48] END max_iter=150, penalty=l2, tol=1e-05;, score=0.712 total time=   0.9s
[CV 5/5; 30/48] START max_iter=150, penalty=l2, tol=1e-05.......................
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 5/5; 30/48] END max_iter=150, penalty=l2, tol=1e-05;, score=0.722 total time=   1.0s
[CV 1/5; 31/48] START max_iter=150, penalty=elasticnet, tol=0.001...............
[CV 1/5; 31/48] END max_iter=150, penalty=elasticnet, tol=0.001;, score=nan total time=   0.0s
[CV 2/5; 31/48] START max_iter=150, penalty=elasticnet, tol=0.001...............
[CV 2/5; 31/48] END max_iter=150, penalty=elasticnet, tol=0.001;, score=nan total time=   0.0s
[CV 3/5; 31/48] START max_iter=150, penalty=elasticnet, tol=0.001...............
[CV 3/5; 31/48] END max_iter=150, penalty=elasticnet, tol=0.001;, score=nan total time=   0.0s
[CV 4/5; 31/48] START max_iter=150, penalty=elasticnet, tol=0.001...............
[CV 4/5; 31/48] END max_iter=150, penalty=elasticnet, tol=0.001;, score=nan total time=   0.0s
[CV 5/5; 31/48] START max_iter=150, penalty=elasticnet, tol=0.001...............
[CV 5/5; 31/48] END max_iter=150, penalty=elasticnet, tol=0.001;, score=nan total time=   0.0s
[CV 1/5; 32/48] START max_iter=150, penalty=elasticnet, tol=0.0001..............
[CV 1/5; 32/48] END max_iter=150, penalty=elasticnet, tol=0.0001;, score=nan total time=   0.0s
[CV 2/5; 32/48] START max_iter=150, penalty=elasticnet, tol=0.0001..............
[CV 2/5; 32/48] END max_iter=150, penalty=elasticnet, tol=0.0001;, score=nan total time=   0.0s
[CV 3/5; 32/48] START max_iter=150, penalty=elasticnet, tol=0.0001..............
[CV 3/5; 32/48] END max_iter=150, penalty=elasticnet, tol=0.0001;, score=nan total time=   0.0s
[CV 4/5; 32/48] START max_iter=150, penalty=elasticnet, tol=0.0001..............
[CV 4/5; 32/48] END max_iter=150, penalty=elasticnet, tol=0.0001;, score=nan total time=   0.0s
[CV 5/5; 32/48] START max_iter=150, penalty=elasticnet, tol=0.0001..............
[CV 5/5; 32/48] END max_iter=150, penalty=elasticnet, tol=0.0001;, score=nan total time=   0.0s
[CV 1/5; 33/48] START max_iter=150, penalty=elasticnet, tol=1e-05...............</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>
[CV 1/5; 33/48] END max_iter=150, penalty=elasticnet, tol=1e-05;, score=nan total time=   0.0s
[CV 2/5; 33/48] START max_iter=150, penalty=elasticnet, tol=1e-05...............
[CV 2/5; 33/48] END max_iter=150, penalty=elasticnet, tol=1e-05;, score=nan total time=   0.0s
[CV 3/5; 33/48] START max_iter=150, penalty=elasticnet, tol=1e-05...............
[CV 3/5; 33/48] END max_iter=150, penalty=elasticnet, tol=1e-05;, score=nan total time=   0.0s
[CV 4/5; 33/48] START max_iter=150, penalty=elasticnet, tol=1e-05...............
[CV 4/5; 33/48] END max_iter=150, penalty=elasticnet, tol=1e-05;, score=nan total time=   0.0s
[CV 5/5; 33/48] START max_iter=150, penalty=elasticnet, tol=1e-05...............
[CV 5/5; 33/48] END max_iter=150, penalty=elasticnet, tol=1e-05;, score=nan total time=   0.0s
[CV 1/5; 34/48] START max_iter=150, penalty=none, tol=0.001.....................
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 1/5; 34/48] END max_iter=150, penalty=none, tol=0.001;, score=0.706 total time=   0.9s
[CV 2/5; 34/48] START max_iter=150, penalty=none, tol=0.001.....................
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 2/5; 34/48] END max_iter=150, penalty=none, tol=0.001;, score=0.726 total time=   0.9s
[CV 3/5; 34/48] START max_iter=150, penalty=none, tol=0.001.....................
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 3/5; 34/48] END max_iter=150, penalty=none, tol=0.001;, score=0.719 total time=   0.9s
[CV 4/5; 34/48] START max_iter=150, penalty=none, tol=0.001.....................
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 4/5; 34/48] END max_iter=150, penalty=none, tol=0.001;, score=0.712 total time=   0.9s
[CV 5/5; 34/48] START max_iter=150, penalty=none, tol=0.001.....................
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 5/5; 34/48] END max_iter=150, penalty=none, tol=0.001;, score=0.720 total time=   0.9s
[CV 1/5; 35/48] START max_iter=150, penalty=none, tol=0.0001....................
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 1/5; 35/48] END max_iter=150, penalty=none, tol=0.0001;, score=0.706 total time=   0.8s
[CV 2/5; 35/48] START max_iter=150, penalty=none, tol=0.0001....................
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 2/5; 35/48] END max_iter=150, penalty=none, tol=0.0001;, score=0.726 total time=   0.8s
[CV 3/5; 35/48] START max_iter=150, penalty=none, tol=0.0001....................
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 3/5; 35/48] END max_iter=150, penalty=none, tol=0.0001;, score=0.719 total time=   0.8s
[CV 4/5; 35/48] START max_iter=150, penalty=none, tol=0.0001....................
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 4/5; 35/48] END max_iter=150, penalty=none, tol=0.0001;, score=0.712 total time=   0.8s
[CV 5/5; 35/48] START max_iter=150, penalty=none, tol=0.0001....................
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 5/5; 35/48] END max_iter=150, penalty=none, tol=0.0001;, score=0.720 total time=   0.9s
[CV 1/5; 36/48] START max_iter=150, penalty=none, tol=1e-05.....................
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 1/5; 36/48] END max_iter=150, penalty=none, tol=1e-05;, score=0.706 total time=   0.9s
[CV 2/5; 36/48] START max_iter=150, penalty=none, tol=1e-05.....................
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 2/5; 36/48] END max_iter=150, penalty=none, tol=1e-05;, score=0.726 total time=   1.0s
[CV 3/5; 36/48] START max_iter=150, penalty=none, tol=1e-05.....................
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 3/5; 36/48] END max_iter=150, penalty=none, tol=1e-05;, score=0.719 total time=   0.9s
[CV 4/5; 36/48] START max_iter=150, penalty=none, tol=1e-05.....................
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 4/5; 36/48] END max_iter=150, penalty=none, tol=1e-05;, score=0.712 total time=   0.9s
[CV 5/5; 36/48] START max_iter=150, penalty=none, tol=1e-05.....................
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 5/5; 36/48] END max_iter=150, penalty=none, tol=1e-05;, score=0.720 total time=   1.1s
[CV 1/5; 37/48] START max_iter=200, penalty=l1, tol=0.001.......................
[CV 1/5; 37/48] END max_iter=200, penalty=l1, tol=0.001;, score=nan total time=   0.0s
[CV 2/5; 37/48] START max_iter=200, penalty=l1, tol=0.001.......................
[CV 2/5; 37/48] END max_iter=200, penalty=l1, tol=0.001;, score=nan total time=   0.0s
[CV 3/5; 37/48] START max_iter=200, penalty=l1, tol=0.001.......................
[CV 3/5; 37/48] END max_iter=200, penalty=l1, tol=0.001;, score=nan total time=   0.0s
[CV 4/5; 37/48] START max_iter=200, penalty=l1, tol=0.001.......................
[CV 4/5; 37/48] END max_iter=200, penalty=l1, tol=0.001;, score=nan total time=   0.0s
[CV 5/5; 37/48] START max_iter=200, penalty=l1, tol=0.001.......................
[CV 5/5; 37/48] END max_iter=200, penalty=l1, tol=0.001;, score=nan total time=   0.0s
[CV 1/5; 38/48] START max_iter=200, penalty=l1, tol=0.0001......................
[CV 1/5; 38/48] END max_iter=200, penalty=l1, tol=0.0001;, score=nan total time=   0.0s
[CV 2/5; 38/48] START max_iter=200, penalty=l1, tol=0.0001......................
[CV 2/5; 38/48] END max_iter=200, penalty=l1, tol=0.0001;, score=nan total time=   0.0s
[CV 3/5; 38/48] START max_iter=200, penalty=l1, tol=0.0001......................
[CV 3/5; 38/48] END max_iter=200, penalty=l1, tol=0.0001;, score=nan total time=   0.0s
[CV 4/5; 38/48] START max_iter=200, penalty=l1, tol=0.0001......................
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 4/5; 38/48] END max_iter=200, penalty=l1, tol=0.0001;, score=nan total time=   0.0s
[CV 5/5; 38/48] START max_iter=200, penalty=l1, tol=0.0001......................
[CV 5/5; 38/48] END max_iter=200, penalty=l1, tol=0.0001;, score=nan total time=   0.0s
[CV 1/5; 39/48] START max_iter=200, penalty=l1, tol=1e-05.......................
[CV 1/5; 39/48] END max_iter=200, penalty=l1, tol=1e-05;, score=nan total time=   0.0s
[CV 2/5; 39/48] START max_iter=200, penalty=l1, tol=1e-05.......................
[CV 2/5; 39/48] END max_iter=200, penalty=l1, tol=1e-05;, score=nan total time=   0.0s
[CV 3/5; 39/48] START max_iter=200, penalty=l1, tol=1e-05.......................
[CV 3/5; 39/48] END max_iter=200, penalty=l1, tol=1e-05;, score=nan total time=   0.0s
[CV 4/5; 39/48] START max_iter=200, penalty=l1, tol=1e-05.......................
[CV 4/5; 39/48] END max_iter=200, penalty=l1, tol=1e-05;, score=nan total time=   0.0s
[CV 5/5; 39/48] START max_iter=200, penalty=l1, tol=1e-05.......................
[CV 5/5; 39/48] END max_iter=200, penalty=l1, tol=1e-05;, score=nan total time=   0.0s
[CV 1/5; 40/48] START max_iter=200, penalty=l2, tol=0.001.......................
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 1/5; 40/48] END max_iter=200, penalty=l2, tol=0.001;, score=0.705 total time=   1.2s
[CV 2/5; 40/48] START max_iter=200, penalty=l2, tol=0.001.......................
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 2/5; 40/48] END max_iter=200, penalty=l2, tol=0.001;, score=0.726 total time=   1.1s
[CV 3/5; 40/48] START max_iter=200, penalty=l2, tol=0.001.......................
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 3/5; 40/48] END max_iter=200, penalty=l2, tol=0.001;, score=0.719 total time=   1.1s
[CV 4/5; 40/48] START max_iter=200, penalty=l2, tol=0.001.......................
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 4/5; 40/48] END max_iter=200, penalty=l2, tol=0.001;, score=0.712 total time=   1.1s
[CV 5/5; 40/48] START max_iter=200, penalty=l2, tol=0.001.......................
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 5/5; 40/48] END max_iter=200, penalty=l2, tol=0.001;, score=0.722 total time=   1.1s
[CV 1/5; 41/48] START max_iter=200, penalty=l2, tol=0.0001......................
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 1/5; 41/48] END max_iter=200, penalty=l2, tol=0.0001;, score=0.705 total time=   1.2s
[CV 2/5; 41/48] START max_iter=200, penalty=l2, tol=0.0001......................
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 2/5; 41/48] END max_iter=200, penalty=l2, tol=0.0001;, score=0.726 total time=   1.1s
[CV 3/5; 41/48] START max_iter=200, penalty=l2, tol=0.0001......................
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 3/5; 41/48] END max_iter=200, penalty=l2, tol=0.0001;, score=0.719 total time=   1.1s
[CV 4/5; 41/48] START max_iter=200, penalty=l2, tol=0.0001......................
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 4/5; 41/48] END max_iter=200, penalty=l2, tol=0.0001;, score=0.712 total time=   1.1s
[CV 5/5; 41/48] START max_iter=200, penalty=l2, tol=0.0001......................
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 5/5; 41/48] END max_iter=200, penalty=l2, tol=0.0001;, score=0.722 total time=   1.3s
[CV 1/5; 42/48] START max_iter=200, penalty=l2, tol=1e-05.......................
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 1/5; 42/48] END max_iter=200, penalty=l2, tol=1e-05;, score=0.705 total time=   1.1s
[CV 2/5; 42/48] START max_iter=200, penalty=l2, tol=1e-05.......................
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 2/5; 42/48] END max_iter=200, penalty=l2, tol=1e-05;, score=0.726 total time=   1.4s
[CV 3/5; 42/48] START max_iter=200, penalty=l2, tol=1e-05.......................
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 3/5; 42/48] END max_iter=200, penalty=l2, tol=1e-05;, score=0.719 total time=   1.3s
[CV 4/5; 42/48] START max_iter=200, penalty=l2, tol=1e-05.......................
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 4/5; 42/48] END max_iter=200, penalty=l2, tol=1e-05;, score=0.712 total time=   1.2s
[CV 5/5; 42/48] START max_iter=200, penalty=l2, tol=1e-05.......................
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 5/5; 42/48] END max_iter=200, penalty=l2, tol=1e-05;, score=0.722 total time=   1.4s
[CV 1/5; 43/48] START max_iter=200, penalty=elasticnet, tol=0.001...............
[CV 1/5; 43/48] END max_iter=200, penalty=elasticnet, tol=0.001;, score=nan total time=   0.0s
[CV 2/5; 43/48] START max_iter=200, penalty=elasticnet, tol=0.001...............
[CV 2/5; 43/48] END max_iter=200, penalty=elasticnet, tol=0.001;, score=nan total time=   0.0s
[CV 3/5; 43/48] START max_iter=200, penalty=elasticnet, tol=0.001...............
[CV 3/5; 43/48] END max_iter=200, penalty=elasticnet, tol=0.001;, score=nan total time=   0.0s
[CV 4/5; 43/48] START max_iter=200, penalty=elasticnet, tol=0.001...............
[CV 4/5; 43/48] END max_iter=200, penalty=elasticnet, tol=0.001;, score=nan total time=   0.0s
[CV 5/5; 43/48] START max_iter=200, penalty=elasticnet, tol=0.001...............
[CV 5/5; 43/48] END max_iter=200, penalty=elasticnet, tol=0.001;, score=nan total time=   0.0s
[CV 1/5; 44/48] START max_iter=200, penalty=elasticnet, tol=0.0001..............
[CV 1/5; 44/48] END max_iter=200, penalty=elasticnet, tol=0.0001;, score=nan total time=   0.0s
[CV 2/5; 44/48] START max_iter=200, penalty=elasticnet, tol=0.0001..............
[CV 2/5; 44/48] END max_iter=200, penalty=elasticnet, tol=0.0001;, score=nan total time=   0.0s
[CV 3/5; 44/48] START max_iter=200, penalty=elasticnet, tol=0.0001..............
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py&#34;, line 598, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 1306, in fit
    solver = _check_solver(self.solver, self.penalty, self.dual)
  File &#34;C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py&#34;, line 443, in _check_solver
    raise ValueError(&#34;Solver %s supports only &#39;l2&#39; or &#39;none&#39; penalties, &#34;
ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got elasticnet penalty.

  warnings.warn(&#34;Estimator fit failed. The score on this train-test&#34;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 3/5; 44/48] END max_iter=200, penalty=elasticnet, tol=0.0001;, score=nan total time=   0.0s
[CV 4/5; 44/48] START max_iter=200, penalty=elasticnet, tol=0.0001..............
[CV 4/5; 44/48] END max_iter=200, penalty=elasticnet, tol=0.0001;, score=nan total time=   0.0s
[CV 5/5; 44/48] START max_iter=200, penalty=elasticnet, tol=0.0001..............
[CV 5/5; 44/48] END max_iter=200, penalty=elasticnet, tol=0.0001;, score=nan total time=   0.0s
[CV 1/5; 45/48] START max_iter=200, penalty=elasticnet, tol=1e-05...............
[CV 1/5; 45/48] END max_iter=200, penalty=elasticnet, tol=1e-05;, score=nan total time=   0.0s
[CV 2/5; 45/48] START max_iter=200, penalty=elasticnet, tol=1e-05...............
[CV 2/5; 45/48] END max_iter=200, penalty=elasticnet, tol=1e-05;, score=nan total time=   0.0s
[CV 3/5; 45/48] START max_iter=200, penalty=elasticnet, tol=1e-05...............
[CV 3/5; 45/48] END max_iter=200, penalty=elasticnet, tol=1e-05;, score=nan total time=   0.0s
[CV 4/5; 45/48] START max_iter=200, penalty=elasticnet, tol=1e-05...............
[CV 4/5; 45/48] END max_iter=200, penalty=elasticnet, tol=1e-05;, score=nan total time=   0.0s
[CV 5/5; 45/48] START max_iter=200, penalty=elasticnet, tol=1e-05...............
[CV 5/5; 45/48] END max_iter=200, penalty=elasticnet, tol=1e-05;, score=nan total time=   0.0s
[CV 1/5; 46/48] START max_iter=200, penalty=none, tol=0.001.....................
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 1/5; 46/48] END max_iter=200, penalty=none, tol=0.001;, score=0.706 total time=   1.2s
[CV 2/5; 46/48] START max_iter=200, penalty=none, tol=0.001.....................
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 2/5; 46/48] END max_iter=200, penalty=none, tol=0.001;, score=0.726 total time=   1.3s
[CV 3/5; 46/48] START max_iter=200, penalty=none, tol=0.001.....................
[CV 3/5; 46/48] END max_iter=200, penalty=none, tol=0.001;, score=0.719 total time=   1.1s
[CV 4/5; 46/48] START max_iter=200, penalty=none, tol=0.001.....................
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 4/5; 46/48] END max_iter=200, penalty=none, tol=0.001;, score=0.712 total time=   1.3s
[CV 5/5; 46/48] START max_iter=200, penalty=none, tol=0.001.....................
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 5/5; 46/48] END max_iter=200, penalty=none, tol=0.001;, score=0.720 total time=   1.3s
[CV 1/5; 47/48] START max_iter=200, penalty=none, tol=0.0001....................
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 1/5; 47/48] END max_iter=200, penalty=none, tol=0.0001;, score=0.706 total time=   1.2s
[CV 2/5; 47/48] START max_iter=200, penalty=none, tol=0.0001....................
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 2/5; 47/48] END max_iter=200, penalty=none, tol=0.0001;, score=0.726 total time=   1.4s
[CV 3/5; 47/48] START max_iter=200, penalty=none, tol=0.0001....................
[CV 3/5; 47/48] END max_iter=200, penalty=none, tol=0.0001;, score=0.719 total time=   1.2s
[CV 4/5; 47/48] START max_iter=200, penalty=none, tol=0.0001....................
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 4/5; 47/48] END max_iter=200, penalty=none, tol=0.0001;, score=0.712 total time=   1.5s
[CV 5/5; 47/48] START max_iter=200, penalty=none, tol=0.0001....................
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 5/5; 47/48] END max_iter=200, penalty=none, tol=0.0001;, score=0.720 total time=   1.3s
[CV 1/5; 48/48] START max_iter=200, penalty=none, tol=1e-05.....................
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 1/5; 48/48] END max_iter=200, penalty=none, tol=1e-05;, score=0.706 total time=   1.4s
[CV 2/5; 48/48] START max_iter=200, penalty=none, tol=1e-05.....................
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 2/5; 48/48] END max_iter=200, penalty=none, tol=1e-05;, score=0.726 total time=   1.4s
[CV 3/5; 48/48] START max_iter=200, penalty=none, tol=1e-05.....................
[CV 3/5; 48/48] END max_iter=200, penalty=none, tol=1e-05;, score=0.719 total time=   1.1s
[CV 4/5; 48/48] START max_iter=200, penalty=none, tol=1e-05.....................
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 4/5; 48/48] END max_iter=200, penalty=none, tol=1e-05;, score=0.712 total time=   1.2s
[CV 5/5; 48/48] START max_iter=200, penalty=none, tol=1e-05.....................
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\model_selection\_search.py:922: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan 0.71695346 0.71695346 0.71695346
        nan        nan        nan 0.71706572 0.71706572 0.71706572
        nan        nan        nan 0.71649056 0.71649056 0.71649056
        nan        nan        nan 0.71652794 0.71652794 0.71652794
        nan        nan        nan 0.71663451 0.71663451 0.71663451
        nan        nan        nan 0.71670507 0.71670507 0.71670507
        nan        nan        nan 0.7168368  0.7168368  0.7168368
        nan        nan        nan 0.71662587 0.71662587 0.71662587]
  warnings.warn(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[CV 5/5; 48/48] END max_iter=200, penalty=none, tol=1e-05;, score=0.720 total time=   1.2s
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt">Out[40]:</div>




<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain">
<pre>GridSearchCV(estimator=LogisticRegression(),
             param_grid={&#39;max_iter&#39;: [50, 100, 150, 200],
                         &#39;penalty&#39;: [&#39;l1&#39;, &#39;l2&#39;, &#39;elasticnet&#39;, &#39;none&#39;],
                         &#39;tol&#39;: [0.001, 0.0001, 1e-05]},
             scoring=&#39;balanced_accuracy&#39;, verbose=10)</pre>
</div>

</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[41]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">grid_search</span><span class="o">.</span><span class="n">best_params_</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt">Out[41]:</div>




<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain">
<pre>{&#39;max_iter&#39;: 50, &#39;penalty&#39;: &#39;none&#39;, &#39;tol&#39;: 0.001}</pre>
</div>

</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[44]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">penalty</span><span class="o">=</span><span class="s1">&#39;none&#39;</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mf">0.001</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">predicted</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">evaluate</span><span class="p">(</span><span class="n">predicted</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Accuracy:  0.8268156424581006
Balanced Accuracy:  0.7205646219313002
Precision:  0.8439236893495569
Recall:  0.9404084365584198
F1:  0.8895574380492439
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[45]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">GridSearchCV</span>
<span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeClassifier</span>

<span class="n">parameters</span> <span class="o">=</span> <span class="p">{</span>  <span class="s1">&#39;max_depth&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">70</span><span class="p">,</span> <span class="mi">90</span><span class="p">,</span> <span class="mi">150</span><span class="p">,</span> <span class="mi">200</span><span class="p">,</span> <span class="mi">300</span><span class="p">],</span>
                <span class="s1">&#39;criterion&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;entropy&#39;</span><span class="p">,</span> <span class="s1">&#39;gini&#39;</span><span class="p">],</span>
                <span class="s1">&#39;min_samples_split&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">10</span><span class="p">]</span>
                 <span class="p">}</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">()</span>

<span class="n">grid_search</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">estimator</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">param_grid</span><span class="o">=</span><span class="n">parameters</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s2">&quot;balanced_accuracy&quot;</span><span class="p">)</span>
<span class="n">grid_search</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Fitting 5 folds for each of 56 candidates, totalling 280 fits
[CV 1/5; 1/56] START criterion=entropy, max_depth=10, min_samples_split=2.......
[CV 1/5; 1/56] END criterion=entropy, max_depth=10, min_samples_split=2;, score=0.657 total time=   0.3s
[CV 2/5; 1/56] START criterion=entropy, max_depth=10, min_samples_split=2.......
[CV 2/5; 1/56] END criterion=entropy, max_depth=10, min_samples_split=2;, score=0.677 total time=   0.3s
[CV 3/5; 1/56] START criterion=entropy, max_depth=10, min_samples_split=2.......
[CV 3/5; 1/56] END criterion=entropy, max_depth=10, min_samples_split=2;, score=0.660 total time=   0.3s
[CV 4/5; 1/56] START criterion=entropy, max_depth=10, min_samples_split=2.......
[CV 4/5; 1/56] END criterion=entropy, max_depth=10, min_samples_split=2;, score=0.656 total time=   0.3s
[CV 5/5; 1/56] START criterion=entropy, max_depth=10, min_samples_split=2.......
[CV 5/5; 1/56] END criterion=entropy, max_depth=10, min_samples_split=2;, score=0.661 total time=   0.3s
[CV 1/5; 2/56] START criterion=entropy, max_depth=10, min_samples_split=4.......
[CV 1/5; 2/56] END criterion=entropy, max_depth=10, min_samples_split=4;, score=0.657 total time=   0.4s
[CV 2/5; 2/56] START criterion=entropy, max_depth=10, min_samples_split=4.......
[CV 2/5; 2/56] END criterion=entropy, max_depth=10, min_samples_split=4;, score=0.677 total time=   0.3s
[CV 3/5; 2/56] START criterion=entropy, max_depth=10, min_samples_split=4.......
[CV 3/5; 2/56] END criterion=entropy, max_depth=10, min_samples_split=4;, score=0.661 total time=   0.4s
[CV 4/5; 2/56] START criterion=entropy, max_depth=10, min_samples_split=4.......
[CV 4/5; 2/56] END criterion=entropy, max_depth=10, min_samples_split=4;, score=0.656 total time=   0.4s
[CV 5/5; 2/56] START criterion=entropy, max_depth=10, min_samples_split=4.......
[CV 5/5; 2/56] END criterion=entropy, max_depth=10, min_samples_split=4;, score=0.661 total time=   0.4s
[CV 1/5; 3/56] START criterion=entropy, max_depth=10, min_samples_split=8.......
[CV 1/5; 3/56] END criterion=entropy, max_depth=10, min_samples_split=8;, score=0.657 total time=   0.3s
[CV 2/5; 3/56] START criterion=entropy, max_depth=10, min_samples_split=8.......
[CV 2/5; 3/56] END criterion=entropy, max_depth=10, min_samples_split=8;, score=0.678 total time=   0.3s
[CV 3/5; 3/56] START criterion=entropy, max_depth=10, min_samples_split=8.......
[CV 3/5; 3/56] END criterion=entropy, max_depth=10, min_samples_split=8;, score=0.662 total time=   0.3s
[CV 4/5; 3/56] START criterion=entropy, max_depth=10, min_samples_split=8.......
[CV 4/5; 3/56] END criterion=entropy, max_depth=10, min_samples_split=8;, score=0.656 total time=   0.3s
[CV 5/5; 3/56] START criterion=entropy, max_depth=10, min_samples_split=8.......
[CV 5/5; 3/56] END criterion=entropy, max_depth=10, min_samples_split=8;, score=0.661 total time=   0.3s
[CV 1/5; 4/56] START criterion=entropy, max_depth=10, min_samples_split=10......
[CV 1/5; 4/56] END criterion=entropy, max_depth=10, min_samples_split=10;, score=0.657 total time=   0.4s
[CV 2/5; 4/56] START criterion=entropy, max_depth=10, min_samples_split=10......
[CV 2/5; 4/56] END criterion=entropy, max_depth=10, min_samples_split=10;, score=0.677 total time=   0.3s
[CV 3/5; 4/56] START criterion=entropy, max_depth=10, min_samples_split=10......
[CV 3/5; 4/56] END criterion=entropy, max_depth=10, min_samples_split=10;, score=0.660 total time=   0.3s
[CV 4/5; 4/56] START criterion=entropy, max_depth=10, min_samples_split=10......
[CV 4/5; 4/56] END criterion=entropy, max_depth=10, min_samples_split=10;, score=0.657 total time=   0.4s
[CV 5/5; 4/56] START criterion=entropy, max_depth=10, min_samples_split=10......
[CV 5/5; 4/56] END criterion=entropy, max_depth=10, min_samples_split=10;, score=0.661 total time=   0.4s
[CV 1/5; 5/56] START criterion=entropy, max_depth=30, min_samples_split=2.......
[CV 1/5; 5/56] END criterion=entropy, max_depth=30, min_samples_split=2;, score=0.638 total time=   0.8s
[CV 2/5; 5/56] START criterion=entropy, max_depth=30, min_samples_split=2.......
[CV 2/5; 5/56] END criterion=entropy, max_depth=30, min_samples_split=2;, score=0.634 total time=   0.7s
[CV 3/5; 5/56] START criterion=entropy, max_depth=30, min_samples_split=2.......
[CV 3/5; 5/56] END criterion=entropy, max_depth=30, min_samples_split=2;, score=0.640 total time=   0.8s
[CV 4/5; 5/56] START criterion=entropy, max_depth=30, min_samples_split=2.......
[CV 4/5; 5/56] END criterion=entropy, max_depth=30, min_samples_split=2;, score=0.648 total time=   0.8s
[CV 5/5; 5/56] START criterion=entropy, max_depth=30, min_samples_split=2.......
[CV 5/5; 5/56] END criterion=entropy, max_depth=30, min_samples_split=2;, score=0.647 total time=   0.8s
[CV 1/5; 6/56] START criterion=entropy, max_depth=30, min_samples_split=4.......
[CV 1/5; 6/56] END criterion=entropy, max_depth=30, min_samples_split=4;, score=0.639 total time=   0.8s
[CV 2/5; 6/56] START criterion=entropy, max_depth=30, min_samples_split=4.......
[CV 2/5; 6/56] END criterion=entropy, max_depth=30, min_samples_split=4;, score=0.639 total time=   0.8s
[CV 3/5; 6/56] START criterion=entropy, max_depth=30, min_samples_split=4.......
[CV 3/5; 6/56] END criterion=entropy, max_depth=30, min_samples_split=4;, score=0.644 total time=   0.8s
[CV 4/5; 6/56] START criterion=entropy, max_depth=30, min_samples_split=4.......
[CV 4/5; 6/56] END criterion=entropy, max_depth=30, min_samples_split=4;, score=0.647 total time=   0.8s
[CV 5/5; 6/56] START criterion=entropy, max_depth=30, min_samples_split=4.......
[CV 5/5; 6/56] END criterion=entropy, max_depth=30, min_samples_split=4;, score=0.647 total time=   0.9s
[CV 1/5; 7/56] START criterion=entropy, max_depth=30, min_samples_split=8.......
[CV 1/5; 7/56] END criterion=entropy, max_depth=30, min_samples_split=8;, score=0.647 total time=   0.8s
[CV 2/5; 7/56] START criterion=entropy, max_depth=30, min_samples_split=8.......
[CV 2/5; 7/56] END criterion=entropy, max_depth=30, min_samples_split=8;, score=0.645 total time=   0.8s
[CV 3/5; 7/56] START criterion=entropy, max_depth=30, min_samples_split=8.......
[CV 3/5; 7/56] END criterion=entropy, max_depth=30, min_samples_split=8;, score=0.644 total time=   0.8s
[CV 4/5; 7/56] START criterion=entropy, max_depth=30, min_samples_split=8.......
[CV 4/5; 7/56] END criterion=entropy, max_depth=30, min_samples_split=8;, score=0.647 total time=   0.8s
[CV 5/5; 7/56] START criterion=entropy, max_depth=30, min_samples_split=8.......
[CV 5/5; 7/56] END criterion=entropy, max_depth=30, min_samples_split=8;, score=0.648 total time=   0.8s
[CV 1/5; 8/56] START criterion=entropy, max_depth=30, min_samples_split=10......
[CV 1/5; 8/56] END criterion=entropy, max_depth=30, min_samples_split=10;, score=0.645 total time=   0.8s
[CV 2/5; 8/56] START criterion=entropy, max_depth=30, min_samples_split=10......
[CV 2/5; 8/56] END criterion=entropy, max_depth=30, min_samples_split=10;, score=0.641 total time=   0.7s
[CV 3/5; 8/56] START criterion=entropy, max_depth=30, min_samples_split=10......
[CV 3/5; 8/56] END criterion=entropy, max_depth=30, min_samples_split=10;, score=0.644 total time=   0.8s
[CV 4/5; 8/56] START criterion=entropy, max_depth=30, min_samples_split=10......
[CV 4/5; 8/56] END criterion=entropy, max_depth=30, min_samples_split=10;, score=0.650 total time=   0.8s
[CV 5/5; 8/56] START criterion=entropy, max_depth=30, min_samples_split=10......
[CV 5/5; 8/56] END criterion=entropy, max_depth=30, min_samples_split=10;, score=0.644 total time=   0.8s
[CV 1/5; 9/56] START criterion=entropy, max_depth=70, min_samples_split=2.......
[CV 1/5; 9/56] END criterion=entropy, max_depth=70, min_samples_split=2;, score=0.640 total time=   0.8s
[CV 2/5; 9/56] START criterion=entropy, max_depth=70, min_samples_split=2.......
[CV 2/5; 9/56] END criterion=entropy, max_depth=70, min_samples_split=2;, score=0.644 total time=   0.8s
[CV 3/5; 9/56] START criterion=entropy, max_depth=70, min_samples_split=2.......
[CV 3/5; 9/56] END criterion=entropy, max_depth=70, min_samples_split=2;, score=0.644 total time=   0.8s
[CV 4/5; 9/56] START criterion=entropy, max_depth=70, min_samples_split=2.......
[CV 4/5; 9/56] END criterion=entropy, max_depth=70, min_samples_split=2;, score=0.651 total time=   0.8s
[CV 5/5; 9/56] START criterion=entropy, max_depth=70, min_samples_split=2.......
[CV 5/5; 9/56] END criterion=entropy, max_depth=70, min_samples_split=2;, score=0.652 total time=   0.8s
[CV 1/5; 10/56] START criterion=entropy, max_depth=70, min_samples_split=4......
[CV 1/5; 10/56] END criterion=entropy, max_depth=70, min_samples_split=4;, score=0.639 total time=   0.8s
[CV 2/5; 10/56] START criterion=entropy, max_depth=70, min_samples_split=4......
[CV 2/5; 10/56] END criterion=entropy, max_depth=70, min_samples_split=4;, score=0.641 total time=   0.8s
[CV 3/5; 10/56] START criterion=entropy, max_depth=70, min_samples_split=4......
[CV 3/5; 10/56] END criterion=entropy, max_depth=70, min_samples_split=4;, score=0.644 total time=   0.8s
[CV 4/5; 10/56] START criterion=entropy, max_depth=70, min_samples_split=4......
[CV 4/5; 10/56] END criterion=entropy, max_depth=70, min_samples_split=4;, score=0.655 total time=   0.8s
[CV 5/5; 10/56] START criterion=entropy, max_depth=70, min_samples_split=4......
[CV 5/5; 10/56] END criterion=entropy, max_depth=70, min_samples_split=4;, score=0.647 total time=   0.8s
[CV 1/5; 11/56] START criterion=entropy, max_depth=70, min_samples_split=8......
[CV 1/5; 11/56] END criterion=entropy, max_depth=70, min_samples_split=8;, score=0.636 total time=   0.8s
[CV 2/5; 11/56] START criterion=entropy, max_depth=70, min_samples_split=8......
[CV 2/5; 11/56] END criterion=entropy, max_depth=70, min_samples_split=8;, score=0.646 total time=   0.8s
[CV 3/5; 11/56] START criterion=entropy, max_depth=70, min_samples_split=8......
[CV 3/5; 11/56] END criterion=entropy, max_depth=70, min_samples_split=8;, score=0.647 total time=   0.8s
[CV 4/5; 11/56] START criterion=entropy, max_depth=70, min_samples_split=8......
[CV 4/5; 11/56] END criterion=entropy, max_depth=70, min_samples_split=8;, score=0.658 total time=   0.8s
[CV 5/5; 11/56] START criterion=entropy, max_depth=70, min_samples_split=8......
[CV 5/5; 11/56] END criterion=entropy, max_depth=70, min_samples_split=8;, score=0.653 total time=   0.7s
[CV 1/5; 12/56] START criterion=entropy, max_depth=70, min_samples_split=10.....
[CV 1/5; 12/56] END criterion=entropy, max_depth=70, min_samples_split=10;, score=0.644 total time=   0.8s
[CV 2/5; 12/56] START criterion=entropy, max_depth=70, min_samples_split=10.....
[CV 2/5; 12/56] END criterion=entropy, max_depth=70, min_samples_split=10;, score=0.651 total time=   0.8s
[CV 3/5; 12/56] START criterion=entropy, max_depth=70, min_samples_split=10.....
[CV 3/5; 12/56] END criterion=entropy, max_depth=70, min_samples_split=10;, score=0.644 total time=   0.8s
[CV 4/5; 12/56] START criterion=entropy, max_depth=70, min_samples_split=10.....
[CV 4/5; 12/56] END criterion=entropy, max_depth=70, min_samples_split=10;, score=0.655 total time=   0.8s
[CV 5/5; 12/56] START criterion=entropy, max_depth=70, min_samples_split=10.....
[CV 5/5; 12/56] END criterion=entropy, max_depth=70, min_samples_split=10;, score=0.652 total time=   0.7s
[CV 1/5; 13/56] START criterion=entropy, max_depth=90, min_samples_split=2......
[CV 1/5; 13/56] END criterion=entropy, max_depth=90, min_samples_split=2;, score=0.639 total time=   0.8s
[CV 2/5; 13/56] START criterion=entropy, max_depth=90, min_samples_split=2......
[CV 2/5; 13/56] END criterion=entropy, max_depth=90, min_samples_split=2;, score=0.642 total time=   0.8s
[CV 3/5; 13/56] START criterion=entropy, max_depth=90, min_samples_split=2......
[CV 3/5; 13/56] END criterion=entropy, max_depth=90, min_samples_split=2;, score=0.645 total time=   0.8s
[CV 4/5; 13/56] START criterion=entropy, max_depth=90, min_samples_split=2......
[CV 4/5; 13/56] END criterion=entropy, max_depth=90, min_samples_split=2;, score=0.650 total time=   0.8s
[CV 5/5; 13/56] START criterion=entropy, max_depth=90, min_samples_split=2......
[CV 5/5; 13/56] END criterion=entropy, max_depth=90, min_samples_split=2;, score=0.653 total time=   0.8s
[CV 1/5; 14/56] START criterion=entropy, max_depth=90, min_samples_split=4......
[CV 1/5; 14/56] END criterion=entropy, max_depth=90, min_samples_split=4;, score=0.639 total time=   0.8s
[CV 2/5; 14/56] START criterion=entropy, max_depth=90, min_samples_split=4......
[CV 2/5; 14/56] END criterion=entropy, max_depth=90, min_samples_split=4;, score=0.643 total time=   0.8s
[CV 3/5; 14/56] START criterion=entropy, max_depth=90, min_samples_split=4......
[CV 3/5; 14/56] END criterion=entropy, max_depth=90, min_samples_split=4;, score=0.646 total time=   0.8s
[CV 4/5; 14/56] START criterion=entropy, max_depth=90, min_samples_split=4......
[CV 4/5; 14/56] END criterion=entropy, max_depth=90, min_samples_split=4;, score=0.653 total time=   0.9s
[CV 5/5; 14/56] START criterion=entropy, max_depth=90, min_samples_split=4......
[CV 5/5; 14/56] END criterion=entropy, max_depth=90, min_samples_split=4;, score=0.647 total time=   0.8s
[CV 1/5; 15/56] START criterion=entropy, max_depth=90, min_samples_split=8......
[CV 1/5; 15/56] END criterion=entropy, max_depth=90, min_samples_split=8;, score=0.641 total time=   0.8s
[CV 2/5; 15/56] START criterion=entropy, max_depth=90, min_samples_split=8......
[CV 2/5; 15/56] END criterion=entropy, max_depth=90, min_samples_split=8;, score=0.643 total time=   0.8s
[CV 3/5; 15/56] START criterion=entropy, max_depth=90, min_samples_split=8......
[CV 3/5; 15/56] END criterion=entropy, max_depth=90, min_samples_split=8;, score=0.647 total time=   0.8s
[CV 4/5; 15/56] START criterion=entropy, max_depth=90, min_samples_split=8......
[CV 4/5; 15/56] END criterion=entropy, max_depth=90, min_samples_split=8;, score=0.657 total time=   0.8s
[CV 5/5; 15/56] START criterion=entropy, max_depth=90, min_samples_split=8......
[CV 5/5; 15/56] END criterion=entropy, max_depth=90, min_samples_split=8;, score=0.655 total time=   0.8s
[CV 1/5; 16/56] START criterion=entropy, max_depth=90, min_samples_split=10.....
[CV 1/5; 16/56] END criterion=entropy, max_depth=90, min_samples_split=10;, score=0.647 total time=   0.8s
[CV 2/5; 16/56] START criterion=entropy, max_depth=90, min_samples_split=10.....
[CV 2/5; 16/56] END criterion=entropy, max_depth=90, min_samples_split=10;, score=0.650 total time=   0.8s
[CV 3/5; 16/56] START criterion=entropy, max_depth=90, min_samples_split=10.....
[CV 3/5; 16/56] END criterion=entropy, max_depth=90, min_samples_split=10;, score=0.649 total time=   0.8s
[CV 4/5; 16/56] START criterion=entropy, max_depth=90, min_samples_split=10.....
[CV 4/5; 16/56] END criterion=entropy, max_depth=90, min_samples_split=10;, score=0.652 total time=   0.8s
[CV 5/5; 16/56] START criterion=entropy, max_depth=90, min_samples_split=10.....
[CV 5/5; 16/56] END criterion=entropy, max_depth=90, min_samples_split=10;, score=0.653 total time=   0.7s
[CV 1/5; 17/56] START criterion=entropy, max_depth=150, min_samples_split=2.....
[CV 1/5; 17/56] END criterion=entropy, max_depth=150, min_samples_split=2;, score=0.643 total time=   0.8s
[CV 2/5; 17/56] START criterion=entropy, max_depth=150, min_samples_split=2.....
[CV 2/5; 17/56] END criterion=entropy, max_depth=150, min_samples_split=2;, score=0.644 total time=   0.8s
[CV 3/5; 17/56] START criterion=entropy, max_depth=150, min_samples_split=2.....
[CV 3/5; 17/56] END criterion=entropy, max_depth=150, min_samples_split=2;, score=0.643 total time=   0.8s
[CV 4/5; 17/56] START criterion=entropy, max_depth=150, min_samples_split=2.....
[CV 4/5; 17/56] END criterion=entropy, max_depth=150, min_samples_split=2;, score=0.652 total time=   0.8s
[CV 5/5; 17/56] START criterion=entropy, max_depth=150, min_samples_split=2.....
[CV 5/5; 17/56] END criterion=entropy, max_depth=150, min_samples_split=2;, score=0.645 total time=   0.8s
[CV 1/5; 18/56] START criterion=entropy, max_depth=150, min_samples_split=4.....
[CV 1/5; 18/56] END criterion=entropy, max_depth=150, min_samples_split=4;, score=0.632 total time=   0.8s
[CV 2/5; 18/56] START criterion=entropy, max_depth=150, min_samples_split=4.....
[CV 2/5; 18/56] END criterion=entropy, max_depth=150, min_samples_split=4;, score=0.641 total time=   0.8s
[CV 3/5; 18/56] START criterion=entropy, max_depth=150, min_samples_split=4.....
[CV 3/5; 18/56] END criterion=entropy, max_depth=150, min_samples_split=4;, score=0.649 total time=   0.8s
[CV 4/5; 18/56] START criterion=entropy, max_depth=150, min_samples_split=4.....
[CV 4/5; 18/56] END criterion=entropy, max_depth=150, min_samples_split=4;, score=0.655 total time=   0.8s
[CV 5/5; 18/56] START criterion=entropy, max_depth=150, min_samples_split=4.....
[CV 5/5; 18/56] END criterion=entropy, max_depth=150, min_samples_split=4;, score=0.647 total time=   0.8s
[CV 1/5; 19/56] START criterion=entropy, max_depth=150, min_samples_split=8.....
[CV 1/5; 19/56] END criterion=entropy, max_depth=150, min_samples_split=8;, score=0.648 total time=   0.8s
[CV 2/5; 19/56] START criterion=entropy, max_depth=150, min_samples_split=8.....
[CV 2/5; 19/56] END criterion=entropy, max_depth=150, min_samples_split=8;, score=0.645 total time=   0.8s
[CV 3/5; 19/56] START criterion=entropy, max_depth=150, min_samples_split=8.....
[CV 3/5; 19/56] END criterion=entropy, max_depth=150, min_samples_split=8;, score=0.644 total time=   0.8s
[CV 4/5; 19/56] START criterion=entropy, max_depth=150, min_samples_split=8.....
[CV 4/5; 19/56] END criterion=entropy, max_depth=150, min_samples_split=8;, score=0.656 total time=   0.8s
[CV 5/5; 19/56] START criterion=entropy, max_depth=150, min_samples_split=8.....
[CV 5/5; 19/56] END criterion=entropy, max_depth=150, min_samples_split=8;, score=0.651 total time=   0.8s
[CV 1/5; 20/56] START criterion=entropy, max_depth=150, min_samples_split=10....
[CV 1/5; 20/56] END criterion=entropy, max_depth=150, min_samples_split=10;, score=0.643 total time=   0.8s
[CV 2/5; 20/56] START criterion=entropy, max_depth=150, min_samples_split=10....
[CV 2/5; 20/56] END criterion=entropy, max_depth=150, min_samples_split=10;, score=0.650 total time=   0.8s
[CV 3/5; 20/56] START criterion=entropy, max_depth=150, min_samples_split=10....
[CV 3/5; 20/56] END criterion=entropy, max_depth=150, min_samples_split=10;, score=0.649 total time=   0.9s
[CV 4/5; 20/56] START criterion=entropy, max_depth=150, min_samples_split=10....
[CV 4/5; 20/56] END criterion=entropy, max_depth=150, min_samples_split=10;, score=0.654 total time=   0.8s
[CV 5/5; 20/56] START criterion=entropy, max_depth=150, min_samples_split=10....
[CV 5/5; 20/56] END criterion=entropy, max_depth=150, min_samples_split=10;, score=0.652 total time=   0.8s
[CV 1/5; 21/56] START criterion=entropy, max_depth=200, min_samples_split=2.....
[CV 1/5; 21/56] END criterion=entropy, max_depth=200, min_samples_split=2;, score=0.647 total time=   0.8s
[CV 2/5; 21/56] START criterion=entropy, max_depth=200, min_samples_split=2.....
[CV 2/5; 21/56] END criterion=entropy, max_depth=200, min_samples_split=2;, score=0.646 total time=   0.8s
[CV 3/5; 21/56] START criterion=entropy, max_depth=200, min_samples_split=2.....
[CV 3/5; 21/56] END criterion=entropy, max_depth=200, min_samples_split=2;, score=0.643 total time=   0.8s
[CV 4/5; 21/56] START criterion=entropy, max_depth=200, min_samples_split=2.....
[CV 4/5; 21/56] END criterion=entropy, max_depth=200, min_samples_split=2;, score=0.650 total time=   0.8s
[CV 5/5; 21/56] START criterion=entropy, max_depth=200, min_samples_split=2.....
[CV 5/5; 21/56] END criterion=entropy, max_depth=200, min_samples_split=2;, score=0.652 total time=   0.8s
[CV 1/5; 22/56] START criterion=entropy, max_depth=200, min_samples_split=4.....
[CV 1/5; 22/56] END criterion=entropy, max_depth=200, min_samples_split=4;, score=0.636 total time=   0.8s
[CV 2/5; 22/56] START criterion=entropy, max_depth=200, min_samples_split=4.....
[CV 2/5; 22/56] END criterion=entropy, max_depth=200, min_samples_split=4;, score=0.643 total time=   0.8s
[CV 3/5; 22/56] START criterion=entropy, max_depth=200, min_samples_split=4.....
[CV 3/5; 22/56] END criterion=entropy, max_depth=200, min_samples_split=4;, score=0.644 total time=   0.8s
[CV 4/5; 22/56] START criterion=entropy, max_depth=200, min_samples_split=4.....
[CV 4/5; 22/56] END criterion=entropy, max_depth=200, min_samples_split=4;, score=0.653 total time=   0.8s
[CV 5/5; 22/56] START criterion=entropy, max_depth=200, min_samples_split=4.....
[CV 5/5; 22/56] END criterion=entropy, max_depth=200, min_samples_split=4;, score=0.651 total time=   0.8s
[CV 1/5; 23/56] START criterion=entropy, max_depth=200, min_samples_split=8.....
[CV 1/5; 23/56] END criterion=entropy, max_depth=200, min_samples_split=8;, score=0.648 total time=   0.8s
[CV 2/5; 23/56] START criterion=entropy, max_depth=200, min_samples_split=8.....
[CV 2/5; 23/56] END criterion=entropy, max_depth=200, min_samples_split=8;, score=0.644 total time=   0.8s
[CV 3/5; 23/56] START criterion=entropy, max_depth=200, min_samples_split=8.....
[CV 3/5; 23/56] END criterion=entropy, max_depth=200, min_samples_split=8;, score=0.641 total time=   0.8s
[CV 4/5; 23/56] START criterion=entropy, max_depth=200, min_samples_split=8.....
[CV 4/5; 23/56] END criterion=entropy, max_depth=200, min_samples_split=8;, score=0.655 total time=   0.8s
[CV 5/5; 23/56] START criterion=entropy, max_depth=200, min_samples_split=8.....
[CV 5/5; 23/56] END criterion=entropy, max_depth=200, min_samples_split=8;, score=0.651 total time=   0.8s
[CV 1/5; 24/56] START criterion=entropy, max_depth=200, min_samples_split=10....
[CV 1/5; 24/56] END criterion=entropy, max_depth=200, min_samples_split=10;, score=0.649 total time=   0.8s
[CV 2/5; 24/56] START criterion=entropy, max_depth=200, min_samples_split=10....
[CV 2/5; 24/56] END criterion=entropy, max_depth=200, min_samples_split=10;, score=0.644 total time=   0.8s
[CV 3/5; 24/56] START criterion=entropy, max_depth=200, min_samples_split=10....
[CV 3/5; 24/56] END criterion=entropy, max_depth=200, min_samples_split=10;, score=0.652 total time=   0.7s
[CV 4/5; 24/56] START criterion=entropy, max_depth=200, min_samples_split=10....
[CV 4/5; 24/56] END criterion=entropy, max_depth=200, min_samples_split=10;, score=0.659 total time=   0.8s
[CV 5/5; 24/56] START criterion=entropy, max_depth=200, min_samples_split=10....
[CV 5/5; 24/56] END criterion=entropy, max_depth=200, min_samples_split=10;, score=0.647 total time=   0.8s
[CV 1/5; 25/56] START criterion=entropy, max_depth=300, min_samples_split=2.....
[CV 1/5; 25/56] END criterion=entropy, max_depth=300, min_samples_split=2;, score=0.641 total time=   0.8s
[CV 2/5; 25/56] START criterion=entropy, max_depth=300, min_samples_split=2.....
[CV 2/5; 25/56] END criterion=entropy, max_depth=300, min_samples_split=2;, score=0.643 total time=   0.8s
[CV 3/5; 25/56] START criterion=entropy, max_depth=300, min_samples_split=2.....
[CV 3/5; 25/56] END criterion=entropy, max_depth=300, min_samples_split=2;, score=0.646 total time=   0.8s
[CV 4/5; 25/56] START criterion=entropy, max_depth=300, min_samples_split=2.....
[CV 4/5; 25/56] END criterion=entropy, max_depth=300, min_samples_split=2;, score=0.652 total time=   0.8s
[CV 5/5; 25/56] START criterion=entropy, max_depth=300, min_samples_split=2.....
[CV 5/5; 25/56] END criterion=entropy, max_depth=300, min_samples_split=2;, score=0.651 total time=   0.8s
[CV 1/5; 26/56] START criterion=entropy, max_depth=300, min_samples_split=4.....
[CV 1/5; 26/56] END criterion=entropy, max_depth=300, min_samples_split=4;, score=0.634 total time=   0.8s
[CV 2/5; 26/56] START criterion=entropy, max_depth=300, min_samples_split=4.....
[CV 2/5; 26/56] END criterion=entropy, max_depth=300, min_samples_split=4;, score=0.639 total time=   0.8s
[CV 3/5; 26/56] START criterion=entropy, max_depth=300, min_samples_split=4.....
[CV 3/5; 26/56] END criterion=entropy, max_depth=300, min_samples_split=4;, score=0.652 total time=   0.8s
[CV 4/5; 26/56] START criterion=entropy, max_depth=300, min_samples_split=4.....
[CV 4/5; 26/56] END criterion=entropy, max_depth=300, min_samples_split=4;, score=0.651 total time=   0.8s
[CV 5/5; 26/56] START criterion=entropy, max_depth=300, min_samples_split=4.....
[CV 5/5; 26/56] END criterion=entropy, max_depth=300, min_samples_split=4;, score=0.648 total time=   0.8s
[CV 1/5; 27/56] START criterion=entropy, max_depth=300, min_samples_split=8.....
[CV 1/5; 27/56] END criterion=entropy, max_depth=300, min_samples_split=8;, score=0.643 total time=   0.8s
[CV 2/5; 27/56] START criterion=entropy, max_depth=300, min_samples_split=8.....
[CV 2/5; 27/56] END criterion=entropy, max_depth=300, min_samples_split=8;, score=0.639 total time=   0.8s
[CV 3/5; 27/56] START criterion=entropy, max_depth=300, min_samples_split=8.....
[CV 3/5; 27/56] END criterion=entropy, max_depth=300, min_samples_split=8;, score=0.645 total time=   0.8s
[CV 4/5; 27/56] START criterion=entropy, max_depth=300, min_samples_split=8.....
[CV 4/5; 27/56] END criterion=entropy, max_depth=300, min_samples_split=8;, score=0.655 total time=   0.8s
[CV 5/5; 27/56] START criterion=entropy, max_depth=300, min_samples_split=8.....
[CV 5/5; 27/56] END criterion=entropy, max_depth=300, min_samples_split=8;, score=0.650 total time=   0.8s
[CV 1/5; 28/56] START criterion=entropy, max_depth=300, min_samples_split=10....
[CV 1/5; 28/56] END criterion=entropy, max_depth=300, min_samples_split=10;, score=0.642 total time=   0.8s
[CV 2/5; 28/56] START criterion=entropy, max_depth=300, min_samples_split=10....
[CV 2/5; 28/56] END criterion=entropy, max_depth=300, min_samples_split=10;, score=0.651 total time=   0.8s
[CV 3/5; 28/56] START criterion=entropy, max_depth=300, min_samples_split=10....
[CV 3/5; 28/56] END criterion=entropy, max_depth=300, min_samples_split=10;, score=0.647 total time=   0.8s
[CV 4/5; 28/56] START criterion=entropy, max_depth=300, min_samples_split=10....
[CV 4/5; 28/56] END criterion=entropy, max_depth=300, min_samples_split=10;, score=0.650 total time=   0.8s
[CV 5/5; 28/56] START criterion=entropy, max_depth=300, min_samples_split=10....
[CV 5/5; 28/56] END criterion=entropy, max_depth=300, min_samples_split=10;, score=0.653 total time=   0.8s
[CV 1/5; 29/56] START criterion=gini, max_depth=10, min_samples_split=2.........
[CV 1/5; 29/56] END criterion=gini, max_depth=10, min_samples_split=2;, score=0.665 total time=   0.3s
[CV 2/5; 29/56] START criterion=gini, max_depth=10, min_samples_split=2.........
[CV 2/5; 29/56] END criterion=gini, max_depth=10, min_samples_split=2;, score=0.672 total time=   0.3s
[CV 3/5; 29/56] START criterion=gini, max_depth=10, min_samples_split=2.........
[CV 3/5; 29/56] END criterion=gini, max_depth=10, min_samples_split=2;, score=0.671 total time=   0.3s
[CV 4/5; 29/56] START criterion=gini, max_depth=10, min_samples_split=2.........
[CV 4/5; 29/56] END criterion=gini, max_depth=10, min_samples_split=2;, score=0.662 total time=   0.3s
[CV 5/5; 29/56] START criterion=gini, max_depth=10, min_samples_split=2.........
[CV 5/5; 29/56] END criterion=gini, max_depth=10, min_samples_split=2;, score=0.658 total time=   0.4s
[CV 1/5; 30/56] START criterion=gini, max_depth=10, min_samples_split=4.........
[CV 1/5; 30/56] END criterion=gini, max_depth=10, min_samples_split=4;, score=0.663 total time=   0.3s
[CV 2/5; 30/56] START criterion=gini, max_depth=10, min_samples_split=4.........
[CV 2/5; 30/56] END criterion=gini, max_depth=10, min_samples_split=4;, score=0.675 total time=   0.4s
[CV 3/5; 30/56] START criterion=gini, max_depth=10, min_samples_split=4.........
[CV 3/5; 30/56] END criterion=gini, max_depth=10, min_samples_split=4;, score=0.672 total time=   0.3s
[CV 4/5; 30/56] START criterion=gini, max_depth=10, min_samples_split=4.........
[CV 4/5; 30/56] END criterion=gini, max_depth=10, min_samples_split=4;, score=0.661 total time=   0.3s
[CV 5/5; 30/56] START criterion=gini, max_depth=10, min_samples_split=4.........
[CV 5/5; 30/56] END criterion=gini, max_depth=10, min_samples_split=4;, score=0.655 total time=   0.3s
[CV 1/5; 31/56] START criterion=gini, max_depth=10, min_samples_split=8.........
[CV 1/5; 31/56] END criterion=gini, max_depth=10, min_samples_split=8;, score=0.663 total time=   0.3s
[CV 2/5; 31/56] START criterion=gini, max_depth=10, min_samples_split=8.........
[CV 2/5; 31/56] END criterion=gini, max_depth=10, min_samples_split=8;, score=0.673 total time=   0.3s
[CV 3/5; 31/56] START criterion=gini, max_depth=10, min_samples_split=8.........
[CV 3/5; 31/56] END criterion=gini, max_depth=10, min_samples_split=8;, score=0.672 total time=   0.4s
[CV 4/5; 31/56] START criterion=gini, max_depth=10, min_samples_split=8.........
[CV 4/5; 31/56] END criterion=gini, max_depth=10, min_samples_split=8;, score=0.661 total time=   0.3s
[CV 5/5; 31/56] START criterion=gini, max_depth=10, min_samples_split=8.........
[CV 5/5; 31/56] END criterion=gini, max_depth=10, min_samples_split=8;, score=0.657 total time=   0.3s
[CV 1/5; 32/56] START criterion=gini, max_depth=10, min_samples_split=10........
[CV 1/5; 32/56] END criterion=gini, max_depth=10, min_samples_split=10;, score=0.663 total time=   0.3s
[CV 2/5; 32/56] START criterion=gini, max_depth=10, min_samples_split=10........
[CV 2/5; 32/56] END criterion=gini, max_depth=10, min_samples_split=10;, score=0.672 total time=   0.3s
[CV 3/5; 32/56] START criterion=gini, max_depth=10, min_samples_split=10........
[CV 3/5; 32/56] END criterion=gini, max_depth=10, min_samples_split=10;, score=0.672 total time=   0.3s
[CV 4/5; 32/56] START criterion=gini, max_depth=10, min_samples_split=10........
[CV 4/5; 32/56] END criterion=gini, max_depth=10, min_samples_split=10;, score=0.660 total time=   0.3s
[CV 5/5; 32/56] START criterion=gini, max_depth=10, min_samples_split=10........
[CV 5/5; 32/56] END criterion=gini, max_depth=10, min_samples_split=10;, score=0.658 total time=   0.3s
[CV 1/5; 33/56] START criterion=gini, max_depth=30, min_samples_split=2.........
[CV 1/5; 33/56] END criterion=gini, max_depth=30, min_samples_split=2;, score=0.628 total time=   0.8s
[CV 2/5; 33/56] START criterion=gini, max_depth=30, min_samples_split=2.........
[CV 2/5; 33/56] END criterion=gini, max_depth=30, min_samples_split=2;, score=0.646 total time=   0.7s
[CV 3/5; 33/56] START criterion=gini, max_depth=30, min_samples_split=2.........
[CV 3/5; 33/56] END criterion=gini, max_depth=30, min_samples_split=2;, score=0.632 total time=   0.8s
[CV 4/5; 33/56] START criterion=gini, max_depth=30, min_samples_split=2.........
[CV 4/5; 33/56] END criterion=gini, max_depth=30, min_samples_split=2;, score=0.648 total time=   0.8s
[CV 5/5; 33/56] START criterion=gini, max_depth=30, min_samples_split=2.........
[CV 5/5; 33/56] END criterion=gini, max_depth=30, min_samples_split=2;, score=0.635 total time=   0.7s
[CV 1/5; 34/56] START criterion=gini, max_depth=30, min_samples_split=4.........
[CV 1/5; 34/56] END criterion=gini, max_depth=30, min_samples_split=4;, score=0.633 total time=   0.7s
[CV 2/5; 34/56] START criterion=gini, max_depth=30, min_samples_split=4.........
[CV 2/5; 34/56] END criterion=gini, max_depth=30, min_samples_split=4;, score=0.644 total time=   0.7s
[CV 3/5; 34/56] START criterion=gini, max_depth=30, min_samples_split=4.........
[CV 3/5; 34/56] END criterion=gini, max_depth=30, min_samples_split=4;, score=0.629 total time=   0.8s
[CV 4/5; 34/56] START criterion=gini, max_depth=30, min_samples_split=4.........
[CV 4/5; 34/56] END criterion=gini, max_depth=30, min_samples_split=4;, score=0.646 total time=   0.7s
[CV 5/5; 34/56] START criterion=gini, max_depth=30, min_samples_split=4.........
[CV 5/5; 34/56] END criterion=gini, max_depth=30, min_samples_split=4;, score=0.634 total time=   0.7s
[CV 1/5; 35/56] START criterion=gini, max_depth=30, min_samples_split=8.........
[CV 1/5; 35/56] END criterion=gini, max_depth=30, min_samples_split=8;, score=0.639 total time=   0.8s
[CV 2/5; 35/56] START criterion=gini, max_depth=30, min_samples_split=8.........
[CV 2/5; 35/56] END criterion=gini, max_depth=30, min_samples_split=8;, score=0.652 total time=   0.7s
[CV 3/5; 35/56] START criterion=gini, max_depth=30, min_samples_split=8.........
[CV 3/5; 35/56] END criterion=gini, max_depth=30, min_samples_split=8;, score=0.638 total time=   0.7s
[CV 4/5; 35/56] START criterion=gini, max_depth=30, min_samples_split=8.........
[CV 4/5; 35/56] END criterion=gini, max_depth=30, min_samples_split=8;, score=0.648 total time=   0.7s
[CV 5/5; 35/56] START criterion=gini, max_depth=30, min_samples_split=8.........
[CV 5/5; 35/56] END criterion=gini, max_depth=30, min_samples_split=8;, score=0.641 total time=   0.7s
[CV 1/5; 36/56] START criterion=gini, max_depth=30, min_samples_split=10........
[CV 1/5; 36/56] END criterion=gini, max_depth=30, min_samples_split=10;, score=0.637 total time=   0.7s
[CV 2/5; 36/56] START criterion=gini, max_depth=30, min_samples_split=10........
[CV 2/5; 36/56] END criterion=gini, max_depth=30, min_samples_split=10;, score=0.652 total time=   0.7s
[CV 3/5; 36/56] START criterion=gini, max_depth=30, min_samples_split=10........
[CV 3/5; 36/56] END criterion=gini, max_depth=30, min_samples_split=10;, score=0.649 total time=   0.7s
[CV 4/5; 36/56] START criterion=gini, max_depth=30, min_samples_split=10........
[CV 4/5; 36/56] END criterion=gini, max_depth=30, min_samples_split=10;, score=0.648 total time=   0.7s
[CV 5/5; 36/56] START criterion=gini, max_depth=30, min_samples_split=10........
[CV 5/5; 36/56] END criterion=gini, max_depth=30, min_samples_split=10;, score=0.648 total time=   0.7s
[CV 1/5; 37/56] START criterion=gini, max_depth=70, min_samples_split=2.........
[CV 1/5; 37/56] END criterion=gini, max_depth=70, min_samples_split=2;, score=0.626 total time=   0.8s
[CV 2/5; 37/56] START criterion=gini, max_depth=70, min_samples_split=2.........
[CV 2/5; 37/56] END criterion=gini, max_depth=70, min_samples_split=2;, score=0.650 total time=   0.8s
[CV 3/5; 37/56] START criterion=gini, max_depth=70, min_samples_split=2.........
[CV 3/5; 37/56] END criterion=gini, max_depth=70, min_samples_split=2;, score=0.644 total time=   0.8s
[CV 4/5; 37/56] START criterion=gini, max_depth=70, min_samples_split=2.........
[CV 4/5; 37/56] END criterion=gini, max_depth=70, min_samples_split=2;, score=0.649 total time=   0.8s
[CV 5/5; 37/56] START criterion=gini, max_depth=70, min_samples_split=2.........
[CV 5/5; 37/56] END criterion=gini, max_depth=70, min_samples_split=2;, score=0.641 total time=   0.8s
[CV 1/5; 38/56] START criterion=gini, max_depth=70, min_samples_split=4.........
[CV 1/5; 38/56] END criterion=gini, max_depth=70, min_samples_split=4;, score=0.634 total time=   0.8s
[CV 2/5; 38/56] START criterion=gini, max_depth=70, min_samples_split=4.........
[CV 2/5; 38/56] END criterion=gini, max_depth=70, min_samples_split=4;, score=0.653 total time=   0.8s
[CV 3/5; 38/56] START criterion=gini, max_depth=70, min_samples_split=4.........
[CV 3/5; 38/56] END criterion=gini, max_depth=70, min_samples_split=4;, score=0.630 total time=   0.7s
[CV 4/5; 38/56] START criterion=gini, max_depth=70, min_samples_split=4.........
[CV 4/5; 38/56] END criterion=gini, max_depth=70, min_samples_split=4;, score=0.645 total time=   0.8s
[CV 5/5; 38/56] START criterion=gini, max_depth=70, min_samples_split=4.........
[CV 5/5; 38/56] END criterion=gini, max_depth=70, min_samples_split=4;, score=0.638 total time=   0.8s
[CV 1/5; 39/56] START criterion=gini, max_depth=70, min_samples_split=8.........
[CV 1/5; 39/56] END criterion=gini, max_depth=70, min_samples_split=8;, score=0.635 total time=   0.8s
[CV 2/5; 39/56] START criterion=gini, max_depth=70, min_samples_split=8.........
[CV 2/5; 39/56] END criterion=gini, max_depth=70, min_samples_split=8;, score=0.651 total time=   0.8s
[CV 3/5; 39/56] START criterion=gini, max_depth=70, min_samples_split=8.........
[CV 3/5; 39/56] END criterion=gini, max_depth=70, min_samples_split=8;, score=0.647 total time=   0.7s
[CV 4/5; 39/56] START criterion=gini, max_depth=70, min_samples_split=8.........
[CV 4/5; 39/56] END criterion=gini, max_depth=70, min_samples_split=8;, score=0.651 total time=   0.8s
[CV 5/5; 39/56] START criterion=gini, max_depth=70, min_samples_split=8.........
[CV 5/5; 39/56] END criterion=gini, max_depth=70, min_samples_split=8;, score=0.642 total time=   0.7s
[CV 1/5; 40/56] START criterion=gini, max_depth=70, min_samples_split=10........
[CV 1/5; 40/56] END criterion=gini, max_depth=70, min_samples_split=10;, score=0.635 total time=   0.8s
[CV 2/5; 40/56] START criterion=gini, max_depth=70, min_samples_split=10........
[CV 2/5; 40/56] END criterion=gini, max_depth=70, min_samples_split=10;, score=0.655 total time=   0.8s
[CV 3/5; 40/56] START criterion=gini, max_depth=70, min_samples_split=10........
[CV 3/5; 40/56] END criterion=gini, max_depth=70, min_samples_split=10;, score=0.652 total time=   0.8s
[CV 4/5; 40/56] START criterion=gini, max_depth=70, min_samples_split=10........
[CV 4/5; 40/56] END criterion=gini, max_depth=70, min_samples_split=10;, score=0.650 total time=   0.8s
[CV 5/5; 40/56] START criterion=gini, max_depth=70, min_samples_split=10........
[CV 5/5; 40/56] END criterion=gini, max_depth=70, min_samples_split=10;, score=0.637 total time=   0.7s
[CV 1/5; 41/56] START criterion=gini, max_depth=90, min_samples_split=2.........
[CV 1/5; 41/56] END criterion=gini, max_depth=90, min_samples_split=2;, score=0.626 total time=   0.8s
[CV 2/5; 41/56] START criterion=gini, max_depth=90, min_samples_split=2.........
[CV 2/5; 41/56] END criterion=gini, max_depth=90, min_samples_split=2;, score=0.655 total time=   0.7s
[CV 3/5; 41/56] START criterion=gini, max_depth=90, min_samples_split=2.........
[CV 3/5; 41/56] END criterion=gini, max_depth=90, min_samples_split=2;, score=0.639 total time=   0.8s
[CV 4/5; 41/56] START criterion=gini, max_depth=90, min_samples_split=2.........
[CV 4/5; 41/56] END criterion=gini, max_depth=90, min_samples_split=2;, score=0.643 total time=   0.8s
[CV 5/5; 41/56] START criterion=gini, max_depth=90, min_samples_split=2.........
[CV 5/5; 41/56] END criterion=gini, max_depth=90, min_samples_split=2;, score=0.638 total time=   0.8s
[CV 1/5; 42/56] START criterion=gini, max_depth=90, min_samples_split=4.........
[CV 1/5; 42/56] END criterion=gini, max_depth=90, min_samples_split=4;, score=0.633 total time=   0.8s
[CV 2/5; 42/56] START criterion=gini, max_depth=90, min_samples_split=4.........
[CV 2/5; 42/56] END criterion=gini, max_depth=90, min_samples_split=4;, score=0.648 total time=   0.7s
[CV 3/5; 42/56] START criterion=gini, max_depth=90, min_samples_split=4.........
[CV 3/5; 42/56] END criterion=gini, max_depth=90, min_samples_split=4;, score=0.637 total time=   0.8s
[CV 4/5; 42/56] START criterion=gini, max_depth=90, min_samples_split=4.........
[CV 4/5; 42/56] END criterion=gini, max_depth=90, min_samples_split=4;, score=0.647 total time=   0.7s
[CV 5/5; 42/56] START criterion=gini, max_depth=90, min_samples_split=4.........
[CV 5/5; 42/56] END criterion=gini, max_depth=90, min_samples_split=4;, score=0.637 total time=   0.8s
[CV 1/5; 43/56] START criterion=gini, max_depth=90, min_samples_split=8.........
[CV 1/5; 43/56] END criterion=gini, max_depth=90, min_samples_split=8;, score=0.644 total time=   0.8s
[CV 2/5; 43/56] START criterion=gini, max_depth=90, min_samples_split=8.........
[CV 2/5; 43/56] END criterion=gini, max_depth=90, min_samples_split=8;, score=0.656 total time=   0.7s
[CV 3/5; 43/56] START criterion=gini, max_depth=90, min_samples_split=8.........
[CV 3/5; 43/56] END criterion=gini, max_depth=90, min_samples_split=8;, score=0.639 total time=   0.8s
[CV 4/5; 43/56] START criterion=gini, max_depth=90, min_samples_split=8.........
[CV 4/5; 43/56] END criterion=gini, max_depth=90, min_samples_split=8;, score=0.652 total time=   0.8s
[CV 5/5; 43/56] START criterion=gini, max_depth=90, min_samples_split=8.........
[CV 5/5; 43/56] END criterion=gini, max_depth=90, min_samples_split=8;, score=0.640 total time=   0.8s
[CV 1/5; 44/56] START criterion=gini, max_depth=90, min_samples_split=10........
[CV 1/5; 44/56] END criterion=gini, max_depth=90, min_samples_split=10;, score=0.643 total time=   0.7s
[CV 2/5; 44/56] START criterion=gini, max_depth=90, min_samples_split=10........
[CV 2/5; 44/56] END criterion=gini, max_depth=90, min_samples_split=10;, score=0.651 total time=   0.7s
[CV 3/5; 44/56] START criterion=gini, max_depth=90, min_samples_split=10........
[CV 3/5; 44/56] END criterion=gini, max_depth=90, min_samples_split=10;, score=0.660 total time=   0.8s
[CV 4/5; 44/56] START criterion=gini, max_depth=90, min_samples_split=10........
[CV 4/5; 44/56] END criterion=gini, max_depth=90, min_samples_split=10;, score=0.649 total time=   0.8s
[CV 5/5; 44/56] START criterion=gini, max_depth=90, min_samples_split=10........
[CV 5/5; 44/56] END criterion=gini, max_depth=90, min_samples_split=10;, score=0.645 total time=   0.8s
[CV 1/5; 45/56] START criterion=gini, max_depth=150, min_samples_split=2........
[CV 1/5; 45/56] END criterion=gini, max_depth=150, min_samples_split=2;, score=0.629 total time=   0.8s
[CV 2/5; 45/56] START criterion=gini, max_depth=150, min_samples_split=2........
[CV 2/5; 45/56] END criterion=gini, max_depth=150, min_samples_split=2;, score=0.645 total time=   0.8s
[CV 3/5; 45/56] START criterion=gini, max_depth=150, min_samples_split=2........
[CV 3/5; 45/56] END criterion=gini, max_depth=150, min_samples_split=2;, score=0.636 total time=   0.8s
[CV 4/5; 45/56] START criterion=gini, max_depth=150, min_samples_split=2........
[CV 4/5; 45/56] END criterion=gini, max_depth=150, min_samples_split=2;, score=0.640 total time=   0.8s
[CV 5/5; 45/56] START criterion=gini, max_depth=150, min_samples_split=2........
[CV 5/5; 45/56] END criterion=gini, max_depth=150, min_samples_split=2;, score=0.644 total time=   0.8s
[CV 1/5; 46/56] START criterion=gini, max_depth=150, min_samples_split=4........
[CV 1/5; 46/56] END criterion=gini, max_depth=150, min_samples_split=4;, score=0.629 total time=   0.8s
[CV 2/5; 46/56] START criterion=gini, max_depth=150, min_samples_split=4........
[CV 2/5; 46/56] END criterion=gini, max_depth=150, min_samples_split=4;, score=0.642 total time=   0.7s
[CV 3/5; 46/56] START criterion=gini, max_depth=150, min_samples_split=4........
[CV 3/5; 46/56] END criterion=gini, max_depth=150, min_samples_split=4;, score=0.646 total time=   0.8s
[CV 4/5; 46/56] START criterion=gini, max_depth=150, min_samples_split=4........
[CV 4/5; 46/56] END criterion=gini, max_depth=150, min_samples_split=4;, score=0.645 total time=   0.8s
[CV 5/5; 46/56] START criterion=gini, max_depth=150, min_samples_split=4........
[CV 5/5; 46/56] END criterion=gini, max_depth=150, min_samples_split=4;, score=0.642 total time=   0.9s
[CV 1/5; 47/56] START criterion=gini, max_depth=150, min_samples_split=8........
[CV 1/5; 47/56] END criterion=gini, max_depth=150, min_samples_split=8;, score=0.645 total time=   0.9s
[CV 2/5; 47/56] START criterion=gini, max_depth=150, min_samples_split=8........
[CV 2/5; 47/56] END criterion=gini, max_depth=150, min_samples_split=8;, score=0.654 total time=   0.8s
[CV 3/5; 47/56] START criterion=gini, max_depth=150, min_samples_split=8........
[CV 3/5; 47/56] END criterion=gini, max_depth=150, min_samples_split=8;, score=0.646 total time=   0.8s
[CV 4/5; 47/56] START criterion=gini, max_depth=150, min_samples_split=8........
[CV 4/5; 47/56] END criterion=gini, max_depth=150, min_samples_split=8;, score=0.651 total time=   0.8s
[CV 5/5; 47/56] START criterion=gini, max_depth=150, min_samples_split=8........
[CV 5/5; 47/56] END criterion=gini, max_depth=150, min_samples_split=8;, score=0.641 total time=   0.8s
[CV 1/5; 48/56] START criterion=gini, max_depth=150, min_samples_split=10.......
[CV 1/5; 48/56] END criterion=gini, max_depth=150, min_samples_split=10;, score=0.642 total time=   0.8s
[CV 2/5; 48/56] START criterion=gini, max_depth=150, min_samples_split=10.......
[CV 2/5; 48/56] END criterion=gini, max_depth=150, min_samples_split=10;, score=0.655 total time=   0.8s
[CV 3/5; 48/56] START criterion=gini, max_depth=150, min_samples_split=10.......
[CV 3/5; 48/56] END criterion=gini, max_depth=150, min_samples_split=10;, score=0.652 total time=   0.8s
[CV 4/5; 48/56] START criterion=gini, max_depth=150, min_samples_split=10.......
[CV 4/5; 48/56] END criterion=gini, max_depth=150, min_samples_split=10;, score=0.651 total time=   0.7s
[CV 5/5; 48/56] START criterion=gini, max_depth=150, min_samples_split=10.......
[CV 5/5; 48/56] END criterion=gini, max_depth=150, min_samples_split=10;, score=0.647 total time=   0.7s
[CV 1/5; 49/56] START criterion=gini, max_depth=200, min_samples_split=2........
[CV 1/5; 49/56] END criterion=gini, max_depth=200, min_samples_split=2;, score=0.630 total time=   0.8s
[CV 2/5; 49/56] START criterion=gini, max_depth=200, min_samples_split=2........
[CV 2/5; 49/56] END criterion=gini, max_depth=200, min_samples_split=2;, score=0.643 total time=   0.8s
[CV 3/5; 49/56] START criterion=gini, max_depth=200, min_samples_split=2........
[CV 3/5; 49/56] END criterion=gini, max_depth=200, min_samples_split=2;, score=0.640 total time=   0.8s
[CV 4/5; 49/56] START criterion=gini, max_depth=200, min_samples_split=2........
[CV 4/5; 49/56] END criterion=gini, max_depth=200, min_samples_split=2;, score=0.644 total time=   0.8s
[CV 5/5; 49/56] START criterion=gini, max_depth=200, min_samples_split=2........
[CV 5/5; 49/56] END criterion=gini, max_depth=200, min_samples_split=2;, score=0.640 total time=   0.8s
[CV 1/5; 50/56] START criterion=gini, max_depth=200, min_samples_split=4........
[CV 1/5; 50/56] END criterion=gini, max_depth=200, min_samples_split=4;, score=0.634 total time=   0.8s
[CV 2/5; 50/56] START criterion=gini, max_depth=200, min_samples_split=4........
[CV 2/5; 50/56] END criterion=gini, max_depth=200, min_samples_split=4;, score=0.646 total time=   0.8s
[CV 3/5; 50/56] START criterion=gini, max_depth=200, min_samples_split=4........
[CV 3/5; 50/56] END criterion=gini, max_depth=200, min_samples_split=4;, score=0.636 total time=   0.8s
[CV 4/5; 50/56] START criterion=gini, max_depth=200, min_samples_split=4........
[CV 4/5; 50/56] END criterion=gini, max_depth=200, min_samples_split=4;, score=0.645 total time=   0.8s
[CV 5/5; 50/56] START criterion=gini, max_depth=200, min_samples_split=4........
[CV 5/5; 50/56] END criterion=gini, max_depth=200, min_samples_split=4;, score=0.637 total time=   0.7s
[CV 1/5; 51/56] START criterion=gini, max_depth=200, min_samples_split=8........
[CV 1/5; 51/56] END criterion=gini, max_depth=200, min_samples_split=8;, score=0.638 total time=   0.8s
[CV 2/5; 51/56] START criterion=gini, max_depth=200, min_samples_split=8........
[CV 2/5; 51/56] END criterion=gini, max_depth=200, min_samples_split=8;, score=0.654 total time=   0.7s
[CV 3/5; 51/56] START criterion=gini, max_depth=200, min_samples_split=8........
[CV 3/5; 51/56] END criterion=gini, max_depth=200, min_samples_split=8;, score=0.639 total time=   0.7s
[CV 4/5; 51/56] START criterion=gini, max_depth=200, min_samples_split=8........
[CV 4/5; 51/56] END criterion=gini, max_depth=200, min_samples_split=8;, score=0.652 total time=   0.8s
[CV 5/5; 51/56] START criterion=gini, max_depth=200, min_samples_split=8........
[CV 5/5; 51/56] END criterion=gini, max_depth=200, min_samples_split=8;, score=0.645 total time=   0.7s
[CV 1/5; 52/56] START criterion=gini, max_depth=200, min_samples_split=10.......
[CV 1/5; 52/56] END criterion=gini, max_depth=200, min_samples_split=10;, score=0.640 total time=   0.8s
[CV 2/5; 52/56] START criterion=gini, max_depth=200, min_samples_split=10.......
[CV 2/5; 52/56] END criterion=gini, max_depth=200, min_samples_split=10;, score=0.654 total time=   0.7s
[CV 3/5; 52/56] START criterion=gini, max_depth=200, min_samples_split=10.......
[CV 3/5; 52/56] END criterion=gini, max_depth=200, min_samples_split=10;, score=0.651 total time=   0.8s
[CV 4/5; 52/56] START criterion=gini, max_depth=200, min_samples_split=10.......
[CV 4/5; 52/56] END criterion=gini, max_depth=200, min_samples_split=10;, score=0.652 total time=   0.8s
[CV 5/5; 52/56] START criterion=gini, max_depth=200, min_samples_split=10.......
[CV 5/5; 52/56] END criterion=gini, max_depth=200, min_samples_split=10;, score=0.644 total time=   0.7s
[CV 1/5; 53/56] START criterion=gini, max_depth=300, min_samples_split=2........
[CV 1/5; 53/56] END criterion=gini, max_depth=300, min_samples_split=2;, score=0.630 total time=   0.8s
[CV 2/5; 53/56] START criterion=gini, max_depth=300, min_samples_split=2........
[CV 2/5; 53/56] END criterion=gini, max_depth=300, min_samples_split=2;, score=0.644 total time=   0.7s
[CV 3/5; 53/56] START criterion=gini, max_depth=300, min_samples_split=2........
[CV 3/5; 53/56] END criterion=gini, max_depth=300, min_samples_split=2;, score=0.633 total time=   0.8s
[CV 4/5; 53/56] START criterion=gini, max_depth=300, min_samples_split=2........
[CV 4/5; 53/56] END criterion=gini, max_depth=300, min_samples_split=2;, score=0.648 total time=   0.7s
[CV 5/5; 53/56] START criterion=gini, max_depth=300, min_samples_split=2........
[CV 5/5; 53/56] END criterion=gini, max_depth=300, min_samples_split=2;, score=0.640 total time=   0.8s
[CV 1/5; 54/56] START criterion=gini, max_depth=300, min_samples_split=4........
[CV 1/5; 54/56] END criterion=gini, max_depth=300, min_samples_split=4;, score=0.625 total time=   0.8s
[CV 2/5; 54/56] START criterion=gini, max_depth=300, min_samples_split=4........
[CV 2/5; 54/56] END criterion=gini, max_depth=300, min_samples_split=4;, score=0.648 total time=   0.8s
[CV 3/5; 54/56] START criterion=gini, max_depth=300, min_samples_split=4........
[CV 3/5; 54/56] END criterion=gini, max_depth=300, min_samples_split=4;, score=0.639 total time=   0.9s
[CV 4/5; 54/56] START criterion=gini, max_depth=300, min_samples_split=4........
[CV 4/5; 54/56] END criterion=gini, max_depth=300, min_samples_split=4;, score=0.652 total time=   0.8s
[CV 5/5; 54/56] START criterion=gini, max_depth=300, min_samples_split=4........
[CV 5/5; 54/56] END criterion=gini, max_depth=300, min_samples_split=4;, score=0.643 total time=   0.9s
[CV 1/5; 55/56] START criterion=gini, max_depth=300, min_samples_split=8........
[CV 1/5; 55/56] END criterion=gini, max_depth=300, min_samples_split=8;, score=0.644 total time=   0.9s
[CV 2/5; 55/56] START criterion=gini, max_depth=300, min_samples_split=8........
[CV 2/5; 55/56] END criterion=gini, max_depth=300, min_samples_split=8;, score=0.650 total time=   0.8s
[CV 3/5; 55/56] START criterion=gini, max_depth=300, min_samples_split=8........
[CV 3/5; 55/56] END criterion=gini, max_depth=300, min_samples_split=8;, score=0.647 total time=   0.9s
[CV 4/5; 55/56] START criterion=gini, max_depth=300, min_samples_split=8........
[CV 4/5; 55/56] END criterion=gini, max_depth=300, min_samples_split=8;, score=0.651 total time=   0.8s
[CV 5/5; 55/56] START criterion=gini, max_depth=300, min_samples_split=8........
[CV 5/5; 55/56] END criterion=gini, max_depth=300, min_samples_split=8;, score=0.642 total time=   0.7s
[CV 1/5; 56/56] START criterion=gini, max_depth=300, min_samples_split=10.......
[CV 1/5; 56/56] END criterion=gini, max_depth=300, min_samples_split=10;, score=0.642 total time=   0.8s
[CV 2/5; 56/56] START criterion=gini, max_depth=300, min_samples_split=10.......
[CV 2/5; 56/56] END criterion=gini, max_depth=300, min_samples_split=10;, score=0.655 total time=   0.8s
[CV 3/5; 56/56] START criterion=gini, max_depth=300, min_samples_split=10.......
[CV 3/5; 56/56] END criterion=gini, max_depth=300, min_samples_split=10;, score=0.654 total time=   0.8s
[CV 4/5; 56/56] START criterion=gini, max_depth=300, min_samples_split=10.......
[CV 4/5; 56/56] END criterion=gini, max_depth=300, min_samples_split=10;, score=0.654 total time=   0.8s
[CV 5/5; 56/56] START criterion=gini, max_depth=300, min_samples_split=10.......
[CV 5/5; 56/56] END criterion=gini, max_depth=300, min_samples_split=10;, score=0.644 total time=   0.9s
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt">Out[45]:</div>




<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain">
<pre>GridSearchCV(estimator=DecisionTreeClassifier(),
             param_grid={&#39;criterion&#39;: [&#39;entropy&#39;, &#39;gini&#39;],
                         &#39;max_depth&#39;: [10, 30, 70, 90, 150, 200, 300],
                         &#39;min_samples_split&#39;: [2, 4, 8, 10]},
             scoring=&#39;balanced_accuracy&#39;, verbose=10)</pre>
</div>

</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[46]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">grid_search</span><span class="o">.</span><span class="n">best_params_</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt">Out[46]:</div>




<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain">
<pre>{&#39;criterion&#39;: &#39;gini&#39;, &#39;max_depth&#39;: 10, &#39;min_samples_split&#39;: 4}</pre>
</div>

</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[47]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">criterion</span><span class="o">=</span><span class="s1">&#39;gini&#39;</span><span class="p">,</span> <span class="n">max_depth</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">min_samples_split</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">predicted</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">evaluate</span><span class="p">(</span><span class="n">predicted</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Accuracy:  0.7927995034140286
Balanced Accuracy:  0.6675698811460264
Precision:  0.8180877789271465
Recall:  0.9266822899229996
F1:  0.8690055725610235
</pre>
</div>
</div>

</div>

</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>As we can see <code>Logistic regression</code> has the best <code>Accuracy</code> and Out neural network has the best <code>Balanced Accuracy</code> and <code>F1 score</code>.</p>

</div>
</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Now let's test another model which is going to be <code>Naive Bayes</code>.</p>

</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[40]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.naive_bayes</span> <span class="kn">import</span> <span class="n">GaussianNB</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">GridSearchCV</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">GaussianNB</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt">Out[40]:</div>




<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain">
<pre>GaussianNB()</pre>
</div>

</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[44]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">predicted</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">evaluate</span><span class="p">(</span><span class="n">predicted</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Accuracy:  0.6862818125387958
Balanced Accuracy:  0.7106833439860412
Precision:  0.8880882684080162
Recall:  0.6601941747572816
F1:  0.7573691790686511
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[45]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">count_0_predicted</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">count_1_predicted</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">count_0_actual</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">count_1_actual</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">predicted</span><span class="p">)):</span>
    <span class="k">if</span> <span class="n">predicted</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">count_0_predicted</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">count_1_predicted</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="k">if</span> <span class="n">y_test</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">count_0_actual</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">count_1_actual</span> <span class="o">+=</span> <span class="mi">1</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;There </span><span class="si">{</span><span class="n">count_0_predicted</span><span class="si">}</span><span class="s2"> 0 values in prediction.&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;There </span><span class="si">{</span><span class="n">count_1_predicted</span><span class="si">}</span><span class="s2"> 1 values in prediction.&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;There </span><span class="si">{</span><span class="n">count_0_actual</span><span class="si">}</span><span class="s2"> 0 values in test dataset.&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;There </span><span class="si">{</span><span class="n">count_1_actual</span><span class="si">}</span><span class="s2"> 1 values in test dataset.&quot;</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>There 3614 0 values in prediction.
There 4441 1 values in prediction.
There 2081 0 values in test dataset.
There 5974 1 values in test dataset.
</pre>
</div>
</div>

</div>

</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Also it has good balanced_accuracy but it's just like a guess between genders, and as a result we got 68% accuracy.</p>

</div>
</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Lets now focus on ANN.</p>
<p>We will change number of features here to see what will happen.</p>

</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[8]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">copy</span>
<span class="kn">from</span> <span class="nn">tqdm</span> <span class="kn">import</span> <span class="n">tqdm</span>

<span class="k">def</span> <span class="nf">create_new_dataset</span><span class="p">(</span><span class="n">percentage</span><span class="p">):</span>
    <span class="n">features</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>

    <span class="k">for</span> <span class="n">query</span> <span class="ow">in</span> <span class="n">queries</span><span class="p">:</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">queries_value_count</span><span class="p">[</span><span class="n">query</span><span class="p">]</span> <span class="o">&gt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">)</span> <span class="o">*</span> <span class="n">percentage</span><span class="p">):</span>
            <span class="n">features</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;q</span><span class="si">{</span><span class="n">query</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span> 
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Queries completed&quot;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">app</span> <span class="ow">in</span> <span class="n">apps</span><span class="p">:</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">apps_value_count</span><span class="p">[</span><span class="n">app</span><span class="p">]</span> <span class="o">&gt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">)</span> <span class="o">*</span> <span class="n">percentage</span><span class="p">):</span>
            <span class="n">features</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;a</span><span class="si">{</span><span class="n">app</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Apps completed&quot;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">game</span> <span class="ow">in</span> <span class="n">games</span><span class="p">:</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">games_value_count</span><span class="p">[</span><span class="n">game</span><span class="p">]</span> <span class="o">&gt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">)</span> <span class="o">*</span> <span class="n">percentage</span><span class="p">):</span>
            <span class="n">features</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;g</span><span class="si">{</span><span class="n">game</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Games completed&quot;</span><span class="p">)</span>

    <span class="n">features</span><span class="p">[</span><span class="s2">&quot;gender&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
    
    <span class="n">new_dataset</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">iterrows</span><span class="p">(),</span> <span class="n">total</span><span class="o">=</span><span class="n">df</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
        <span class="n">new_item</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">query</span> <span class="ow">in</span> <span class="n">row</span><span class="p">[</span><span class="s1">&#39;queries&#39;</span><span class="p">]:</span>
            <span class="k">if</span> <span class="n">check_key</span><span class="p">(</span><span class="n">new_item</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;q</span><span class="si">{</span><span class="n">query</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">):</span>
                <span class="n">new_item</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;q</span><span class="si">{</span><span class="n">query</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="k">for</span> <span class="n">game</span> <span class="ow">in</span> <span class="n">row</span><span class="p">[</span><span class="s1">&#39;games&#39;</span><span class="p">]:</span>
            <span class="k">if</span> <span class="n">check_key</span><span class="p">(</span><span class="n">new_item</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;g</span><span class="si">{</span><span class="n">game</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">):</span>
                <span class="n">new_item</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;g</span><span class="si">{</span><span class="n">game</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="k">for</span> <span class="n">app</span> <span class="ow">in</span> <span class="n">row</span><span class="p">[</span><span class="s1">&#39;apps&#39;</span><span class="p">]:</span>
            <span class="k">if</span> <span class="n">check_key</span><span class="p">(</span><span class="n">new_item</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;a</span><span class="si">{</span><span class="n">app</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">):</span>
                <span class="n">new_item</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;a</span><span class="si">{</span><span class="n">app</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="n">new_item</span><span class="p">[</span><span class="s1">&#39;gender&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">row</span><span class="p">[</span><span class="s1">&#39;gender&#39;</span><span class="p">]</span>
        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">new_item</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">features</span><span class="p">),</span> <span class="s2">&quot;Featues count error&quot;</span>
        <span class="n">new_dataset</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">copy</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">new_item</span><span class="p">))</span>
    
    <span class="n">new_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="o">.</span><span class="n">from_dict</span><span class="p">(</span><span class="n">new_dataset</span><span class="p">,</span> <span class="n">orient</span><span class="o">=</span><span class="s1">&#39;columns&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">new_df</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[9]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dataset_3_percent</span> <span class="o">=</span> <span class="n">create_new_dataset</span><span class="p">(</span><span class="mf">0.03</span><span class="p">)</span>
<span class="n">dataset_10_percent</span> <span class="o">=</span> <span class="n">create_new_dataset</span><span class="p">(</span><span class="mf">0.1</span><span class="p">)</span>
<span class="n">dataset_20_percent</span> <span class="o">=</span> <span class="n">create_new_dataset</span><span class="p">(</span><span class="mf">0.2</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Queries completed
Apps completed
Games completed
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>100%|| 40271/40271 [00:04&lt;00:00, 8223.36it/s]
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Queries completed
Apps completed
Games completed
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>100%|| 40271/40271 [00:05&lt;00:00, 7851.27it/s]
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Queries completed
Apps completed
Games completed
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>100%|| 40271/40271 [00:04&lt;00:00, 8059.71it/s]
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[11]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">dataset_3_percent</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">dataset_10_percent</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">dataset_20_percent</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>(40271, 315)
(40271, 114)
(40271, 58)
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[22]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dataset_3_percent</span><span class="p">[</span><span class="s1">&#39;gender&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">dataset_3_percent</span><span class="p">[</span><span class="s1">&#39;gender&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">({</span><span class="s1">&#39;M&#39;</span><span class="p">:</span><span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;F&#39;</span><span class="p">:</span><span class="mi">1</span><span class="p">})</span>
<span class="n">dataset_10_percent</span><span class="p">[</span><span class="s1">&#39;gender&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">dataset_10_percent</span><span class="p">[</span><span class="s1">&#39;gender&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">({</span><span class="s1">&#39;M&#39;</span><span class="p">:</span><span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;F&#39;</span><span class="p">:</span><span class="mi">1</span><span class="p">})</span>
<span class="n">dataset_20_percent</span><span class="p">[</span><span class="s1">&#39;gender&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">dataset_20_percent</span><span class="p">[</span><span class="s1">&#39;gender&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">({</span><span class="s1">&#39;M&#39;</span><span class="p">:</span><span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;F&#39;</span><span class="p">:</span><span class="mi">1</span><span class="p">})</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[24]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">tensorflow</span> <span class="kn">import</span> <span class="n">keras</span>
<span class="kn">from</span> <span class="nn">keras.layers</span> <span class="kn">import</span> <span class="n">Dense</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.optimizers</span> <span class="kn">import</span> <span class="n">SGD</span>
<span class="kn">from</span> <span class="nn">kerastuner.engine.hyperparameters</span> <span class="kn">import</span> <span class="n">HyperParameters</span>
<span class="kn">from</span> <span class="nn">kerastuner.tuners</span> <span class="kn">import</span> <span class="n">RandomSearch</span>
<span class="kn">import</span> <span class="nn">time</span>

<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span>  <span class="n">dataset_3_percent</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;gender&quot;</span><span class="p">]),</span> <span class="n">dataset_3_percent</span><span class="p">[</span><span class="s2">&quot;gender&quot;</span><span class="p">]</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="n">opt</span> <span class="o">=</span> <span class="n">SGD</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
<span class="n">input_d</span> <span class="o">=</span> <span class="n">dataset_3_percent</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

<span class="k">def</span> <span class="nf">build_model</span><span class="p">(</span><span class="n">hp</span><span class="p">):</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>
    
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="n">hp</span><span class="o">.</span><span class="n">Int</span><span class="p">(</span><span class="s2">&quot;input_units&quot;</span><span class="p">,</span> <span class="n">min_value</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">max_value</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mi">20</span><span class="p">),</span> <span class="n">input_dim</span><span class="o">=</span><span class="n">input_d</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
    
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">hp</span><span class="o">.</span><span class="n">Int</span><span class="p">(</span><span class="s1">&#39;n_layers&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">)):</span>
        <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="n">hp</span><span class="o">.</span><span class="n">Int</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;dense_units_</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">min_value</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">max_value</span><span class="o">=</span><span class="mi">300</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mi">10</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
    
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;sigmoid&#39;</span><span class="p">))</span>
    
    <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;binary_crossentropy&#39;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">opt</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>
    
    <span class="k">return</span> <span class="n">model</span>

<span class="n">t</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">LOG_DIR</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="nb">int</span><span class="p">(</span><span class="n">t</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>

<span class="n">tuner</span> <span class="o">=</span> <span class="n">RandomSearch</span><span class="p">(</span>
    <span class="n">build_model</span><span class="p">,</span>
    <span class="n">objective</span> <span class="o">=</span> <span class="s2">&quot;val_accuracy&quot;</span><span class="p">,</span>
    <span class="n">max_trials</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">executions_per_trial</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">directory</span> <span class="o">=</span> <span class="n">LOG_DIR</span>
<span class="p">)</span>

<span class="n">tuner</span><span class="o">.</span><span class="n">search</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y_train</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span><span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">))</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Trial 1 Complete [00h 06m 07s]
val_accuracy: 0.8269397616386414

Best val_accuracy So Far: 0.8269397616386414
Total elapsed time: 00h 06m 07s
INFO:tensorflow:Oracle triggered exit
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[25]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">t</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt">Out[25]:</div>




<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain">
<pre>1627980159.3318021</pre>
</div>

</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[28]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;tuner_</span><span class="si">{</span><span class="nb">int</span><span class="p">(</span><span class="n">t</span><span class="p">)</span><span class="si">}</span><span class="s2">.pkl&quot;</span><span class="p">,</span> <span class="s2">&quot;wb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">tuner</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>
    
<span class="n">tuner</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="nb">open</span><span class="p">(</span><span class="s2">&quot;tuner_1627980159.pkl&quot;</span><span class="p">,</span> <span class="s2">&quot;rb&quot;</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">tuner</span><span class="o">.</span><span class="n">get_best_hyperparameters</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">tuner</span><span class="o">.</span><span class="n">results_summary</span><span class="p">())</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;input_units&#39;: 340, &#39;n_layers&#39;: 6, &#39;dense_units_0&#39;: 100, &#39;dense_units_1&#39;: 10, &#39;dense_units_2&#39;: 10, &#39;dense_units_3&#39;: 10, &#39;dense_units_4&#39;: 10, &#39;dense_units_5&#39;: 10}
Results summary
Results in 1627980159\untitled_project
Showing 10 best trials
Objective(name=&#39;val_accuracy&#39;, direction=&#39;max&#39;)
Trial summary
Hyperparameters:
input_units: 340
n_layers: 6
dense_units_0: 100
dense_units_1: 10
dense_units_2: 10
dense_units_3: 10
dense_units_4: 10
dense_units_5: 10
Score: 0.8269397616386414
None
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[29]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">callback</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">EarlyStopping</span><span class="p">(</span><span class="n">monitor</span><span class="o">=</span><span class="s1">&#39;val_loss&#39;</span><span class="p">,</span> <span class="n">patience</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">tuner</span><span class="o">.</span><span class="n">get_best_models</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">validation_split</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">callback</span><span class="p">])</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Epoch 1/100
2900/2900 [==============================] - 4s 1ms/step - loss: 0.3753 - accuracy: 0.8380 - val_loss: 0.3886 - val_accuracy: 0.8293
Epoch 2/100
2900/2900 [==============================] - 3s 1ms/step - loss: 0.3681 - accuracy: 0.8426 - val_loss: 0.3858 - val_accuracy: 0.8318
Epoch 3/100
2900/2900 [==============================] - 3s 1ms/step - loss: 0.3621 - accuracy: 0.8439 - val_loss: 0.3822 - val_accuracy: 0.8302
Epoch 4/100
2900/2900 [==============================] - 3s 1ms/step - loss: 0.3531 - accuracy: 0.8492 - val_loss: 0.3987 - val_accuracy: 0.8187
Epoch 5/100
2900/2900 [==============================] - 3s 1ms/step - loss: 0.3446 - accuracy: 0.8529 - val_loss: 0.3842 - val_accuracy: 0.8309
Epoch 6/100
2900/2900 [==============================] - 3s 1ms/step - loss: 0.3321 - accuracy: 0.8616 - val_loss: 0.4112 - val_accuracy: 0.8203
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[30]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;model loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;epoch&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s1">&#39;train&#39;</span><span class="p">,</span> <span class="s1">&#39;test&#39;</span><span class="p">],</span> <span class="n">loc</span><span class="o">=</span><span class="s1">&#39;upper left&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedImage jp-OutputArea-output ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[31]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">predicted</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_classes</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">evaluate</span><span class="p">(</span><span class="n">predicted</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\tensorflow\python\keras\engine\sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) &gt; 0.5).astype(&#34;int32&#34;)`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).
  warnings.warn(&#39;`model.predict_classes()` is deprecated and &#39;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Accuracy:  0.8176288019863439
Balanced Accuracy:  0.6836827920186578
Precision:  0.7833333333333333
Recall:  0.40653531955790484
F1:  0.5352736475798798
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[32]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">tensorflow</span> <span class="kn">import</span> <span class="n">keras</span>
<span class="kn">from</span> <span class="nn">keras.layers</span> <span class="kn">import</span> <span class="n">Dense</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.optimizers</span> <span class="kn">import</span> <span class="n">SGD</span>
<span class="kn">from</span> <span class="nn">kerastuner.engine.hyperparameters</span> <span class="kn">import</span> <span class="n">HyperParameters</span>
<span class="kn">from</span> <span class="nn">kerastuner.tuners</span> <span class="kn">import</span> <span class="n">RandomSearch</span>
<span class="kn">import</span> <span class="nn">time</span>

<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span>  <span class="n">dataset_10_percent</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;gender&quot;</span><span class="p">]),</span> <span class="n">dataset_10_percent</span><span class="p">[</span><span class="s2">&quot;gender&quot;</span><span class="p">]</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="n">opt</span> <span class="o">=</span> <span class="n">SGD</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
<span class="n">input_d</span> <span class="o">=</span> <span class="n">dataset_10_percent</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

<span class="k">def</span> <span class="nf">build_model</span><span class="p">(</span><span class="n">hp</span><span class="p">):</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>
    
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="n">hp</span><span class="o">.</span><span class="n">Int</span><span class="p">(</span><span class="s2">&quot;input_units&quot;</span><span class="p">,</span> <span class="n">min_value</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">max_value</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mi">20</span><span class="p">),</span> <span class="n">input_dim</span><span class="o">=</span><span class="n">input_d</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
    
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">hp</span><span class="o">.</span><span class="n">Int</span><span class="p">(</span><span class="s1">&#39;n_layers&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">)):</span>
        <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="n">hp</span><span class="o">.</span><span class="n">Int</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;dense_units_</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">min_value</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">max_value</span><span class="o">=</span><span class="mi">300</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mi">10</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
    
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;sigmoid&#39;</span><span class="p">))</span>
    
    <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;binary_crossentropy&#39;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">opt</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>
    
    <span class="k">return</span> <span class="n">model</span>

<span class="n">t</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">LOG_DIR</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="nb">int</span><span class="p">(</span><span class="n">t</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>

<span class="n">tuner</span> <span class="o">=</span> <span class="n">RandomSearch</span><span class="p">(</span>
    <span class="n">build_model</span><span class="p">,</span>
    <span class="n">objective</span> <span class="o">=</span> <span class="s2">&quot;val_accuracy&quot;</span><span class="p">,</span>
    <span class="n">max_trials</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">executions_per_trial</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">directory</span> <span class="o">=</span> <span class="n">LOG_DIR</span>
<span class="p">)</span>

<span class="n">tuner</span><span class="o">.</span><span class="n">search</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y_train</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span><span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">))</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Trial 1 Complete [00h 04m 35s]
val_accuracy: 0.791558027267456

Best val_accuracy So Far: 0.791558027267456
Total elapsed time: 00h 04m 35s
INFO:tensorflow:Oracle triggered exit
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[33]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">t</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt">Out[33]:</div>




<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain">
<pre>1627981259.7144318</pre>
</div>

</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[34]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;tuner_</span><span class="si">{</span><span class="nb">int</span><span class="p">(</span><span class="n">t</span><span class="p">)</span><span class="si">}</span><span class="s2">.pkl&quot;</span><span class="p">,</span> <span class="s2">&quot;wb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">tuner</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>
    
<span class="n">tuner</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="nb">open</span><span class="p">(</span><span class="s2">&quot;tuner_1627981259.pkl&quot;</span><span class="p">,</span> <span class="s2">&quot;rb&quot;</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">tuner</span><span class="o">.</span><span class="n">get_best_hyperparameters</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">tuner</span><span class="o">.</span><span class="n">results_summary</span><span class="p">())</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;input_units&#39;: 100, &#39;n_layers&#39;: 7, &#39;dense_units_0&#39;: 210, &#39;dense_units_1&#39;: 10, &#39;dense_units_2&#39;: 10, &#39;dense_units_3&#39;: 10, &#39;dense_units_4&#39;: 10, &#39;dense_units_5&#39;: 10, &#39;dense_units_6&#39;: 10}
Results summary
Results in 1627981259\untitled_project
Showing 10 best trials
Objective(name=&#39;val_accuracy&#39;, direction=&#39;max&#39;)
Trial summary
Hyperparameters:
input_units: 100
n_layers: 7
dense_units_0: 210
dense_units_1: 10
dense_units_2: 10
dense_units_3: 10
dense_units_4: 10
dense_units_5: 10
dense_units_6: 10
Score: 0.791558027267456
None
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[35]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">callback</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">EarlyStopping</span><span class="p">(</span><span class="n">monitor</span><span class="o">=</span><span class="s1">&#39;val_loss&#39;</span><span class="p">,</span> <span class="n">patience</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">tuner</span><span class="o">.</span><span class="n">get_best_models</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">validation_split</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">callback</span><span class="p">])</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Epoch 1/100
2900/2900 [==============================] - 3s 844us/step - loss: 0.4472 - accuracy: 0.7966 - val_loss: 0.4569 - val_accuracy: 0.7908
Epoch 2/100
2900/2900 [==============================] - 2s 809us/step - loss: 0.4451 - accuracy: 0.7982 - val_loss: 0.4531 - val_accuracy: 0.7908
Epoch 3/100
2900/2900 [==============================] - 2s 808us/step - loss: 0.4426 - accuracy: 0.7979 - val_loss: 0.4556 - val_accuracy: 0.7877
Epoch 4/100
2900/2900 [==============================] - 2s 815us/step - loss: 0.4400 - accuracy: 0.8002 - val_loss: 0.4549 - val_accuracy: 0.7917
Epoch 5/100
2900/2900 [==============================] - 2s 822us/step - loss: 0.4379 - accuracy: 0.8021 - val_loss: 0.4609 - val_accuracy: 0.7880
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[36]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;model loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;epoch&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s1">&#39;train&#39;</span><span class="p">,</span> <span class="s1">&#39;test&#39;</span><span class="p">],</span> <span class="n">loc</span><span class="o">=</span><span class="s1">&#39;upper left&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedImage jp-OutputArea-output ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[37]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">predicted</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_classes</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">evaluate</span><span class="p">(</span><span class="n">predicted</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\tensorflow\python\keras\engine\sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) &gt; 0.5).astype(&#34;int32&#34;)`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).
  warnings.warn(&#39;`model.predict_classes()` is deprecated and &#39;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Accuracy:  0.786219739292365
Balanced Accuracy:  0.6177277975503974
Precision:  0.735873850197109
Recall:  0.2691013935607881
F1:  0.39408866995073893
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[38]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">tensorflow</span> <span class="kn">import</span> <span class="n">keras</span>
<span class="kn">from</span> <span class="nn">keras.layers</span> <span class="kn">import</span> <span class="n">Dense</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.optimizers</span> <span class="kn">import</span> <span class="n">SGD</span>
<span class="kn">from</span> <span class="nn">kerastuner.engine.hyperparameters</span> <span class="kn">import</span> <span class="n">HyperParameters</span>
<span class="kn">from</span> <span class="nn">kerastuner.tuners</span> <span class="kn">import</span> <span class="n">RandomSearch</span>
<span class="kn">import</span> <span class="nn">time</span>

<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span>  <span class="n">dataset_20_percent</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;gender&quot;</span><span class="p">]),</span> <span class="n">dataset_20_percent</span><span class="p">[</span><span class="s2">&quot;gender&quot;</span><span class="p">]</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="n">opt</span> <span class="o">=</span> <span class="n">SGD</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
<span class="n">input_d</span> <span class="o">=</span> <span class="n">dataset_20_percent</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

<span class="k">def</span> <span class="nf">build_model</span><span class="p">(</span><span class="n">hp</span><span class="p">):</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>
    
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="n">hp</span><span class="o">.</span><span class="n">Int</span><span class="p">(</span><span class="s2">&quot;input_units&quot;</span><span class="p">,</span> <span class="n">min_value</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">max_value</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mi">20</span><span class="p">),</span> <span class="n">input_dim</span><span class="o">=</span><span class="n">input_d</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
    
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">hp</span><span class="o">.</span><span class="n">Int</span><span class="p">(</span><span class="s1">&#39;n_layers&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">)):</span>
        <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="n">hp</span><span class="o">.</span><span class="n">Int</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;dense_units_</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">min_value</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">max_value</span><span class="o">=</span><span class="mi">300</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mi">10</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
    
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;sigmoid&#39;</span><span class="p">))</span>
    
    <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;binary_crossentropy&#39;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">opt</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>
    
    <span class="k">return</span> <span class="n">model</span>

<span class="n">t</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">LOG_DIR</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="nb">int</span><span class="p">(</span><span class="n">t</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>

<span class="n">tuner</span> <span class="o">=</span> <span class="n">RandomSearch</span><span class="p">(</span>
    <span class="n">build_model</span><span class="p">,</span>
    <span class="n">objective</span> <span class="o">=</span> <span class="s2">&quot;val_accuracy&quot;</span><span class="p">,</span>
    <span class="n">max_trials</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">executions_per_trial</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">directory</span> <span class="o">=</span> <span class="n">LOG_DIR</span>
<span class="p">)</span>

<span class="n">tuner</span><span class="o">.</span><span class="n">search</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y_train</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span><span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">))</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Trial 1 Complete [00h 04m 32s]
val_accuracy: 0.751334547996521

Best val_accuracy So Far: 0.751334547996521
Total elapsed time: 00h 04m 32s
INFO:tensorflow:Oracle triggered exit
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[39]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">t</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt">Out[39]:</div>




<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain">
<pre>1627981770.58637</pre>
</div>

</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[40]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;tuner_</span><span class="si">{</span><span class="nb">int</span><span class="p">(</span><span class="n">t</span><span class="p">)</span><span class="si">}</span><span class="s2">.pkl&quot;</span><span class="p">,</span> <span class="s2">&quot;wb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">tuner</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>
    
<span class="n">tuner</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="nb">open</span><span class="p">(</span><span class="s2">&quot;tuner_1627981770.pkl&quot;</span><span class="p">,</span> <span class="s2">&quot;rb&quot;</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">tuner</span><span class="o">.</span><span class="n">get_best_hyperparameters</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">tuner</span><span class="o">.</span><span class="n">results_summary</span><span class="p">())</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;input_units&#39;: 260, &#39;n_layers&#39;: 3, &#39;dense_units_0&#39;: 190, &#39;dense_units_1&#39;: 10, &#39;dense_units_2&#39;: 10}
Results summary
Results in 1627981770\untitled_project
Showing 10 best trials
Objective(name=&#39;val_accuracy&#39;, direction=&#39;max&#39;)
Trial summary
Hyperparameters:
input_units: 260
n_layers: 3
dense_units_0: 190
dense_units_1: 10
dense_units_2: 10
Score: 0.751334547996521
None
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[41]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">callback</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">EarlyStopping</span><span class="p">(</span><span class="n">monitor</span><span class="o">=</span><span class="s1">&#39;val_loss&#39;</span><span class="p">,</span> <span class="n">patience</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">tuner</span><span class="o">.</span><span class="n">get_best_models</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">validation_split</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">callback</span><span class="p">])</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Epoch 1/100
2900/2900 [==============================] - 3s 813us/step - loss: 0.5061 - accuracy: 0.7584 - val_loss: 0.5062 - val_accuracy: 0.7598
Epoch 2/100
2900/2900 [==============================] - 2s 764us/step - loss: 0.5041 - accuracy: 0.7597 - val_loss: 0.5031 - val_accuracy: 0.7598
Epoch 3/100
2900/2900 [==============================] - 2s 772us/step - loss: 0.5027 - accuracy: 0.7601 - val_loss: 0.5028 - val_accuracy: 0.7573
Epoch 4/100
2900/2900 [==============================] - 2s 787us/step - loss: 0.5008 - accuracy: 0.7630 - val_loss: 0.5079 - val_accuracy: 0.7604
Epoch 5/100
2900/2900 [==============================] - 2s 745us/step - loss: 0.4992 - accuracy: 0.7637 - val_loss: 0.5087 - val_accuracy: 0.7573
Epoch 6/100
2900/2900 [==============================] - 2s 749us/step - loss: 0.4974 - accuracy: 0.7642 - val_loss: 0.5037 - val_accuracy: 0.7595
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[42]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;model loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;epoch&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s1">&#39;train&#39;</span><span class="p">,</span> <span class="s1">&#39;test&#39;</span><span class="p">],</span> <span class="n">loc</span><span class="o">=</span><span class="s1">&#39;upper left&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedImage jp-OutputArea-output ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[43]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">predicted</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_classes</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">evaluate</span><span class="p">(</span><span class="n">predicted</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>C:\Users\TheRealRondon\anaconda3\lib\site-packages\tensorflow\python\keras\engine\sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) &gt; 0.5).astype(&#34;int32&#34;)`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).
  warnings.warn(&#39;`model.predict_classes()` is deprecated and &#39;
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Accuracy:  0.748975791433892
Balanced Accuracy:  0.571325053125453
Precision:  0.5373891001267427
Recall:  0.20374819798173954
F1:  0.2954703832752613
</pre>
</div>
</div>

</div>

</div>

</div>
</body>







</html>
