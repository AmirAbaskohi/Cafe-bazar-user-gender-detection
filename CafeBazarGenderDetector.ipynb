{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf102f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50da8a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"data/gender.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49fe7f6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>queries</th>\n",
       "      <th>apps</th>\n",
       "      <th>games</th>\n",
       "      <th>gender</th>\n",
       "      <th>birth_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[216, 359, 12329, 3, 45, 4002, 2066, 32, 3931,...</td>\n",
       "      <td>[4, 4, 25, 7, 30, 58, 16, 19, 17, 21, 10, 10, ...</td>\n",
       "      <td>[9151, 208]</td>\n",
       "      <td>M</td>\n",
       "      <td>1366.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[]</td>\n",
       "      <td>[129, 71, 9, 8, 11, 25, 18, 58, 6, 16, 125, 12...</td>\n",
       "      <td>[460, 4939, 14, 232, 6387, 1758, 5834, 3, 2]</td>\n",
       "      <td>F</td>\n",
       "      <td>1359.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[23463, 18831]</td>\n",
       "      <td>[9, 174, 65, 8, 63, 97, 62, 103, 61, 116, 59, ...</td>\n",
       "      <td>[448, 723, 267, 9064, 10634, 166, 782, 224, 27...</td>\n",
       "      <td>M</td>\n",
       "      <td>1373.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1634, 3609, 654]</td>\n",
       "      <td>[99, 73, 9, 8, 59, 37, 131, 3, 89, 6, 24, 16, ...</td>\n",
       "      <td>[78, 2607, 478, 435, 9, 192]</td>\n",
       "      <td>M</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[11064, 227, 623, 1301, 43999, 35411, 2492, 11...</td>\n",
       "      <td>[9, 8, 17, 54, 3, 25, 22, 6, 21, 7, 14, 5, 817...</td>\n",
       "      <td>[1702, 1, 53]</td>\n",
       "      <td>M</td>\n",
       "      <td>1364.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             queries  \\\n",
       "0  [216, 359, 12329, 3, 45, 4002, 2066, 32, 3931,...   \n",
       "1                                                 []   \n",
       "2                                     [23463, 18831]   \n",
       "3                                  [1634, 3609, 654]   \n",
       "4  [11064, 227, 623, 1301, 43999, 35411, 2492, 11...   \n",
       "\n",
       "                                                apps  \\\n",
       "0  [4, 4, 25, 7, 30, 58, 16, 19, 17, 21, 10, 10, ...   \n",
       "1  [129, 71, 9, 8, 11, 25, 18, 58, 6, 16, 125, 12...   \n",
       "2  [9, 174, 65, 8, 63, 97, 62, 103, 61, 116, 59, ...   \n",
       "3  [99, 73, 9, 8, 59, 37, 131, 3, 89, 6, 24, 16, ...   \n",
       "4  [9, 8, 17, 54, 3, 25, 22, 6, 21, 7, 14, 5, 817...   \n",
       "\n",
       "                                               games gender  birth_year  \n",
       "0                                        [9151, 208]      M      1366.0  \n",
       "1       [460, 4939, 14, 232, 6387, 1758, 5834, 3, 2]      F      1359.0  \n",
       "2  [448, 723, 267, 9064, 10634, 166, 782, 224, 27...      M      1373.0  \n",
       "3                       [78, 2607, 478, 435, 9, 192]      M         0.0  \n",
       "4                                      [1702, 1, 53]      M      1364.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet(DATA_DIR, engine=\"pyarrow\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "514c97b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>queries</th>\n",
       "      <th>apps</th>\n",
       "      <th>games</th>\n",
       "      <th>gender</th>\n",
       "      <th>birth_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40266</th>\n",
       "      <td>[13388, 10571, 122, 1961, 42946, 823, 3349, 10...</td>\n",
       "      <td>[9, 8, 17, 3, 25, 22, 6, 24, 12, 7, 14, 5, 4, ...</td>\n",
       "      <td>[3, 55, 1115, 135, 410, 38, 1426, 107, 374]</td>\n",
       "      <td>M</td>\n",
       "      <td>1394.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40267</th>\n",
       "      <td>[2655, 11, 1732, 2847, 15222, 884, 39, 1433, 2...</td>\n",
       "      <td>[8, 11, 10, 10, 39, 17, 771, 48, 3, 25, 95, 22...</td>\n",
       "      <td>[717]</td>\n",
       "      <td>M</td>\n",
       "      <td>1354.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40268</th>\n",
       "      <td>[9, 33200, 5028, 357, 4, 233, 262, 2180, 376, ...</td>\n",
       "      <td>[54, 9, 8, 10, 10, 39, 17, 48, 3, 25, 6, 21, 1...</td>\n",
       "      <td>[312, 22]</td>\n",
       "      <td>M</td>\n",
       "      <td>1364.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40269</th>\n",
       "      <td>[9, 276, 27, 1074]</td>\n",
       "      <td>[9, 8, 17, 48, 54, 3, 25, 22, 6, 21, 7, 45, 14...</td>\n",
       "      <td>[73, 2, 53, 75]</td>\n",
       "      <td>M</td>\n",
       "      <td>1365.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40270</th>\n",
       "      <td>[6421, 11377, 6980, 852, 31, 185, 2348, 534, 4...</td>\n",
       "      <td>[43, 8, 10, 10, 39, 17, 48, 54, 3, 25, 22, 6, ...</td>\n",
       "      <td>[355, 278, 185]</td>\n",
       "      <td>M</td>\n",
       "      <td>1390.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 queries  \\\n",
       "40266  [13388, 10571, 122, 1961, 42946, 823, 3349, 10...   \n",
       "40267  [2655, 11, 1732, 2847, 15222, 884, 39, 1433, 2...   \n",
       "40268  [9, 33200, 5028, 357, 4, 233, 262, 2180, 376, ...   \n",
       "40269                                 [9, 276, 27, 1074]   \n",
       "40270  [6421, 11377, 6980, 852, 31, 185, 2348, 534, 4...   \n",
       "\n",
       "                                                    apps  \\\n",
       "40266  [9, 8, 17, 3, 25, 22, 6, 24, 12, 7, 14, 5, 4, ...   \n",
       "40267  [8, 11, 10, 10, 39, 17, 771, 48, 3, 25, 95, 22...   \n",
       "40268  [54, 9, 8, 10, 10, 39, 17, 48, 3, 25, 6, 21, 1...   \n",
       "40269  [9, 8, 17, 48, 54, 3, 25, 22, 6, 21, 7, 45, 14...   \n",
       "40270  [43, 8, 10, 10, 39, 17, 48, 54, 3, 25, 22, 6, ...   \n",
       "\n",
       "                                             games gender  birth_year  \n",
       "40266  [3, 55, 1115, 135, 410, 38, 1426, 107, 374]      M      1394.0  \n",
       "40267                                        [717]      M      1354.0  \n",
       "40268                                    [312, 22]      M      1364.0  \n",
       "40269                              [73, 2, 53, 75]      M      1365.0  \n",
       "40270                              [355, 278, 185]      M      1390.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f26f459",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40271, 5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f06c436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40271 entries, 0 to 40270\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   queries     40271 non-null  object \n",
      " 1   apps        40271 non-null  object \n",
      " 2   games       40271 non-null  object \n",
      " 3   gender      40271 non-null  object \n",
      " 4   birth_year  40271 non-null  float64\n",
      "dtypes: float64(1), object(4)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f96845c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"birth_year\"] = df[\"birth_year\"].astype(np.uint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e468ebd8",
   "metadata": {},
   "source": [
    "There is no `NaN` value heare as we can see in `birth_year` we have `0` which is not acceptable. So we should replace them with new values.\n",
    "\n",
    "In addition to `birth_year` we should make gender column numeric, although it is our goal column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44a2f8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_birth_year = df[\"birth_year\"][df[\"birth_year\"] != 0]\n",
    "mean_birth_year = round(valid_birth_year.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a031a07c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>queries</th>\n",
       "      <th>apps</th>\n",
       "      <th>games</th>\n",
       "      <th>gender</th>\n",
       "      <th>birth_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[216, 359, 12329, 3, 45, 4002, 2066, 32, 3931,...</td>\n",
       "      <td>[4, 4, 25, 7, 30, 58, 16, 19, 17, 21, 10, 10, ...</td>\n",
       "      <td>[9151, 208]</td>\n",
       "      <td>1</td>\n",
       "      <td>1366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[]</td>\n",
       "      <td>[129, 71, 9, 8, 11, 25, 18, 58, 6, 16, 125, 12...</td>\n",
       "      <td>[460, 4939, 14, 232, 6387, 1758, 5834, 3, 2]</td>\n",
       "      <td>0</td>\n",
       "      <td>1359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[23463, 18831]</td>\n",
       "      <td>[9, 174, 65, 8, 63, 97, 62, 103, 61, 116, 59, ...</td>\n",
       "      <td>[448, 723, 267, 9064, 10634, 166, 782, 224, 27...</td>\n",
       "      <td>1</td>\n",
       "      <td>1373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1634, 3609, 654]</td>\n",
       "      <td>[99, 73, 9, 8, 59, 37, 131, 3, 89, 6, 24, 16, ...</td>\n",
       "      <td>[78, 2607, 478, 435, 9, 192]</td>\n",
       "      <td>1</td>\n",
       "      <td>1371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[11064, 227, 623, 1301, 43999, 35411, 2492, 11...</td>\n",
       "      <td>[9, 8, 17, 54, 3, 25, 22, 6, 21, 7, 14, 5, 817...</td>\n",
       "      <td>[1702, 1, 53]</td>\n",
       "      <td>1</td>\n",
       "      <td>1364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             queries  \\\n",
       "0  [216, 359, 12329, 3, 45, 4002, 2066, 32, 3931,...   \n",
       "1                                                 []   \n",
       "2                                     [23463, 18831]   \n",
       "3                                  [1634, 3609, 654]   \n",
       "4  [11064, 227, 623, 1301, 43999, 35411, 2492, 11...   \n",
       "\n",
       "                                                apps  \\\n",
       "0  [4, 4, 25, 7, 30, 58, 16, 19, 17, 21, 10, 10, ...   \n",
       "1  [129, 71, 9, 8, 11, 25, 18, 58, 6, 16, 125, 12...   \n",
       "2  [9, 174, 65, 8, 63, 97, 62, 103, 61, 116, 59, ...   \n",
       "3  [99, 73, 9, 8, 59, 37, 131, 3, 89, 6, 24, 16, ...   \n",
       "4  [9, 8, 17, 54, 3, 25, 22, 6, 21, 7, 14, 5, 817...   \n",
       "\n",
       "                                               games  gender  birth_year  \n",
       "0                                        [9151, 208]       1        1366  \n",
       "1       [460, 4939, 14, 232, 6387, 1758, 5834, 3, 2]       0        1359  \n",
       "2  [448, 723, 267, 9064, 10634, 166, 782, 224, 27...       1        1373  \n",
       "3                       [78, 2607, 478, 435, 9, 192]       1        1371  \n",
       "4                                      [1702, 1, 53]       1        1364  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"birth_year\"] = df[\"birth_year\"].replace(0, mean_birth_year)\n",
    "df[\"gender\"] = df[\"gender\"].replace({'M': 1, 'F': 0})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af9518d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>birth_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>40271.000000</td>\n",
       "      <td>40271.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.742991</td>\n",
       "      <td>1370.967495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.436990</td>\n",
       "      <td>11.706620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1300.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1364.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1371.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1380.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1398.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             gender    birth_year\n",
       "count  40271.000000  40271.000000\n",
       "mean       0.742991   1370.967495\n",
       "std        0.436990     11.706620\n",
       "min        0.000000   1300.000000\n",
       "25%        0.000000   1364.000000\n",
       "50%        1.000000   1371.000000\n",
       "75%        1.000000   1380.000000\n",
       "max        1.000000   1398.000000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "attachments": {
    "image-2.png": {
     "image/png": "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"
    },
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "0f8f95bc",
   "metadata": {},
   "source": [
    "## Dealing with list values\n",
    "\n",
    "As it's clear hear that three of our main columns which are `queries`, `apps`, and `games` are lists so we should desl with them.\n",
    "\n",
    "Actually, if you look closely, you will find that lists are everywhere! Here are some practical problems, where you will probably encounter list values.\n",
    "\n",
    "* Audio-video tags\n",
    "* Open-ended questions in survey data\n",
    "* List of all authors, artists, producers, etc. invloved in a creative product\n",
    "\n",
    "### What is wrong with list values?\n",
    "List values mess up everything you know about data analysis. The simplest operations can not be performed without endless looping. \n",
    "\n",
    "An example of this is here:\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "![image-2.png](attachment:image-2.png)\n",
    "\n",
    "The reason this does not work is that Pandas does not have direct access to every individual element of the lists. Thus, Pandas is unable to apply functions like value_counts() properly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5511a30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_1D(series):\n",
    "    return pd.Series([x for _list in series for x in _list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69307769",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2        8229\n",
       "3        8174\n",
       "4        7870\n",
       "1        7816\n",
       "5        6605\n",
       "         ... \n",
       "43591       1\n",
       "49796       1\n",
       "36214       1\n",
       "37550       1\n",
       "41955       1\n",
       "Length: 47287, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_1D(df['queries']).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "383cb885",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4        41154\n",
       "1        40271\n",
       "2        40194\n",
       "3        38390\n",
       "10       37980\n",
       "         ...  \n",
       "22089        1\n",
       "19999        1\n",
       "16220        1\n",
       "12370        1\n",
       "30151        1\n",
       "Length: 36598, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_1D(df['apps']).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f31ac1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2        5534\n",
       "1        3662\n",
       "9        2324\n",
       "4        2131\n",
       "16       2045\n",
       "         ... \n",
       "3942        1\n",
       "30718       1\n",
       "8524        1\n",
       "8361        1\n",
       "14970       1\n",
       "Length: 15414, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_1D(df['games']).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2f6edb18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Query Ids')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize = (14,4))\n",
    "ax.bar(to_1D(df[\"queries\"]).value_counts().index,\n",
    "        to_1D(df[\"queries\"]).value_counts().values)\n",
    "ax.set_ylabel(\"Frequency\", size = 12)\n",
    "ax.set_title(\"Query Ids\", size = 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "93f55dd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'App Ids')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1MAAAEJCAYAAABxMn0kAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAgkElEQVR4nO3df7BfdX3n8efLhCJqQcAL0iQ0KFlXoDUut2lm7GypuBJ/jKDFaWyVbCc2XQo7uuuuBdu1ul23slNLh7Wwg8IQ0DakWJeMllUK/ujuIOlNBSEgchUqMSmJghRtiya894/v5+o315ub+z3eX8l9PmbOfM95n8/nfN9n+Axz3/mc8/mmqpAkSZIkDeYZc52AJEmSJB2KLKYkSZIkqQOLKUmSJEnqwGJKkiRJkjqwmJIkSZKkDiymJEmSJKkDiylJkqZRkk8kuW6u85AkzTyLKUnSISfJS5PsS/L/Zvl7P5vkg7P5nZKk+ctiSpJ0KPoN4ErgjCQvnutkJEkLk8WUJOmQkuQo4FeBDwE3AevHnV+epJL8apL/m+Sfk3w5ySv72pzV2rw2yV2tzbYkZw6Yy7OSXJfkO0keTfKuCdq8IcmXkvxTkseSfC7Jid3uXpI0n1hMSZIONecDf1dVXwJuAC5IcsQE7f4HcAWwErgVuDnJknFt/hD4bWAY+BrwySTPGiCXPwT+DfDLwNnAS4F/PXYyyfOBTcBG4MXt3A0DXF+SNI9ZTEmSDjVv5YcFyeeAfwReN0G7q6pqc1V9GXgb8Ahw4bg2v19Vn6qqe4FfB55Jb9broJI8h96s2DvHXePpvmY/BRwB3FRVD1fVvVX14ap6dEp3Kkma1yymJEmHjCSnAi8D/hSgqgr4KL0Ca7w7xnaq6mngTuC0Sdp8B7hngjYH8kLgJw5wjTF3A38F3JvkY0kuTDI0xetLkua5xXOdgCRJA3grsAj4epKxWACSLKuqR2YxlxysQVXta+9qrQZeSW8m6w+S/GJV3T3TCUqSZpYzU5KkQ0KSxcA64FJ670GNbS8BvkTvEbt+q/v6BlgF3D9Jm2cDZ0zQ5kBGge8f4Bo/UD13VNV7gZ8DdgK/MsXvkCTNY85MSZIOFa8Bngd8qKq+1X8iySbgwiT/rS98YZKv0Hvs7reAnwauGnfN302yh16B827ge7RHCA+mqr6T5BrgsnHXWNSX12rgFcCngEfpLVCxDLhvSncsSZrXLKYkSYeK9cBnxhdSzZ8D76dXuHylxS4B/iPwr4C/A15fVTvG9bsE+ADwImA78Nqq+u4AOf0n4NnAx+kthPE/2/GYJ+i94/XvgefSWwTj96vqIwN8hyRpnkrv3V1Jkg4PSZYDDwE/V1UjB2hzFvAZYKiqvjlryUmSDiu+MyVJkiRJHVhMSZIkSVIHPuYnSZIkSR04MyVJkiRJHSzo1fye97zn1fLly+c6DUmSJEnz1LZt275ZVUMTnVvQxdTy5csZGZlwoSdJkiRJIsnfHeicj/lJkiRJUgcWU5IkSZLUgcWUJEmSJHVgMSVJkiRJHVhMSZIkSVIHFlOSJEmS1IHFlCRJkiR1YDElSZIkSR1YTEmSJElSBxZTkiRJktSBxZQkSZIkdTCrxVSSRUm+mOQT7fi4JLcmebB9HtvX9tIko0keSHJOX/zMJPe0c1ckSYsfmeTGFr8zyfLZvDdJkiRJC8tsz0y9Dbi/7/gS4LaqWgHc1o5JchqwFjgdWANcmWRR63MVsAFY0bY1Lb4eeLyqTgUuBy6b2VuRJEmStJDNWjGVZCnwGuDDfeFzgY1tfyNwXl98U1U9VVUPAaPAqiQnAUdX1R1VVcD14/qMXesm4OyxWStJkiRJmm6zOTP1x8A7gaf7YidW1S6A9nlCiy8BHulrt6PFlrT98fH9+lTVXuAJ4PhpvQNJkiRJamalmEryWmB3VW2bapcJYjVJfLI+43PZkGQkyciePXummI4kSZIk7W+2ZqZeBrwuycPAJuDlST4CPNoe3aN97m7tdwDL+vovBXa2+NIJ4vv1SbIYOAZ4bHwiVXV1VQ1X1fDQ0ND03J0kSZKkBWdWiqmqurSqllbVcnoLS9xeVW8GtgDrWrN1wM1tfwuwtq3Qdwq9hSa2tkcBn0yyur0PdcG4PmPXOr99x4/MTEmSJEnSdFg8x9//fmBzkvXA14E3AlTV9iSbgfuAvcBFVbWv9bkQuA44CrilbQDXADckGaU3I7V2tm5CkiRJ0sKThTx5Mzw8XCMjI3OdhiRJkqR5Ksm2qhqe6Nxs/86UJEmSJB0WLKYkSZIkqQOLKUmSJEnqwGJKkiRJkjqwmJIkSZKkDiymJEmSJKkDiylJkiRJ6sBiSpIkSZI6sJiSJEmSpA4spiRJkiSpA4spSZIkSerAYkqSJEmSOrCYkiRJkqQOLKYkSZIkqQOLKUmSJEnqwGJKkiRJkjqwmJIkSZKkDmalmEryzCRbk9ydZHuS97b4e5J8I8ldbXt1X59Lk4wmeSDJOX3xM5Pc085dkSQtfmSSG1v8ziTLZ+PeJEmSJC1MszUz9RTw8qp6CbASWJNkdTt3eVWtbNtfAiQ5DVgLnA6sAa5Msqi1vwrYAKxo25oWXw88XlWnApcDl838bUmSJElaqGalmKqe77TDI9pWk3Q5F9hUVU9V1UPAKLAqyUnA0VV1R1UVcD1wXl+fjW3/JuDssVkrSZIkSZpus/bOVJJFSe4CdgO3VtWd7dTFSb6U5Nokx7bYEuCRvu47WmxJ2x8f369PVe0FngCOnyCPDUlGkozs2bNnem5OkiRJ0oIza8VUVe2rqpXAUnqzTGfQe2TvhfQe/dsFfKA1n2hGqSaJT9ZnfB5XV9VwVQ0PDQ0NdA+SJEmSNGbWV/Orqm8DnwXWVNWjrch6GvgQsKo12wEs6+u2FNjZ4ksniO/XJ8li4BjgsZm5C0mSJEkL3Wyt5jeU5Llt/yjgFcCX2ztQY14P3Nv2twBr2wp9p9BbaGJrVe0Cnkyyur0PdQFwc1+fdW3/fOD29l6VJEmSJE27xbP0PScBG9uKfM8ANlfVJ5LckGQlvcfxHgZ+E6CqtifZDNwH7AUuqqp97VoXAtcBRwG3tA3gGuCGJKP0ZqTWzsJ9SZIkSVqgspAnb4aHh2tkZGSu05AkSZI0TyXZVlXDE52b9XemJEmSJOlwYDElSZIkSR1YTEmSJElSBxZTkiRJktSBxZQkSZIkdWAxJUmSJEkdWExJkiRJUgcWU5IkSZLUgcWUJEmSJHVgMSVJkiRJHVhMSZIkSVIHFlOSJEmS1IHFlCRJkiR1YDElSZIkSR1YTEmSJElSBxZTkiRJktTBrBRTSZ6ZZGuSu5NsT/LeFj8uya1JHmyfx/b1uTTJaJIHkpzTFz8zyT3t3BVJ0uJHJrmxxe9Msnw27k2SJEnSwjRbM1NPAS+vqpcAK4E1SVYDlwC3VdUK4LZ2TJLTgLXA6cAa4Moki9q1rgI2ACvatqbF1wOPV9WpwOXAZbNwX5IkSZIWqFkppqrnO+3wiLYVcC6wscU3Aue1/XOBTVX1VFU9BIwCq5KcBBxdVXdUVQHXj+szdq2bgLPHZq0kSZIkabrN2jtTSRYluQvYDdxaVXcCJ1bVLoD2eUJrvgR4pK/7jhZb0vbHx/frU1V7gSeA4yfIY0OSkSQje/bsmaa7kyRJkrTQzFoxVVX7qmolsJTeLNMZkzSfaEapJolP1md8HldX1XBVDQ8NDR0ka0mSJEma2Kyv5ldV3wY+S+9dp0fbo3u0z92t2Q5gWV+3pcDOFl86QXy/PkkWA8cAj83EPUiSJEnSbK3mN5TkuW3/KOAVwJeBLcC61mwdcHPb3wKsbSv0nUJvoYmt7VHAJ5Osbu9DXTCuz9i1zgdub+9VSZIkSdK0WzxL33MSsLGtyPcMYHNVfSLJHcDmJOuBrwNvBKiq7Uk2A/cBe4GLqmpfu9aFwHXAUcAtbQO4BrghySi9Gam1s3JnkiRJkhakLOTJm+Hh4RoZGZnrNCRJkiTNU0m2VdXwROdm/Z0pSZIkSTocWExJkiRJUgcWU5IkSZLUgcWUJEmSJHVgMSVJkiRJHVhMSZIkSVIHFlOSJEmS1IHFlCRJkiR1YDElSZIkSR1MuZhK8roki2cyGUmSJEk6VAwyM/X7wK4kH0zy8zOVkCRJkiQdCqZcTFXVS4BXAP8EfCzJA0l+N8nymUpOkiRJkuargd6Zqqq7q+o/A8uAi4A3Al9N8vkkv5bEd7AkSZIkLQgDvwOV5IXAm9v2NPBu4OvAxcAvA2+YzgQlSZIkaT6acjGV5CLgLcCpwGbgLVX1hb7zHwN2T3uGkiRJkjQPDTIz9SrgA8DNVfW98Ser6h+TOCslSZIkaUEY5B2n84H/3V9IJTkiyZFjx1X16Yk6JlmW5DNJ7k+yPcnbWvw9Sb6R5K62vbqvz6VJRttCF+f0xc9Mck87d0WStPiRSW5s8TtdGEOSJEnSTBqkmPo0cOa42JnAp6bQdy/wjqp6MbAauCjJae3c5VW1sm1/CdDOrQVOB9YAVyZZ1NpfBWwAVrRtTYuvBx6vqlOBy4HLBrg3SZIkSRrIIMXUzwJ3jottBV5ysI5Vtauq/rbtPwncDyyZpMu5wKaqeqqqHgJGgVVJTgKOrqo7qqqA64Hz+vpsbPs3AWePzVpJkiRJ0nQbpJj6NnDiuNiJwHcH+cL2+N1L+WFhdnGSLyW5NsmxLbYEeKSv244WW9L2x8f361NVe4EngOMn+P4NSUaSjOzZs2eQ1CVJkiTpBwYppj4G/GmSM5I8K8nP0JsZ2jzVCyR5TrvO26vqH+g9svdCYCWwi94CFwATzSjVJPHJ+uwfqLq6qoaranhoaGiqqUuSJEnSfgYppn6H3uN5W4EngS8ADwDvmkrnJEfQK6Q+WlV/AVBVj1bVvqp6GvgQsKo130Hvh4HHLAV2tvjSCeL79UmyGDgGeGyA+5MkSZKkKZtyMVVV/1xVFwHPBp4PPKeqLq6qfz5Y3/bu0jXA/VX1R33xk/qavR64t+1vAda2FfpOobfQxNaq2gU8mWR1u+YFwM19fda1/fOB29t7VZIkSZI07Qb5nSmSHAO8CHhOOwagqm4/SNeX0fvB33uS3NVi7wLelGQlvcfxHgZ+s11ve5LNwH30VgK8qKr2tX4XAtcBRwG3tA16xdoNSUbpzUitHeTeJEmSJGkQmerkTZJ/C/wJ8B3gH/tOVVW9YPpTm3nDw8M1MjIy12lIkiRJmqeSbKuq4YnODTIz9T7g/Kq65aAtJUmSJOkwN8gCFIvp/XCvJEmSJC14gxRTlwG/m2SQPpIkSZJ0WBrkMb//QG8Vv3cm+Vb/iao6eVqzkiRJkqR5bpBi6s0zloUkSZIkHWKmXExV1edmMhFJkiRJOpRM+f2n9gO670vytSRPtNgrk1w8c+lJkiRJ0vw0yGISlwNnAL9G70d2AbbT+xFdSZIkSVpQBnln6vXAqVX13SRPA1TVN5IsmZnUJEmSJGn+GmRm6nuMK76SDAHfmri5JEmSJB2+Bimm/hzYmOQUgCQnAR8ENs1EYpIkSZI0nw1STL0LeBi4B3gu8CCwE3jvtGclSZIkSfPcIEujfw94O/D29njfN6uqJu8lSZIkSYenKRdTSV4wLvSTSQCoqq9NZ1KSJEmSNN8NsprfKL0l0dMXG5uZWjRtGUmSJEnSIWCQx/z2e78qyfOB3wP+erqTkiRJkqT5bpAFKPZTVX9P7x2qPzhY2yTLknwmyf1Jtid5W4sfl+TWJA+2z2P7+lyaZDTJA0nO6YufmeSedu6KtGcNkxyZ5MYWvzPJ8q73JkmSJEkH07mYal4EPGsK7fYC76iqFwOrgYuSnAZcAtxWVSuA29ox7dxa4HRgDXBlkrFHCa8CNgAr2ramxdcDj1fVqcDlwGU/5r1JkiRJ0gENsgDFX/PDd6SgV0SdDvzXg/Wtql3Arrb/ZJL7gSXAucBZrdlG4LPAb7f4pqp6CngoySiwKsnDwNFVdUfL6XrgPOCW1uc97Vo3AR9MElcclCRJkjQTBlmA4sPjjr8L3F1VDw7yhe3xu5cCdwIntkKLqtqV5ITWbAnwhb5uO1rs+21/fHyszyPtWnuTPAEcD3xz3PdvoDezxcknnzxI6pIkSZL0A4MsQLHxx/2yJM8BPga8var+YWxp9YmaTpTCJPHJ+uwfqLoauBpgeHjYWStJkiRJnQzymN9BH+cDqKp3H6D/EfQKqY9W1V+08KNJTmqzUicBu1t8B7Csr/tSYGeLL50g3t9nR5LFwDHAY1PJWZIkSZIGNcgCFCvoLRBxNnAq8PJ2vIJeEbOM/QudH2gr7l0D3F9Vf9R3aguwru2vA27ui69tK/Sd0r5ja3sk8Mkkq9s1LxjXZ+xa5wO3+76UJEmSpJkyyDtTAd5UVR/7QSB5A/DGqvr1g/R9GfAW4J4kd7XYu4D3A5uTrAe+DrwRoKq2J9kM3EdvJcCLqmpf63chcB1wFL2FJ25p8WuAG9piFY/RWw1QkiRJkmZEpjp50xZ0OK6vqKEtV/5YVR0zQ/nNqOHh4RoZGZnrNCRJkiTNU0m2VdXwROcGecxvFLhoXOy3gK92TUySJEmSDlWDPOb3VuDjSd4JfIPeUuR7gTfMRGKSJEmSNJ8NsjT6F5OsAFYDP0XvR3jvqKrvz1RykiRJkjRfDfKY336q6vPATyR59jTmI0mSJEmHhCkXU0l+BvgK8CF6K+cB/CJw7QzkJUmSJEnz2iAzU1cB766qfwmMPdr3OeAXpj0rSZIkSZrnBimmTgc+0vYLoKq+S+/3niRJkiRpQRmkmHoYOLM/kGQVvSXTJUmSJGlBGWRp9P8CfDLJ/6K38MSlwL8DfmNGMpMkSZKkeWzKM1NV9QngVcAQvXelfhp4Q1V9eoZykyRJkqR5a0ozU0kW0VvJ77Sq+q2ZTUmSJEmS5r8pzUxV1T5gH/DMmU1HkiRJkg4Ng7wz9cfA5iT/HdhBW9EPoKq+Ns15SZIkSdK8dtBiKsnzq+rvgQ+20CuA9DUpYNEM5CZJkiRJ89ZUHvP7CkBVPaOqngFsGdtvm4WUJEmSpAVnKsVUxh3/4kwkIkmSJEmHkqkUUzXueHxxdVBJrk2yO8m9fbH3JPlGkrva9uq+c5cmGU3yQJJz+uJnJrmnnbsiSVr8yCQ3tvidSZYPmqMkSZIkDWIqC1AsTvJL/LCIWjTumKq6/SDXuI7eO1fXj4tfXlV/2B9IchqwFjgd+Cngr5L8i7ai4FXABuALwF8Ca4BbgPXA41V1apK1wGXAr0zh3iRJkiSpk6kUU7uBa/uOvzXuuIAXTHaBqvr8ALNF5wKbquop4KEko8CqJA8DR1fVHQBJrgfOo1dMnQu8p/W/CfhgklTV+Fk1SZIkSZoWBy2mqmr5DH7/xUkuAEaAd1TV48ASejNPY3a02Pfb/vg47fORlu/eJE8AxwPfHP+FSTbQm93i5JNPntabkSRJkrRwTOlHe2fIVcALgZXALuADLT7RO1k1SXyyPj8arLq6qoaranhoaGighCVJkiRpzJwVU1X1aFXtq6qngQ8Bq9qpHcCyvqZLgZ0tvnSC+H59kiwGjgEem7nsJUmSJC10c1ZMJTmp7/D1wNhKf1uAtW2FvlOAFcDWqtoFPJlkdVvF7wLg5r4+69r++cDtvi8lSZIkaSZNZQGKH1uSPwPOAp6XZAfwe8BZSVbSexzvYeA3Aapqe5LNwH3AXuCitpIfwIX0VgY8it7CE7e0+DXADW2xisforQYoSZIkSTMmC3kCZ3h4uEZGRuY6DUmSJEnzVJJtVTU80bm5XIBCkiRJkg5ZFlOSJEmS1IHFlCRJkiR1YDElSZIkSR1YTEmSJElSBxZTkiRJktSBxZQkSZIkdWAxJUmSJEkdWExJkiRJUgcWU5IkSZLUgcWUJEmSJHVgMSVJkiRJHVhMSZIkSVIHFlOSJEmS1IHFlCRJkiR1YDElSZIkSR3MSjGV5Noku5Pc2xc7LsmtSR5sn8f2nbs0yWiSB5Kc0xc/M8k97dwVSdLiRya5scXvTLJ8Nu5LkiRJ0sI1WzNT1wFrxsUuAW6rqhXAbe2YJKcBa4HTW58rkyxqfa4CNgAr2jZ2zfXA41V1KnA5cNmM3YkkSZIkMUvFVFV9HnhsXPhcYGPb3wic1xffVFVPVdVDwCiwKslJwNFVdUdVFXD9uD5j17oJOHts1kqSJEmSZsJcvjN1YlXtAmifJ7T4EuCRvnY7WmxJ2x8f369PVe0FngCOn+hLk2xIMpJkZM+ePdN0K5IkSZIWmvm4AMVEM0o1SXyyPj8arLq6qoaranhoaKhjipIkSZIWurksph5tj+7RPne3+A5gWV+7pcDOFl86QXy/PkkWA8fwo48VSpIkSdK0mctiaguwru2vA27ui69tK/SdQm+hia3tUcAnk6xu70NdMK7P2LXOB25v71VJkiRJ0oxYPBtfkuTPgLOA5yXZAfwe8H5gc5L1wNeBNwJU1fYkm4H7gL3ARVW1r13qQnorAx4F3NI2gGuAG5KM0puRWjsLtyVJkiRpActCnsAZHh6ukZGRuU5DkiRJ0jyVZFtVDU90bj4uQCFJkiRJ857FlCRJkiR1YDElSZIkSR1YTEmSJElSBxZTkiRJktSBxZQkSZIkdWAxJUmSJEkdWExJkiRJUgcWU5IkSZLUgcWUJEmSJHVgMSVJkiRJHVhMSZIkSVIHFlPzyPJLPjnXKUiSJEmaIospSZIkSerAYkqSJEmSOrCYkiRJkqQO5ryYSvJwknuS3JVkpMWOS3Jrkgfb57F97S9NMprkgSTn9MXPbNcZTXJFkszF/UiSJElaGOa8mGp+qapWVtVwO74EuK2qVgC3tWOSnAasBU4H1gBXJlnU+lwFbABWtG3NLOYvSZIkaYGZL8XUeOcCG9v+RuC8vvimqnqqqh4CRoFVSU4Cjq6qO6qqgOv7+kiSJEnStJsPxVQBn06yLcmGFjuxqnYBtM8TWnwJ8Ehf3x0ttqTtj49LkiRJ0oxYPNcJAC+rqp1JTgBuTfLlSdpO9B5UTRL/0Qv0CrYNACeffPKguUqSJEkSMA9mpqpqZ/vcDXwcWAU82h7do33ubs13AMv6ui8Fdrb40gniE33f1VU1XFXDQ0ND03krkiRJkhaQOS2mkjw7yU+O7QOvBO4FtgDrWrN1wM1tfwuwNsmRSU6ht9DE1vYo4JNJVrdV/C7o6yNJkiRJ026uH/M7Efh4W8V8MfCnVfV/kvwNsDnJeuDrwBsBqmp7ks3AfcBe4KKq2teudSFwHXAUcEvbJEmSJGlGzGkxVVVfA14yQfxbwNkH6PM+4H0TxEeAM6Y7R0mSJEmayJy/MyVJkiRJhyKLKUmSJEnqwGJKkiRJkjqwmJIkSZKkDiymJEmSJKkDiylJkiRJ6sBiSpIkSZI6sJiSJEmSpA4spiRJkiSpA4spSZIkSerAYkqSJEmSOrCYkiRJkqQOLKYkSZIkqQOLKUmSJEnqwGJKkiRJkjqwmJIkSZKkDiymJEmSJKmDw6qYSrImyQNJRpNcMtf5/DiWX/JJll/yyblOQ5IkSdIBHDbFVJJFwJ8ArwJOA96U5LS5zaqbiYqosZgFliRJkjQ/LJ7rBKbRKmC0qr4GkGQTcC5w35xmNY3GF1Jjxw+//zUHbPPw+19zwFh/v7G+42OSJEmSJpaqmuscpkWS84E1VfXWdvwW4Oer6uJx7TYAG9rhi4AHZjXRyT0P+OZcJ6FDjuNGXThu1IXjRl04btTFfBo3P11VQxOdOJxmpjJB7Ecqxaq6Grh65tMZXJKRqhqe6zx0aHHcqAvHjbpw3KgLx426OFTGzWHzzhSwA1jWd7wU2DlHuUiSJEk6zB1OxdTfACuSnJLkJ4C1wJY5zkmSJEnSYeqwecyvqvYmuRj4FLAIuLaqts9xWoOal48fat5z3KgLx426cNyoC8eNujgkxs1hswCFJEmSJM2mw+kxP0mSJEmaNRZTkiRJktSBxdQ8kGRNkgeSjCa5ZK7z0exLcm2S3Unu7Ysdl+TWJA+2z2P7zl3axssDSc7pi5+Z5J527ookafEjk9zY4ncmWT6rN6hpl2RZks8kuT/J9iRva3HHjSaV5JlJtia5u42d97a4Y0eTSrIoyReTfKIdO2Z0UEkebv/N70oy0mKHzdixmJpjSRYBfwK8CjgNeFOS0+Y2K82B64A142KXALdV1QrgtnZMGx9rgdNbnyvbOAK4it6PUq9o29g11wOPV9WpwOXAZTN2J5ote4F3VNWLgdXARW1sOG50ME8BL6+qlwArgTVJVuPY0cG9Dbi/79gxo6n6papa2fe7UYfN2LGYmnurgNGq+lpVfQ/YBJw7xzlpllXV54HHxoXPBTa2/Y3AeX3xTVX1VFU9BIwCq5KcBBxdVXdUb2WZ68f1GbvWTcDZY/+io0NTVe2qqr9t+0/S+wNnCY4bHUT1fKcdHtG2wrGjSSRZCrwG+HBf2DGjrg6bsWMxNfeWAI/0He9oMenEqtoFvT+cgRNa/EBjZknbHx/fr09V7QWeAI6fscw1q9ojDS8F7sRxoyloj2vdBewGbq0qx44O5o+BdwJP98UcM5qKAj6dZFuSDS122Iydw+Z3pg5hE1XOrlevyRxozEw2lhxnh6kkzwE+Bry9qv5hkn+Mc9zoB6pqH7AyyXOBjyc5Y5Lmjp0FLslrgd1VtS3JWVPpMkHMMbNwvayqdiY5Abg1yZcnaXvIjR1npubeDmBZ3/FSYOcc5aL55dE2rU373N3iBxozO9r++Ph+fZIsBo7hRx8r1CEmyRH0CqmPVtVftLDjRlNWVd8GPkvv3QPHjg7kZcDrkjxM73WElyf5CI4ZTUFV7Wyfu4GP03vF5bAZOxZTc+9vgBVJTknyE/ReutsyxzlpftgCrGv764Cb++Jr2+o1p9B7CXNrmyZ/Msnq9qzwBeP6jF3rfOD28he7D2ntv/E1wP1V9Ud9pxw3mlSSoTYjRZKjgFcAX8axowOoqkuramlVLaf3d8rtVfVmHDM6iCTPTvKTY/vAK4F7OZzGTlW5zfEGvBr4CvBV4HfmOh+3ORkDfwbsAr5P719Y1tN73vc24MH2eVxf+99p4+UB4FV98WF6/5P6KvBBIC3+TODP6b3IuRV4wVzfs9uPPWZ+gd5jDF8C7mrbqx03blMYOz8LfLGNnXuBd7e4Y8dtKuPnLOATjhm3KY6XFwB3t2372N+5h9PYGUtCkiRJkjQAH/OTJEmSpA4spiRJkiSpA4spSZIkSerAYkqSJEmSOrCYkiRJkqQOLKYkSZIkqQOLKUmSJEnq4P8DfFb5HQhNswkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1008x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize = (14,4))\n",
    "ax.bar(to_1D(df[\"apps\"]).value_counts().index,\n",
    "        to_1D(df[\"apps\"]).value_counts().values)\n",
    "ax.set_ylabel(\"Frequency\", size = 12)\n",
    "ax.set_title(\"App Ids\", size = 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "78178353",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Game Ids')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize = (14,4))\n",
    "ax.bar(to_1D(df[\"games\"]).value_counts().index,\n",
    "        to_1D(df[\"games\"]).value_counts().values)\n",
    "ax.set_ylabel(\"Frequency\", size = 12)\n",
    "ax.set_title(\"Game Ids\", size = 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a65f94be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>gender</th>\n",
       "      <th>birth_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9151.0</td>\n",
       "      <td>208.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>460.0</td>\n",
       "      <td>4939.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>232.0</td>\n",
       "      <td>6387.0</td>\n",
       "      <td>1758.0</td>\n",
       "      <td>5834.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>448.0</td>\n",
       "      <td>723.0</td>\n",
       "      <td>267.0</td>\n",
       "      <td>9064.0</td>\n",
       "      <td>10634.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>782.0</td>\n",
       "      <td>224.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>4086.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>78.0</td>\n",
       "      <td>2607.0</td>\n",
       "      <td>478.0</td>\n",
       "      <td>435.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1702.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 932 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0       1      2       3        4       5       6      7      8  \\\n",
       "0  9151.0   208.0    0.0     0.0      0.0     0.0     0.0    0.0    0.0   \n",
       "1   460.0  4939.0   14.0   232.0   6387.0  1758.0  5834.0    3.0    2.0   \n",
       "2   448.0   723.0  267.0  9064.0  10634.0   166.0   782.0  224.0  273.0   \n",
       "3    78.0  2607.0  478.0   435.0      9.0   192.0     0.0    0.0    0.0   \n",
       "4  1702.0     1.0   53.0     0.0      0.0     0.0     0.0    0.0    0.0   \n",
       "\n",
       "        9  ...   88   89   90   91   92   93   94   95  gender  birth_year  \n",
       "0     0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0       1        1366  \n",
       "1     0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0       0        1359  \n",
       "2  4086.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0       1        1373  \n",
       "3     0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0       1        1371  \n",
       "4     0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0       1        1364  \n",
       "\n",
       "[5 rows x 932 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([df.pop('queries').apply(pd.Series), df], axis=1)\n",
    "df = pd.concat([df.pop('apps').apply(pd.Series), df], axis=1)\n",
    "df = pd.concat([df.pop('games').apply(pd.Series), df], axis=1)\n",
    "df.fillna(0, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa2dc977",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y =  df.drop(columns=[\"gender\"]), df[\"gender\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ad4f8ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e2d62d13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.63935444, 0.64276847, 0.63687151, 0.63842334, 0.62259466,\n",
       "       0.63749224, 0.63458553, 0.64141571, 0.63023906, 0.64452034])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "model = DecisionTreeClassifier(random_state=0)\n",
    "cross_val_score(model, X_train, y_train, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "367441f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)\n",
    "predicted = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83c118d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "def evaluate(predicted, actual):\n",
    "    print(\"Accuracy: \", metrics.accuracy_score(actual, predicted))\n",
    "    print(\"Balanced Accuracy: \", metrics.balanced_accuracy_score(actual, predicted))\n",
    "    print(\"Precision: \", metrics.precision_score(actual, predicted))\n",
    "    print(\"Recall: \", metrics.recall_score(actual, predicted))\n",
    "    print(\"F1: \", metrics.f1_score(actual, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8d5143b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.6441961514587213\n",
      "Balanced Accuracy:  0.5421774831735213\n",
      "Precision:  0.7637474541751528\n",
      "Recall:  0.7532641446267158\n",
      "F1:  0.7584695769425248\n"
     ]
    }
   ],
   "source": [
    "evaluate(predicted, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2886a0b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.74332713, 0.74332713, 0.74332713, 0.74332713, 0.74332713,\n",
       "       0.74332713, 0.7435579 , 0.74324744, 0.74324744, 0.74324744])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier(random_state=0, max_depth=10)\n",
    "cross_val_score(model, X_train, y_train, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0e589fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)\n",
    "predicted = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c263becc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.741651148355059\n",
      "Balanced Accuracy:  0.5\n",
      "Precision:  0.741651148355059\n",
      "Recall:  1.0\n",
      "F1:  0.8516644094375936\n"
     ]
    }
   ],
   "source": [
    "evaluate(predicted, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "37f1b324",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=RandomForestClassifier(max_depth=10, random_state=0),\n",
       "             param_grid={'max_depth': [2, 5, 10, 20, 50, 100],\n",
       "                         'min_samples_leaf': [1, 2, 3],\n",
       "                         'min_samples_split': [2, 3],\n",
       "                         'n_estimators': [2, 5, 10, 20, 30, 50, 100, 200]})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = { 'n_estimators': [2, 5, 10, 20, 30, 50, 100, 200],\n",
    "                   'min_samples_split': [2, 3],\n",
    "                   'min_samples_leaf': [1, 2, 3],\n",
    "                   'max_depth': [2, 5, 10, 20, 50 ,100]\n",
    "                 }\n",
    "\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=parameters)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f94c22d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 20,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'n_estimators': 100}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ae4e01a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.74270639, 0.74301676, 0.74394786, 0.74332713, 0.74363749,\n",
       "       0.74301676, 0.74262651, 0.74324744, 0.74293698, 0.74231605])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestClassifier(random_state=0, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100)\n",
    "cross_val_score(model, X_train, y_train, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "54eee9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)\n",
    "predicted = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a7ef692f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7417752948479206\n",
      "Balanced Accuracy:  0.5007099883573654\n",
      "Precision:  0.7419234592445328\n",
      "Recall:  0.9994978239035822\n",
      "F1:  0.8516616745114819\n"
     ]
    }
   ],
   "source": [
    "evaluate(predicted, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65dc0d0e",
   "metadata": {},
   "source": [
    "As we can see although we have not-bad accuracy but balanced accuracy which is wanted for this task is not good so we should look for better moodels.\n",
    "\n",
    "By remember that with these parameters:\n",
    "```\n",
    "{'max_depth': 20,\n",
    " 'min_samples_leaf': 1,\n",
    " 'min_samples_split': 2,\n",
    " 'n_estimators': 100\n",
    "}\n",
    "```\n",
    " \n",
    "We got these results:\n",
    "```\n",
    "Accuracy:  0.7417752948479206\n",
    "Balanced Accuracy:  0.5007099883573654\n",
    "Precision:  0.7419234592445328\n",
    "Recall:  0.9994978239035822\n",
    "F1:  0.8516616745114819\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fc07d664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 88 candidates, totalling 440 fits\n",
      "[CV 1/5; 1/88] START leaf_size=20, n_neighbors=3, weights=uniform...............\n",
      "[CV 1/5; 1/88] END leaf_size=20, n_neighbors=3, weights=uniform;, score=0.504 total time=   4.5s\n",
      "[CV 2/5; 1/88] START leaf_size=20, n_neighbors=3, weights=uniform...............\n",
      "[CV 2/5; 1/88] END leaf_size=20, n_neighbors=3, weights=uniform;, score=0.510 total time=   4.1s\n",
      "[CV 3/5; 1/88] START leaf_size=20, n_neighbors=3, weights=uniform...............\n",
      "[CV 3/5; 1/88] END leaf_size=20, n_neighbors=3, weights=uniform;, score=0.504 total time=   4.1s\n",
      "[CV 4/5; 1/88] START leaf_size=20, n_neighbors=3, weights=uniform...............\n",
      "[CV 4/5; 1/88] END leaf_size=20, n_neighbors=3, weights=uniform;, score=0.506 total time=   4.3s\n",
      "[CV 5/5; 1/88] START leaf_size=20, n_neighbors=3, weights=uniform...............\n",
      "[CV 5/5; 1/88] END leaf_size=20, n_neighbors=3, weights=uniform;, score=0.501 total time=   4.1s\n",
      "[CV 1/5; 2/88] START leaf_size=20, n_neighbors=3, weights=distance..............\n",
      "[CV 1/5; 2/88] END leaf_size=20, n_neighbors=3, weights=distance;, score=0.504 total time=   4.3s\n",
      "[CV 2/5; 2/88] START leaf_size=20, n_neighbors=3, weights=distance..............\n",
      "[CV 2/5; 2/88] END leaf_size=20, n_neighbors=3, weights=distance;, score=0.510 total time=   4.3s\n",
      "[CV 3/5; 2/88] START leaf_size=20, n_neighbors=3, weights=distance..............\n",
      "[CV 3/5; 2/88] END leaf_size=20, n_neighbors=3, weights=distance;, score=0.504 total time=   4.4s\n",
      "[CV 4/5; 2/88] START leaf_size=20, n_neighbors=3, weights=distance..............\n",
      "[CV 4/5; 2/88] END leaf_size=20, n_neighbors=3, weights=distance;, score=0.506 total time=   4.2s\n",
      "[CV 5/5; 2/88] START leaf_size=20, n_neighbors=3, weights=distance..............\n",
      "[CV 5/5; 2/88] END leaf_size=20, n_neighbors=3, weights=distance;, score=0.500 total time=   4.0s\n",
      "[CV 1/5; 3/88] START leaf_size=20, n_neighbors=5, weights=uniform...............\n",
      "[CV 1/5; 3/88] END leaf_size=20, n_neighbors=5, weights=uniform;, score=0.500 total time=   5.5s\n",
      "[CV 2/5; 3/88] START leaf_size=20, n_neighbors=5, weights=uniform...............\n",
      "[CV 2/5; 3/88] END leaf_size=20, n_neighbors=5, weights=uniform;, score=0.515 total time=   5.1s\n",
      "[CV 3/5; 3/88] START leaf_size=20, n_neighbors=5, weights=uniform...............\n",
      "[CV 3/5; 3/88] END leaf_size=20, n_neighbors=5, weights=uniform;, score=0.507 total time=   5.5s\n",
      "[CV 4/5; 3/88] START leaf_size=20, n_neighbors=5, weights=uniform...............\n",
      "[CV 4/5; 3/88] END leaf_size=20, n_neighbors=5, weights=uniform;, score=0.506 total time=   5.1s\n",
      "[CV 5/5; 3/88] START leaf_size=20, n_neighbors=5, weights=uniform...............\n",
      "[CV 5/5; 3/88] END leaf_size=20, n_neighbors=5, weights=uniform;, score=0.498 total time=   5.1s\n",
      "[CV 1/5; 4/88] START leaf_size=20, n_neighbors=5, weights=distance..............\n",
      "[CV 1/5; 4/88] END leaf_size=20, n_neighbors=5, weights=distance;, score=0.500 total time=   4.8s\n",
      "[CV 2/5; 4/88] START leaf_size=20, n_neighbors=5, weights=distance..............\n",
      "[CV 2/5; 4/88] END leaf_size=20, n_neighbors=5, weights=distance;, score=0.515 total time=   5.0s\n",
      "[CV 3/5; 4/88] START leaf_size=20, n_neighbors=5, weights=distance..............\n",
      "[CV 3/5; 4/88] END leaf_size=20, n_neighbors=5, weights=distance;, score=0.506 total time=   4.8s\n",
      "[CV 4/5; 4/88] START leaf_size=20, n_neighbors=5, weights=distance..............\n",
      "[CV 4/5; 4/88] END leaf_size=20, n_neighbors=5, weights=distance;, score=0.506 total time=   5.4s\n",
      "[CV 5/5; 4/88] START leaf_size=20, n_neighbors=5, weights=distance..............\n",
      "[CV 5/5; 4/88] END leaf_size=20, n_neighbors=5, weights=distance;, score=0.498 total time=   5.3s\n",
      "[CV 1/5; 5/88] START leaf_size=20, n_neighbors=7, weights=uniform...............\n",
      "[CV 1/5; 5/88] END leaf_size=20, n_neighbors=7, weights=uniform;, score=0.503 total time=   5.8s\n",
      "[CV 2/5; 5/88] START leaf_size=20, n_neighbors=7, weights=uniform...............\n",
      "[CV 2/5; 5/88] END leaf_size=20, n_neighbors=7, weights=uniform;, score=0.506 total time=   5.5s\n",
      "[CV 3/5; 5/88] START leaf_size=20, n_neighbors=7, weights=uniform...............\n",
      "[CV 3/5; 5/88] END leaf_size=20, n_neighbors=7, weights=uniform;, score=0.502 total time=   6.2s\n",
      "[CV 4/5; 5/88] START leaf_size=20, n_neighbors=7, weights=uniform...............\n",
      "[CV 4/5; 5/88] END leaf_size=20, n_neighbors=7, weights=uniform;, score=0.505 total time=   7.0s\n",
      "[CV 5/5; 5/88] START leaf_size=20, n_neighbors=7, weights=uniform...............\n",
      "[CV 5/5; 5/88] END leaf_size=20, n_neighbors=7, weights=uniform;, score=0.507 total time=   6.3s\n",
      "[CV 1/5; 6/88] START leaf_size=20, n_neighbors=7, weights=distance..............\n",
      "[CV 1/5; 6/88] END leaf_size=20, n_neighbors=7, weights=distance;, score=0.503 total time=   6.0s\n",
      "[CV 2/5; 6/88] START leaf_size=20, n_neighbors=7, weights=distance..............\n",
      "[CV 2/5; 6/88] END leaf_size=20, n_neighbors=7, weights=distance;, score=0.506 total time=   5.3s\n",
      "[CV 3/5; 6/88] START leaf_size=20, n_neighbors=7, weights=distance..............\n",
      "[CV 3/5; 6/88] END leaf_size=20, n_neighbors=7, weights=distance;, score=0.502 total time=   6.1s\n",
      "[CV 4/5; 6/88] START leaf_size=20, n_neighbors=7, weights=distance..............\n",
      "[CV 4/5; 6/88] END leaf_size=20, n_neighbors=7, weights=distance;, score=0.504 total time=   5.2s\n",
      "[CV 5/5; 6/88] START leaf_size=20, n_neighbors=7, weights=distance..............\n",
      "[CV 5/5; 6/88] END leaf_size=20, n_neighbors=7, weights=distance;, score=0.507 total time=   5.1s\n",
      "[CV 1/5; 7/88] START leaf_size=20, n_neighbors=9, weights=uniform...............\n",
      "[CV 1/5; 7/88] END leaf_size=20, n_neighbors=9, weights=uniform;, score=0.505 total time=   5.9s\n",
      "[CV 2/5; 7/88] START leaf_size=20, n_neighbors=9, weights=uniform...............\n",
      "[CV 2/5; 7/88] END leaf_size=20, n_neighbors=9, weights=uniform;, score=0.507 total time=   5.6s\n",
      "[CV 3/5; 7/88] START leaf_size=20, n_neighbors=9, weights=uniform...............\n",
      "[CV 3/5; 7/88] END leaf_size=20, n_neighbors=9, weights=uniform;, score=0.504 total time=   5.7s\n",
      "[CV 4/5; 7/88] START leaf_size=20, n_neighbors=9, weights=uniform...............\n",
      "[CV 4/5; 7/88] END leaf_size=20, n_neighbors=9, weights=uniform;, score=0.500 total time=   5.3s\n",
      "[CV 5/5; 7/88] START leaf_size=20, n_neighbors=9, weights=uniform...............\n",
      "[CV 5/5; 7/88] END leaf_size=20, n_neighbors=9, weights=uniform;, score=0.507 total time=   5.2s\n",
      "[CV 1/5; 8/88] START leaf_size=20, n_neighbors=9, weights=distance..............\n",
      "[CV 1/5; 8/88] END leaf_size=20, n_neighbors=9, weights=distance;, score=0.505 total time=   5.1s\n",
      "[CV 2/5; 8/88] START leaf_size=20, n_neighbors=9, weights=distance..............\n",
      "[CV 2/5; 8/88] END leaf_size=20, n_neighbors=9, weights=distance;, score=0.508 total time=   5.0s\n",
      "[CV 3/5; 8/88] START leaf_size=20, n_neighbors=9, weights=distance..............\n",
      "[CV 3/5; 8/88] END leaf_size=20, n_neighbors=9, weights=distance;, score=0.504 total time=   5.0s\n",
      "[CV 4/5; 8/88] START leaf_size=20, n_neighbors=9, weights=distance..............\n",
      "[CV 4/5; 8/88] END leaf_size=20, n_neighbors=9, weights=distance;, score=0.500 total time=   4.9s\n",
      "[CV 5/5; 8/88] START leaf_size=20, n_neighbors=9, weights=distance..............\n",
      "[CV 5/5; 8/88] END leaf_size=20, n_neighbors=9, weights=distance;, score=0.507 total time=   5.3s\n",
      "[CV 1/5; 9/88] START leaf_size=20, n_neighbors=15, weights=uniform..............\n",
      "[CV 1/5; 9/88] END leaf_size=20, n_neighbors=15, weights=uniform;, score=0.503 total time=   5.7s\n",
      "[CV 2/5; 9/88] START leaf_size=20, n_neighbors=15, weights=uniform..............\n",
      "[CV 2/5; 9/88] END leaf_size=20, n_neighbors=15, weights=uniform;, score=0.503 total time=   5.5s\n",
      "[CV 3/5; 9/88] START leaf_size=20, n_neighbors=15, weights=uniform..............\n",
      "[CV 3/5; 9/88] END leaf_size=20, n_neighbors=15, weights=uniform;, score=0.500 total time=   5.2s\n",
      "[CV 4/5; 9/88] START leaf_size=20, n_neighbors=15, weights=uniform..............\n",
      "[CV 4/5; 9/88] END leaf_size=20, n_neighbors=15, weights=uniform;, score=0.500 total time=   5.0s\n",
      "[CV 5/5; 9/88] START leaf_size=20, n_neighbors=15, weights=uniform..............\n",
      "[CV 5/5; 9/88] END leaf_size=20, n_neighbors=15, weights=uniform;, score=0.503 total time=   6.0s\n",
      "[CV 1/5; 10/88] START leaf_size=20, n_neighbors=15, weights=distance............\n",
      "[CV 1/5; 10/88] END leaf_size=20, n_neighbors=15, weights=distance;, score=0.503 total time=   5.6s\n",
      "[CV 2/5; 10/88] START leaf_size=20, n_neighbors=15, weights=distance............\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 10/88] END leaf_size=20, n_neighbors=15, weights=distance;, score=0.503 total time=   5.1s\n",
      "[CV 3/5; 10/88] START leaf_size=20, n_neighbors=15, weights=distance............\n",
      "[CV 3/5; 10/88] END leaf_size=20, n_neighbors=15, weights=distance;, score=0.500 total time=   4.9s\n",
      "[CV 4/5; 10/88] START leaf_size=20, n_neighbors=15, weights=distance............\n",
      "[CV 4/5; 10/88] END leaf_size=20, n_neighbors=15, weights=distance;, score=0.501 total time=   5.0s\n",
      "[CV 5/5; 10/88] START leaf_size=20, n_neighbors=15, weights=distance............\n",
      "[CV 5/5; 10/88] END leaf_size=20, n_neighbors=15, weights=distance;, score=0.503 total time=   4.8s\n",
      "[CV 1/5; 11/88] START leaf_size=20, n_neighbors=19, weights=uniform.............\n",
      "[CV 1/5; 11/88] END leaf_size=20, n_neighbors=19, weights=uniform;, score=0.501 total time=   5.3s\n",
      "[CV 2/5; 11/88] START leaf_size=20, n_neighbors=19, weights=uniform.............\n",
      "[CV 2/5; 11/88] END leaf_size=20, n_neighbors=19, weights=uniform;, score=0.501 total time=   5.1s\n",
      "[CV 3/5; 11/88] START leaf_size=20, n_neighbors=19, weights=uniform.............\n",
      "[CV 3/5; 11/88] END leaf_size=20, n_neighbors=19, weights=uniform;, score=0.501 total time=   5.2s\n",
      "[CV 4/5; 11/88] START leaf_size=20, n_neighbors=19, weights=uniform.............\n",
      "[CV 4/5; 11/88] END leaf_size=20, n_neighbors=19, weights=uniform;, score=0.500 total time=   5.3s\n",
      "[CV 5/5; 11/88] START leaf_size=20, n_neighbors=19, weights=uniform.............\n",
      "[CV 5/5; 11/88] END leaf_size=20, n_neighbors=19, weights=uniform;, score=0.502 total time=   5.4s\n",
      "[CV 1/5; 12/88] START leaf_size=20, n_neighbors=19, weights=distance............\n",
      "[CV 1/5; 12/88] END leaf_size=20, n_neighbors=19, weights=distance;, score=0.501 total time=   4.9s\n",
      "[CV 2/5; 12/88] START leaf_size=20, n_neighbors=19, weights=distance............\n",
      "[CV 2/5; 12/88] END leaf_size=20, n_neighbors=19, weights=distance;, score=0.502 total time=   5.1s\n",
      "[CV 3/5; 12/88] START leaf_size=20, n_neighbors=19, weights=distance............\n",
      "[CV 3/5; 12/88] END leaf_size=20, n_neighbors=19, weights=distance;, score=0.501 total time=   5.0s\n",
      "[CV 4/5; 12/88] START leaf_size=20, n_neighbors=19, weights=distance............\n",
      "[CV 4/5; 12/88] END leaf_size=20, n_neighbors=19, weights=distance;, score=0.500 total time=   5.0s\n",
      "[CV 5/5; 12/88] START leaf_size=20, n_neighbors=19, weights=distance............\n",
      "[CV 5/5; 12/88] END leaf_size=20, n_neighbors=19, weights=distance;, score=0.502 total time=   4.9s\n",
      "[CV 1/5; 13/88] START leaf_size=20, n_neighbors=25, weights=uniform.............\n",
      "[CV 1/5; 13/88] END leaf_size=20, n_neighbors=25, weights=uniform;, score=0.499 total time=   5.5s\n",
      "[CV 2/5; 13/88] START leaf_size=20, n_neighbors=25, weights=uniform.............\n",
      "[CV 2/5; 13/88] END leaf_size=20, n_neighbors=25, weights=uniform;, score=0.501 total time=   5.2s\n",
      "[CV 3/5; 13/88] START leaf_size=20, n_neighbors=25, weights=uniform.............\n",
      "[CV 3/5; 13/88] END leaf_size=20, n_neighbors=25, weights=uniform;, score=0.499 total time=   5.3s\n",
      "[CV 4/5; 13/88] START leaf_size=20, n_neighbors=25, weights=uniform.............\n",
      "[CV 4/5; 13/88] END leaf_size=20, n_neighbors=25, weights=uniform;, score=0.502 total time=   5.5s\n",
      "[CV 5/5; 13/88] START leaf_size=20, n_neighbors=25, weights=uniform.............\n",
      "[CV 5/5; 13/88] END leaf_size=20, n_neighbors=25, weights=uniform;, score=0.501 total time=   5.4s\n",
      "[CV 1/5; 14/88] START leaf_size=20, n_neighbors=25, weights=distance............\n",
      "[CV 1/5; 14/88] END leaf_size=20, n_neighbors=25, weights=distance;, score=0.499 total time=   5.2s\n",
      "[CV 2/5; 14/88] START leaf_size=20, n_neighbors=25, weights=distance............\n",
      "[CV 2/5; 14/88] END leaf_size=20, n_neighbors=25, weights=distance;, score=0.501 total time=   5.3s\n",
      "[CV 3/5; 14/88] START leaf_size=20, n_neighbors=25, weights=distance............\n",
      "[CV 3/5; 14/88] END leaf_size=20, n_neighbors=25, weights=distance;, score=0.499 total time=   5.2s\n",
      "[CV 4/5; 14/88] START leaf_size=20, n_neighbors=25, weights=distance............\n",
      "[CV 4/5; 14/88] END leaf_size=20, n_neighbors=25, weights=distance;, score=0.501 total time=   5.3s\n",
      "[CV 5/5; 14/88] START leaf_size=20, n_neighbors=25, weights=distance............\n",
      "[CV 5/5; 14/88] END leaf_size=20, n_neighbors=25, weights=distance;, score=0.501 total time=   5.2s\n",
      "[CV 1/5; 15/88] START leaf_size=20, n_neighbors=35, weights=uniform.............\n",
      "[CV 1/5; 15/88] END leaf_size=20, n_neighbors=35, weights=uniform;, score=0.500 total time=   5.4s\n",
      "[CV 2/5; 15/88] START leaf_size=20, n_neighbors=35, weights=uniform.............\n",
      "[CV 2/5; 15/88] END leaf_size=20, n_neighbors=35, weights=uniform;, score=0.500 total time=   5.0s\n",
      "[CV 3/5; 15/88] START leaf_size=20, n_neighbors=35, weights=uniform.............\n",
      "[CV 3/5; 15/88] END leaf_size=20, n_neighbors=35, weights=uniform;, score=0.500 total time=   5.1s\n",
      "[CV 4/5; 15/88] START leaf_size=20, n_neighbors=35, weights=uniform.............\n",
      "[CV 4/5; 15/88] END leaf_size=20, n_neighbors=35, weights=uniform;, score=0.500 total time=   5.3s\n",
      "[CV 5/5; 15/88] START leaf_size=20, n_neighbors=35, weights=uniform.............\n",
      "[CV 5/5; 15/88] END leaf_size=20, n_neighbors=35, weights=uniform;, score=0.501 total time=   5.4s\n",
      "[CV 1/5; 16/88] START leaf_size=20, n_neighbors=35, weights=distance............\n",
      "[CV 1/5; 16/88] END leaf_size=20, n_neighbors=35, weights=distance;, score=0.500 total time=   5.6s\n",
      "[CV 2/5; 16/88] START leaf_size=20, n_neighbors=35, weights=distance............\n",
      "[CV 2/5; 16/88] END leaf_size=20, n_neighbors=35, weights=distance;, score=0.500 total time=   5.1s\n",
      "[CV 3/5; 16/88] START leaf_size=20, n_neighbors=35, weights=distance............\n",
      "[CV 3/5; 16/88] END leaf_size=20, n_neighbors=35, weights=distance;, score=0.500 total time=   5.0s\n",
      "[CV 4/5; 16/88] START leaf_size=20, n_neighbors=35, weights=distance............\n",
      "[CV 4/5; 16/88] END leaf_size=20, n_neighbors=35, weights=distance;, score=0.500 total time=   5.1s\n",
      "[CV 5/5; 16/88] START leaf_size=20, n_neighbors=35, weights=distance............\n",
      "[CV 5/5; 16/88] END leaf_size=20, n_neighbors=35, weights=distance;, score=0.501 total time=   5.0s\n",
      "[CV 1/5; 17/88] START leaf_size=20, n_neighbors=55, weights=uniform.............\n",
      "[CV 1/5; 17/88] END leaf_size=20, n_neighbors=55, weights=uniform;, score=0.500 total time=   5.3s\n",
      "[CV 2/5; 17/88] START leaf_size=20, n_neighbors=55, weights=uniform.............\n",
      "[CV 2/5; 17/88] END leaf_size=20, n_neighbors=55, weights=uniform;, score=0.500 total time=   5.2s\n",
      "[CV 3/5; 17/88] START leaf_size=20, n_neighbors=55, weights=uniform.............\n",
      "[CV 3/5; 17/88] END leaf_size=20, n_neighbors=55, weights=uniform;, score=0.501 total time=   5.0s\n",
      "[CV 4/5; 17/88] START leaf_size=20, n_neighbors=55, weights=uniform.............\n",
      "[CV 4/5; 17/88] END leaf_size=20, n_neighbors=55, weights=uniform;, score=0.500 total time=   5.2s\n",
      "[CV 5/5; 17/88] START leaf_size=20, n_neighbors=55, weights=uniform.............\n",
      "[CV 5/5; 17/88] END leaf_size=20, n_neighbors=55, weights=uniform;, score=0.500 total time=   4.9s\n",
      "[CV 1/5; 18/88] START leaf_size=20, n_neighbors=55, weights=distance............\n",
      "[CV 1/5; 18/88] END leaf_size=20, n_neighbors=55, weights=distance;, score=0.500 total time=   5.0s\n",
      "[CV 2/5; 18/88] START leaf_size=20, n_neighbors=55, weights=distance............\n",
      "[CV 2/5; 18/88] END leaf_size=20, n_neighbors=55, weights=distance;, score=0.500 total time=   5.0s\n",
      "[CV 3/5; 18/88] START leaf_size=20, n_neighbors=55, weights=distance............\n",
      "[CV 3/5; 18/88] END leaf_size=20, n_neighbors=55, weights=distance;, score=0.500 total time=   5.0s\n",
      "[CV 4/5; 18/88] START leaf_size=20, n_neighbors=55, weights=distance............\n",
      "[CV 4/5; 18/88] END leaf_size=20, n_neighbors=55, weights=distance;, score=0.500 total time=   4.9s\n",
      "[CV 5/5; 18/88] START leaf_size=20, n_neighbors=55, weights=distance............\n",
      "[CV 5/5; 18/88] END leaf_size=20, n_neighbors=55, weights=distance;, score=0.500 total time=   5.4s\n",
      "[CV 1/5; 19/88] START leaf_size=20, n_neighbors=75, weights=uniform.............\n",
      "[CV 1/5; 19/88] END leaf_size=20, n_neighbors=75, weights=uniform;, score=0.500 total time=   5.6s\n",
      "[CV 2/5; 19/88] START leaf_size=20, n_neighbors=75, weights=uniform.............\n",
      "[CV 2/5; 19/88] END leaf_size=20, n_neighbors=75, weights=uniform;, score=0.500 total time=   6.0s\n",
      "[CV 3/5; 19/88] START leaf_size=20, n_neighbors=75, weights=uniform.............\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 19/88] END leaf_size=20, n_neighbors=75, weights=uniform;, score=0.500 total time=   5.6s\n",
      "[CV 4/5; 19/88] START leaf_size=20, n_neighbors=75, weights=uniform.............\n",
      "[CV 4/5; 19/88] END leaf_size=20, n_neighbors=75, weights=uniform;, score=0.500 total time=   5.4s\n",
      "[CV 5/5; 19/88] START leaf_size=20, n_neighbors=75, weights=uniform.............\n",
      "[CV 5/5; 19/88] END leaf_size=20, n_neighbors=75, weights=uniform;, score=0.500 total time=   5.4s\n",
      "[CV 1/5; 20/88] START leaf_size=20, n_neighbors=75, weights=distance............\n",
      "[CV 1/5; 20/88] END leaf_size=20, n_neighbors=75, weights=distance;, score=0.500 total time=   5.7s\n",
      "[CV 2/5; 20/88] START leaf_size=20, n_neighbors=75, weights=distance............\n",
      "[CV 2/5; 20/88] END leaf_size=20, n_neighbors=75, weights=distance;, score=0.500 total time=   5.9s\n",
      "[CV 3/5; 20/88] START leaf_size=20, n_neighbors=75, weights=distance............\n",
      "[CV 3/5; 20/88] END leaf_size=20, n_neighbors=75, weights=distance;, score=0.500 total time=   5.2s\n",
      "[CV 4/5; 20/88] START leaf_size=20, n_neighbors=75, weights=distance............\n",
      "[CV 4/5; 20/88] END leaf_size=20, n_neighbors=75, weights=distance;, score=0.500 total time=   5.1s\n",
      "[CV 5/5; 20/88] START leaf_size=20, n_neighbors=75, weights=distance............\n",
      "[CV 5/5; 20/88] END leaf_size=20, n_neighbors=75, weights=distance;, score=0.500 total time=   4.6s\n",
      "[CV 1/5; 21/88] START leaf_size=20, n_neighbors=99, weights=uniform.............\n",
      "[CV 1/5; 21/88] END leaf_size=20, n_neighbors=99, weights=uniform;, score=0.500 total time=   5.9s\n",
      "[CV 2/5; 21/88] START leaf_size=20, n_neighbors=99, weights=uniform.............\n",
      "[CV 2/5; 21/88] END leaf_size=20, n_neighbors=99, weights=uniform;, score=0.500 total time=   5.7s\n",
      "[CV 3/5; 21/88] START leaf_size=20, n_neighbors=99, weights=uniform.............\n",
      "[CV 3/5; 21/88] END leaf_size=20, n_neighbors=99, weights=uniform;, score=0.500 total time=   5.5s\n",
      "[CV 4/5; 21/88] START leaf_size=20, n_neighbors=99, weights=uniform.............\n",
      "[CV 4/5; 21/88] END leaf_size=20, n_neighbors=99, weights=uniform;, score=0.500 total time=   6.5s\n",
      "[CV 5/5; 21/88] START leaf_size=20, n_neighbors=99, weights=uniform.............\n",
      "[CV 5/5; 21/88] END leaf_size=20, n_neighbors=99, weights=uniform;, score=0.500 total time=   4.8s\n",
      "[CV 1/5; 22/88] START leaf_size=20, n_neighbors=99, weights=distance............\n",
      "[CV 1/5; 22/88] END leaf_size=20, n_neighbors=99, weights=distance;, score=0.500 total time=   5.3s\n",
      "[CV 2/5; 22/88] START leaf_size=20, n_neighbors=99, weights=distance............\n",
      "[CV 2/5; 22/88] END leaf_size=20, n_neighbors=99, weights=distance;, score=0.500 total time=   6.5s\n",
      "[CV 3/5; 22/88] START leaf_size=20, n_neighbors=99, weights=distance............\n",
      "[CV 3/5; 22/88] END leaf_size=20, n_neighbors=99, weights=distance;, score=0.500 total time=   5.1s\n",
      "[CV 4/5; 22/88] START leaf_size=20, n_neighbors=99, weights=distance............\n",
      "[CV 4/5; 22/88] END leaf_size=20, n_neighbors=99, weights=distance;, score=0.500 total time=   4.9s\n",
      "[CV 5/5; 22/88] START leaf_size=20, n_neighbors=99, weights=distance............\n",
      "[CV 5/5; 22/88] END leaf_size=20, n_neighbors=99, weights=distance;, score=0.500 total time=   5.5s\n",
      "[CV 1/5; 23/88] START leaf_size=30, n_neighbors=3, weights=uniform..............\n",
      "[CV 1/5; 23/88] END leaf_size=30, n_neighbors=3, weights=uniform;, score=0.504 total time=   4.5s\n",
      "[CV 2/5; 23/88] START leaf_size=30, n_neighbors=3, weights=uniform..............\n",
      "[CV 2/5; 23/88] END leaf_size=30, n_neighbors=3, weights=uniform;, score=0.510 total time=   4.6s\n",
      "[CV 3/5; 23/88] START leaf_size=30, n_neighbors=3, weights=uniform..............\n",
      "[CV 3/5; 23/88] END leaf_size=30, n_neighbors=3, weights=uniform;, score=0.504 total time=   4.5s\n",
      "[CV 4/5; 23/88] START leaf_size=30, n_neighbors=3, weights=uniform..............\n",
      "[CV 4/5; 23/88] END leaf_size=30, n_neighbors=3, weights=uniform;, score=0.506 total time=   4.8s\n",
      "[CV 5/5; 23/88] START leaf_size=30, n_neighbors=3, weights=uniform..............\n",
      "[CV 5/5; 23/88] END leaf_size=30, n_neighbors=3, weights=uniform;, score=0.501 total time=   4.4s\n",
      "[CV 1/5; 24/88] START leaf_size=30, n_neighbors=3, weights=distance.............\n",
      "[CV 1/5; 24/88] END leaf_size=30, n_neighbors=3, weights=distance;, score=0.504 total time=   4.6s\n",
      "[CV 2/5; 24/88] START leaf_size=30, n_neighbors=3, weights=distance.............\n",
      "[CV 2/5; 24/88] END leaf_size=30, n_neighbors=3, weights=distance;, score=0.510 total time=   4.3s\n",
      "[CV 3/5; 24/88] START leaf_size=30, n_neighbors=3, weights=distance.............\n",
      "[CV 3/5; 24/88] END leaf_size=30, n_neighbors=3, weights=distance;, score=0.504 total time=   4.4s\n",
      "[CV 4/5; 24/88] START leaf_size=30, n_neighbors=3, weights=distance.............\n",
      "[CV 4/5; 24/88] END leaf_size=30, n_neighbors=3, weights=distance;, score=0.506 total time=   4.3s\n",
      "[CV 5/5; 24/88] START leaf_size=30, n_neighbors=3, weights=distance.............\n",
      "[CV 5/5; 24/88] END leaf_size=30, n_neighbors=3, weights=distance;, score=0.500 total time=   4.6s\n",
      "[CV 1/5; 25/88] START leaf_size=30, n_neighbors=5, weights=uniform..............\n",
      "[CV 1/5; 25/88] END leaf_size=30, n_neighbors=5, weights=uniform;, score=0.500 total time=   5.9s\n",
      "[CV 2/5; 25/88] START leaf_size=30, n_neighbors=5, weights=uniform..............\n",
      "[CV 2/5; 25/88] END leaf_size=30, n_neighbors=5, weights=uniform;, score=0.515 total time=   6.3s\n",
      "[CV 3/5; 25/88] START leaf_size=30, n_neighbors=5, weights=uniform..............\n",
      "[CV 3/5; 25/88] END leaf_size=30, n_neighbors=5, weights=uniform;, score=0.507 total time=   5.9s\n",
      "[CV 4/5; 25/88] START leaf_size=30, n_neighbors=5, weights=uniform..............\n",
      "[CV 4/5; 25/88] END leaf_size=30, n_neighbors=5, weights=uniform;, score=0.506 total time=   6.2s\n",
      "[CV 5/5; 25/88] START leaf_size=30, n_neighbors=5, weights=uniform..............\n",
      "[CV 5/5; 25/88] END leaf_size=30, n_neighbors=5, weights=uniform;, score=0.498 total time=   5.7s\n",
      "[CV 1/5; 26/88] START leaf_size=30, n_neighbors=5, weights=distance.............\n",
      "[CV 1/5; 26/88] END leaf_size=30, n_neighbors=5, weights=distance;, score=0.500 total time=   5.8s\n",
      "[CV 2/5; 26/88] START leaf_size=30, n_neighbors=5, weights=distance.............\n",
      "[CV 2/5; 26/88] END leaf_size=30, n_neighbors=5, weights=distance;, score=0.515 total time=   5.3s\n",
      "[CV 3/5; 26/88] START leaf_size=30, n_neighbors=5, weights=distance.............\n",
      "[CV 3/5; 26/88] END leaf_size=30, n_neighbors=5, weights=distance;, score=0.506 total time=   5.8s\n",
      "[CV 4/5; 26/88] START leaf_size=30, n_neighbors=5, weights=distance.............\n",
      "[CV 4/5; 26/88] END leaf_size=30, n_neighbors=5, weights=distance;, score=0.506 total time=   5.5s\n",
      "[CV 5/5; 26/88] START leaf_size=30, n_neighbors=5, weights=distance.............\n",
      "[CV 5/5; 26/88] END leaf_size=30, n_neighbors=5, weights=distance;, score=0.498 total time=   5.7s\n",
      "[CV 1/5; 27/88] START leaf_size=30, n_neighbors=7, weights=uniform..............\n",
      "[CV 1/5; 27/88] END leaf_size=30, n_neighbors=7, weights=uniform;, score=0.503 total time=   5.5s\n",
      "[CV 2/5; 27/88] START leaf_size=30, n_neighbors=7, weights=uniform..............\n",
      "[CV 2/5; 27/88] END leaf_size=30, n_neighbors=7, weights=uniform;, score=0.506 total time=   5.4s\n",
      "[CV 3/5; 27/88] START leaf_size=30, n_neighbors=7, weights=uniform..............\n",
      "[CV 3/5; 27/88] END leaf_size=30, n_neighbors=7, weights=uniform;, score=0.502 total time=   5.1s\n",
      "[CV 4/5; 27/88] START leaf_size=30, n_neighbors=7, weights=uniform..............\n",
      "[CV 4/5; 27/88] END leaf_size=30, n_neighbors=7, weights=uniform;, score=0.505 total time=   5.5s\n",
      "[CV 5/5; 27/88] START leaf_size=30, n_neighbors=7, weights=uniform..............\n",
      "[CV 5/5; 27/88] END leaf_size=30, n_neighbors=7, weights=uniform;, score=0.507 total time=   4.9s\n",
      "[CV 1/5; 28/88] START leaf_size=30, n_neighbors=7, weights=distance.............\n",
      "[CV 1/5; 28/88] END leaf_size=30, n_neighbors=7, weights=distance;, score=0.503 total time=   5.0s\n",
      "[CV 2/5; 28/88] START leaf_size=30, n_neighbors=7, weights=distance.............\n",
      "[CV 2/5; 28/88] END leaf_size=30, n_neighbors=7, weights=distance;, score=0.506 total time=   4.8s\n",
      "[CV 3/5; 28/88] START leaf_size=30, n_neighbors=7, weights=distance.............\n",
      "[CV 3/5; 28/88] END leaf_size=30, n_neighbors=7, weights=distance;, score=0.502 total time=   5.2s\n",
      "[CV 4/5; 28/88] START leaf_size=30, n_neighbors=7, weights=distance.............\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 28/88] END leaf_size=30, n_neighbors=7, weights=distance;, score=0.504 total time=   5.0s\n",
      "[CV 5/5; 28/88] START leaf_size=30, n_neighbors=7, weights=distance.............\n",
      "[CV 5/5; 28/88] END leaf_size=30, n_neighbors=7, weights=distance;, score=0.507 total time=   5.1s\n",
      "[CV 1/5; 29/88] START leaf_size=30, n_neighbors=9, weights=uniform..............\n",
      "[CV 1/5; 29/88] END leaf_size=30, n_neighbors=9, weights=uniform;, score=0.505 total time=   5.8s\n",
      "[CV 2/5; 29/88] START leaf_size=30, n_neighbors=9, weights=uniform..............\n",
      "[CV 2/5; 29/88] END leaf_size=30, n_neighbors=9, weights=uniform;, score=0.507 total time=   5.6s\n",
      "[CV 3/5; 29/88] START leaf_size=30, n_neighbors=9, weights=uniform..............\n",
      "[CV 3/5; 29/88] END leaf_size=30, n_neighbors=9, weights=uniform;, score=0.504 total time=   5.1s\n",
      "[CV 4/5; 29/88] START leaf_size=30, n_neighbors=9, weights=uniform..............\n",
      "[CV 4/5; 29/88] END leaf_size=30, n_neighbors=9, weights=uniform;, score=0.500 total time=   5.5s\n",
      "[CV 5/5; 29/88] START leaf_size=30, n_neighbors=9, weights=uniform..............\n",
      "[CV 5/5; 29/88] END leaf_size=30, n_neighbors=9, weights=uniform;, score=0.507 total time=   5.5s\n",
      "[CV 1/5; 30/88] START leaf_size=30, n_neighbors=9, weights=distance.............\n",
      "[CV 1/5; 30/88] END leaf_size=30, n_neighbors=9, weights=distance;, score=0.505 total time=   5.2s\n",
      "[CV 2/5; 30/88] START leaf_size=30, n_neighbors=9, weights=distance.............\n",
      "[CV 2/5; 30/88] END leaf_size=30, n_neighbors=9, weights=distance;, score=0.508 total time=   5.0s\n",
      "[CV 3/5; 30/88] START leaf_size=30, n_neighbors=9, weights=distance.............\n",
      "[CV 3/5; 30/88] END leaf_size=30, n_neighbors=9, weights=distance;, score=0.504 total time=   5.0s\n",
      "[CV 4/5; 30/88] START leaf_size=30, n_neighbors=9, weights=distance.............\n",
      "[CV 4/5; 30/88] END leaf_size=30, n_neighbors=9, weights=distance;, score=0.500 total time=   5.5s\n",
      "[CV 5/5; 30/88] START leaf_size=30, n_neighbors=9, weights=distance.............\n",
      "[CV 5/5; 30/88] END leaf_size=30, n_neighbors=9, weights=distance;, score=0.507 total time=   4.8s\n",
      "[CV 1/5; 31/88] START leaf_size=30, n_neighbors=15, weights=uniform.............\n",
      "[CV 1/5; 31/88] END leaf_size=30, n_neighbors=15, weights=uniform;, score=0.503 total time=   5.2s\n",
      "[CV 2/5; 31/88] START leaf_size=30, n_neighbors=15, weights=uniform.............\n",
      "[CV 2/5; 31/88] END leaf_size=30, n_neighbors=15, weights=uniform;, score=0.503 total time=   5.5s\n",
      "[CV 3/5; 31/88] START leaf_size=30, n_neighbors=15, weights=uniform.............\n",
      "[CV 3/5; 31/88] END leaf_size=30, n_neighbors=15, weights=uniform;, score=0.500 total time=   5.6s\n",
      "[CV 4/5; 31/88] START leaf_size=30, n_neighbors=15, weights=uniform.............\n",
      "[CV 4/5; 31/88] END leaf_size=30, n_neighbors=15, weights=uniform;, score=0.500 total time=   5.1s\n",
      "[CV 5/5; 31/88] START leaf_size=30, n_neighbors=15, weights=uniform.............\n",
      "[CV 5/5; 31/88] END leaf_size=30, n_neighbors=15, weights=uniform;, score=0.503 total time=   5.1s\n",
      "[CV 1/5; 32/88] START leaf_size=30, n_neighbors=15, weights=distance............\n",
      "[CV 1/5; 32/88] END leaf_size=30, n_neighbors=15, weights=distance;, score=0.503 total time=   5.0s\n",
      "[CV 2/5; 32/88] START leaf_size=30, n_neighbors=15, weights=distance............\n",
      "[CV 2/5; 32/88] END leaf_size=30, n_neighbors=15, weights=distance;, score=0.503 total time=   5.0s\n",
      "[CV 3/5; 32/88] START leaf_size=30, n_neighbors=15, weights=distance............\n",
      "[CV 3/5; 32/88] END leaf_size=30, n_neighbors=15, weights=distance;, score=0.500 total time=   4.9s\n",
      "[CV 4/5; 32/88] START leaf_size=30, n_neighbors=15, weights=distance............\n",
      "[CV 4/5; 32/88] END leaf_size=30, n_neighbors=15, weights=distance;, score=0.501 total time=   5.2s\n",
      "[CV 5/5; 32/88] START leaf_size=30, n_neighbors=15, weights=distance............\n",
      "[CV 5/5; 32/88] END leaf_size=30, n_neighbors=15, weights=distance;, score=0.503 total time=   5.5s\n",
      "[CV 1/5; 33/88] START leaf_size=30, n_neighbors=19, weights=uniform.............\n",
      "[CV 1/5; 33/88] END leaf_size=30, n_neighbors=19, weights=uniform;, score=0.501 total time=   5.5s\n",
      "[CV 2/5; 33/88] START leaf_size=30, n_neighbors=19, weights=uniform.............\n",
      "[CV 2/5; 33/88] END leaf_size=30, n_neighbors=19, weights=uniform;, score=0.501 total time=   5.5s\n",
      "[CV 3/5; 33/88] START leaf_size=30, n_neighbors=19, weights=uniform.............\n",
      "[CV 3/5; 33/88] END leaf_size=30, n_neighbors=19, weights=uniform;, score=0.501 total time=   5.5s\n",
      "[CV 4/5; 33/88] START leaf_size=30, n_neighbors=19, weights=uniform.............\n",
      "[CV 4/5; 33/88] END leaf_size=30, n_neighbors=19, weights=uniform;, score=0.500 total time=   5.5s\n",
      "[CV 5/5; 33/88] START leaf_size=30, n_neighbors=19, weights=uniform.............\n",
      "[CV 5/5; 33/88] END leaf_size=30, n_neighbors=19, weights=uniform;, score=0.502 total time=   5.5s\n",
      "[CV 1/5; 34/88] START leaf_size=30, n_neighbors=19, weights=distance............\n",
      "[CV 1/5; 34/88] END leaf_size=30, n_neighbors=19, weights=distance;, score=0.501 total time=   5.4s\n",
      "[CV 2/5; 34/88] START leaf_size=30, n_neighbors=19, weights=distance............\n",
      "[CV 2/5; 34/88] END leaf_size=30, n_neighbors=19, weights=distance;, score=0.502 total time=   5.1s\n",
      "[CV 3/5; 34/88] START leaf_size=30, n_neighbors=19, weights=distance............\n",
      "[CV 3/5; 34/88] END leaf_size=30, n_neighbors=19, weights=distance;, score=0.501 total time=   5.0s\n",
      "[CV 4/5; 34/88] START leaf_size=30, n_neighbors=19, weights=distance............\n",
      "[CV 4/5; 34/88] END leaf_size=30, n_neighbors=19, weights=distance;, score=0.500 total time=   4.9s\n",
      "[CV 5/5; 34/88] START leaf_size=30, n_neighbors=19, weights=distance............\n",
      "[CV 5/5; 34/88] END leaf_size=30, n_neighbors=19, weights=distance;, score=0.502 total time=   5.1s\n",
      "[CV 1/5; 35/88] START leaf_size=30, n_neighbors=25, weights=uniform.............\n",
      "[CV 1/5; 35/88] END leaf_size=30, n_neighbors=25, weights=uniform;, score=0.499 total time=   5.5s\n",
      "[CV 2/5; 35/88] START leaf_size=30, n_neighbors=25, weights=uniform.............\n",
      "[CV 2/5; 35/88] END leaf_size=30, n_neighbors=25, weights=uniform;, score=0.501 total time=   5.6s\n",
      "[CV 3/5; 35/88] START leaf_size=30, n_neighbors=25, weights=uniform.............\n",
      "[CV 3/5; 35/88] END leaf_size=30, n_neighbors=25, weights=uniform;, score=0.499 total time=   5.5s\n",
      "[CV 4/5; 35/88] START leaf_size=30, n_neighbors=25, weights=uniform.............\n",
      "[CV 4/5; 35/88] END leaf_size=30, n_neighbors=25, weights=uniform;, score=0.502 total time=   5.4s\n",
      "[CV 5/5; 35/88] START leaf_size=30, n_neighbors=25, weights=uniform.............\n",
      "[CV 5/5; 35/88] END leaf_size=30, n_neighbors=25, weights=uniform;, score=0.501 total time=   5.4s\n",
      "[CV 1/5; 36/88] START leaf_size=30, n_neighbors=25, weights=distance............\n",
      "[CV 1/5; 36/88] END leaf_size=30, n_neighbors=25, weights=distance;, score=0.499 total time=   5.4s\n",
      "[CV 2/5; 36/88] START leaf_size=30, n_neighbors=25, weights=distance............\n",
      "[CV 2/5; 36/88] END leaf_size=30, n_neighbors=25, weights=distance;, score=0.501 total time=   6.1s\n",
      "[CV 3/5; 36/88] START leaf_size=30, n_neighbors=25, weights=distance............\n",
      "[CV 3/5; 36/88] END leaf_size=30, n_neighbors=25, weights=distance;, score=0.499 total time=   5.9s\n",
      "[CV 4/5; 36/88] START leaf_size=30, n_neighbors=25, weights=distance............\n",
      "[CV 4/5; 36/88] END leaf_size=30, n_neighbors=25, weights=distance;, score=0.501 total time=   4.9s\n",
      "[CV 5/5; 36/88] START leaf_size=30, n_neighbors=25, weights=distance............\n",
      "[CV 5/5; 36/88] END leaf_size=30, n_neighbors=25, weights=distance;, score=0.501 total time=   6.2s\n",
      "[CV 1/5; 37/88] START leaf_size=30, n_neighbors=35, weights=uniform.............\n",
      "[CV 1/5; 37/88] END leaf_size=30, n_neighbors=35, weights=uniform;, score=0.500 total time=   7.1s\n",
      "[CV 2/5; 37/88] START leaf_size=30, n_neighbors=35, weights=uniform.............\n",
      "[CV 2/5; 37/88] END leaf_size=30, n_neighbors=35, weights=uniform;, score=0.500 total time=   6.4s\n",
      "[CV 3/5; 37/88] START leaf_size=30, n_neighbors=35, weights=uniform.............\n",
      "[CV 3/5; 37/88] END leaf_size=30, n_neighbors=35, weights=uniform;, score=0.500 total time=   6.9s\n",
      "[CV 4/5; 37/88] START leaf_size=30, n_neighbors=35, weights=uniform.............\n",
      "[CV 4/5; 37/88] END leaf_size=30, n_neighbors=35, weights=uniform;, score=0.500 total time=   6.4s\n",
      "[CV 5/5; 37/88] START leaf_size=30, n_neighbors=35, weights=uniform.............\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 37/88] END leaf_size=30, n_neighbors=35, weights=uniform;, score=0.501 total time=   6.2s\n",
      "[CV 1/5; 38/88] START leaf_size=30, n_neighbors=35, weights=distance............\n",
      "[CV 1/5; 38/88] END leaf_size=30, n_neighbors=35, weights=distance;, score=0.500 total time=   6.9s\n",
      "[CV 2/5; 38/88] START leaf_size=30, n_neighbors=35, weights=distance............\n",
      "[CV 2/5; 38/88] END leaf_size=30, n_neighbors=35, weights=distance;, score=0.500 total time=   6.8s\n",
      "[CV 3/5; 38/88] START leaf_size=30, n_neighbors=35, weights=distance............\n",
      "[CV 3/5; 38/88] END leaf_size=30, n_neighbors=35, weights=distance;, score=0.500 total time=   6.2s\n",
      "[CV 4/5; 38/88] START leaf_size=30, n_neighbors=35, weights=distance............\n",
      "[CV 4/5; 38/88] END leaf_size=30, n_neighbors=35, weights=distance;, score=0.500 total time=   5.5s\n",
      "[CV 5/5; 38/88] START leaf_size=30, n_neighbors=35, weights=distance............\n",
      "[CV 5/5; 38/88] END leaf_size=30, n_neighbors=35, weights=distance;, score=0.501 total time=   5.1s\n",
      "[CV 1/5; 39/88] START leaf_size=30, n_neighbors=55, weights=uniform.............\n",
      "[CV 1/5; 39/88] END leaf_size=30, n_neighbors=55, weights=uniform;, score=0.500 total time=   4.9s\n",
      "[CV 2/5; 39/88] START leaf_size=30, n_neighbors=55, weights=uniform.............\n",
      "[CV 2/5; 39/88] END leaf_size=30, n_neighbors=55, weights=uniform;, score=0.500 total time=   5.3s\n",
      "[CV 3/5; 39/88] START leaf_size=30, n_neighbors=55, weights=uniform.............\n",
      "[CV 3/5; 39/88] END leaf_size=30, n_neighbors=55, weights=uniform;, score=0.501 total time=   5.3s\n",
      "[CV 4/5; 39/88] START leaf_size=30, n_neighbors=55, weights=uniform.............\n",
      "[CV 4/5; 39/88] END leaf_size=30, n_neighbors=55, weights=uniform;, score=0.500 total time=   6.3s\n",
      "[CV 5/5; 39/88] START leaf_size=30, n_neighbors=55, weights=uniform.............\n",
      "[CV 5/5; 39/88] END leaf_size=30, n_neighbors=55, weights=uniform;, score=0.500 total time=   6.4s\n",
      "[CV 1/5; 40/88] START leaf_size=30, n_neighbors=55, weights=distance............\n",
      "[CV 1/5; 40/88] END leaf_size=30, n_neighbors=55, weights=distance;, score=0.500 total time=   6.2s\n",
      "[CV 2/5; 40/88] START leaf_size=30, n_neighbors=55, weights=distance............\n",
      "[CV 2/5; 40/88] END leaf_size=30, n_neighbors=55, weights=distance;, score=0.500 total time=   6.0s\n",
      "[CV 3/5; 40/88] START leaf_size=30, n_neighbors=55, weights=distance............\n",
      "[CV 3/5; 40/88] END leaf_size=30, n_neighbors=55, weights=distance;, score=0.500 total time=   6.0s\n",
      "[CV 4/5; 40/88] START leaf_size=30, n_neighbors=55, weights=distance............\n",
      "[CV 4/5; 40/88] END leaf_size=30, n_neighbors=55, weights=distance;, score=0.500 total time=   6.2s\n",
      "[CV 5/5; 40/88] START leaf_size=30, n_neighbors=55, weights=distance............\n",
      "[CV 5/5; 40/88] END leaf_size=30, n_neighbors=55, weights=distance;, score=0.500 total time=   5.7s\n",
      "[CV 1/5; 41/88] START leaf_size=30, n_neighbors=75, weights=uniform.............\n",
      "[CV 1/5; 41/88] END leaf_size=30, n_neighbors=75, weights=uniform;, score=0.500 total time=   6.3s\n",
      "[CV 2/5; 41/88] START leaf_size=30, n_neighbors=75, weights=uniform.............\n",
      "[CV 2/5; 41/88] END leaf_size=30, n_neighbors=75, weights=uniform;, score=0.500 total time=   6.0s\n",
      "[CV 3/5; 41/88] START leaf_size=30, n_neighbors=75, weights=uniform.............\n",
      "[CV 3/5; 41/88] END leaf_size=30, n_neighbors=75, weights=uniform;, score=0.500 total time=   6.6s\n",
      "[CV 4/5; 41/88] START leaf_size=30, n_neighbors=75, weights=uniform.............\n",
      "[CV 4/5; 41/88] END leaf_size=30, n_neighbors=75, weights=uniform;, score=0.500 total time=   6.4s\n",
      "[CV 5/5; 41/88] START leaf_size=30, n_neighbors=75, weights=uniform.............\n",
      "[CV 5/5; 41/88] END leaf_size=30, n_neighbors=75, weights=uniform;, score=0.500 total time=   6.1s\n",
      "[CV 1/5; 42/88] START leaf_size=30, n_neighbors=75, weights=distance............\n",
      "[CV 1/5; 42/88] END leaf_size=30, n_neighbors=75, weights=distance;, score=0.500 total time=   6.6s\n",
      "[CV 2/5; 42/88] START leaf_size=30, n_neighbors=75, weights=distance............\n",
      "[CV 2/5; 42/88] END leaf_size=30, n_neighbors=75, weights=distance;, score=0.500 total time=   6.6s\n",
      "[CV 3/5; 42/88] START leaf_size=30, n_neighbors=75, weights=distance............\n",
      "[CV 3/5; 42/88] END leaf_size=30, n_neighbors=75, weights=distance;, score=0.500 total time=   5.6s\n",
      "[CV 4/5; 42/88] START leaf_size=30, n_neighbors=75, weights=distance............\n",
      "[CV 4/5; 42/88] END leaf_size=30, n_neighbors=75, weights=distance;, score=0.500 total time=   5.8s\n",
      "[CV 5/5; 42/88] START leaf_size=30, n_neighbors=75, weights=distance............\n",
      "[CV 5/5; 42/88] END leaf_size=30, n_neighbors=75, weights=distance;, score=0.500 total time=   4.8s\n",
      "[CV 1/5; 43/88] START leaf_size=30, n_neighbors=99, weights=uniform.............\n",
      "[CV 1/5; 43/88] END leaf_size=30, n_neighbors=99, weights=uniform;, score=0.500 total time=   4.8s\n",
      "[CV 2/5; 43/88] START leaf_size=30, n_neighbors=99, weights=uniform.............\n",
      "[CV 2/5; 43/88] END leaf_size=30, n_neighbors=99, weights=uniform;, score=0.500 total time=   4.8s\n",
      "[CV 3/5; 43/88] START leaf_size=30, n_neighbors=99, weights=uniform.............\n",
      "[CV 3/5; 43/88] END leaf_size=30, n_neighbors=99, weights=uniform;, score=0.500 total time=   4.8s\n",
      "[CV 4/5; 43/88] START leaf_size=30, n_neighbors=99, weights=uniform.............\n",
      "[CV 4/5; 43/88] END leaf_size=30, n_neighbors=99, weights=uniform;, score=0.500 total time=   4.7s\n",
      "[CV 5/5; 43/88] START leaf_size=30, n_neighbors=99, weights=uniform.............\n",
      "[CV 5/5; 43/88] END leaf_size=30, n_neighbors=99, weights=uniform;, score=0.500 total time=   4.7s\n",
      "[CV 1/5; 44/88] START leaf_size=30, n_neighbors=99, weights=distance............\n",
      "[CV 1/5; 44/88] END leaf_size=30, n_neighbors=99, weights=distance;, score=0.500 total time=   5.3s\n",
      "[CV 2/5; 44/88] START leaf_size=30, n_neighbors=99, weights=distance............\n",
      "[CV 2/5; 44/88] END leaf_size=30, n_neighbors=99, weights=distance;, score=0.500 total time=   5.6s\n",
      "[CV 3/5; 44/88] START leaf_size=30, n_neighbors=99, weights=distance............\n",
      "[CV 3/5; 44/88] END leaf_size=30, n_neighbors=99, weights=distance;, score=0.500 total time=   5.9s\n",
      "[CV 4/5; 44/88] START leaf_size=30, n_neighbors=99, weights=distance............\n",
      "[CV 4/5; 44/88] END leaf_size=30, n_neighbors=99, weights=distance;, score=0.500 total time=   5.8s\n",
      "[CV 5/5; 44/88] START leaf_size=30, n_neighbors=99, weights=distance............\n",
      "[CV 5/5; 44/88] END leaf_size=30, n_neighbors=99, weights=distance;, score=0.500 total time=   6.2s\n",
      "[CV 1/5; 45/88] START leaf_size=50, n_neighbors=3, weights=uniform..............\n",
      "[CV 1/5; 45/88] END leaf_size=50, n_neighbors=3, weights=uniform;, score=0.504 total time=   4.7s\n",
      "[CV 2/5; 45/88] START leaf_size=50, n_neighbors=3, weights=uniform..............\n",
      "[CV 2/5; 45/88] END leaf_size=50, n_neighbors=3, weights=uniform;, score=0.510 total time=   5.1s\n",
      "[CV 3/5; 45/88] START leaf_size=50, n_neighbors=3, weights=uniform..............\n",
      "[CV 3/5; 45/88] END leaf_size=50, n_neighbors=3, weights=uniform;, score=0.504 total time=   4.6s\n",
      "[CV 4/5; 45/88] START leaf_size=50, n_neighbors=3, weights=uniform..............\n",
      "[CV 4/5; 45/88] END leaf_size=50, n_neighbors=3, weights=uniform;, score=0.506 total time=   4.8s\n",
      "[CV 5/5; 45/88] START leaf_size=50, n_neighbors=3, weights=uniform..............\n",
      "[CV 5/5; 45/88] END leaf_size=50, n_neighbors=3, weights=uniform;, score=0.501 total time=   4.5s\n",
      "[CV 1/5; 46/88] START leaf_size=50, n_neighbors=3, weights=distance.............\n",
      "[CV 1/5; 46/88] END leaf_size=50, n_neighbors=3, weights=distance;, score=0.504 total time=   3.7s\n",
      "[CV 2/5; 46/88] START leaf_size=50, n_neighbors=3, weights=distance.............\n",
      "[CV 2/5; 46/88] END leaf_size=50, n_neighbors=3, weights=distance;, score=0.510 total time=   4.2s\n",
      "[CV 3/5; 46/88] START leaf_size=50, n_neighbors=3, weights=distance.............\n",
      "[CV 3/5; 46/88] END leaf_size=50, n_neighbors=3, weights=distance;, score=0.504 total time=   3.8s\n",
      "[CV 4/5; 46/88] START leaf_size=50, n_neighbors=3, weights=distance.............\n",
      "[CV 4/5; 46/88] END leaf_size=50, n_neighbors=3, weights=distance;, score=0.506 total time=   3.8s\n",
      "[CV 5/5; 46/88] START leaf_size=50, n_neighbors=3, weights=distance.............\n",
      "[CV 5/5; 46/88] END leaf_size=50, n_neighbors=3, weights=distance;, score=0.500 total time=   4.1s\n",
      "[CV 1/5; 47/88] START leaf_size=50, n_neighbors=5, weights=uniform..............\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 47/88] END leaf_size=50, n_neighbors=5, weights=uniform;, score=0.500 total time=   4.8s\n",
      "[CV 2/5; 47/88] START leaf_size=50, n_neighbors=5, weights=uniform..............\n",
      "[CV 2/5; 47/88] END leaf_size=50, n_neighbors=5, weights=uniform;, score=0.515 total time=   4.8s\n",
      "[CV 3/5; 47/88] START leaf_size=50, n_neighbors=5, weights=uniform..............\n",
      "[CV 3/5; 47/88] END leaf_size=50, n_neighbors=5, weights=uniform;, score=0.507 total time=   4.9s\n",
      "[CV 4/5; 47/88] START leaf_size=50, n_neighbors=5, weights=uniform..............\n",
      "[CV 4/5; 47/88] END leaf_size=50, n_neighbors=5, weights=uniform;, score=0.506 total time=   4.7s\n",
      "[CV 5/5; 47/88] START leaf_size=50, n_neighbors=5, weights=uniform..............\n",
      "[CV 5/5; 47/88] END leaf_size=50, n_neighbors=5, weights=uniform;, score=0.498 total time=   4.9s\n",
      "[CV 1/5; 48/88] START leaf_size=50, n_neighbors=5, weights=distance.............\n",
      "[CV 1/5; 48/88] END leaf_size=50, n_neighbors=5, weights=distance;, score=0.500 total time=   4.9s\n",
      "[CV 2/5; 48/88] START leaf_size=50, n_neighbors=5, weights=distance.............\n",
      "[CV 2/5; 48/88] END leaf_size=50, n_neighbors=5, weights=distance;, score=0.515 total time=   4.6s\n",
      "[CV 3/5; 48/88] START leaf_size=50, n_neighbors=5, weights=distance.............\n",
      "[CV 3/5; 48/88] END leaf_size=50, n_neighbors=5, weights=distance;, score=0.506 total time=   4.6s\n",
      "[CV 4/5; 48/88] START leaf_size=50, n_neighbors=5, weights=distance.............\n",
      "[CV 4/5; 48/88] END leaf_size=50, n_neighbors=5, weights=distance;, score=0.506 total time=   4.7s\n",
      "[CV 5/5; 48/88] START leaf_size=50, n_neighbors=5, weights=distance.............\n",
      "[CV 5/5; 48/88] END leaf_size=50, n_neighbors=5, weights=distance;, score=0.498 total time=   4.5s\n",
      "[CV 1/5; 49/88] START leaf_size=50, n_neighbors=7, weights=uniform..............\n",
      "[CV 1/5; 49/88] END leaf_size=50, n_neighbors=7, weights=uniform;, score=0.503 total time=   4.9s\n",
      "[CV 2/5; 49/88] START leaf_size=50, n_neighbors=7, weights=uniform..............\n",
      "[CV 2/5; 49/88] END leaf_size=50, n_neighbors=7, weights=uniform;, score=0.506 total time=   5.3s\n",
      "[CV 3/5; 49/88] START leaf_size=50, n_neighbors=7, weights=uniform..............\n",
      "[CV 3/5; 49/88] END leaf_size=50, n_neighbors=7, weights=uniform;, score=0.502 total time=   4.9s\n",
      "[CV 4/5; 49/88] START leaf_size=50, n_neighbors=7, weights=uniform..............\n",
      "[CV 4/5; 49/88] END leaf_size=50, n_neighbors=7, weights=uniform;, score=0.505 total time=   4.9s\n",
      "[CV 5/5; 49/88] START leaf_size=50, n_neighbors=7, weights=uniform..............\n",
      "[CV 5/5; 49/88] END leaf_size=50, n_neighbors=7, weights=uniform;, score=0.507 total time=   4.8s\n",
      "[CV 1/5; 50/88] START leaf_size=50, n_neighbors=7, weights=distance.............\n",
      "[CV 1/5; 50/88] END leaf_size=50, n_neighbors=7, weights=distance;, score=0.503 total time=   4.5s\n",
      "[CV 2/5; 50/88] START leaf_size=50, n_neighbors=7, weights=distance.............\n",
      "[CV 2/5; 50/88] END leaf_size=50, n_neighbors=7, weights=distance;, score=0.506 total time=   4.7s\n",
      "[CV 3/5; 50/88] START leaf_size=50, n_neighbors=7, weights=distance.............\n",
      "[CV 3/5; 50/88] END leaf_size=50, n_neighbors=7, weights=distance;, score=0.502 total time=   4.9s\n",
      "[CV 4/5; 50/88] START leaf_size=50, n_neighbors=7, weights=distance.............\n",
      "[CV 4/5; 50/88] END leaf_size=50, n_neighbors=7, weights=distance;, score=0.504 total time=   5.0s\n",
      "[CV 5/5; 50/88] START leaf_size=50, n_neighbors=7, weights=distance.............\n",
      "[CV 5/5; 50/88] END leaf_size=50, n_neighbors=7, weights=distance;, score=0.507 total time=   4.6s\n",
      "[CV 1/5; 51/88] START leaf_size=50, n_neighbors=9, weights=uniform..............\n",
      "[CV 1/5; 51/88] END leaf_size=50, n_neighbors=9, weights=uniform;, score=0.505 total time=   5.0s\n",
      "[CV 2/5; 51/88] START leaf_size=50, n_neighbors=9, weights=uniform..............\n",
      "[CV 2/5; 51/88] END leaf_size=50, n_neighbors=9, weights=uniform;, score=0.507 total time=   5.3s\n",
      "[CV 3/5; 51/88] START leaf_size=50, n_neighbors=9, weights=uniform..............\n",
      "[CV 3/5; 51/88] END leaf_size=50, n_neighbors=9, weights=uniform;, score=0.504 total time=   5.3s\n",
      "[CV 4/5; 51/88] START leaf_size=50, n_neighbors=9, weights=uniform..............\n",
      "[CV 4/5; 51/88] END leaf_size=50, n_neighbors=9, weights=uniform;, score=0.500 total time=   6.6s\n",
      "[CV 5/5; 51/88] START leaf_size=50, n_neighbors=9, weights=uniform..............\n",
      "[CV 5/5; 51/88] END leaf_size=50, n_neighbors=9, weights=uniform;, score=0.507 total time=   6.7s\n",
      "[CV 1/5; 52/88] START leaf_size=50, n_neighbors=9, weights=distance.............\n",
      "[CV 1/5; 52/88] END leaf_size=50, n_neighbors=9, weights=distance;, score=0.505 total time=   6.2s\n",
      "[CV 2/5; 52/88] START leaf_size=50, n_neighbors=9, weights=distance.............\n",
      "[CV 2/5; 52/88] END leaf_size=50, n_neighbors=9, weights=distance;, score=0.508 total time=   6.5s\n",
      "[CV 3/5; 52/88] START leaf_size=50, n_neighbors=9, weights=distance.............\n",
      "[CV 3/5; 52/88] END leaf_size=50, n_neighbors=9, weights=distance;, score=0.504 total time=   6.5s\n",
      "[CV 4/5; 52/88] START leaf_size=50, n_neighbors=9, weights=distance.............\n",
      "[CV 4/5; 52/88] END leaf_size=50, n_neighbors=9, weights=distance;, score=0.500 total time=   6.2s\n",
      "[CV 5/5; 52/88] START leaf_size=50, n_neighbors=9, weights=distance.............\n",
      "[CV 5/5; 52/88] END leaf_size=50, n_neighbors=9, weights=distance;, score=0.507 total time=   6.3s\n",
      "[CV 1/5; 53/88] START leaf_size=50, n_neighbors=15, weights=uniform.............\n",
      "[CV 1/5; 53/88] END leaf_size=50, n_neighbors=15, weights=uniform;, score=0.503 total time=   6.2s\n",
      "[CV 2/5; 53/88] START leaf_size=50, n_neighbors=15, weights=uniform.............\n",
      "[CV 2/5; 53/88] END leaf_size=50, n_neighbors=15, weights=uniform;, score=0.503 total time=   6.8s\n",
      "[CV 3/5; 53/88] START leaf_size=50, n_neighbors=15, weights=uniform.............\n",
      "[CV 3/5; 53/88] END leaf_size=50, n_neighbors=15, weights=uniform;, score=0.500 total time=   7.4s\n",
      "[CV 4/5; 53/88] START leaf_size=50, n_neighbors=15, weights=uniform.............\n",
      "[CV 4/5; 53/88] END leaf_size=50, n_neighbors=15, weights=uniform;, score=0.500 total time=   6.8s\n",
      "[CV 5/5; 53/88] START leaf_size=50, n_neighbors=15, weights=uniform.............\n",
      "[CV 5/5; 53/88] END leaf_size=50, n_neighbors=15, weights=uniform;, score=0.503 total time=   6.5s\n",
      "[CV 1/5; 54/88] START leaf_size=50, n_neighbors=15, weights=distance............\n",
      "[CV 1/5; 54/88] END leaf_size=50, n_neighbors=15, weights=distance;, score=0.503 total time=   6.5s\n",
      "[CV 2/5; 54/88] START leaf_size=50, n_neighbors=15, weights=distance............\n",
      "[CV 2/5; 54/88] END leaf_size=50, n_neighbors=15, weights=distance;, score=0.503 total time=   6.9s\n",
      "[CV 3/5; 54/88] START leaf_size=50, n_neighbors=15, weights=distance............\n",
      "[CV 3/5; 54/88] END leaf_size=50, n_neighbors=15, weights=distance;, score=0.500 total time=   6.8s\n",
      "[CV 4/5; 54/88] START leaf_size=50, n_neighbors=15, weights=distance............\n",
      "[CV 4/5; 54/88] END leaf_size=50, n_neighbors=15, weights=distance;, score=0.501 total time=   6.5s\n",
      "[CV 5/5; 54/88] START leaf_size=50, n_neighbors=15, weights=distance............\n",
      "[CV 5/5; 54/88] END leaf_size=50, n_neighbors=15, weights=distance;, score=0.503 total time=   7.0s\n",
      "[CV 1/5; 55/88] START leaf_size=50, n_neighbors=19, weights=uniform.............\n",
      "[CV 1/5; 55/88] END leaf_size=50, n_neighbors=19, weights=uniform;, score=0.501 total time=   7.5s\n",
      "[CV 2/5; 55/88] START leaf_size=50, n_neighbors=19, weights=uniform.............\n",
      "[CV 2/5; 55/88] END leaf_size=50, n_neighbors=19, weights=uniform;, score=0.501 total time=   6.9s\n",
      "[CV 3/5; 55/88] START leaf_size=50, n_neighbors=19, weights=uniform.............\n",
      "[CV 3/5; 55/88] END leaf_size=50, n_neighbors=19, weights=uniform;, score=0.501 total time=   7.3s\n",
      "[CV 4/5; 55/88] START leaf_size=50, n_neighbors=19, weights=uniform.............\n",
      "[CV 4/5; 55/88] END leaf_size=50, n_neighbors=19, weights=uniform;, score=0.500 total time=   7.0s\n",
      "[CV 5/5; 55/88] START leaf_size=50, n_neighbors=19, weights=uniform.............\n",
      "[CV 5/5; 55/88] END leaf_size=50, n_neighbors=19, weights=uniform;, score=0.502 total time=   7.4s\n",
      "[CV 1/5; 56/88] START leaf_size=50, n_neighbors=19, weights=distance............\n",
      "[CV 1/5; 56/88] END leaf_size=50, n_neighbors=19, weights=distance;, score=0.501 total time=   7.0s\n",
      "[CV 2/5; 56/88] START leaf_size=50, n_neighbors=19, weights=distance............\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 56/88] END leaf_size=50, n_neighbors=19, weights=distance;, score=0.502 total time=   7.0s\n",
      "[CV 3/5; 56/88] START leaf_size=50, n_neighbors=19, weights=distance............\n",
      "[CV 3/5; 56/88] END leaf_size=50, n_neighbors=19, weights=distance;, score=0.501 total time=   6.1s\n",
      "[CV 4/5; 56/88] START leaf_size=50, n_neighbors=19, weights=distance............\n",
      "[CV 4/5; 56/88] END leaf_size=50, n_neighbors=19, weights=distance;, score=0.500 total time=   5.7s\n",
      "[CV 5/5; 56/88] START leaf_size=50, n_neighbors=19, weights=distance............\n",
      "[CV 5/5; 56/88] END leaf_size=50, n_neighbors=19, weights=distance;, score=0.502 total time=   6.1s\n",
      "[CV 1/5; 57/88] START leaf_size=50, n_neighbors=25, weights=uniform.............\n",
      "[CV 1/5; 57/88] END leaf_size=50, n_neighbors=25, weights=uniform;, score=0.499 total time=   5.8s\n",
      "[CV 2/5; 57/88] START leaf_size=50, n_neighbors=25, weights=uniform.............\n",
      "[CV 2/5; 57/88] END leaf_size=50, n_neighbors=25, weights=uniform;, score=0.501 total time=   7.3s\n",
      "[CV 3/5; 57/88] START leaf_size=50, n_neighbors=25, weights=uniform.............\n",
      "[CV 3/5; 57/88] END leaf_size=50, n_neighbors=25, weights=uniform;, score=0.499 total time=   7.2s\n",
      "[CV 4/5; 57/88] START leaf_size=50, n_neighbors=25, weights=uniform.............\n",
      "[CV 4/5; 57/88] END leaf_size=50, n_neighbors=25, weights=uniform;, score=0.502 total time=   7.3s\n",
      "[CV 5/5; 57/88] START leaf_size=50, n_neighbors=25, weights=uniform.............\n",
      "[CV 5/5; 57/88] END leaf_size=50, n_neighbors=25, weights=uniform;, score=0.501 total time=   7.5s\n",
      "[CV 1/5; 58/88] START leaf_size=50, n_neighbors=25, weights=distance............\n",
      "[CV 1/5; 58/88] END leaf_size=50, n_neighbors=25, weights=distance;, score=0.499 total time=   7.3s\n",
      "[CV 2/5; 58/88] START leaf_size=50, n_neighbors=25, weights=distance............\n",
      "[CV 2/5; 58/88] END leaf_size=50, n_neighbors=25, weights=distance;, score=0.501 total time=   6.2s\n",
      "[CV 3/5; 58/88] START leaf_size=50, n_neighbors=25, weights=distance............\n",
      "[CV 3/5; 58/88] END leaf_size=50, n_neighbors=25, weights=distance;, score=0.499 total time=   6.3s\n",
      "[CV 4/5; 58/88] START leaf_size=50, n_neighbors=25, weights=distance............\n",
      "[CV 4/5; 58/88] END leaf_size=50, n_neighbors=25, weights=distance;, score=0.501 total time=   6.5s\n",
      "[CV 5/5; 58/88] START leaf_size=50, n_neighbors=25, weights=distance............\n",
      "[CV 5/5; 58/88] END leaf_size=50, n_neighbors=25, weights=distance;, score=0.501 total time=   5.9s\n",
      "[CV 1/5; 59/88] START leaf_size=50, n_neighbors=35, weights=uniform.............\n",
      "[CV 1/5; 59/88] END leaf_size=50, n_neighbors=35, weights=uniform;, score=0.500 total time=   6.7s\n",
      "[CV 2/5; 59/88] START leaf_size=50, n_neighbors=35, weights=uniform.............\n",
      "[CV 2/5; 59/88] END leaf_size=50, n_neighbors=35, weights=uniform;, score=0.500 total time=   7.0s\n",
      "[CV 3/5; 59/88] START leaf_size=50, n_neighbors=35, weights=uniform.............\n",
      "[CV 3/5; 59/88] END leaf_size=50, n_neighbors=35, weights=uniform;, score=0.500 total time=   6.4s\n",
      "[CV 4/5; 59/88] START leaf_size=50, n_neighbors=35, weights=uniform.............\n",
      "[CV 4/5; 59/88] END leaf_size=50, n_neighbors=35, weights=uniform;, score=0.500 total time=   6.9s\n",
      "[CV 5/5; 59/88] START leaf_size=50, n_neighbors=35, weights=uniform.............\n",
      "[CV 5/5; 59/88] END leaf_size=50, n_neighbors=35, weights=uniform;, score=0.501 total time=   6.9s\n",
      "[CV 1/5; 60/88] START leaf_size=50, n_neighbors=35, weights=distance............\n",
      "[CV 1/5; 60/88] END leaf_size=50, n_neighbors=35, weights=distance;, score=0.500 total time=   7.2s\n",
      "[CV 2/5; 60/88] START leaf_size=50, n_neighbors=35, weights=distance............\n",
      "[CV 2/5; 60/88] END leaf_size=50, n_neighbors=35, weights=distance;, score=0.500 total time=   6.9s\n",
      "[CV 3/5; 60/88] START leaf_size=50, n_neighbors=35, weights=distance............\n",
      "[CV 3/5; 60/88] END leaf_size=50, n_neighbors=35, weights=distance;, score=0.500 total time=   6.3s\n",
      "[CV 4/5; 60/88] START leaf_size=50, n_neighbors=35, weights=distance............\n",
      "[CV 4/5; 60/88] END leaf_size=50, n_neighbors=35, weights=distance;, score=0.500 total time=   4.9s\n",
      "[CV 5/5; 60/88] START leaf_size=50, n_neighbors=35, weights=distance............\n",
      "[CV 5/5; 60/88] END leaf_size=50, n_neighbors=35, weights=distance;, score=0.501 total time=   4.9s\n",
      "[CV 1/5; 61/88] START leaf_size=50, n_neighbors=55, weights=uniform.............\n",
      "[CV 1/5; 61/88] END leaf_size=50, n_neighbors=55, weights=uniform;, score=0.500 total time=   4.8s\n",
      "[CV 2/5; 61/88] START leaf_size=50, n_neighbors=55, weights=uniform.............\n",
      "[CV 2/5; 61/88] END leaf_size=50, n_neighbors=55, weights=uniform;, score=0.500 total time=   5.0s\n",
      "[CV 3/5; 61/88] START leaf_size=50, n_neighbors=55, weights=uniform.............\n",
      "[CV 3/5; 61/88] END leaf_size=50, n_neighbors=55, weights=uniform;, score=0.501 total time=   4.9s\n",
      "[CV 4/5; 61/88] START leaf_size=50, n_neighbors=55, weights=uniform.............\n",
      "[CV 4/5; 61/88] END leaf_size=50, n_neighbors=55, weights=uniform;, score=0.500 total time=   5.0s\n",
      "[CV 5/5; 61/88] START leaf_size=50, n_neighbors=55, weights=uniform.............\n",
      "[CV 5/5; 61/88] END leaf_size=50, n_neighbors=55, weights=uniform;, score=0.500 total time=   4.8s\n",
      "[CV 1/5; 62/88] START leaf_size=50, n_neighbors=55, weights=distance............\n",
      "[CV 1/5; 62/88] END leaf_size=50, n_neighbors=55, weights=distance;, score=0.500 total time=   4.7s\n",
      "[CV 2/5; 62/88] START leaf_size=50, n_neighbors=55, weights=distance............\n",
      "[CV 2/5; 62/88] END leaf_size=50, n_neighbors=55, weights=distance;, score=0.500 total time=   4.8s\n",
      "[CV 3/5; 62/88] START leaf_size=50, n_neighbors=55, weights=distance............\n",
      "[CV 3/5; 62/88] END leaf_size=50, n_neighbors=55, weights=distance;, score=0.500 total time=   4.6s\n",
      "[CV 4/5; 62/88] START leaf_size=50, n_neighbors=55, weights=distance............\n",
      "[CV 4/5; 62/88] END leaf_size=50, n_neighbors=55, weights=distance;, score=0.500 total time=   5.3s\n",
      "[CV 5/5; 62/88] START leaf_size=50, n_neighbors=55, weights=distance............\n",
      "[CV 5/5; 62/88] END leaf_size=50, n_neighbors=55, weights=distance;, score=0.500 total time=   6.1s\n",
      "[CV 1/5; 63/88] START leaf_size=50, n_neighbors=75, weights=uniform.............\n",
      "[CV 1/5; 63/88] END leaf_size=50, n_neighbors=75, weights=uniform;, score=0.500 total time=   6.8s\n",
      "[CV 2/5; 63/88] START leaf_size=50, n_neighbors=75, weights=uniform.............\n",
      "[CV 2/5; 63/88] END leaf_size=50, n_neighbors=75, weights=uniform;, score=0.500 total time=   6.4s\n",
      "[CV 3/5; 63/88] START leaf_size=50, n_neighbors=75, weights=uniform.............\n",
      "[CV 3/5; 63/88] END leaf_size=50, n_neighbors=75, weights=uniform;, score=0.500 total time=   6.6s\n",
      "[CV 4/5; 63/88] START leaf_size=50, n_neighbors=75, weights=uniform.............\n",
      "[CV 4/5; 63/88] END leaf_size=50, n_neighbors=75, weights=uniform;, score=0.500 total time=   7.2s\n",
      "[CV 5/5; 63/88] START leaf_size=50, n_neighbors=75, weights=uniform.............\n",
      "[CV 5/5; 63/88] END leaf_size=50, n_neighbors=75, weights=uniform;, score=0.500 total time=   6.9s\n",
      "[CV 1/5; 64/88] START leaf_size=50, n_neighbors=75, weights=distance............\n",
      "[CV 1/5; 64/88] END leaf_size=50, n_neighbors=75, weights=distance;, score=0.500 total time=   6.5s\n",
      "[CV 2/5; 64/88] START leaf_size=50, n_neighbors=75, weights=distance............\n",
      "[CV 2/5; 64/88] END leaf_size=50, n_neighbors=75, weights=distance;, score=0.500 total time=   6.7s\n",
      "[CV 3/5; 64/88] START leaf_size=50, n_neighbors=75, weights=distance............\n",
      "[CV 3/5; 64/88] END leaf_size=50, n_neighbors=75, weights=distance;, score=0.500 total time=   6.9s\n",
      "[CV 4/5; 64/88] START leaf_size=50, n_neighbors=75, weights=distance............\n",
      "[CV 4/5; 64/88] END leaf_size=50, n_neighbors=75, weights=distance;, score=0.500 total time=   7.1s\n",
      "[CV 5/5; 64/88] START leaf_size=50, n_neighbors=75, weights=distance............\n",
      "[CV 5/5; 64/88] END leaf_size=50, n_neighbors=75, weights=distance;, score=0.500 total time=   6.3s\n",
      "[CV 1/5; 65/88] START leaf_size=50, n_neighbors=99, weights=uniform.............\n",
      "[CV 1/5; 65/88] END leaf_size=50, n_neighbors=99, weights=uniform;, score=0.500 total time=   6.8s\n",
      "[CV 2/5; 65/88] START leaf_size=50, n_neighbors=99, weights=uniform.............\n",
      "[CV 2/5; 65/88] END leaf_size=50, n_neighbors=99, weights=uniform;, score=0.500 total time=   6.4s\n",
      "[CV 3/5; 65/88] START leaf_size=50, n_neighbors=99, weights=uniform.............\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 65/88] END leaf_size=50, n_neighbors=99, weights=uniform;, score=0.500 total time=   6.6s\n",
      "[CV 4/5; 65/88] START leaf_size=50, n_neighbors=99, weights=uniform.............\n",
      "[CV 4/5; 65/88] END leaf_size=50, n_neighbors=99, weights=uniform;, score=0.500 total time=   6.7s\n",
      "[CV 5/5; 65/88] START leaf_size=50, n_neighbors=99, weights=uniform.............\n",
      "[CV 5/5; 65/88] END leaf_size=50, n_neighbors=99, weights=uniform;, score=0.500 total time=   7.1s\n",
      "[CV 1/5; 66/88] START leaf_size=50, n_neighbors=99, weights=distance............\n",
      "[CV 1/5; 66/88] END leaf_size=50, n_neighbors=99, weights=distance;, score=0.500 total time=   7.3s\n",
      "[CV 2/5; 66/88] START leaf_size=50, n_neighbors=99, weights=distance............\n",
      "[CV 2/5; 66/88] END leaf_size=50, n_neighbors=99, weights=distance;, score=0.500 total time=   6.2s\n",
      "[CV 3/5; 66/88] START leaf_size=50, n_neighbors=99, weights=distance............\n",
      "[CV 3/5; 66/88] END leaf_size=50, n_neighbors=99, weights=distance;, score=0.500 total time=   6.7s\n",
      "[CV 4/5; 66/88] START leaf_size=50, n_neighbors=99, weights=distance............\n",
      "[CV 4/5; 66/88] END leaf_size=50, n_neighbors=99, weights=distance;, score=0.500 total time=   7.0s\n",
      "[CV 5/5; 66/88] START leaf_size=50, n_neighbors=99, weights=distance............\n",
      "[CV 5/5; 66/88] END leaf_size=50, n_neighbors=99, weights=distance;, score=0.500 total time=   8.0s\n",
      "[CV 1/5; 67/88] START leaf_size=70, n_neighbors=3, weights=uniform..............\n",
      "[CV 1/5; 67/88] END leaf_size=70, n_neighbors=3, weights=uniform;, score=0.504 total time=   5.9s\n",
      "[CV 2/5; 67/88] START leaf_size=70, n_neighbors=3, weights=uniform..............\n",
      "[CV 2/5; 67/88] END leaf_size=70, n_neighbors=3, weights=uniform;, score=0.510 total time=   4.7s\n",
      "[CV 3/5; 67/88] START leaf_size=70, n_neighbors=3, weights=uniform..............\n",
      "[CV 3/5; 67/88] END leaf_size=70, n_neighbors=3, weights=uniform;, score=0.504 total time=   5.2s\n",
      "[CV 4/5; 67/88] START leaf_size=70, n_neighbors=3, weights=uniform..............\n",
      "[CV 4/5; 67/88] END leaf_size=70, n_neighbors=3, weights=uniform;, score=0.506 total time=   4.8s\n",
      "[CV 5/5; 67/88] START leaf_size=70, n_neighbors=3, weights=uniform..............\n",
      "[CV 5/5; 67/88] END leaf_size=70, n_neighbors=3, weights=uniform;, score=0.501 total time=   4.8s\n",
      "[CV 1/5; 68/88] START leaf_size=70, n_neighbors=3, weights=distance.............\n",
      "[CV 1/5; 68/88] END leaf_size=70, n_neighbors=3, weights=distance;, score=0.504 total time=   5.7s\n",
      "[CV 2/5; 68/88] START leaf_size=70, n_neighbors=3, weights=distance.............\n",
      "[CV 2/5; 68/88] END leaf_size=70, n_neighbors=3, weights=distance;, score=0.510 total time=   5.6s\n",
      "[CV 3/5; 68/88] START leaf_size=70, n_neighbors=3, weights=distance.............\n",
      "[CV 3/5; 68/88] END leaf_size=70, n_neighbors=3, weights=distance;, score=0.504 total time=   5.4s\n",
      "[CV 4/5; 68/88] START leaf_size=70, n_neighbors=3, weights=distance.............\n",
      "[CV 4/5; 68/88] END leaf_size=70, n_neighbors=3, weights=distance;, score=0.506 total time=   5.8s\n",
      "[CV 5/5; 68/88] START leaf_size=70, n_neighbors=3, weights=distance.............\n",
      "[CV 5/5; 68/88] END leaf_size=70, n_neighbors=3, weights=distance;, score=0.500 total time=   5.5s\n",
      "[CV 1/5; 69/88] START leaf_size=70, n_neighbors=5, weights=uniform..............\n",
      "[CV 1/5; 69/88] END leaf_size=70, n_neighbors=5, weights=uniform;, score=0.500 total time=   7.7s\n",
      "[CV 2/5; 69/88] START leaf_size=70, n_neighbors=5, weights=uniform..............\n",
      "[CV 2/5; 69/88] END leaf_size=70, n_neighbors=5, weights=uniform;, score=0.515 total time=   7.6s\n",
      "[CV 3/5; 69/88] START leaf_size=70, n_neighbors=5, weights=uniform..............\n",
      "[CV 3/5; 69/88] END leaf_size=70, n_neighbors=5, weights=uniform;, score=0.507 total time=   5.8s\n",
      "[CV 4/5; 69/88] START leaf_size=70, n_neighbors=5, weights=uniform..............\n",
      "[CV 4/5; 69/88] END leaf_size=70, n_neighbors=5, weights=uniform;, score=0.506 total time=   7.3s\n",
      "[CV 5/5; 69/88] START leaf_size=70, n_neighbors=5, weights=uniform..............\n",
      "[CV 5/5; 69/88] END leaf_size=70, n_neighbors=5, weights=uniform;, score=0.498 total time=   7.6s\n",
      "[CV 1/5; 70/88] START leaf_size=70, n_neighbors=5, weights=distance.............\n",
      "[CV 1/5; 70/88] END leaf_size=70, n_neighbors=5, weights=distance;, score=0.500 total time=   7.5s\n",
      "[CV 2/5; 70/88] START leaf_size=70, n_neighbors=5, weights=distance.............\n",
      "[CV 2/5; 70/88] END leaf_size=70, n_neighbors=5, weights=distance;, score=0.515 total time=   7.3s\n",
      "[CV 3/5; 70/88] START leaf_size=70, n_neighbors=5, weights=distance.............\n",
      "[CV 3/5; 70/88] END leaf_size=70, n_neighbors=5, weights=distance;, score=0.506 total time=   7.1s\n",
      "[CV 4/5; 70/88] START leaf_size=70, n_neighbors=5, weights=distance.............\n",
      "[CV 4/5; 70/88] END leaf_size=70, n_neighbors=5, weights=distance;, score=0.506 total time=   7.1s\n",
      "[CV 5/5; 70/88] START leaf_size=70, n_neighbors=5, weights=distance.............\n",
      "[CV 5/5; 70/88] END leaf_size=70, n_neighbors=5, weights=distance;, score=0.498 total time=   6.6s\n",
      "[CV 1/5; 71/88] START leaf_size=70, n_neighbors=7, weights=uniform..............\n",
      "[CV 1/5; 71/88] END leaf_size=70, n_neighbors=7, weights=uniform;, score=0.503 total time=   7.4s\n",
      "[CV 2/5; 71/88] START leaf_size=70, n_neighbors=7, weights=uniform..............\n",
      "[CV 2/5; 71/88] END leaf_size=70, n_neighbors=7, weights=uniform;, score=0.506 total time=   7.1s\n",
      "[CV 3/5; 71/88] START leaf_size=70, n_neighbors=7, weights=uniform..............\n",
      "[CV 3/5; 71/88] END leaf_size=70, n_neighbors=7, weights=uniform;, score=0.502 total time=   6.7s\n",
      "[CV 4/5; 71/88] START leaf_size=70, n_neighbors=7, weights=uniform..............\n",
      "[CV 4/5; 71/88] END leaf_size=70, n_neighbors=7, weights=uniform;, score=0.505 total time=   7.4s\n",
      "[CV 5/5; 71/88] START leaf_size=70, n_neighbors=7, weights=uniform..............\n",
      "[CV 5/5; 71/88] END leaf_size=70, n_neighbors=7, weights=uniform;, score=0.507 total time=   7.0s\n",
      "[CV 1/5; 72/88] START leaf_size=70, n_neighbors=7, weights=distance.............\n",
      "[CV 1/5; 72/88] END leaf_size=70, n_neighbors=7, weights=distance;, score=0.503 total time=   7.5s\n",
      "[CV 2/5; 72/88] START leaf_size=70, n_neighbors=7, weights=distance.............\n",
      "[CV 2/5; 72/88] END leaf_size=70, n_neighbors=7, weights=distance;, score=0.506 total time=   6.6s\n",
      "[CV 3/5; 72/88] START leaf_size=70, n_neighbors=7, weights=distance.............\n",
      "[CV 3/5; 72/88] END leaf_size=70, n_neighbors=7, weights=distance;, score=0.502 total time=   7.1s\n",
      "[CV 4/5; 72/88] START leaf_size=70, n_neighbors=7, weights=distance.............\n",
      "[CV 4/5; 72/88] END leaf_size=70, n_neighbors=7, weights=distance;, score=0.504 total time=   6.9s\n",
      "[CV 5/5; 72/88] START leaf_size=70, n_neighbors=7, weights=distance.............\n",
      "[CV 5/5; 72/88] END leaf_size=70, n_neighbors=7, weights=distance;, score=0.507 total time=   6.8s\n",
      "[CV 1/5; 73/88] START leaf_size=70, n_neighbors=9, weights=uniform..............\n",
      "[CV 1/5; 73/88] END leaf_size=70, n_neighbors=9, weights=uniform;, score=0.505 total time=   7.4s\n",
      "[CV 2/5; 73/88] START leaf_size=70, n_neighbors=9, weights=uniform..............\n",
      "[CV 2/5; 73/88] END leaf_size=70, n_neighbors=9, weights=uniform;, score=0.507 total time=   7.8s\n",
      "[CV 3/5; 73/88] START leaf_size=70, n_neighbors=9, weights=uniform..............\n",
      "[CV 3/5; 73/88] END leaf_size=70, n_neighbors=9, weights=uniform;, score=0.504 total time=   7.6s\n",
      "[CV 4/5; 73/88] START leaf_size=70, n_neighbors=9, weights=uniform..............\n",
      "[CV 4/5; 73/88] END leaf_size=70, n_neighbors=9, weights=uniform;, score=0.500 total time=   7.7s\n",
      "[CV 5/5; 73/88] START leaf_size=70, n_neighbors=9, weights=uniform..............\n",
      "[CV 5/5; 73/88] END leaf_size=70, n_neighbors=9, weights=uniform;, score=0.507 total time=   7.3s\n",
      "[CV 1/5; 74/88] START leaf_size=70, n_neighbors=9, weights=distance.............\n",
      "[CV 1/5; 74/88] END leaf_size=70, n_neighbors=9, weights=distance;, score=0.505 total time=   6.3s\n",
      "[CV 2/5; 74/88] START leaf_size=70, n_neighbors=9, weights=distance.............\n",
      "[CV 2/5; 74/88] END leaf_size=70, n_neighbors=9, weights=distance;, score=0.508 total time=   6.5s\n",
      "[CV 3/5; 74/88] START leaf_size=70, n_neighbors=9, weights=distance.............\n",
      "[CV 3/5; 74/88] END leaf_size=70, n_neighbors=9, weights=distance;, score=0.504 total time=   6.5s\n",
      "[CV 4/5; 74/88] START leaf_size=70, n_neighbors=9, weights=distance.............\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 74/88] END leaf_size=70, n_neighbors=9, weights=distance;, score=0.500 total time=   6.5s\n",
      "[CV 5/5; 74/88] START leaf_size=70, n_neighbors=9, weights=distance.............\n",
      "[CV 5/5; 74/88] END leaf_size=70, n_neighbors=9, weights=distance;, score=0.507 total time=   6.3s\n",
      "[CV 1/5; 75/88] START leaf_size=70, n_neighbors=15, weights=uniform.............\n",
      "[CV 1/5; 75/88] END leaf_size=70, n_neighbors=15, weights=uniform;, score=0.503 total time=   7.0s\n",
      "[CV 2/5; 75/88] START leaf_size=70, n_neighbors=15, weights=uniform.............\n",
      "[CV 2/5; 75/88] END leaf_size=70, n_neighbors=15, weights=uniform;, score=0.503 total time=   7.3s\n",
      "[CV 3/5; 75/88] START leaf_size=70, n_neighbors=15, weights=uniform.............\n",
      "[CV 3/5; 75/88] END leaf_size=70, n_neighbors=15, weights=uniform;, score=0.500 total time=   7.3s\n",
      "[CV 4/5; 75/88] START leaf_size=70, n_neighbors=15, weights=uniform.............\n",
      "[CV 4/5; 75/88] END leaf_size=70, n_neighbors=15, weights=uniform;, score=0.500 total time=   7.6s\n",
      "[CV 5/5; 75/88] START leaf_size=70, n_neighbors=15, weights=uniform.............\n",
      "[CV 5/5; 75/88] END leaf_size=70, n_neighbors=15, weights=uniform;, score=0.503 total time=   7.5s\n",
      "[CV 1/5; 76/88] START leaf_size=70, n_neighbors=15, weights=distance............\n",
      "[CV 1/5; 76/88] END leaf_size=70, n_neighbors=15, weights=distance;, score=0.503 total time=   7.2s\n",
      "[CV 2/5; 76/88] START leaf_size=70, n_neighbors=15, weights=distance............\n",
      "[CV 2/5; 76/88] END leaf_size=70, n_neighbors=15, weights=distance;, score=0.503 total time=   7.5s\n",
      "[CV 3/5; 76/88] START leaf_size=70, n_neighbors=15, weights=distance............\n",
      "[CV 3/5; 76/88] END leaf_size=70, n_neighbors=15, weights=distance;, score=0.500 total time=   7.3s\n",
      "[CV 4/5; 76/88] START leaf_size=70, n_neighbors=15, weights=distance............\n",
      "[CV 4/5; 76/88] END leaf_size=70, n_neighbors=15, weights=distance;, score=0.501 total time=   7.3s\n",
      "[CV 5/5; 76/88] START leaf_size=70, n_neighbors=15, weights=distance............\n",
      "[CV 5/5; 76/88] END leaf_size=70, n_neighbors=15, weights=distance;, score=0.503 total time=   7.2s\n",
      "[CV 1/5; 77/88] START leaf_size=70, n_neighbors=19, weights=uniform.............\n",
      "[CV 1/5; 77/88] END leaf_size=70, n_neighbors=19, weights=uniform;, score=0.501 total time=   7.9s\n",
      "[CV 2/5; 77/88] START leaf_size=70, n_neighbors=19, weights=uniform.............\n",
      "[CV 2/5; 77/88] END leaf_size=70, n_neighbors=19, weights=uniform;, score=0.501 total time=   7.3s\n",
      "[CV 3/5; 77/88] START leaf_size=70, n_neighbors=19, weights=uniform.............\n",
      "[CV 3/5; 77/88] END leaf_size=70, n_neighbors=19, weights=uniform;, score=0.501 total time=   7.1s\n",
      "[CV 4/5; 77/88] START leaf_size=70, n_neighbors=19, weights=uniform.............\n",
      "[CV 4/5; 77/88] END leaf_size=70, n_neighbors=19, weights=uniform;, score=0.500 total time=   6.9s\n",
      "[CV 5/5; 77/88] START leaf_size=70, n_neighbors=19, weights=uniform.............\n",
      "[CV 5/5; 77/88] END leaf_size=70, n_neighbors=19, weights=uniform;, score=0.502 total time=   6.8s\n",
      "[CV 1/5; 78/88] START leaf_size=70, n_neighbors=19, weights=distance............\n",
      "[CV 1/5; 78/88] END leaf_size=70, n_neighbors=19, weights=distance;, score=0.501 total time=   7.1s\n",
      "[CV 2/5; 78/88] START leaf_size=70, n_neighbors=19, weights=distance............\n",
      "[CV 2/5; 78/88] END leaf_size=70, n_neighbors=19, weights=distance;, score=0.502 total time=   6.9s\n",
      "[CV 3/5; 78/88] START leaf_size=70, n_neighbors=19, weights=distance............\n",
      "[CV 3/5; 78/88] END leaf_size=70, n_neighbors=19, weights=distance;, score=0.501 total time=   6.7s\n",
      "[CV 4/5; 78/88] START leaf_size=70, n_neighbors=19, weights=distance............\n",
      "[CV 4/5; 78/88] END leaf_size=70, n_neighbors=19, weights=distance;, score=0.500 total time=   7.4s\n",
      "[CV 5/5; 78/88] START leaf_size=70, n_neighbors=19, weights=distance............\n",
      "[CV 5/5; 78/88] END leaf_size=70, n_neighbors=19, weights=distance;, score=0.502 total time=   7.0s\n",
      "[CV 1/5; 79/88] START leaf_size=70, n_neighbors=25, weights=uniform.............\n",
      "[CV 1/5; 79/88] END leaf_size=70, n_neighbors=25, weights=uniform;, score=0.499 total time=   7.6s\n",
      "[CV 2/5; 79/88] START leaf_size=70, n_neighbors=25, weights=uniform.............\n",
      "[CV 2/5; 79/88] END leaf_size=70, n_neighbors=25, weights=uniform;, score=0.501 total time=   7.2s\n",
      "[CV 3/5; 79/88] START leaf_size=70, n_neighbors=25, weights=uniform.............\n",
      "[CV 3/5; 79/88] END leaf_size=70, n_neighbors=25, weights=uniform;, score=0.499 total time=   7.3s\n",
      "[CV 4/5; 79/88] START leaf_size=70, n_neighbors=25, weights=uniform.............\n",
      "[CV 4/5; 79/88] END leaf_size=70, n_neighbors=25, weights=uniform;, score=0.502 total time=   7.5s\n",
      "[CV 5/5; 79/88] START leaf_size=70, n_neighbors=25, weights=uniform.............\n",
      "[CV 5/5; 79/88] END leaf_size=70, n_neighbors=25, weights=uniform;, score=0.501 total time=   7.2s\n",
      "[CV 1/5; 80/88] START leaf_size=70, n_neighbors=25, weights=distance............\n",
      "[CV 1/5; 80/88] END leaf_size=70, n_neighbors=25, weights=distance;, score=0.499 total time=   7.0s\n",
      "[CV 2/5; 80/88] START leaf_size=70, n_neighbors=25, weights=distance............\n",
      "[CV 2/5; 80/88] END leaf_size=70, n_neighbors=25, weights=distance;, score=0.501 total time=   7.2s\n",
      "[CV 3/5; 80/88] START leaf_size=70, n_neighbors=25, weights=distance............\n",
      "[CV 3/5; 80/88] END leaf_size=70, n_neighbors=25, weights=distance;, score=0.499 total time=   6.7s\n",
      "[CV 4/5; 80/88] START leaf_size=70, n_neighbors=25, weights=distance............\n",
      "[CV 4/5; 80/88] END leaf_size=70, n_neighbors=25, weights=distance;, score=0.501 total time=   7.0s\n",
      "[CV 5/5; 80/88] START leaf_size=70, n_neighbors=25, weights=distance............\n",
      "[CV 5/5; 80/88] END leaf_size=70, n_neighbors=25, weights=distance;, score=0.501 total time=   6.5s\n",
      "[CV 1/5; 81/88] START leaf_size=70, n_neighbors=35, weights=uniform.............\n",
      "[CV 1/5; 81/88] END leaf_size=70, n_neighbors=35, weights=uniform;, score=0.500 total time=   7.3s\n",
      "[CV 2/5; 81/88] START leaf_size=70, n_neighbors=35, weights=uniform.............\n",
      "[CV 2/5; 81/88] END leaf_size=70, n_neighbors=35, weights=uniform;, score=0.500 total time=   7.4s\n",
      "[CV 3/5; 81/88] START leaf_size=70, n_neighbors=35, weights=uniform.............\n",
      "[CV 3/5; 81/88] END leaf_size=70, n_neighbors=35, weights=uniform;, score=0.500 total time=   7.4s\n",
      "[CV 4/5; 81/88] START leaf_size=70, n_neighbors=35, weights=uniform.............\n",
      "[CV 4/5; 81/88] END leaf_size=70, n_neighbors=35, weights=uniform;, score=0.500 total time=   7.1s\n",
      "[CV 5/5; 81/88] START leaf_size=70, n_neighbors=35, weights=uniform.............\n",
      "[CV 5/5; 81/88] END leaf_size=70, n_neighbors=35, weights=uniform;, score=0.501 total time=   7.1s\n",
      "[CV 1/5; 82/88] START leaf_size=70, n_neighbors=35, weights=distance............\n",
      "[CV 1/5; 82/88] END leaf_size=70, n_neighbors=35, weights=distance;, score=0.500 total time=   7.0s\n",
      "[CV 2/5; 82/88] START leaf_size=70, n_neighbors=35, weights=distance............\n",
      "[CV 2/5; 82/88] END leaf_size=70, n_neighbors=35, weights=distance;, score=0.500 total time=   7.0s\n",
      "[CV 3/5; 82/88] START leaf_size=70, n_neighbors=35, weights=distance............\n",
      "[CV 3/5; 82/88] END leaf_size=70, n_neighbors=35, weights=distance;, score=0.500 total time=   7.1s\n",
      "[CV 4/5; 82/88] START leaf_size=70, n_neighbors=35, weights=distance............\n",
      "[CV 4/5; 82/88] END leaf_size=70, n_neighbors=35, weights=distance;, score=0.500 total time=   7.0s\n",
      "[CV 5/5; 82/88] START leaf_size=70, n_neighbors=35, weights=distance............\n",
      "[CV 5/5; 82/88] END leaf_size=70, n_neighbors=35, weights=distance;, score=0.501 total time=   5.8s\n",
      "[CV 1/5; 83/88] START leaf_size=70, n_neighbors=55, weights=uniform.............\n",
      "[CV 1/5; 83/88] END leaf_size=70, n_neighbors=55, weights=uniform;, score=0.500 total time=   5.6s\n",
      "[CV 2/5; 83/88] START leaf_size=70, n_neighbors=55, weights=uniform.............\n",
      "[CV 2/5; 83/88] END leaf_size=70, n_neighbors=55, weights=uniform;, score=0.500 total time=   5.3s\n",
      "[CV 3/5; 83/88] START leaf_size=70, n_neighbors=55, weights=uniform.............\n",
      "[CV 3/5; 83/88] END leaf_size=70, n_neighbors=55, weights=uniform;, score=0.501 total time=   5.8s\n",
      "[CV 4/5; 83/88] START leaf_size=70, n_neighbors=55, weights=uniform.............\n",
      "[CV 4/5; 83/88] END leaf_size=70, n_neighbors=55, weights=uniform;, score=0.500 total time=   5.3s\n",
      "[CV 5/5; 83/88] START leaf_size=70, n_neighbors=55, weights=uniform.............\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 83/88] END leaf_size=70, n_neighbors=55, weights=uniform;, score=0.500 total time=   6.0s\n",
      "[CV 1/5; 84/88] START leaf_size=70, n_neighbors=55, weights=distance............\n",
      "[CV 1/5; 84/88] END leaf_size=70, n_neighbors=55, weights=distance;, score=0.500 total time=   5.3s\n",
      "[CV 2/5; 84/88] START leaf_size=70, n_neighbors=55, weights=distance............\n",
      "[CV 2/5; 84/88] END leaf_size=70, n_neighbors=55, weights=distance;, score=0.500 total time=   6.2s\n",
      "[CV 3/5; 84/88] START leaf_size=70, n_neighbors=55, weights=distance............\n",
      "[CV 3/5; 84/88] END leaf_size=70, n_neighbors=55, weights=distance;, score=0.500 total time=   5.7s\n",
      "[CV 4/5; 84/88] START leaf_size=70, n_neighbors=55, weights=distance............\n",
      "[CV 4/5; 84/88] END leaf_size=70, n_neighbors=55, weights=distance;, score=0.500 total time=   5.6s\n",
      "[CV 5/5; 84/88] START leaf_size=70, n_neighbors=55, weights=distance............\n",
      "[CV 5/5; 84/88] END leaf_size=70, n_neighbors=55, weights=distance;, score=0.500 total time=   5.8s\n",
      "[CV 1/5; 85/88] START leaf_size=70, n_neighbors=75, weights=uniform.............\n",
      "[CV 1/5; 85/88] END leaf_size=70, n_neighbors=75, weights=uniform;, score=0.500 total time=   5.8s\n",
      "[CV 2/5; 85/88] START leaf_size=70, n_neighbors=75, weights=uniform.............\n",
      "[CV 2/5; 85/88] END leaf_size=70, n_neighbors=75, weights=uniform;, score=0.500 total time=   5.3s\n",
      "[CV 3/5; 85/88] START leaf_size=70, n_neighbors=75, weights=uniform.............\n",
      "[CV 3/5; 85/88] END leaf_size=70, n_neighbors=75, weights=uniform;, score=0.500 total time=   5.5s\n",
      "[CV 4/5; 85/88] START leaf_size=70, n_neighbors=75, weights=uniform.............\n",
      "[CV 4/5; 85/88] END leaf_size=70, n_neighbors=75, weights=uniform;, score=0.500 total time=   5.6s\n",
      "[CV 5/5; 85/88] START leaf_size=70, n_neighbors=75, weights=uniform.............\n",
      "[CV 5/5; 85/88] END leaf_size=70, n_neighbors=75, weights=uniform;, score=0.500 total time=   6.1s\n",
      "[CV 1/5; 86/88] START leaf_size=70, n_neighbors=75, weights=distance............\n",
      "[CV 1/5; 86/88] END leaf_size=70, n_neighbors=75, weights=distance;, score=0.500 total time=   5.4s\n",
      "[CV 2/5; 86/88] START leaf_size=70, n_neighbors=75, weights=distance............\n",
      "[CV 2/5; 86/88] END leaf_size=70, n_neighbors=75, weights=distance;, score=0.500 total time=   6.1s\n",
      "[CV 3/5; 86/88] START leaf_size=70, n_neighbors=75, weights=distance............\n",
      "[CV 3/5; 86/88] END leaf_size=70, n_neighbors=75, weights=distance;, score=0.500 total time=   5.4s\n",
      "[CV 4/5; 86/88] START leaf_size=70, n_neighbors=75, weights=distance............\n",
      "[CV 4/5; 86/88] END leaf_size=70, n_neighbors=75, weights=distance;, score=0.500 total time=   5.8s\n",
      "[CV 5/5; 86/88] START leaf_size=70, n_neighbors=75, weights=distance............\n",
      "[CV 5/5; 86/88] END leaf_size=70, n_neighbors=75, weights=distance;, score=0.500 total time=   4.6s\n",
      "[CV 1/5; 87/88] START leaf_size=70, n_neighbors=99, weights=uniform.............\n",
      "[CV 1/5; 87/88] END leaf_size=70, n_neighbors=99, weights=uniform;, score=0.500 total time=   5.7s\n",
      "[CV 2/5; 87/88] START leaf_size=70, n_neighbors=99, weights=uniform.............\n",
      "[CV 2/5; 87/88] END leaf_size=70, n_neighbors=99, weights=uniform;, score=0.500 total time=   5.2s\n",
      "[CV 3/5; 87/88] START leaf_size=70, n_neighbors=99, weights=uniform.............\n",
      "[CV 3/5; 87/88] END leaf_size=70, n_neighbors=99, weights=uniform;, score=0.500 total time=   5.8s\n",
      "[CV 4/5; 87/88] START leaf_size=70, n_neighbors=99, weights=uniform.............\n",
      "[CV 4/5; 87/88] END leaf_size=70, n_neighbors=99, weights=uniform;, score=0.500 total time=   5.4s\n",
      "[CV 5/5; 87/88] START leaf_size=70, n_neighbors=99, weights=uniform.............\n",
      "[CV 5/5; 87/88] END leaf_size=70, n_neighbors=99, weights=uniform;, score=0.500 total time=   5.5s\n",
      "[CV 1/5; 88/88] START leaf_size=70, n_neighbors=99, weights=distance............\n",
      "[CV 1/5; 88/88] END leaf_size=70, n_neighbors=99, weights=distance;, score=0.500 total time=   5.8s\n",
      "[CV 2/5; 88/88] START leaf_size=70, n_neighbors=99, weights=distance............\n",
      "[CV 2/5; 88/88] END leaf_size=70, n_neighbors=99, weights=distance;, score=0.500 total time=   5.3s\n",
      "[CV 3/5; 88/88] START leaf_size=70, n_neighbors=99, weights=distance............\n",
      "[CV 3/5; 88/88] END leaf_size=70, n_neighbors=99, weights=distance;, score=0.500 total time=   6.2s\n",
      "[CV 4/5; 88/88] START leaf_size=70, n_neighbors=99, weights=distance............\n",
      "[CV 4/5; 88/88] END leaf_size=70, n_neighbors=99, weights=distance;, score=0.500 total time=   5.4s\n",
      "[CV 5/5; 88/88] START leaf_size=70, n_neighbors=99, weights=distance............\n",
      "[CV 5/5; 88/88] END leaf_size=70, n_neighbors=99, weights=distance;, score=0.500 total time=   5.2s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=KNeighborsClassifier(),\n",
       "             param_grid={'leaf_size': [20, 30, 50, 70],\n",
       "                         'n_neighbors': [3, 5, 7, 9, 15, 19, 25, 35, 55, 75,\n",
       "                                         99],\n",
       "                         'weights': ['uniform', 'distance']},\n",
       "             scoring='balanced_accuracy', verbose=10)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "parameters = { 'n_neighbors': [3, 5, 7, 9, 15, 19, 25, 35, 55,75, 99],\n",
    "                'leaf_size': [20, 30, 50, 70],\n",
    "              'weights': ['uniform', 'distance']\n",
    "                 }\n",
    "\n",
    "model = KNeighborsClassifier()\n",
    "\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=parameters, verbose=10, scoring=\"balanced_accuracy\")\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "17040147",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'leaf_size': 20, 'n_neighbors': 5, 'weights': 'uniform'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ec4e2398",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KNeighborsClassifier(n_neighbors=5, leaf_size=20, weights='uniform')\n",
    "model.fit(X_train, y_train)\n",
    "predicted = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f77d7671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7045313469894475\n",
      "Balanced Accuracy:  0.5156838933793998\n",
      "Precision:  0.7483416252072969\n",
      "Recall:  0.9064278540341479\n",
      "F1:  0.8198334595003786\n"
     ]
    }
   ],
   "source": [
    "evaluate(predicted, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f898fc9",
   "metadata": {},
   "source": [
    "As we can see although we have not-bad accuracy but balanced accuracy which is wanted for this task is not good so we should look for better moodels.\n",
    "\n",
    "By remember that with these parameters:\n",
    "```\n",
    "{'n_neighbors': 5,\n",
    " 'leaf_size': 20,\n",
    " 'weights': uniform\n",
    "}\n",
    "```\n",
    " \n",
    "We got these results:\n",
    "```\n",
    "Accuracy:  0.7045313469894475\n",
    "Balanced Accuracy:  0.5156838933793998\n",
    "Precision:  0.7483416252072969\n",
    "Recall:  0.9064278540341479\n",
    "F1:  0.8198334595003786\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f874ded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 240 candidates, totalling 1200 fits\n",
      "[CV 1/5; 1/240] START max_iter=50, penalty=l1, solver=newton-cg, tol=0.001......\n",
      "[CV 1/5; 1/240] END max_iter=50, penalty=l1, solver=newton-cg, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 2/5; 1/240] START max_iter=50, penalty=l1, solver=newton-cg, tol=0.001......\n",
      "[CV 2/5; 1/240] END max_iter=50, penalty=l1, solver=newton-cg, tol=0.001;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 1/240] START max_iter=50, penalty=l1, solver=newton-cg, tol=0.001......\n",
      "[CV 3/5; 1/240] END max_iter=50, penalty=l1, solver=newton-cg, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 4/5; 1/240] START max_iter=50, penalty=l1, solver=newton-cg, tol=0.001......\n",
      "[CV 4/5; 1/240] END max_iter=50, penalty=l1, solver=newton-cg, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 5/5; 1/240] START max_iter=50, penalty=l1, solver=newton-cg, tol=0.001......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 1/240] END max_iter=50, penalty=l1, solver=newton-cg, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 1/5; 2/240] START max_iter=50, penalty=l1, solver=newton-cg, tol=0.0001.....\n",
      "[CV 1/5; 2/240] END max_iter=50, penalty=l1, solver=newton-cg, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 2/5; 2/240] START max_iter=50, penalty=l1, solver=newton-cg, tol=0.0001.....\n",
      "[CV 2/5; 2/240] END max_iter=50, penalty=l1, solver=newton-cg, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 3/5; 2/240] START max_iter=50, penalty=l1, solver=newton-cg, tol=0.0001.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 2/240] END max_iter=50, penalty=l1, solver=newton-cg, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 4/5; 2/240] START max_iter=50, penalty=l1, solver=newton-cg, tol=0.0001.....\n",
      "[CV 4/5; 2/240] END max_iter=50, penalty=l1, solver=newton-cg, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 5/5; 2/240] START max_iter=50, penalty=l1, solver=newton-cg, tol=0.0001.....\n",
      "[CV 5/5; 2/240] END max_iter=50, penalty=l1, solver=newton-cg, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 1/5; 3/240] START max_iter=50, penalty=l1, solver=newton-cg, tol=1e-05......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 3/240] END max_iter=50, penalty=l1, solver=newton-cg, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 2/5; 3/240] START max_iter=50, penalty=l1, solver=newton-cg, tol=1e-05......\n",
      "[CV 2/5; 3/240] END max_iter=50, penalty=l1, solver=newton-cg, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 3/5; 3/240] START max_iter=50, penalty=l1, solver=newton-cg, tol=1e-05......\n",
      "[CV 3/5; 3/240] END max_iter=50, penalty=l1, solver=newton-cg, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 4/5; 3/240] START max_iter=50, penalty=l1, solver=newton-cg, tol=1e-05......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 3/240] END max_iter=50, penalty=l1, solver=newton-cg, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 5/5; 3/240] START max_iter=50, penalty=l1, solver=newton-cg, tol=1e-05......\n",
      "[CV 5/5; 3/240] END max_iter=50, penalty=l1, solver=newton-cg, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 1/5; 4/240] START max_iter=50, penalty=l1, solver=lbfgs, tol=0.001..........\n",
      "[CV 1/5; 4/240] END max_iter=50, penalty=l1, solver=lbfgs, tol=0.001;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 4/240] START max_iter=50, penalty=l1, solver=lbfgs, tol=0.001..........\n",
      "[CV 2/5; 4/240] END max_iter=50, penalty=l1, solver=lbfgs, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 3/5; 4/240] START max_iter=50, penalty=l1, solver=lbfgs, tol=0.001..........\n",
      "[CV 3/5; 4/240] END max_iter=50, penalty=l1, solver=lbfgs, tol=0.001;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 4/240] START max_iter=50, penalty=l1, solver=lbfgs, tol=0.001..........\n",
      "[CV 4/5; 4/240] END max_iter=50, penalty=l1, solver=lbfgs, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 5/5; 4/240] START max_iter=50, penalty=l1, solver=lbfgs, tol=0.001..........\n",
      "[CV 5/5; 4/240] END max_iter=50, penalty=l1, solver=lbfgs, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 1/5; 5/240] START max_iter=50, penalty=l1, solver=lbfgs, tol=0.0001.........\n",
      "[CV 1/5; 5/240] END max_iter=50, penalty=l1, solver=lbfgs, tol=0.0001;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 5/240] START max_iter=50, penalty=l1, solver=lbfgs, tol=0.0001.........\n",
      "[CV 2/5; 5/240] END max_iter=50, penalty=l1, solver=lbfgs, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 3/5; 5/240] START max_iter=50, penalty=l1, solver=lbfgs, tol=0.0001.........\n",
      "[CV 3/5; 5/240] END max_iter=50, penalty=l1, solver=lbfgs, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 4/5; 5/240] START max_iter=50, penalty=l1, solver=lbfgs, tol=0.0001.........\n",
      "[CV 4/5; 5/240] END max_iter=50, penalty=l1, solver=lbfgs, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 5/5; 5/240] START max_iter=50, penalty=l1, solver=lbfgs, tol=0.0001.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 5/240] END max_iter=50, penalty=l1, solver=lbfgs, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 1/5; 6/240] START max_iter=50, penalty=l1, solver=lbfgs, tol=1e-05..........\n",
      "[CV 1/5; 6/240] END max_iter=50, penalty=l1, solver=lbfgs, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 2/5; 6/240] START max_iter=50, penalty=l1, solver=lbfgs, tol=1e-05..........\n",
      "[CV 2/5; 6/240] END max_iter=50, penalty=l1, solver=lbfgs, tol=1e-05;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 6/240] START max_iter=50, penalty=l1, solver=lbfgs, tol=1e-05..........\n",
      "[CV 3/5; 6/240] END max_iter=50, penalty=l1, solver=lbfgs, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 4/5; 6/240] START max_iter=50, penalty=l1, solver=lbfgs, tol=1e-05..........\n",
      "[CV 4/5; 6/240] END max_iter=50, penalty=l1, solver=lbfgs, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 5/5; 6/240] START max_iter=50, penalty=l1, solver=lbfgs, tol=1e-05..........\n",
      "[CV 5/5; 6/240] END max_iter=50, penalty=l1, solver=lbfgs, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 1/5; 7/240] START max_iter=50, penalty=l1, solver=liblinear, tol=0.001......\n",
      "[CV 1/5; 7/240] END max_iter=50, penalty=l1, solver=liblinear, tol=0.001;, score=0.498 total time=   0.5s\n",
      "[CV 2/5; 7/240] START max_iter=50, penalty=l1, solver=liblinear, tol=0.001......\n",
      "[CV 2/5; 7/240] END max_iter=50, penalty=l1, solver=liblinear, tol=0.001;, score=0.499 total time=   0.7s\n",
      "[CV 3/5; 7/240] START max_iter=50, penalty=l1, solver=liblinear, tol=0.001......\n",
      "[CV 3/5; 7/240] END max_iter=50, penalty=l1, solver=liblinear, tol=0.001;, score=0.500 total time=   0.8s\n",
      "[CV 4/5; 7/240] START max_iter=50, penalty=l1, solver=liblinear, tol=0.001......\n",
      "[CV 4/5; 7/240] END max_iter=50, penalty=l1, solver=liblinear, tol=0.001;, score=0.499 total time=   0.7s\n",
      "[CV 5/5; 7/240] START max_iter=50, penalty=l1, solver=liblinear, tol=0.001......\n",
      "[CV 5/5; 7/240] END max_iter=50, penalty=l1, solver=liblinear, tol=0.001;, score=0.500 total time=   0.6s\n",
      "[CV 1/5; 8/240] START max_iter=50, penalty=l1, solver=liblinear, tol=0.0001.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 8/240] END max_iter=50, penalty=l1, solver=liblinear, tol=0.0001;, score=0.498 total time= 4.1min\n",
      "[CV 2/5; 8/240] START max_iter=50, penalty=l1, solver=liblinear, tol=0.0001.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 8/240] END max_iter=50, penalty=l1, solver=liblinear, tol=0.0001;, score=0.499 total time= 3.8min\n",
      "[CV 3/5; 8/240] START max_iter=50, penalty=l1, solver=liblinear, tol=0.0001.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 8/240] END max_iter=50, penalty=l1, solver=liblinear, tol=0.0001;, score=0.499 total time= 4.3min\n",
      "[CV 4/5; 8/240] START max_iter=50, penalty=l1, solver=liblinear, tol=0.0001.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 8/240] END max_iter=50, penalty=l1, solver=liblinear, tol=0.0001;, score=0.498 total time= 3.6min\n",
      "[CV 5/5; 8/240] START max_iter=50, penalty=l1, solver=liblinear, tol=0.0001.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 8/240] END max_iter=50, penalty=l1, solver=liblinear, tol=0.0001;, score=0.500 total time= 3.6min\n",
      "[CV 1/5; 9/240] START max_iter=50, penalty=l1, solver=liblinear, tol=1e-05......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 9/240] END max_iter=50, penalty=l1, solver=liblinear, tol=1e-05;, score=0.498 total time= 3.5min\n",
      "[CV 2/5; 9/240] START max_iter=50, penalty=l1, solver=liblinear, tol=1e-05......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 9/240] END max_iter=50, penalty=l1, solver=liblinear, tol=1e-05;, score=0.499 total time= 3.6min\n",
      "[CV 3/5; 9/240] START max_iter=50, penalty=l1, solver=liblinear, tol=1e-05......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 9/240] END max_iter=50, penalty=l1, solver=liblinear, tol=1e-05;, score=0.499 total time= 3.5min\n",
      "[CV 4/5; 9/240] START max_iter=50, penalty=l1, solver=liblinear, tol=1e-05......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 9/240] END max_iter=50, penalty=l1, solver=liblinear, tol=1e-05;, score=0.499 total time= 3.5min\n",
      "[CV 5/5; 9/240] START max_iter=50, penalty=l1, solver=liblinear, tol=1e-05......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 9/240] END max_iter=50, penalty=l1, solver=liblinear, tol=1e-05;, score=0.500 total time= 3.8min\n",
      "[CV 1/5; 10/240] START max_iter=50, penalty=l1, solver=sag, tol=0.001...........\n",
      "[CV 1/5; 10/240] END max_iter=50, penalty=l1, solver=sag, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 2/5; 10/240] START max_iter=50, penalty=l1, solver=sag, tol=0.001...........\n",
      "[CV 2/5; 10/240] END max_iter=50, penalty=l1, solver=sag, tol=0.001;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 10/240] START max_iter=50, penalty=l1, solver=sag, tol=0.001...........\n",
      "[CV 3/5; 10/240] END max_iter=50, penalty=l1, solver=sag, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 4/5; 10/240] START max_iter=50, penalty=l1, solver=sag, tol=0.001...........\n",
      "[CV 4/5; 10/240] END max_iter=50, penalty=l1, solver=sag, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 5/5; 10/240] START max_iter=50, penalty=l1, solver=sag, tol=0.001...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 10/240] END max_iter=50, penalty=l1, solver=sag, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 1/5; 11/240] START max_iter=50, penalty=l1, solver=sag, tol=0.0001..........\n",
      "[CV 1/5; 11/240] END max_iter=50, penalty=l1, solver=sag, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 2/5; 11/240] START max_iter=50, penalty=l1, solver=sag, tol=0.0001..........\n",
      "[CV 2/5; 11/240] END max_iter=50, penalty=l1, solver=sag, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 3/5; 11/240] START max_iter=50, penalty=l1, solver=sag, tol=0.0001..........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 11/240] END max_iter=50, penalty=l1, solver=sag, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 4/5; 11/240] START max_iter=50, penalty=l1, solver=sag, tol=0.0001..........\n",
      "[CV 4/5; 11/240] END max_iter=50, penalty=l1, solver=sag, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 5/5; 11/240] START max_iter=50, penalty=l1, solver=sag, tol=0.0001..........\n",
      "[CV 5/5; 11/240] END max_iter=50, penalty=l1, solver=sag, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 1/5; 12/240] START max_iter=50, penalty=l1, solver=sag, tol=1e-05...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 12/240] END max_iter=50, penalty=l1, solver=sag, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 2/5; 12/240] START max_iter=50, penalty=l1, solver=sag, tol=1e-05...........\n",
      "[CV 2/5; 12/240] END max_iter=50, penalty=l1, solver=sag, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 3/5; 12/240] START max_iter=50, penalty=l1, solver=sag, tol=1e-05...........\n",
      "[CV 3/5; 12/240] END max_iter=50, penalty=l1, solver=sag, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 4/5; 12/240] START max_iter=50, penalty=l1, solver=sag, tol=1e-05...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 12/240] END max_iter=50, penalty=l1, solver=sag, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 5/5; 12/240] START max_iter=50, penalty=l1, solver=sag, tol=1e-05...........\n",
      "[CV 5/5; 12/240] END max_iter=50, penalty=l1, solver=sag, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 1/5; 13/240] START max_iter=50, penalty=l1, solver=saga, tol=0.001..........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 13/240] END max_iter=50, penalty=l1, solver=saga, tol=0.001;, score=0.499 total time=  20.0s\n",
      "[CV 2/5; 13/240] START max_iter=50, penalty=l1, solver=saga, tol=0.001..........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 13/240] END max_iter=50, penalty=l1, solver=saga, tol=0.001;, score=0.500 total time=  19.3s\n",
      "[CV 3/5; 13/240] START max_iter=50, penalty=l1, solver=saga, tol=0.001..........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 13/240] END max_iter=50, penalty=l1, solver=saga, tol=0.001;, score=0.500 total time=  19.6s\n",
      "[CV 4/5; 13/240] START max_iter=50, penalty=l1, solver=saga, tol=0.001..........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 13/240] END max_iter=50, penalty=l1, solver=saga, tol=0.001;, score=0.499 total time=  20.5s\n",
      "[CV 5/5; 13/240] START max_iter=50, penalty=l1, solver=saga, tol=0.001..........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 13/240] END max_iter=50, penalty=l1, solver=saga, tol=0.001;, score=0.499 total time=  19.7s\n",
      "[CV 1/5; 14/240] START max_iter=50, penalty=l1, solver=saga, tol=0.0001.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 14/240] END max_iter=50, penalty=l1, solver=saga, tol=0.0001;, score=0.499 total time=  20.0s\n",
      "[CV 2/5; 14/240] START max_iter=50, penalty=l1, solver=saga, tol=0.0001.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 14/240] END max_iter=50, penalty=l1, solver=saga, tol=0.0001;, score=0.500 total time=  20.3s\n",
      "[CV 3/5; 14/240] START max_iter=50, penalty=l1, solver=saga, tol=0.0001.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 14/240] END max_iter=50, penalty=l1, solver=saga, tol=0.0001;, score=0.500 total time=  19.8s\n",
      "[CV 4/5; 14/240] START max_iter=50, penalty=l1, solver=saga, tol=0.0001.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 14/240] END max_iter=50, penalty=l1, solver=saga, tol=0.0001;, score=0.499 total time=  18.7s\n",
      "[CV 5/5; 14/240] START max_iter=50, penalty=l1, solver=saga, tol=0.0001.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 14/240] END max_iter=50, penalty=l1, solver=saga, tol=0.0001;, score=0.499 total time=  19.3s\n",
      "[CV 1/5; 15/240] START max_iter=50, penalty=l1, solver=saga, tol=1e-05..........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 15/240] END max_iter=50, penalty=l1, solver=saga, tol=1e-05;, score=0.499 total time=  20.4s\n",
      "[CV 2/5; 15/240] START max_iter=50, penalty=l1, solver=saga, tol=1e-05..........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 15/240] END max_iter=50, penalty=l1, solver=saga, tol=1e-05;, score=0.500 total time=  19.1s\n",
      "[CV 3/5; 15/240] START max_iter=50, penalty=l1, solver=saga, tol=1e-05..........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 15/240] END max_iter=50, penalty=l1, solver=saga, tol=1e-05;, score=0.500 total time=  19.6s\n",
      "[CV 4/5; 15/240] START max_iter=50, penalty=l1, solver=saga, tol=1e-05..........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 15/240] END max_iter=50, penalty=l1, solver=saga, tol=1e-05;, score=0.499 total time=  20.4s\n",
      "[CV 5/5; 15/240] START max_iter=50, penalty=l1, solver=saga, tol=1e-05..........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 15/240] END max_iter=50, penalty=l1, solver=saga, tol=1e-05;, score=0.499 total time=  20.1s\n",
      "[CV 1/5; 16/240] START max_iter=50, penalty=l2, solver=newton-cg, tol=0.001.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"newton-cg failed to converge. Increase the \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 16/240] END max_iter=50, penalty=l2, solver=newton-cg, tol=0.001;, score=0.497 total time= 1.7min\n",
      "[CV 2/5; 16/240] START max_iter=50, penalty=l2, solver=newton-cg, tol=0.001.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"newton-cg failed to converge. Increase the \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 16/240] END max_iter=50, penalty=l2, solver=newton-cg, tol=0.001;, score=0.499 total time= 1.6min\n",
      "[CV 3/5; 16/240] START max_iter=50, penalty=l2, solver=newton-cg, tol=0.001.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"newton-cg failed to converge. Increase the \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 16/240] END max_iter=50, penalty=l2, solver=newton-cg, tol=0.001;, score=0.498 total time= 1.6min\n",
      "[CV 4/5; 16/240] START max_iter=50, penalty=l2, solver=newton-cg, tol=0.001.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"newton-cg failed to converge. Increase the \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 16/240] END max_iter=50, penalty=l2, solver=newton-cg, tol=0.001;, score=0.498 total time= 1.7min\n",
      "[CV 5/5; 16/240] START max_iter=50, penalty=l2, solver=newton-cg, tol=0.001.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"newton-cg failed to converge. Increase the \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 16/240] END max_iter=50, penalty=l2, solver=newton-cg, tol=0.001;, score=0.500 total time= 1.6min\n",
      "[CV 1/5; 17/240] START max_iter=50, penalty=l2, solver=newton-cg, tol=0.0001....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"newton-cg failed to converge. Increase the \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 17/240] END max_iter=50, penalty=l2, solver=newton-cg, tol=0.0001;, score=0.497 total time= 1.7min\n",
      "[CV 2/5; 17/240] START max_iter=50, penalty=l2, solver=newton-cg, tol=0.0001....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"newton-cg failed to converge. Increase the \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 17/240] END max_iter=50, penalty=l2, solver=newton-cg, tol=0.0001;, score=0.499 total time= 1.6min\n",
      "[CV 3/5; 17/240] START max_iter=50, penalty=l2, solver=newton-cg, tol=0.0001....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"newton-cg failed to converge. Increase the \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 17/240] END max_iter=50, penalty=l2, solver=newton-cg, tol=0.0001;, score=0.498 total time= 1.6min\n",
      "[CV 4/5; 17/240] START max_iter=50, penalty=l2, solver=newton-cg, tol=0.0001....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"newton-cg failed to converge. Increase the \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 17/240] END max_iter=50, penalty=l2, solver=newton-cg, tol=0.0001;, score=0.498 total time= 1.8min\n",
      "[CV 5/5; 17/240] START max_iter=50, penalty=l2, solver=newton-cg, tol=0.0001....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"newton-cg failed to converge. Increase the \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 17/240] END max_iter=50, penalty=l2, solver=newton-cg, tol=0.0001;, score=0.500 total time= 1.6min\n",
      "[CV 1/5; 18/240] START max_iter=50, penalty=l2, solver=newton-cg, tol=1e-05.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"newton-cg failed to converge. Increase the \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 18/240] END max_iter=50, penalty=l2, solver=newton-cg, tol=1e-05;, score=0.497 total time= 1.7min\n",
      "[CV 2/5; 18/240] START max_iter=50, penalty=l2, solver=newton-cg, tol=1e-05.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"newton-cg failed to converge. Increase the \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 18/240] END max_iter=50, penalty=l2, solver=newton-cg, tol=1e-05;, score=0.499 total time= 1.6min\n",
      "[CV 3/5; 18/240] START max_iter=50, penalty=l2, solver=newton-cg, tol=1e-05.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"newton-cg failed to converge. Increase the \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 18/240] END max_iter=50, penalty=l2, solver=newton-cg, tol=1e-05;, score=0.498 total time= 1.8min\n",
      "[CV 4/5; 18/240] START max_iter=50, penalty=l2, solver=newton-cg, tol=1e-05.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"newton-cg failed to converge. Increase the \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 18/240] END max_iter=50, penalty=l2, solver=newton-cg, tol=1e-05;, score=0.498 total time= 2.3min\n",
      "[CV 5/5; 18/240] START max_iter=50, penalty=l2, solver=newton-cg, tol=1e-05.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"newton-cg failed to converge. Increase the \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 18/240] END max_iter=50, penalty=l2, solver=newton-cg, tol=1e-05;, score=0.500 total time= 2.1min\n",
      "[CV 1/5; 19/240] START max_iter=50, penalty=l2, solver=lbfgs, tol=0.001.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 19/240] END max_iter=50, penalty=l2, solver=lbfgs, tol=0.001;, score=0.499 total time=   1.7s\n",
      "[CV 2/5; 19/240] START max_iter=50, penalty=l2, solver=lbfgs, tol=0.001.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 19/240] END max_iter=50, penalty=l2, solver=lbfgs, tol=0.001;, score=0.500 total time=   1.6s\n",
      "[CV 3/5; 19/240] START max_iter=50, penalty=l2, solver=lbfgs, tol=0.001.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 19/240] END max_iter=50, penalty=l2, solver=lbfgs, tol=0.001;, score=0.501 total time=   1.6s\n",
      "[CV 4/5; 19/240] START max_iter=50, penalty=l2, solver=lbfgs, tol=0.001.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 19/240] END max_iter=50, penalty=l2, solver=lbfgs, tol=0.001;, score=0.500 total time=   1.6s\n",
      "[CV 5/5; 19/240] START max_iter=50, penalty=l2, solver=lbfgs, tol=0.001.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 19/240] END max_iter=50, penalty=l2, solver=lbfgs, tol=0.001;, score=0.500 total time=   1.6s\n",
      "[CV 1/5; 20/240] START max_iter=50, penalty=l2, solver=lbfgs, tol=0.0001........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 20/240] END max_iter=50, penalty=l2, solver=lbfgs, tol=0.0001;, score=0.499 total time=   1.6s\n",
      "[CV 2/5; 20/240] START max_iter=50, penalty=l2, solver=lbfgs, tol=0.0001........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 20/240] END max_iter=50, penalty=l2, solver=lbfgs, tol=0.0001;, score=0.500 total time=   1.6s\n",
      "[CV 3/5; 20/240] START max_iter=50, penalty=l2, solver=lbfgs, tol=0.0001........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 20/240] END max_iter=50, penalty=l2, solver=lbfgs, tol=0.0001;, score=0.501 total time=   1.6s\n",
      "[CV 4/5; 20/240] START max_iter=50, penalty=l2, solver=lbfgs, tol=0.0001........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 20/240] END max_iter=50, penalty=l2, solver=lbfgs, tol=0.0001;, score=0.500 total time=   1.6s\n",
      "[CV 5/5; 20/240] START max_iter=50, penalty=l2, solver=lbfgs, tol=0.0001........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 20/240] END max_iter=50, penalty=l2, solver=lbfgs, tol=0.0001;, score=0.500 total time=   1.6s\n",
      "[CV 1/5; 21/240] START max_iter=50, penalty=l2, solver=lbfgs, tol=1e-05.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 21/240] END max_iter=50, penalty=l2, solver=lbfgs, tol=1e-05;, score=0.499 total time=   1.5s\n",
      "[CV 2/5; 21/240] START max_iter=50, penalty=l2, solver=lbfgs, tol=1e-05.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 21/240] END max_iter=50, penalty=l2, solver=lbfgs, tol=1e-05;, score=0.500 total time=   1.6s\n",
      "[CV 3/5; 21/240] START max_iter=50, penalty=l2, solver=lbfgs, tol=1e-05.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 21/240] END max_iter=50, penalty=l2, solver=lbfgs, tol=1e-05;, score=0.501 total time=   1.6s\n",
      "[CV 4/5; 21/240] START max_iter=50, penalty=l2, solver=lbfgs, tol=1e-05.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 21/240] END max_iter=50, penalty=l2, solver=lbfgs, tol=1e-05;, score=0.500 total time=   1.6s\n",
      "[CV 5/5; 21/240] START max_iter=50, penalty=l2, solver=lbfgs, tol=1e-05.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 21/240] END max_iter=50, penalty=l2, solver=lbfgs, tol=1e-05;, score=0.500 total time=   1.6s\n",
      "[CV 1/5; 22/240] START max_iter=50, penalty=l2, solver=liblinear, tol=0.001.....\n",
      "[CV 1/5; 22/240] END max_iter=50, penalty=l2, solver=liblinear, tol=0.001;, score=0.498 total time=  18.1s\n",
      "[CV 2/5; 22/240] START max_iter=50, penalty=l2, solver=liblinear, tol=0.001.....\n",
      "[CV 2/5; 22/240] END max_iter=50, penalty=l2, solver=liblinear, tol=0.001;, score=0.499 total time=  17.2s\n",
      "[CV 3/5; 22/240] START max_iter=50, penalty=l2, solver=liblinear, tol=0.001.....\n",
      "[CV 3/5; 22/240] END max_iter=50, penalty=l2, solver=liblinear, tol=0.001;, score=0.499 total time=  17.9s\n",
      "[CV 4/5; 22/240] START max_iter=50, penalty=l2, solver=liblinear, tol=0.001.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 22/240] END max_iter=50, penalty=l2, solver=liblinear, tol=0.001;, score=0.498 total time=  22.4s\n",
      "[CV 5/5; 22/240] START max_iter=50, penalty=l2, solver=liblinear, tol=0.001.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 22/240] END max_iter=50, penalty=l2, solver=liblinear, tol=0.001;, score=0.499 total time=  11.8s\n",
      "[CV 1/5; 23/240] START max_iter=50, penalty=l2, solver=liblinear, tol=0.0001....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 23/240] END max_iter=50, penalty=l2, solver=liblinear, tol=0.0001;, score=0.497 total time=  53.2s\n",
      "[CV 2/5; 23/240] START max_iter=50, penalty=l2, solver=liblinear, tol=0.0001....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 23/240] END max_iter=50, penalty=l2, solver=liblinear, tol=0.0001;, score=0.500 total time= 2.3min\n",
      "[CV 3/5; 23/240] START max_iter=50, penalty=l2, solver=liblinear, tol=0.0001....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 23/240] END max_iter=50, penalty=l2, solver=liblinear, tol=0.0001;, score=0.499 total time= 2.5min\n",
      "[CV 4/5; 23/240] START max_iter=50, penalty=l2, solver=liblinear, tol=0.0001....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 23/240] END max_iter=50, penalty=l2, solver=liblinear, tol=0.0001;, score=0.498 total time=  21.0s\n",
      "[CV 5/5; 23/240] START max_iter=50, penalty=l2, solver=liblinear, tol=0.0001....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 23/240] END max_iter=50, penalty=l2, solver=liblinear, tol=0.0001;, score=0.499 total time=  10.9s\n",
      "[CV 1/5; 24/240] START max_iter=50, penalty=l2, solver=liblinear, tol=1e-05.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 24/240] END max_iter=50, penalty=l2, solver=liblinear, tol=1e-05;, score=0.497 total time=  51.2s\n",
      "[CV 2/5; 24/240] START max_iter=50, penalty=l2, solver=liblinear, tol=1e-05.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 24/240] END max_iter=50, penalty=l2, solver=liblinear, tol=1e-05;, score=0.500 total time= 2.5min\n",
      "[CV 3/5; 24/240] START max_iter=50, penalty=l2, solver=liblinear, tol=1e-05.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 24/240] END max_iter=50, penalty=l2, solver=liblinear, tol=1e-05;, score=0.499 total time= 2.7min\n",
      "[CV 4/5; 24/240] START max_iter=50, penalty=l2, solver=liblinear, tol=1e-05.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 24/240] END max_iter=50, penalty=l2, solver=liblinear, tol=1e-05;, score=0.498 total time=  25.5s\n",
      "[CV 5/5; 24/240] START max_iter=50, penalty=l2, solver=liblinear, tol=1e-05.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 24/240] END max_iter=50, penalty=l2, solver=liblinear, tol=1e-05;, score=0.499 total time=  13.2s\n",
      "[CV 1/5; 25/240] START max_iter=50, penalty=l2, solver=sag, tol=0.001...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 25/240] END max_iter=50, penalty=l2, solver=sag, tol=0.001;, score=0.499 total time=  13.8s\n",
      "[CV 2/5; 25/240] START max_iter=50, penalty=l2, solver=sag, tol=0.001...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 25/240] END max_iter=50, penalty=l2, solver=sag, tol=0.001;, score=0.500 total time=  13.6s\n",
      "[CV 3/5; 25/240] START max_iter=50, penalty=l2, solver=sag, tol=0.001...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 25/240] END max_iter=50, penalty=l2, solver=sag, tol=0.001;, score=0.500 total time=  12.3s\n",
      "[CV 4/5; 25/240] START max_iter=50, penalty=l2, solver=sag, tol=0.001...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 25/240] END max_iter=50, penalty=l2, solver=sag, tol=0.001;, score=0.500 total time=  12.1s\n",
      "[CV 5/5; 25/240] START max_iter=50, penalty=l2, solver=sag, tol=0.001...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 25/240] END max_iter=50, penalty=l2, solver=sag, tol=0.001;, score=0.500 total time=  12.1s\n",
      "[CV 1/5; 26/240] START max_iter=50, penalty=l2, solver=sag, tol=0.0001..........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 26/240] END max_iter=50, penalty=l2, solver=sag, tol=0.0001;, score=0.499 total time=  11.9s\n",
      "[CV 2/5; 26/240] START max_iter=50, penalty=l2, solver=sag, tol=0.0001..........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 26/240] END max_iter=50, penalty=l2, solver=sag, tol=0.0001;, score=0.500 total time=  11.8s\n",
      "[CV 3/5; 26/240] START max_iter=50, penalty=l2, solver=sag, tol=0.0001..........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 26/240] END max_iter=50, penalty=l2, solver=sag, tol=0.0001;, score=0.500 total time=  11.1s\n",
      "[CV 4/5; 26/240] START max_iter=50, penalty=l2, solver=sag, tol=0.0001..........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 26/240] END max_iter=50, penalty=l2, solver=sag, tol=0.0001;, score=0.500 total time=  11.8s\n",
      "[CV 5/5; 26/240] START max_iter=50, penalty=l2, solver=sag, tol=0.0001..........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 26/240] END max_iter=50, penalty=l2, solver=sag, tol=0.0001;, score=0.500 total time=  12.4s\n",
      "[CV 1/5; 27/240] START max_iter=50, penalty=l2, solver=sag, tol=1e-05...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 27/240] END max_iter=50, penalty=l2, solver=sag, tol=1e-05;, score=0.499 total time=  13.3s\n",
      "[CV 2/5; 27/240] START max_iter=50, penalty=l2, solver=sag, tol=1e-05...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 27/240] END max_iter=50, penalty=l2, solver=sag, tol=1e-05;, score=0.500 total time=  12.8s\n",
      "[CV 3/5; 27/240] START max_iter=50, penalty=l2, solver=sag, tol=1e-05...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 27/240] END max_iter=50, penalty=l2, solver=sag, tol=1e-05;, score=0.500 total time=  13.3s\n",
      "[CV 4/5; 27/240] START max_iter=50, penalty=l2, solver=sag, tol=1e-05...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 27/240] END max_iter=50, penalty=l2, solver=sag, tol=1e-05;, score=0.500 total time=  13.1s\n",
      "[CV 5/5; 27/240] START max_iter=50, penalty=l2, solver=sag, tol=1e-05...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 27/240] END max_iter=50, penalty=l2, solver=sag, tol=1e-05;, score=0.500 total time=  13.9s\n",
      "[CV 1/5; 28/240] START max_iter=50, penalty=l2, solver=saga, tol=0.001..........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 28/240] END max_iter=50, penalty=l2, solver=saga, tol=0.001;, score=0.499 total time=  15.5s\n",
      "[CV 2/5; 28/240] START max_iter=50, penalty=l2, solver=saga, tol=0.001..........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 28/240] END max_iter=50, penalty=l2, solver=saga, tol=0.001;, score=0.500 total time=  15.9s\n",
      "[CV 3/5; 28/240] START max_iter=50, penalty=l2, solver=saga, tol=0.001..........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 28/240] END max_iter=50, penalty=l2, solver=saga, tol=0.001;, score=0.500 total time=  16.1s\n",
      "[CV 4/5; 28/240] START max_iter=50, penalty=l2, solver=saga, tol=0.001..........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 28/240] END max_iter=50, penalty=l2, solver=saga, tol=0.001;, score=0.499 total time=  16.2s\n",
      "[CV 5/5; 28/240] START max_iter=50, penalty=l2, solver=saga, tol=0.001..........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 28/240] END max_iter=50, penalty=l2, solver=saga, tol=0.001;, score=0.499 total time=  15.7s\n",
      "[CV 1/5; 29/240] START max_iter=50, penalty=l2, solver=saga, tol=0.0001.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 29/240] END max_iter=50, penalty=l2, solver=saga, tol=0.0001;, score=0.499 total time=  15.6s\n",
      "[CV 2/5; 29/240] START max_iter=50, penalty=l2, solver=saga, tol=0.0001.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 29/240] END max_iter=50, penalty=l2, solver=saga, tol=0.0001;, score=0.500 total time=  15.6s\n",
      "[CV 3/5; 29/240] START max_iter=50, penalty=l2, solver=saga, tol=0.0001.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 29/240] END max_iter=50, penalty=l2, solver=saga, tol=0.0001;, score=0.500 total time=  15.5s\n",
      "[CV 4/5; 29/240] START max_iter=50, penalty=l2, solver=saga, tol=0.0001.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 29/240] END max_iter=50, penalty=l2, solver=saga, tol=0.0001;, score=0.499 total time=  14.9s\n",
      "[CV 5/5; 29/240] START max_iter=50, penalty=l2, solver=saga, tol=0.0001.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 29/240] END max_iter=50, penalty=l2, solver=saga, tol=0.0001;, score=0.499 total time=  15.4s\n",
      "[CV 1/5; 30/240] START max_iter=50, penalty=l2, solver=saga, tol=1e-05..........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 30/240] END max_iter=50, penalty=l2, solver=saga, tol=1e-05;, score=0.499 total time=  15.2s\n",
      "[CV 2/5; 30/240] START max_iter=50, penalty=l2, solver=saga, tol=1e-05..........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 30/240] END max_iter=50, penalty=l2, solver=saga, tol=1e-05;, score=0.500 total time=  15.4s\n",
      "[CV 3/5; 30/240] START max_iter=50, penalty=l2, solver=saga, tol=1e-05..........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 30/240] END max_iter=50, penalty=l2, solver=saga, tol=1e-05;, score=0.500 total time=  15.6s\n",
      "[CV 4/5; 30/240] START max_iter=50, penalty=l2, solver=saga, tol=1e-05..........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 30/240] END max_iter=50, penalty=l2, solver=saga, tol=1e-05;, score=0.499 total time=  15.5s\n",
      "[CV 5/5; 30/240] START max_iter=50, penalty=l2, solver=saga, tol=1e-05..........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 30/240] END max_iter=50, penalty=l2, solver=saga, tol=1e-05;, score=0.499 total time=  15.7s\n",
      "[CV 1/5; 31/240] START max_iter=50, penalty=elasticnet, solver=newton-cg, tol=0.001\n",
      "[CV 1/5; 31/240] END max_iter=50, penalty=elasticnet, solver=newton-cg, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 2/5; 31/240] START max_iter=50, penalty=elasticnet, solver=newton-cg, tol=0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 31/240] END max_iter=50, penalty=elasticnet, solver=newton-cg, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 3/5; 31/240] START max_iter=50, penalty=elasticnet, solver=newton-cg, tol=0.001\n",
      "[CV 3/5; 31/240] END max_iter=50, penalty=elasticnet, solver=newton-cg, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 4/5; 31/240] START max_iter=50, penalty=elasticnet, solver=newton-cg, tol=0.001\n",
      "[CV 4/5; 31/240] END max_iter=50, penalty=elasticnet, solver=newton-cg, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 5/5; 31/240] START max_iter=50, penalty=elasticnet, solver=newton-cg, tol=0.001\n",
      "[CV 5/5; 31/240] END max_iter=50, penalty=elasticnet, solver=newton-cg, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 1/5; 32/240] START max_iter=50, penalty=elasticnet, solver=newton-cg, tol=0.0001\n",
      "[CV 1/5; 32/240] END max_iter=50, penalty=elasticnet, solver=newton-cg, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 2/5; 32/240] START max_iter=50, penalty=elasticnet, solver=newton-cg, tol=0.0001"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV 2/5; 32/240] END max_iter=50, penalty=elasticnet, solver=newton-cg, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 3/5; 32/240] START max_iter=50, penalty=elasticnet, solver=newton-cg, tol=0.0001\n",
      "[CV 3/5; 32/240] END max_iter=50, penalty=elasticnet, solver=newton-cg, tol=0.0001;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 32/240] START max_iter=50, penalty=elasticnet, solver=newton-cg, tol=0.0001\n",
      "[CV 4/5; 32/240] END max_iter=50, penalty=elasticnet, solver=newton-cg, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 5/5; 32/240] START max_iter=50, penalty=elasticnet, solver=newton-cg, tol=0.0001\n",
      "[CV 5/5; 32/240] END max_iter=50, penalty=elasticnet, solver=newton-cg, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 1/5; 33/240] START max_iter=50, penalty=elasticnet, solver=newton-cg, tol=1e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV 1/5; 33/240] END max_iter=50, penalty=elasticnet, solver=newton-cg, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 2/5; 33/240] START max_iter=50, penalty=elasticnet, solver=newton-cg, tol=1e-05\n",
      "[CV 2/5; 33/240] END max_iter=50, penalty=elasticnet, solver=newton-cg, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 3/5; 33/240] START max_iter=50, penalty=elasticnet, solver=newton-cg, tol=1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 33/240] END max_iter=50, penalty=elasticnet, solver=newton-cg, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 4/5; 33/240] START max_iter=50, penalty=elasticnet, solver=newton-cg, tol=1e-05\n",
      "[CV 4/5; 33/240] END max_iter=50, penalty=elasticnet, solver=newton-cg, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 5/5; 33/240] START max_iter=50, penalty=elasticnet, solver=newton-cg, tol=1e-05\n",
      "[CV 5/5; 33/240] END max_iter=50, penalty=elasticnet, solver=newton-cg, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 1/5; 34/240] START max_iter=50, penalty=elasticnet, solver=lbfgs, tol=0.001."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV 1/5; 34/240] END max_iter=50, penalty=elasticnet, solver=lbfgs, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 2/5; 34/240] START max_iter=50, penalty=elasticnet, solver=lbfgs, tol=0.001.\n",
      "[CV 2/5; 34/240] END max_iter=50, penalty=elasticnet, solver=lbfgs, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 3/5; 34/240] START max_iter=50, penalty=elasticnet, solver=lbfgs, tol=0.001.\n",
      "[CV 3/5; 34/240] END max_iter=50, penalty=elasticnet, solver=lbfgs, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 4/5; 34/240] START max_iter=50, penalty=elasticnet, solver=lbfgs, tol=0.001."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV 4/5; 34/240] END max_iter=50, penalty=elasticnet, solver=lbfgs, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 5/5; 34/240] START max_iter=50, penalty=elasticnet, solver=lbfgs, tol=0.001.\n",
      "[CV 5/5; 34/240] END max_iter=50, penalty=elasticnet, solver=lbfgs, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 1/5; 35/240] START max_iter=50, penalty=elasticnet, solver=lbfgs, tol=0.0001\n",
      "[CV 1/5; 35/240] END max_iter=50, penalty=elasticnet, solver=lbfgs, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 2/5; 35/240] START max_iter=50, penalty=elasticnet, solver=lbfgs, tol=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 35/240] END max_iter=50, penalty=elasticnet, solver=lbfgs, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 3/5; 35/240] START max_iter=50, penalty=elasticnet, solver=lbfgs, tol=0.0001\n",
      "[CV 3/5; 35/240] END max_iter=50, penalty=elasticnet, solver=lbfgs, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 4/5; 35/240] START max_iter=50, penalty=elasticnet, solver=lbfgs, tol=0.0001\n",
      "[CV 4/5; 35/240] END max_iter=50, penalty=elasticnet, solver=lbfgs, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 5/5; 35/240] START max_iter=50, penalty=elasticnet, solver=lbfgs, tol=0.0001\n",
      "[CV 5/5; 35/240] END max_iter=50, penalty=elasticnet, solver=lbfgs, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 1/5; 36/240] START max_iter=50, penalty=elasticnet, solver=lbfgs, tol=1e-05.\n",
      "[CV 1/5; 36/240] END max_iter=50, penalty=elasticnet, solver=lbfgs, tol=1e-05;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 36/240] START max_iter=50, penalty=elasticnet, solver=lbfgs, tol=1e-05.\n",
      "[CV 2/5; 36/240] END max_iter=50, penalty=elasticnet, solver=lbfgs, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 3/5; 36/240] START max_iter=50, penalty=elasticnet, solver=lbfgs, tol=1e-05.\n",
      "[CV 3/5; 36/240] END max_iter=50, penalty=elasticnet, solver=lbfgs, tol=1e-05;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 36/240] START max_iter=50, penalty=elasticnet, solver=lbfgs, tol=1e-05.\n",
      "[CV 4/5; 36/240] END max_iter=50, penalty=elasticnet, solver=lbfgs, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 5/5; 36/240] START max_iter=50, penalty=elasticnet, solver=lbfgs, tol=1e-05.\n",
      "[CV 5/5; 36/240] END max_iter=50, penalty=elasticnet, solver=lbfgs, tol=1e-05;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 37/240] START max_iter=50, penalty=elasticnet, solver=liblinear, tol=0.001\n",
      "[CV 1/5; 37/240] END max_iter=50, penalty=elasticnet, solver=liblinear, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 2/5; 37/240] START max_iter=50, penalty=elasticnet, solver=liblinear, tol=0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 37/240] END max_iter=50, penalty=elasticnet, solver=liblinear, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 3/5; 37/240] START max_iter=50, penalty=elasticnet, solver=liblinear, tol=0.001\n",
      "[CV 3/5; 37/240] END max_iter=50, penalty=elasticnet, solver=liblinear, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 4/5; 37/240] START max_iter=50, penalty=elasticnet, solver=liblinear, tol=0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 37/240] END max_iter=50, penalty=elasticnet, solver=liblinear, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 5/5; 37/240] START max_iter=50, penalty=elasticnet, solver=liblinear, tol=0.001\n",
      "[CV 5/5; 37/240] END max_iter=50, penalty=elasticnet, solver=liblinear, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 1/5; 38/240] START max_iter=50, penalty=elasticnet, solver=liblinear, tol=0.0001\n",
      "[CV 1/5; 38/240] END max_iter=50, penalty=elasticnet, solver=liblinear, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 2/5; 38/240] START max_iter=50, penalty=elasticnet, solver=liblinear, tol=0.0001"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV 2/5; 38/240] END max_iter=50, penalty=elasticnet, solver=liblinear, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 3/5; 38/240] START max_iter=50, penalty=elasticnet, solver=liblinear, tol=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 38/240] END max_iter=50, penalty=elasticnet, solver=liblinear, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 4/5; 38/240] START max_iter=50, penalty=elasticnet, solver=liblinear, tol=0.0001\n",
      "[CV 4/5; 38/240] END max_iter=50, penalty=elasticnet, solver=liblinear, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 5/5; 38/240] START max_iter=50, penalty=elasticnet, solver=liblinear, tol=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 38/240] END max_iter=50, penalty=elasticnet, solver=liblinear, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 1/5; 39/240] START max_iter=50, penalty=elasticnet, solver=liblinear, tol=1e-05\n",
      "[CV 1/5; 39/240] END max_iter=50, penalty=elasticnet, solver=liblinear, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 2/5; 39/240] START max_iter=50, penalty=elasticnet, solver=liblinear, tol=1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 39/240] END max_iter=50, penalty=elasticnet, solver=liblinear, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 3/5; 39/240] START max_iter=50, penalty=elasticnet, solver=liblinear, tol=1e-05\n",
      "[CV 3/5; 39/240] END max_iter=50, penalty=elasticnet, solver=liblinear, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 4/5; 39/240] START max_iter=50, penalty=elasticnet, solver=liblinear, tol=1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 39/240] END max_iter=50, penalty=elasticnet, solver=liblinear, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 5/5; 39/240] START max_iter=50, penalty=elasticnet, solver=liblinear, tol=1e-05\n",
      "[CV 5/5; 39/240] END max_iter=50, penalty=elasticnet, solver=liblinear, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 1/5; 40/240] START max_iter=50, penalty=elasticnet, solver=sag, tol=0.001...\n",
      "[CV 1/5; 40/240] END max_iter=50, penalty=elasticnet, solver=sag, tol=0.001;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 40/240] START max_iter=50, penalty=elasticnet, solver=sag, tol=0.001...\n",
      "[CV 2/5; 40/240] END max_iter=50, penalty=elasticnet, solver=sag, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 3/5; 40/240] START max_iter=50, penalty=elasticnet, solver=sag, tol=0.001...\n",
      "[CV 3/5; 40/240] END max_iter=50, penalty=elasticnet, solver=sag, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 4/5; 40/240] START max_iter=50, penalty=elasticnet, solver=sag, tol=0.001...\n",
      "[CV 4/5; 40/240] END max_iter=50, penalty=elasticnet, solver=sag, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 5/5; 40/240] START max_iter=50, penalty=elasticnet, solver=sag, tol=0.001..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV 5/5; 40/240] END max_iter=50, penalty=elasticnet, solver=sag, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 1/5; 41/240] START max_iter=50, penalty=elasticnet, solver=sag, tol=0.0001..\n",
      "[CV 1/5; 41/240] END max_iter=50, penalty=elasticnet, solver=sag, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 2/5; 41/240] START max_iter=50, penalty=elasticnet, solver=sag, tol=0.0001..\n",
      "[CV 2/5; 41/240] END max_iter=50, penalty=elasticnet, solver=sag, tol=0.0001;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 41/240] START max_iter=50, penalty=elasticnet, solver=sag, tol=0.0001..\n",
      "[CV 3/5; 41/240] END max_iter=50, penalty=elasticnet, solver=sag, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 4/5; 41/240] START max_iter=50, penalty=elasticnet, solver=sag, tol=0.0001..\n",
      "[CV 4/5; 41/240] END max_iter=50, penalty=elasticnet, solver=sag, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 5/5; 41/240] START max_iter=50, penalty=elasticnet, solver=sag, tol=0.0001..\n",
      "[CV 5/5; 41/240] END max_iter=50, penalty=elasticnet, solver=sag, tol=0.0001;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 42/240] START max_iter=50, penalty=elasticnet, solver=sag, tol=1e-05...\n",
      "[CV 1/5; 42/240] END max_iter=50, penalty=elasticnet, solver=sag, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 2/5; 42/240] START max_iter=50, penalty=elasticnet, solver=sag, tol=1e-05...\n",
      "[CV 2/5; 42/240] END max_iter=50, penalty=elasticnet, solver=sag, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 3/5; 42/240] START max_iter=50, penalty=elasticnet, solver=sag, tol=1e-05...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 42/240] END max_iter=50, penalty=elasticnet, solver=sag, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 4/5; 42/240] START max_iter=50, penalty=elasticnet, solver=sag, tol=1e-05...\n",
      "[CV 4/5; 42/240] END max_iter=50, penalty=elasticnet, solver=sag, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 5/5; 42/240] START max_iter=50, penalty=elasticnet, solver=sag, tol=1e-05...\n",
      "[CV 5/5; 42/240] END max_iter=50, penalty=elasticnet, solver=sag, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 1/5; 43/240] START max_iter=50, penalty=elasticnet, solver=saga, tol=0.001..\n",
      "[CV 1/5; 43/240] END max_iter=50, penalty=elasticnet, solver=saga, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 2/5; 43/240] START max_iter=50, penalty=elasticnet, solver=saga, tol=0.001..\n",
      "[CV 2/5; 43/240] END max_iter=50, penalty=elasticnet, solver=saga, tol=0.001;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1314, in fit\n",
      "    raise ValueError(\"l1_ratio must be between 0 and 1;\"\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1314, in fit\n",
      "    raise ValueError(\"l1_ratio must be between 0 and 1;\"\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1314, in fit\n",
      "    raise ValueError(\"l1_ratio must be between 0 and 1;\"\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 43/240] START max_iter=50, penalty=elasticnet, solver=saga, tol=0.001..\n",
      "[CV 3/5; 43/240] END max_iter=50, penalty=elasticnet, solver=saga, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 4/5; 43/240] START max_iter=50, penalty=elasticnet, solver=saga, tol=0.001..\n",
      "[CV 4/5; 43/240] END max_iter=50, penalty=elasticnet, solver=saga, tol=0.001;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1314, in fit\n",
      "    raise ValueError(\"l1_ratio must be between 0 and 1;\"\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1314, in fit\n",
      "    raise ValueError(\"l1_ratio must be between 0 and 1;\"\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1314, in fit\n",
      "    raise ValueError(\"l1_ratio must be between 0 and 1;\"\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 43/240] START max_iter=50, penalty=elasticnet, solver=saga, tol=0.001..\n",
      "[CV 5/5; 43/240] END max_iter=50, penalty=elasticnet, solver=saga, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 1/5; 44/240] START max_iter=50, penalty=elasticnet, solver=saga, tol=0.0001.\n",
      "[CV 1/5; 44/240] END max_iter=50, penalty=elasticnet, solver=saga, tol=0.0001;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1314, in fit\n",
      "    raise ValueError(\"l1_ratio must be between 0 and 1;\"\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1314, in fit\n",
      "    raise ValueError(\"l1_ratio must be between 0 and 1;\"\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1314, in fit\n",
      "    raise ValueError(\"l1_ratio must be between 0 and 1;\"\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 44/240] START max_iter=50, penalty=elasticnet, solver=saga, tol=0.0001.\n",
      "[CV 2/5; 44/240] END max_iter=50, penalty=elasticnet, solver=saga, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 3/5; 44/240] START max_iter=50, penalty=elasticnet, solver=saga, tol=0.0001.\n",
      "[CV 3/5; 44/240] END max_iter=50, penalty=elasticnet, solver=saga, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 4/5; 44/240] START max_iter=50, penalty=elasticnet, solver=saga, tol=0.0001.\n",
      "[CV 4/5; 44/240] END max_iter=50, penalty=elasticnet, solver=saga, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 5/5; 44/240] START max_iter=50, penalty=elasticnet, solver=saga, tol=0.0001."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1314, in fit\n",
      "    raise ValueError(\"l1_ratio must be between 0 and 1;\"\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1314, in fit\n",
      "    raise ValueError(\"l1_ratio must be between 0 and 1;\"\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1314, in fit\n",
      "    raise ValueError(\"l1_ratio must be between 0 and 1;\"\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV 5/5; 44/240] END max_iter=50, penalty=elasticnet, solver=saga, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 1/5; 45/240] START max_iter=50, penalty=elasticnet, solver=saga, tol=1e-05..\n",
      "[CV 1/5; 45/240] END max_iter=50, penalty=elasticnet, solver=saga, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 2/5; 45/240] START max_iter=50, penalty=elasticnet, solver=saga, tol=1e-05..\n",
      "[CV 2/5; 45/240] END max_iter=50, penalty=elasticnet, solver=saga, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 3/5; 45/240] START max_iter=50, penalty=elasticnet, solver=saga, tol=1e-05.."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1314, in fit\n",
      "    raise ValueError(\"l1_ratio must be between 0 and 1;\"\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1314, in fit\n",
      "    raise ValueError(\"l1_ratio must be between 0 and 1;\"\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1314, in fit\n",
      "    raise ValueError(\"l1_ratio must be between 0 and 1;\"\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV 3/5; 45/240] END max_iter=50, penalty=elasticnet, solver=saga, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 4/5; 45/240] START max_iter=50, penalty=elasticnet, solver=saga, tol=1e-05..\n",
      "[CV 4/5; 45/240] END max_iter=50, penalty=elasticnet, solver=saga, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 5/5; 45/240] START max_iter=50, penalty=elasticnet, solver=saga, tol=1e-05..\n",
      "[CV 5/5; 45/240] END max_iter=50, penalty=elasticnet, solver=saga, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 1/5; 46/240] START max_iter=50, penalty=none, solver=newton-cg, tol=0.001..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"newton-cg failed to converge. Increase the \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV 1/5; 46/240] END max_iter=50, penalty=none, solver=newton-cg, tol=0.001;, score=0.497 total time= 2.3min\n",
      "[CV 2/5; 46/240] START max_iter=50, penalty=none, solver=newton-cg, tol=0.001...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"newton-cg failed to converge. Increase the \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 46/240] END max_iter=50, penalty=none, solver=newton-cg, tol=0.001;, score=0.499 total time= 2.4min\n",
      "[CV 3/5; 46/240] START max_iter=50, penalty=none, solver=newton-cg, tol=0.001...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"newton-cg failed to converge. Increase the \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 46/240] END max_iter=50, penalty=none, solver=newton-cg, tol=0.001;, score=0.498 total time= 2.4min\n",
      "[CV 4/5; 46/240] START max_iter=50, penalty=none, solver=newton-cg, tol=0.001...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"newton-cg failed to converge. Increase the \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 46/240] END max_iter=50, penalty=none, solver=newton-cg, tol=0.001;, score=0.499 total time= 2.1min\n",
      "[CV 5/5; 46/240] START max_iter=50, penalty=none, solver=newton-cg, tol=0.001...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"newton-cg failed to converge. Increase the \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 46/240] END max_iter=50, penalty=none, solver=newton-cg, tol=0.001;, score=0.500 total time= 2.4min\n",
      "[CV 1/5; 47/240] START max_iter=50, penalty=none, solver=newton-cg, tol=0.0001..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"newton-cg failed to converge. Increase the \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 47/240] END max_iter=50, penalty=none, solver=newton-cg, tol=0.0001;, score=0.497 total time= 2.3min\n",
      "[CV 2/5; 47/240] START max_iter=50, penalty=none, solver=newton-cg, tol=0.0001..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"newton-cg failed to converge. Increase the \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 47/240] END max_iter=50, penalty=none, solver=newton-cg, tol=0.0001;, score=0.499 total time= 2.2min\n",
      "[CV 3/5; 47/240] START max_iter=50, penalty=none, solver=newton-cg, tol=0.0001..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"newton-cg failed to converge. Increase the \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 47/240] END max_iter=50, penalty=none, solver=newton-cg, tol=0.0001;, score=0.498 total time= 2.2min\n",
      "[CV 4/5; 47/240] START max_iter=50, penalty=none, solver=newton-cg, tol=0.0001..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"newton-cg failed to converge. Increase the \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 47/240] END max_iter=50, penalty=none, solver=newton-cg, tol=0.0001;, score=0.499 total time= 2.2min\n",
      "[CV 5/5; 47/240] START max_iter=50, penalty=none, solver=newton-cg, tol=0.0001..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"newton-cg failed to converge. Increase the \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 47/240] END max_iter=50, penalty=none, solver=newton-cg, tol=0.0001;, score=0.500 total time= 2.4min\n",
      "[CV 1/5; 48/240] START max_iter=50, penalty=none, solver=newton-cg, tol=1e-05...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"newton-cg failed to converge. Increase the \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 48/240] END max_iter=50, penalty=none, solver=newton-cg, tol=1e-05;, score=0.497 total time= 2.3min\n",
      "[CV 2/5; 48/240] START max_iter=50, penalty=none, solver=newton-cg, tol=1e-05...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"newton-cg failed to converge. Increase the \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 48/240] END max_iter=50, penalty=none, solver=newton-cg, tol=1e-05;, score=0.499 total time= 2.3min\n",
      "[CV 3/5; 48/240] START max_iter=50, penalty=none, solver=newton-cg, tol=1e-05...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"newton-cg failed to converge. Increase the \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 48/240] END max_iter=50, penalty=none, solver=newton-cg, tol=1e-05;, score=0.498 total time= 2.3min\n",
      "[CV 4/5; 48/240] START max_iter=50, penalty=none, solver=newton-cg, tol=1e-05...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"newton-cg failed to converge. Increase the \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 48/240] END max_iter=50, penalty=none, solver=newton-cg, tol=1e-05;, score=0.499 total time= 2.2min\n",
      "[CV 5/5; 48/240] START max_iter=50, penalty=none, solver=newton-cg, tol=1e-05...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"newton-cg failed to converge. Increase the \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 48/240] END max_iter=50, penalty=none, solver=newton-cg, tol=1e-05;, score=0.500 total time= 2.3min\n",
      "[CV 1/5; 49/240] START max_iter=50, penalty=none, solver=lbfgs, tol=0.001.......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 49/240] END max_iter=50, penalty=none, solver=lbfgs, tol=0.001;, score=0.499 total time=   1.7s\n",
      "[CV 2/5; 49/240] START max_iter=50, penalty=none, solver=lbfgs, tol=0.001.......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 49/240] END max_iter=50, penalty=none, solver=lbfgs, tol=0.001;, score=0.500 total time=   1.7s\n",
      "[CV 3/5; 49/240] START max_iter=50, penalty=none, solver=lbfgs, tol=0.001.......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 49/240] END max_iter=50, penalty=none, solver=lbfgs, tol=0.001;, score=0.501 total time=   1.7s\n",
      "[CV 4/5; 49/240] START max_iter=50, penalty=none, solver=lbfgs, tol=0.001.......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 49/240] END max_iter=50, penalty=none, solver=lbfgs, tol=0.001;, score=0.500 total time=   1.7s\n",
      "[CV 5/5; 49/240] START max_iter=50, penalty=none, solver=lbfgs, tol=0.001.......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 49/240] END max_iter=50, penalty=none, solver=lbfgs, tol=0.001;, score=0.500 total time=   1.7s\n",
      "[CV 1/5; 50/240] START max_iter=50, penalty=none, solver=lbfgs, tol=0.0001......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 50/240] END max_iter=50, penalty=none, solver=lbfgs, tol=0.0001;, score=0.499 total time=   1.7s\n",
      "[CV 2/5; 50/240] START max_iter=50, penalty=none, solver=lbfgs, tol=0.0001......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 50/240] END max_iter=50, penalty=none, solver=lbfgs, tol=0.0001;, score=0.500 total time=   1.7s\n",
      "[CV 3/5; 50/240] START max_iter=50, penalty=none, solver=lbfgs, tol=0.0001......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 50/240] END max_iter=50, penalty=none, solver=lbfgs, tol=0.0001;, score=0.501 total time=   1.7s\n",
      "[CV 4/5; 50/240] START max_iter=50, penalty=none, solver=lbfgs, tol=0.0001......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 50/240] END max_iter=50, penalty=none, solver=lbfgs, tol=0.0001;, score=0.500 total time=   1.7s\n",
      "[CV 5/5; 50/240] START max_iter=50, penalty=none, solver=lbfgs, tol=0.0001......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 50/240] END max_iter=50, penalty=none, solver=lbfgs, tol=0.0001;, score=0.500 total time=   1.7s\n",
      "[CV 1/5; 51/240] START max_iter=50, penalty=none, solver=lbfgs, tol=1e-05.......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 51/240] END max_iter=50, penalty=none, solver=lbfgs, tol=1e-05;, score=0.499 total time=   1.7s\n",
      "[CV 2/5; 51/240] START max_iter=50, penalty=none, solver=lbfgs, tol=1e-05.......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 51/240] END max_iter=50, penalty=none, solver=lbfgs, tol=1e-05;, score=0.500 total time=   1.7s\n",
      "[CV 3/5; 51/240] START max_iter=50, penalty=none, solver=lbfgs, tol=1e-05.......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 51/240] END max_iter=50, penalty=none, solver=lbfgs, tol=1e-05;, score=0.501 total time=   1.7s\n",
      "[CV 4/5; 51/240] START max_iter=50, penalty=none, solver=lbfgs, tol=1e-05.......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 51/240] END max_iter=50, penalty=none, solver=lbfgs, tol=1e-05;, score=0.500 total time=   1.7s\n",
      "[CV 5/5; 51/240] START max_iter=50, penalty=none, solver=lbfgs, tol=1e-05.......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 454, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 51/240] END max_iter=50, penalty=none, solver=lbfgs, tol=1e-05;, score=0.500 total time=   1.7s\n",
      "[CV 1/5; 52/240] START max_iter=50, penalty=none, solver=liblinear, tol=0.001...\n",
      "[CV 1/5; 52/240] END max_iter=50, penalty=none, solver=liblinear, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 2/5; 52/240] START max_iter=50, penalty=none, solver=liblinear, tol=0.001...\n",
      "[CV 2/5; 52/240] END max_iter=50, penalty=none, solver=liblinear, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 3/5; 52/240] START max_iter=50, penalty=none, solver=liblinear, tol=0.001..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 454, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 454, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 454, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV 3/5; 52/240] END max_iter=50, penalty=none, solver=liblinear, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 4/5; 52/240] START max_iter=50, penalty=none, solver=liblinear, tol=0.001...\n",
      "[CV 4/5; 52/240] END max_iter=50, penalty=none, solver=liblinear, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 5/5; 52/240] START max_iter=50, penalty=none, solver=liblinear, tol=0.001...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 454, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 454, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 454, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 52/240] END max_iter=50, penalty=none, solver=liblinear, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 1/5; 53/240] START max_iter=50, penalty=none, solver=liblinear, tol=0.0001..\n",
      "[CV 1/5; 53/240] END max_iter=50, penalty=none, solver=liblinear, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 2/5; 53/240] START max_iter=50, penalty=none, solver=liblinear, tol=0.0001..\n",
      "[CV 2/5; 53/240] END max_iter=50, penalty=none, solver=liblinear, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 3/5; 53/240] START max_iter=50, penalty=none, solver=liblinear, tol=0.0001..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 454, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 454, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 454, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 53/240] END max_iter=50, penalty=none, solver=liblinear, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 4/5; 53/240] START max_iter=50, penalty=none, solver=liblinear, tol=0.0001..\n",
      "[CV 4/5; 53/240] END max_iter=50, penalty=none, solver=liblinear, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 5/5; 53/240] START max_iter=50, penalty=none, solver=liblinear, tol=0.0001..\n",
      "[CV 5/5; 53/240] END max_iter=50, penalty=none, solver=liblinear, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 1/5; 54/240] START max_iter=50, penalty=none, solver=liblinear, tol=1e-05...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 454, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 454, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 454, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 54/240] END max_iter=50, penalty=none, solver=liblinear, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 2/5; 54/240] START max_iter=50, penalty=none, solver=liblinear, tol=1e-05...\n",
      "[CV 2/5; 54/240] END max_iter=50, penalty=none, solver=liblinear, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 3/5; 54/240] START max_iter=50, penalty=none, solver=liblinear, tol=1e-05...\n",
      "[CV 3/5; 54/240] END max_iter=50, penalty=none, solver=liblinear, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 4/5; 54/240] START max_iter=50, penalty=none, solver=liblinear, tol=1e-05...\n",
      "[CV 4/5; 54/240] END max_iter=50, penalty=none, solver=liblinear, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 5/5; 54/240] START max_iter=50, penalty=none, solver=liblinear, tol=1e-05...\n",
      "[CV 5/5; 54/240] END max_iter=50, penalty=none, solver=liblinear, tol=1e-05;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 454, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 454, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 55/240] START max_iter=50, penalty=none, solver=sag, tol=0.001.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 55/240] END max_iter=50, penalty=none, solver=sag, tol=0.001;, score=0.499 total time=  11.9s\n",
      "[CV 2/5; 55/240] START max_iter=50, penalty=none, solver=sag, tol=0.001.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 55/240] END max_iter=50, penalty=none, solver=sag, tol=0.001;, score=0.500 total time=  11.6s\n",
      "[CV 3/5; 55/240] START max_iter=50, penalty=none, solver=sag, tol=0.001.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 55/240] END max_iter=50, penalty=none, solver=sag, tol=0.001;, score=0.500 total time=  11.3s\n",
      "[CV 4/5; 55/240] START max_iter=50, penalty=none, solver=sag, tol=0.001.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 55/240] END max_iter=50, penalty=none, solver=sag, tol=0.001;, score=0.500 total time=  11.8s\n",
      "[CV 5/5; 55/240] START max_iter=50, penalty=none, solver=sag, tol=0.001.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 55/240] END max_iter=50, penalty=none, solver=sag, tol=0.001;, score=0.500 total time=  11.2s\n",
      "[CV 1/5; 56/240] START max_iter=50, penalty=none, solver=sag, tol=0.0001........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 56/240] END max_iter=50, penalty=none, solver=sag, tol=0.0001;, score=0.499 total time=  11.2s\n",
      "[CV 2/5; 56/240] START max_iter=50, penalty=none, solver=sag, tol=0.0001........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 56/240] END max_iter=50, penalty=none, solver=sag, tol=0.0001;, score=0.500 total time=  11.4s\n",
      "[CV 3/5; 56/240] START max_iter=50, penalty=none, solver=sag, tol=0.0001........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 56/240] END max_iter=50, penalty=none, solver=sag, tol=0.0001;, score=0.500 total time=  11.4s\n",
      "[CV 4/5; 56/240] START max_iter=50, penalty=none, solver=sag, tol=0.0001........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 56/240] END max_iter=50, penalty=none, solver=sag, tol=0.0001;, score=0.500 total time=  11.1s\n",
      "[CV 5/5; 56/240] START max_iter=50, penalty=none, solver=sag, tol=0.0001........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 56/240] END max_iter=50, penalty=none, solver=sag, tol=0.0001;, score=0.500 total time=  11.2s\n",
      "[CV 1/5; 57/240] START max_iter=50, penalty=none, solver=sag, tol=1e-05.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 57/240] END max_iter=50, penalty=none, solver=sag, tol=1e-05;, score=0.499 total time=  11.1s\n",
      "[CV 2/5; 57/240] START max_iter=50, penalty=none, solver=sag, tol=1e-05.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 57/240] END max_iter=50, penalty=none, solver=sag, tol=1e-05;, score=0.500 total time=  11.3s\n",
      "[CV 3/5; 57/240] START max_iter=50, penalty=none, solver=sag, tol=1e-05.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 57/240] END max_iter=50, penalty=none, solver=sag, tol=1e-05;, score=0.500 total time=  11.2s\n",
      "[CV 4/5; 57/240] START max_iter=50, penalty=none, solver=sag, tol=1e-05.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 57/240] END max_iter=50, penalty=none, solver=sag, tol=1e-05;, score=0.500 total time=  11.1s\n",
      "[CV 5/5; 57/240] START max_iter=50, penalty=none, solver=sag, tol=1e-05.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 57/240] END max_iter=50, penalty=none, solver=sag, tol=1e-05;, score=0.500 total time=  11.4s\n",
      "[CV 1/5; 58/240] START max_iter=50, penalty=none, solver=saga, tol=0.001........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 58/240] END max_iter=50, penalty=none, solver=saga, tol=0.001;, score=0.499 total time=  12.4s\n",
      "[CV 2/5; 58/240] START max_iter=50, penalty=none, solver=saga, tol=0.001........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 58/240] END max_iter=50, penalty=none, solver=saga, tol=0.001;, score=0.500 total time=  12.7s\n",
      "[CV 3/5; 58/240] START max_iter=50, penalty=none, solver=saga, tol=0.001........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 58/240] END max_iter=50, penalty=none, solver=saga, tol=0.001;, score=0.500 total time=  12.8s\n",
      "[CV 4/5; 58/240] START max_iter=50, penalty=none, solver=saga, tol=0.001........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 58/240] END max_iter=50, penalty=none, solver=saga, tol=0.001;, score=0.499 total time=  12.5s\n",
      "[CV 5/5; 58/240] START max_iter=50, penalty=none, solver=saga, tol=0.001........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 58/240] END max_iter=50, penalty=none, solver=saga, tol=0.001;, score=0.499 total time=  12.5s\n",
      "[CV 1/5; 59/240] START max_iter=50, penalty=none, solver=saga, tol=0.0001.......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 59/240] END max_iter=50, penalty=none, solver=saga, tol=0.0001;, score=0.499 total time=  12.5s\n",
      "[CV 2/5; 59/240] START max_iter=50, penalty=none, solver=saga, tol=0.0001.......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 59/240] END max_iter=50, penalty=none, solver=saga, tol=0.0001;, score=0.500 total time=  12.7s\n",
      "[CV 3/5; 59/240] START max_iter=50, penalty=none, solver=saga, tol=0.0001.......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 59/240] END max_iter=50, penalty=none, solver=saga, tol=0.0001;, score=0.500 total time=  13.6s\n",
      "[CV 4/5; 59/240] START max_iter=50, penalty=none, solver=saga, tol=0.0001.......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 59/240] END max_iter=50, penalty=none, solver=saga, tol=0.0001;, score=0.499 total time=  12.7s\n",
      "[CV 5/5; 59/240] START max_iter=50, penalty=none, solver=saga, tol=0.0001.......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 59/240] END max_iter=50, penalty=none, solver=saga, tol=0.0001;, score=0.499 total time=  14.0s\n",
      "[CV 1/5; 60/240] START max_iter=50, penalty=none, solver=saga, tol=1e-05........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 60/240] END max_iter=50, penalty=none, solver=saga, tol=1e-05;, score=0.499 total time=  13.4s\n",
      "[CV 2/5; 60/240] START max_iter=50, penalty=none, solver=saga, tol=1e-05........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 60/240] END max_iter=50, penalty=none, solver=saga, tol=1e-05;, score=0.500 total time=  12.9s\n",
      "[CV 3/5; 60/240] START max_iter=50, penalty=none, solver=saga, tol=1e-05........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 60/240] END max_iter=50, penalty=none, solver=saga, tol=1e-05;, score=0.500 total time=  13.0s\n",
      "[CV 4/5; 60/240] START max_iter=50, penalty=none, solver=saga, tol=1e-05........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 60/240] END max_iter=50, penalty=none, solver=saga, tol=1e-05;, score=0.499 total time=  12.7s\n",
      "[CV 5/5; 60/240] START max_iter=50, penalty=none, solver=saga, tol=1e-05........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 60/240] END max_iter=50, penalty=none, solver=saga, tol=1e-05;, score=0.499 total time=  12.6s\n",
      "[CV 1/5; 61/240] START max_iter=100, penalty=l1, solver=newton-cg, tol=0.001....\n",
      "[CV 1/5; 61/240] END max_iter=100, penalty=l1, solver=newton-cg, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 2/5; 61/240] START max_iter=100, penalty=l1, solver=newton-cg, tol=0.001....\n",
      "[CV 2/5; 61/240] END max_iter=100, penalty=l1, solver=newton-cg, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 3/5; 61/240] START max_iter=100, penalty=l1, solver=newton-cg, tol=0.001....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 61/240] END max_iter=100, penalty=l1, solver=newton-cg, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 4/5; 61/240] START max_iter=100, penalty=l1, solver=newton-cg, tol=0.001....\n",
      "[CV 4/5; 61/240] END max_iter=100, penalty=l1, solver=newton-cg, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 5/5; 61/240] START max_iter=100, penalty=l1, solver=newton-cg, tol=0.001....\n",
      "[CV 5/5; 61/240] END max_iter=100, penalty=l1, solver=newton-cg, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 1/5; 62/240] START max_iter=100, penalty=l1, solver=newton-cg, tol=0.0001...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 62/240] END max_iter=100, penalty=l1, solver=newton-cg, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 2/5; 62/240] START max_iter=100, penalty=l1, solver=newton-cg, tol=0.0001...\n",
      "[CV 2/5; 62/240] END max_iter=100, penalty=l1, solver=newton-cg, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 3/5; 62/240] START max_iter=100, penalty=l1, solver=newton-cg, tol=0.0001...\n",
      "[CV 3/5; 62/240] END max_iter=100, penalty=l1, solver=newton-cg, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 4/5; 62/240] START max_iter=100, penalty=l1, solver=newton-cg, tol=0.0001...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 62/240] END max_iter=100, penalty=l1, solver=newton-cg, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 5/5; 62/240] START max_iter=100, penalty=l1, solver=newton-cg, tol=0.0001...\n",
      "[CV 5/5; 62/240] END max_iter=100, penalty=l1, solver=newton-cg, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 1/5; 63/240] START max_iter=100, penalty=l1, solver=newton-cg, tol=1e-05....\n",
      "[CV 1/5; 63/240] END max_iter=100, penalty=l1, solver=newton-cg, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 2/5; 63/240] START max_iter=100, penalty=l1, solver=newton-cg, tol=1e-05....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 63/240] END max_iter=100, penalty=l1, solver=newton-cg, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 3/5; 63/240] START max_iter=100, penalty=l1, solver=newton-cg, tol=1e-05....\n",
      "[CV 3/5; 63/240] END max_iter=100, penalty=l1, solver=newton-cg, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 4/5; 63/240] START max_iter=100, penalty=l1, solver=newton-cg, tol=1e-05....\n",
      "[CV 4/5; 63/240] END max_iter=100, penalty=l1, solver=newton-cg, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 5/5; 63/240] START max_iter=100, penalty=l1, solver=newton-cg, tol=1e-05....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 63/240] END max_iter=100, penalty=l1, solver=newton-cg, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 1/5; 64/240] START max_iter=100, penalty=l1, solver=lbfgs, tol=0.001........\n",
      "[CV 1/5; 64/240] END max_iter=100, penalty=l1, solver=lbfgs, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 2/5; 64/240] START max_iter=100, penalty=l1, solver=lbfgs, tol=0.001........\n",
      "[CV 2/5; 64/240] END max_iter=100, penalty=l1, solver=lbfgs, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 3/5; 64/240] START max_iter=100, penalty=l1, solver=lbfgs, tol=0.001........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 64/240] END max_iter=100, penalty=l1, solver=lbfgs, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 4/5; 64/240] START max_iter=100, penalty=l1, solver=lbfgs, tol=0.001........\n",
      "[CV 4/5; 64/240] END max_iter=100, penalty=l1, solver=lbfgs, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 5/5; 64/240] START max_iter=100, penalty=l1, solver=lbfgs, tol=0.001........\n",
      "[CV 5/5; 64/240] END max_iter=100, penalty=l1, solver=lbfgs, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 1/5; 65/240] START max_iter=100, penalty=l1, solver=lbfgs, tol=0.0001......."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV 1/5; 65/240] END max_iter=100, penalty=l1, solver=lbfgs, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 2/5; 65/240] START max_iter=100, penalty=l1, solver=lbfgs, tol=0.0001.......\n",
      "[CV 2/5; 65/240] END max_iter=100, penalty=l1, solver=lbfgs, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 3/5; 65/240] START max_iter=100, penalty=l1, solver=lbfgs, tol=0.0001.......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 65/240] END max_iter=100, penalty=l1, solver=lbfgs, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 4/5; 65/240] START max_iter=100, penalty=l1, solver=lbfgs, tol=0.0001.......\n",
      "[CV 4/5; 65/240] END max_iter=100, penalty=l1, solver=lbfgs, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 5/5; 65/240] START max_iter=100, penalty=l1, solver=lbfgs, tol=0.0001.......\n",
      "[CV 5/5; 65/240] END max_iter=100, penalty=l1, solver=lbfgs, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 1/5; 66/240] START max_iter=100, penalty=l1, solver=lbfgs, tol=1e-05........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 66/240] END max_iter=100, penalty=l1, solver=lbfgs, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 2/5; 66/240] START max_iter=100, penalty=l1, solver=lbfgs, tol=1e-05........\n",
      "[CV 2/5; 66/240] END max_iter=100, penalty=l1, solver=lbfgs, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 3/5; 66/240] START max_iter=100, penalty=l1, solver=lbfgs, tol=1e-05........\n",
      "[CV 3/5; 66/240] END max_iter=100, penalty=l1, solver=lbfgs, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 4/5; 66/240] START max_iter=100, penalty=l1, solver=lbfgs, tol=1e-05........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 66/240] END max_iter=100, penalty=l1, solver=lbfgs, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 5/5; 66/240] START max_iter=100, penalty=l1, solver=lbfgs, tol=1e-05........\n",
      "[CV 5/5; 66/240] END max_iter=100, penalty=l1, solver=lbfgs, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 1/5; 67/240] START max_iter=100, penalty=l1, solver=liblinear, tol=0.001....\n",
      "[CV 1/5; 67/240] END max_iter=100, penalty=l1, solver=liblinear, tol=0.001;, score=0.498 total time=   0.7s\n",
      "[CV 2/5; 67/240] START max_iter=100, penalty=l1, solver=liblinear, tol=0.001....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 67/240] END max_iter=100, penalty=l1, solver=liblinear, tol=0.001;, score=0.500 total time=10.8min\n",
      "[CV 3/5; 67/240] START max_iter=100, penalty=l1, solver=liblinear, tol=0.001....\n",
      "[CV 3/5; 67/240] END max_iter=100, penalty=l1, solver=liblinear, tol=0.001;, score=0.499 total time=   0.8s\n",
      "[CV 4/5; 67/240] START max_iter=100, penalty=l1, solver=liblinear, tol=0.001....\n",
      "[CV 4/5; 67/240] END max_iter=100, penalty=l1, solver=liblinear, tol=0.001;, score=0.498 total time=   0.6s\n",
      "[CV 5/5; 67/240] START max_iter=100, penalty=l1, solver=liblinear, tol=0.001....\n",
      "[CV 5/5; 67/240] END max_iter=100, penalty=l1, solver=liblinear, tol=0.001;, score=0.500 total time=   0.6s\n",
      "[CV 1/5; 68/240] START max_iter=100, penalty=l1, solver=liblinear, tol=0.0001...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 68/240] END max_iter=100, penalty=l1, solver=liblinear, tol=0.0001;, score=0.497 total time= 8.4min\n",
      "[CV 2/5; 68/240] START max_iter=100, penalty=l1, solver=liblinear, tol=0.0001...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 68/240] END max_iter=100, penalty=l1, solver=liblinear, tol=0.0001;, score=0.500 total time= 8.1min\n",
      "[CV 3/5; 68/240] START max_iter=100, penalty=l1, solver=liblinear, tol=0.0001...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 68/240] END max_iter=100, penalty=l1, solver=liblinear, tol=0.0001;, score=0.499 total time= 8.3min\n",
      "[CV 4/5; 68/240] START max_iter=100, penalty=l1, solver=liblinear, tol=0.0001...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 68/240] END max_iter=100, penalty=l1, solver=liblinear, tol=0.0001;, score=0.499 total time= 8.1min\n",
      "[CV 5/5; 68/240] START max_iter=100, penalty=l1, solver=liblinear, tol=0.0001...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 68/240] END max_iter=100, penalty=l1, solver=liblinear, tol=0.0001;, score=0.500 total time= 8.4min\n",
      "[CV 1/5; 69/240] START max_iter=100, penalty=l1, solver=liblinear, tol=1e-05....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 69/240] END max_iter=100, penalty=l1, solver=liblinear, tol=1e-05;, score=0.498 total time= 7.9min\n",
      "[CV 2/5; 69/240] START max_iter=100, penalty=l1, solver=liblinear, tol=1e-05....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 69/240] END max_iter=100, penalty=l1, solver=liblinear, tol=1e-05;, score=0.500 total time= 8.2min\n",
      "[CV 3/5; 69/240] START max_iter=100, penalty=l1, solver=liblinear, tol=1e-05....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 69/240] END max_iter=100, penalty=l1, solver=liblinear, tol=1e-05;, score=0.499 total time= 8.2min\n",
      "[CV 4/5; 69/240] START max_iter=100, penalty=l1, solver=liblinear, tol=1e-05....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 69/240] END max_iter=100, penalty=l1, solver=liblinear, tol=1e-05;, score=0.499 total time= 8.0min\n",
      "[CV 5/5; 69/240] START max_iter=100, penalty=l1, solver=liblinear, tol=1e-05....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 69/240] END max_iter=100, penalty=l1, solver=liblinear, tol=1e-05;, score=0.501 total time= 7.9min\n",
      "[CV 1/5; 70/240] START max_iter=100, penalty=l1, solver=sag, tol=0.001..........\n",
      "[CV 1/5; 70/240] END max_iter=100, penalty=l1, solver=sag, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 2/5; 70/240] START max_iter=100, penalty=l1, solver=sag, tol=0.001..........\n",
      "[CV 2/5; 70/240] END max_iter=100, penalty=l1, solver=sag, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 3/5; 70/240] START max_iter=100, penalty=l1, solver=sag, tol=0.001..........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 70/240] END max_iter=100, penalty=l1, solver=sag, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 4/5; 70/240] START max_iter=100, penalty=l1, solver=sag, tol=0.001..........\n",
      "[CV 4/5; 70/240] END max_iter=100, penalty=l1, solver=sag, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 5/5; 70/240] START max_iter=100, penalty=l1, solver=sag, tol=0.001..........\n",
      "[CV 5/5; 70/240] END max_iter=100, penalty=l1, solver=sag, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 1/5; 71/240] START max_iter=100, penalty=l1, solver=sag, tol=0.0001.........\n",
      "[CV 1/5; 71/240] END max_iter=100, penalty=l1, solver=sag, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 2/5; 71/240] START max_iter=100, penalty=l1, solver=sag, tol=0.0001.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 71/240] END max_iter=100, penalty=l1, solver=sag, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 3/5; 71/240] START max_iter=100, penalty=l1, solver=sag, tol=0.0001.........\n",
      "[CV 3/5; 71/240] END max_iter=100, penalty=l1, solver=sag, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 4/5; 71/240] START max_iter=100, penalty=l1, solver=sag, tol=0.0001.........\n",
      "[CV 4/5; 71/240] END max_iter=100, penalty=l1, solver=sag, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 5/5; 71/240] START max_iter=100, penalty=l1, solver=sag, tol=0.0001.........\n",
      "[CV 5/5; 71/240] END max_iter=100, penalty=l1, solver=sag, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 1/5; 72/240] START max_iter=100, penalty=l1, solver=sag, tol=1e-05..........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 72/240] END max_iter=100, penalty=l1, solver=sag, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 2/5; 72/240] START max_iter=100, penalty=l1, solver=sag, tol=1e-05..........\n",
      "[CV 2/5; 72/240] END max_iter=100, penalty=l1, solver=sag, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 3/5; 72/240] START max_iter=100, penalty=l1, solver=sag, tol=1e-05..........\n",
      "[CV 3/5; 72/240] END max_iter=100, penalty=l1, solver=sag, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 4/5; 72/240] START max_iter=100, penalty=l1, solver=sag, tol=1e-05..........\n",
      "[CV 4/5; 72/240] END max_iter=100, penalty=l1, solver=sag, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 5/5; 72/240] START max_iter=100, penalty=l1, solver=sag, tol=1e-05..........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 72/240] END max_iter=100, penalty=l1, solver=sag, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 1/5; 73/240] START max_iter=100, penalty=l1, solver=saga, tol=0.001.........\n",
      "[CV 1/5; 73/240] END max_iter=100, penalty=l1, solver=saga, tol=0.001;, score=0.499 total time=  36.8s\n",
      "[CV 2/5; 73/240] START max_iter=100, penalty=l1, solver=saga, tol=0.001.........\n",
      "[CV 2/5; 73/240] END max_iter=100, penalty=l1, solver=saga, tol=0.001;, score=0.500 total time=  35.4s\n",
      "[CV 3/5; 73/240] START max_iter=100, penalty=l1, solver=saga, tol=0.001.........\n",
      "[CV 3/5; 73/240] END max_iter=100, penalty=l1, solver=saga, tol=0.001;, score=0.500 total time=  36.5s\n",
      "[CV 4/5; 73/240] START max_iter=100, penalty=l1, solver=saga, tol=0.001.........\n",
      "[CV 4/5; 73/240] END max_iter=100, penalty=l1, solver=saga, tol=0.001;, score=0.499 total time=  35.4s\n",
      "[CV 5/5; 73/240] START max_iter=100, penalty=l1, solver=saga, tol=0.001.........\n",
      "[CV 5/5; 73/240] END max_iter=100, penalty=l1, solver=saga, tol=0.001;, score=0.500 total time=  36.7s\n",
      "[CV 1/5; 74/240] START max_iter=100, penalty=l1, solver=saga, tol=0.0001........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 74/240] END max_iter=100, penalty=l1, solver=saga, tol=0.0001;, score=0.499 total time=  36.3s\n",
      "[CV 2/5; 74/240] START max_iter=100, penalty=l1, solver=saga, tol=0.0001........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 74/240] END max_iter=100, penalty=l1, solver=saga, tol=0.0001;, score=0.500 total time=  35.5s\n",
      "[CV 3/5; 74/240] START max_iter=100, penalty=l1, solver=saga, tol=0.0001........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 74/240] END max_iter=100, penalty=l1, solver=saga, tol=0.0001;, score=0.500 total time=  38.1s\n",
      "[CV 4/5; 74/240] START max_iter=100, penalty=l1, solver=saga, tol=0.0001........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 74/240] END max_iter=100, penalty=l1, solver=saga, tol=0.0001;, score=0.499 total time=  38.3s\n",
      "[CV 5/5; 74/240] START max_iter=100, penalty=l1, solver=saga, tol=0.0001........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 74/240] END max_iter=100, penalty=l1, solver=saga, tol=0.0001;, score=0.500 total time=  38.0s\n",
      "[CV 1/5; 75/240] START max_iter=100, penalty=l1, solver=saga, tol=1e-05.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 75/240] END max_iter=100, penalty=l1, solver=saga, tol=1e-05;, score=0.499 total time=  38.6s\n",
      "[CV 2/5; 75/240] START max_iter=100, penalty=l1, solver=saga, tol=1e-05.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 75/240] END max_iter=100, penalty=l1, solver=saga, tol=1e-05;, score=0.500 total time=  39.6s\n",
      "[CV 3/5; 75/240] START max_iter=100, penalty=l1, solver=saga, tol=1e-05.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 75/240] END max_iter=100, penalty=l1, solver=saga, tol=1e-05;, score=0.500 total time=  40.6s\n",
      "[CV 4/5; 75/240] START max_iter=100, penalty=l1, solver=saga, tol=1e-05.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 75/240] END max_iter=100, penalty=l1, solver=saga, tol=1e-05;, score=0.499 total time=  41.6s\n",
      "[CV 5/5; 75/240] START max_iter=100, penalty=l1, solver=saga, tol=1e-05.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 75/240] END max_iter=100, penalty=l1, solver=saga, tol=1e-05;, score=0.500 total time=  40.5s\n",
      "[CV 1/5; 76/240] START max_iter=100, penalty=l2, solver=newton-cg, tol=0.001....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"newton-cg failed to converge. Increase the \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 76/240] END max_iter=100, penalty=l2, solver=newton-cg, tol=0.001;, score=0.497 total time= 3.7min\n",
      "[CV 2/5; 76/240] START max_iter=100, penalty=l2, solver=newton-cg, tol=0.001....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"newton-cg failed to converge. Increase the \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 76/240] END max_iter=100, penalty=l2, solver=newton-cg, tol=0.001;, score=0.500 total time= 3.6min\n",
      "[CV 3/5; 76/240] START max_iter=100, penalty=l2, solver=newton-cg, tol=0.001....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"newton-cg failed to converge. Increase the \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 76/240] END max_iter=100, penalty=l2, solver=newton-cg, tol=0.001;, score=0.499 total time= 3.3min\n",
      "[CV 4/5; 76/240] START max_iter=100, penalty=l2, solver=newton-cg, tol=0.001....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"newton-cg failed to converge. Increase the \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 76/240] END max_iter=100, penalty=l2, solver=newton-cg, tol=0.001;, score=0.499 total time= 3.9min\n",
      "[CV 5/5; 76/240] START max_iter=100, penalty=l2, solver=newton-cg, tol=0.001....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"newton-cg failed to converge. Increase the \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 76/240] END max_iter=100, penalty=l2, solver=newton-cg, tol=0.001;, score=0.500 total time= 3.7min\n",
      "[CV 1/5; 77/240] START max_iter=100, penalty=l2, solver=newton-cg, tol=0.0001...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"newton-cg failed to converge. Increase the \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 77/240] END max_iter=100, penalty=l2, solver=newton-cg, tol=0.0001;, score=0.497 total time= 3.8min\n",
      "[CV 2/5; 77/240] START max_iter=100, penalty=l2, solver=newton-cg, tol=0.0001...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"newton-cg failed to converge. Increase the \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 77/240] END max_iter=100, penalty=l2, solver=newton-cg, tol=0.0001;, score=0.500 total time= 3.7min\n",
      "[CV 3/5; 77/240] START max_iter=100, penalty=l2, solver=newton-cg, tol=0.0001...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"newton-cg failed to converge. Increase the \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 77/240] END max_iter=100, penalty=l2, solver=newton-cg, tol=0.0001;, score=0.499 total time= 3.8min\n",
      "[CV 4/5; 77/240] START max_iter=100, penalty=l2, solver=newton-cg, tol=0.0001...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"newton-cg failed to converge. Increase the \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 77/240] END max_iter=100, penalty=l2, solver=newton-cg, tol=0.0001;, score=0.499 total time= 3.6min\n",
      "[CV 5/5; 77/240] START max_iter=100, penalty=l2, solver=newton-cg, tol=0.0001...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"newton-cg failed to converge. Increase the \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 77/240] END max_iter=100, penalty=l2, solver=newton-cg, tol=0.0001;, score=0.500 total time= 3.4min\n",
      "[CV 1/5; 78/240] START max_iter=100, penalty=l2, solver=newton-cg, tol=1e-05....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"newton-cg failed to converge. Increase the \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 78/240] END max_iter=100, penalty=l2, solver=newton-cg, tol=1e-05;, score=0.497 total time= 3.7min\n",
      "[CV 2/5; 78/240] START max_iter=100, penalty=l2, solver=newton-cg, tol=1e-05....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"newton-cg failed to converge. Increase the \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 78/240] END max_iter=100, penalty=l2, solver=newton-cg, tol=1e-05;, score=0.500 total time= 3.6min\n",
      "[CV 3/5; 78/240] START max_iter=100, penalty=l2, solver=newton-cg, tol=1e-05....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"newton-cg failed to converge. Increase the \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 78/240] END max_iter=100, penalty=l2, solver=newton-cg, tol=1e-05;, score=0.499 total time= 3.4min\n",
      "[CV 4/5; 78/240] START max_iter=100, penalty=l2, solver=newton-cg, tol=1e-05....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"newton-cg failed to converge. Increase the \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 78/240] END max_iter=100, penalty=l2, solver=newton-cg, tol=1e-05;, score=0.499 total time= 3.8min\n",
      "[CV 5/5; 78/240] START max_iter=100, penalty=l2, solver=newton-cg, tol=1e-05....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"newton-cg failed to converge. Increase the \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 78/240] END max_iter=100, penalty=l2, solver=newton-cg, tol=1e-05;, score=0.500 total time= 3.5min\n",
      "[CV 1/5; 79/240] START max_iter=100, penalty=l2, solver=lbfgs, tol=0.001........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 79/240] END max_iter=100, penalty=l2, solver=lbfgs, tol=0.001;, score=0.498 total time=   2.1s\n",
      "[CV 2/5; 79/240] START max_iter=100, penalty=l2, solver=lbfgs, tol=0.001........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 79/240] END max_iter=100, penalty=l2, solver=lbfgs, tol=0.001;, score=0.500 total time=   2.0s\n",
      "[CV 3/5; 79/240] START max_iter=100, penalty=l2, solver=lbfgs, tol=0.001........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 79/240] END max_iter=100, penalty=l2, solver=lbfgs, tol=0.001;, score=0.500 total time=   2.1s\n",
      "[CV 4/5; 79/240] START max_iter=100, penalty=l2, solver=lbfgs, tol=0.001........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 79/240] END max_iter=100, penalty=l2, solver=lbfgs, tol=0.001;, score=0.499 total time=   2.1s\n",
      "[CV 5/5; 79/240] START max_iter=100, penalty=l2, solver=lbfgs, tol=0.001........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 79/240] END max_iter=100, penalty=l2, solver=lbfgs, tol=0.001;, score=0.500 total time=   2.0s\n",
      "[CV 1/5; 80/240] START max_iter=100, penalty=l2, solver=lbfgs, tol=0.0001.......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 80/240] END max_iter=100, penalty=l2, solver=lbfgs, tol=0.0001;, score=0.498 total time=   2.0s\n",
      "[CV 2/5; 80/240] START max_iter=100, penalty=l2, solver=lbfgs, tol=0.0001.......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 80/240] END max_iter=100, penalty=l2, solver=lbfgs, tol=0.0001;, score=0.500 total time=   2.0s\n",
      "[CV 3/5; 80/240] START max_iter=100, penalty=l2, solver=lbfgs, tol=0.0001.......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 80/240] END max_iter=100, penalty=l2, solver=lbfgs, tol=0.0001;, score=0.500 total time=   2.1s\n",
      "[CV 4/5; 80/240] START max_iter=100, penalty=l2, solver=lbfgs, tol=0.0001.......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 80/240] END max_iter=100, penalty=l2, solver=lbfgs, tol=0.0001;, score=0.499 total time=   2.1s\n",
      "[CV 5/5; 80/240] START max_iter=100, penalty=l2, solver=lbfgs, tol=0.0001.......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 80/240] END max_iter=100, penalty=l2, solver=lbfgs, tol=0.0001;, score=0.500 total time=   2.1s\n",
      "[CV 1/5; 81/240] START max_iter=100, penalty=l2, solver=lbfgs, tol=1e-05........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 81/240] END max_iter=100, penalty=l2, solver=lbfgs, tol=1e-05;, score=0.498 total time=   2.0s\n",
      "[CV 2/5; 81/240] START max_iter=100, penalty=l2, solver=lbfgs, tol=1e-05........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 81/240] END max_iter=100, penalty=l2, solver=lbfgs, tol=1e-05;, score=0.500 total time=   2.0s\n",
      "[CV 3/5; 81/240] START max_iter=100, penalty=l2, solver=lbfgs, tol=1e-05........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 81/240] END max_iter=100, penalty=l2, solver=lbfgs, tol=1e-05;, score=0.500 total time=   2.2s\n",
      "[CV 4/5; 81/240] START max_iter=100, penalty=l2, solver=lbfgs, tol=1e-05........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 81/240] END max_iter=100, penalty=l2, solver=lbfgs, tol=1e-05;, score=0.499 total time=   2.2s\n",
      "[CV 5/5; 81/240] START max_iter=100, penalty=l2, solver=lbfgs, tol=1e-05........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 81/240] END max_iter=100, penalty=l2, solver=lbfgs, tol=1e-05;, score=0.500 total time=   2.1s\n",
      "[CV 1/5; 82/240] START max_iter=100, penalty=l2, solver=liblinear, tol=0.001....\n",
      "[CV 1/5; 82/240] END max_iter=100, penalty=l2, solver=liblinear, tol=0.001;, score=0.498 total time=  17.0s\n",
      "[CV 2/5; 82/240] START max_iter=100, penalty=l2, solver=liblinear, tol=0.001....\n",
      "[CV 2/5; 82/240] END max_iter=100, penalty=l2, solver=liblinear, tol=0.001;, score=0.499 total time=  14.6s\n",
      "[CV 3/5; 82/240] START max_iter=100, penalty=l2, solver=liblinear, tol=0.001....\n",
      "[CV 3/5; 82/240] END max_iter=100, penalty=l2, solver=liblinear, tol=0.001;, score=0.499 total time=  14.9s\n",
      "[CV 4/5; 82/240] START max_iter=100, penalty=l2, solver=liblinear, tol=0.001....\n",
      "[CV 4/5; 82/240] END max_iter=100, penalty=l2, solver=liblinear, tol=0.001;, score=0.499 total time=  31.1s\n",
      "[CV 5/5; 82/240] START max_iter=100, penalty=l2, solver=liblinear, tol=0.001....\n",
      "[CV 5/5; 82/240] END max_iter=100, penalty=l2, solver=liblinear, tol=0.001;, score=0.500 total time=  24.1s\n",
      "[CV 1/5; 83/240] START max_iter=100, penalty=l2, solver=liblinear, tol=0.0001...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 83/240] END max_iter=100, penalty=l2, solver=liblinear, tol=0.0001;, score=0.497 total time= 3.1min\n",
      "[CV 2/5; 83/240] START max_iter=100, penalty=l2, solver=liblinear, tol=0.0001...\n",
      "[CV 2/5; 83/240] END max_iter=100, penalty=l2, solver=liblinear, tol=0.0001;, score=0.499 total time= 5.2min\n",
      "[CV 3/5; 83/240] START max_iter=100, penalty=l2, solver=liblinear, tol=0.0001...\n",
      "[CV 3/5; 83/240] END max_iter=100, penalty=l2, solver=liblinear, tol=0.0001;, score=0.499 total time= 4.3min\n",
      "[CV 4/5; 83/240] START max_iter=100, penalty=l2, solver=liblinear, tol=0.0001...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 83/240] END max_iter=100, penalty=l2, solver=liblinear, tol=0.0001;, score=0.499 total time= 2.6min\n",
      "[CV 5/5; 83/240] START max_iter=100, penalty=l2, solver=liblinear, tol=0.0001...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 83/240] END max_iter=100, penalty=l2, solver=liblinear, tol=0.0001;, score=0.500 total time= 1.4min\n",
      "[CV 1/5; 84/240] START max_iter=100, penalty=l2, solver=liblinear, tol=1e-05....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 84/240] END max_iter=100, penalty=l2, solver=liblinear, tol=1e-05;, score=0.497 total time= 3.0min\n",
      "[CV 2/5; 84/240] START max_iter=100, penalty=l2, solver=liblinear, tol=1e-05....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 84/240] END max_iter=100, penalty=l2, solver=liblinear, tol=1e-05;, score=0.499 total time= 7.6min\n",
      "[CV 3/5; 84/240] START max_iter=100, penalty=l2, solver=liblinear, tol=1e-05....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 84/240] END max_iter=100, penalty=l2, solver=liblinear, tol=1e-05;, score=0.499 total time= 7.3min\n",
      "[CV 4/5; 84/240] START max_iter=100, penalty=l2, solver=liblinear, tol=1e-05....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 84/240] END max_iter=100, penalty=l2, solver=liblinear, tol=1e-05;, score=0.499 total time= 2.6min\n",
      "[CV 5/5; 84/240] START max_iter=100, penalty=l2, solver=liblinear, tol=1e-05....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 84/240] END max_iter=100, penalty=l2, solver=liblinear, tol=1e-05;, score=0.500 total time= 1.5min\n",
      "[CV 1/5; 85/240] START max_iter=100, penalty=l2, solver=sag, tol=0.001..........\n",
      "[CV 1/5; 85/240] END max_iter=100, penalty=l2, solver=sag, tol=0.001;, score=0.499 total time=  11.3s\n",
      "[CV 2/5; 85/240] START max_iter=100, penalty=l2, solver=sag, tol=0.001..........\n",
      "[CV 2/5; 85/240] END max_iter=100, penalty=l2, solver=sag, tol=0.001;, score=0.500 total time=  11.2s\n",
      "[CV 3/5; 85/240] START max_iter=100, penalty=l2, solver=sag, tol=0.001..........\n",
      "[CV 3/5; 85/240] END max_iter=100, penalty=l2, solver=sag, tol=0.001;, score=0.500 total time=  11.7s\n",
      "[CV 4/5; 85/240] START max_iter=100, penalty=l2, solver=sag, tol=0.001..........\n",
      "[CV 4/5; 85/240] END max_iter=100, penalty=l2, solver=sag, tol=0.001;, score=0.499 total time=  11.6s\n",
      "[CV 5/5; 85/240] START max_iter=100, penalty=l2, solver=sag, tol=0.001..........\n",
      "[CV 5/5; 85/240] END max_iter=100, penalty=l2, solver=sag, tol=0.001;, score=0.500 total time=  11.5s\n",
      "[CV 1/5; 86/240] START max_iter=100, penalty=l2, solver=sag, tol=0.0001.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 86/240] END max_iter=100, penalty=l2, solver=sag, tol=0.0001;, score=0.499 total time=  20.2s\n",
      "[CV 2/5; 86/240] START max_iter=100, penalty=l2, solver=sag, tol=0.0001.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 86/240] END max_iter=100, penalty=l2, solver=sag, tol=0.0001;, score=0.499 total time=  20.1s\n",
      "[CV 3/5; 86/240] START max_iter=100, penalty=l2, solver=sag, tol=0.0001.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 86/240] END max_iter=100, penalty=l2, solver=sag, tol=0.0001;, score=0.500 total time=  20.0s\n",
      "[CV 4/5; 86/240] START max_iter=100, penalty=l2, solver=sag, tol=0.0001.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 86/240] END max_iter=100, penalty=l2, solver=sag, tol=0.0001;, score=0.500 total time=  20.3s\n",
      "[CV 5/5; 86/240] START max_iter=100, penalty=l2, solver=sag, tol=0.0001.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 86/240] END max_iter=100, penalty=l2, solver=sag, tol=0.0001;, score=0.500 total time=  20.5s\n",
      "[CV 1/5; 87/240] START max_iter=100, penalty=l2, solver=sag, tol=1e-05..........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 87/240] END max_iter=100, penalty=l2, solver=sag, tol=1e-05;, score=0.499 total time=  20.0s\n",
      "[CV 2/5; 87/240] START max_iter=100, penalty=l2, solver=sag, tol=1e-05..........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 87/240] END max_iter=100, penalty=l2, solver=sag, tol=1e-05;, score=0.499 total time=  20.3s\n",
      "[CV 3/5; 87/240] START max_iter=100, penalty=l2, solver=sag, tol=1e-05..........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 87/240] END max_iter=100, penalty=l2, solver=sag, tol=1e-05;, score=0.500 total time=  20.1s\n",
      "[CV 4/5; 87/240] START max_iter=100, penalty=l2, solver=sag, tol=1e-05..........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 87/240] END max_iter=100, penalty=l2, solver=sag, tol=1e-05;, score=0.500 total time=  20.0s\n",
      "[CV 5/5; 87/240] START max_iter=100, penalty=l2, solver=sag, tol=1e-05..........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 87/240] END max_iter=100, penalty=l2, solver=sag, tol=1e-05;, score=0.500 total time=  20.3s\n",
      "[CV 1/5; 88/240] START max_iter=100, penalty=l2, solver=saga, tol=0.001.........\n",
      "[CV 1/5; 88/240] END max_iter=100, penalty=l2, solver=saga, tol=0.001;, score=0.499 total time=  21.9s\n",
      "[CV 2/5; 88/240] START max_iter=100, penalty=l2, solver=saga, tol=0.001.........\n",
      "[CV 2/5; 88/240] END max_iter=100, penalty=l2, solver=saga, tol=0.001;, score=0.500 total time=  21.5s\n",
      "[CV 3/5; 88/240] START max_iter=100, penalty=l2, solver=saga, tol=0.001.........\n",
      "[CV 3/5; 88/240] END max_iter=100, penalty=l2, solver=saga, tol=0.001;, score=0.500 total time=  22.1s\n",
      "[CV 4/5; 88/240] START max_iter=100, penalty=l2, solver=saga, tol=0.001.........\n",
      "[CV 4/5; 88/240] END max_iter=100, penalty=l2, solver=saga, tol=0.001;, score=0.499 total time=  22.1s\n",
      "[CV 5/5; 88/240] START max_iter=100, penalty=l2, solver=saga, tol=0.001.........\n",
      "[CV 5/5; 88/240] END max_iter=100, penalty=l2, solver=saga, tol=0.001;, score=0.500 total time=  23.2s\n",
      "[CV 1/5; 89/240] START max_iter=100, penalty=l2, solver=saga, tol=0.0001........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 89/240] END max_iter=100, penalty=l2, solver=saga, tol=0.0001;, score=0.499 total time=  24.9s\n",
      "[CV 2/5; 89/240] START max_iter=100, penalty=l2, solver=saga, tol=0.0001........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 89/240] END max_iter=100, penalty=l2, solver=saga, tol=0.0001;, score=0.500 total time=  29.0s\n",
      "[CV 3/5; 89/240] START max_iter=100, penalty=l2, solver=saga, tol=0.0001........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 89/240] END max_iter=100, penalty=l2, solver=saga, tol=0.0001;, score=0.500 total time=  28.8s\n",
      "[CV 4/5; 89/240] START max_iter=100, penalty=l2, solver=saga, tol=0.0001........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 89/240] END max_iter=100, penalty=l2, solver=saga, tol=0.0001;, score=0.499 total time=  27.0s\n",
      "[CV 5/5; 89/240] START max_iter=100, penalty=l2, solver=saga, tol=0.0001........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 89/240] END max_iter=100, penalty=l2, solver=saga, tol=0.0001;, score=0.500 total time=  27.4s\n",
      "[CV 1/5; 90/240] START max_iter=100, penalty=l2, solver=saga, tol=1e-05.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 90/240] END max_iter=100, penalty=l2, solver=saga, tol=1e-05;, score=0.499 total time=  24.6s\n",
      "[CV 2/5; 90/240] START max_iter=100, penalty=l2, solver=saga, tol=1e-05.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 90/240] END max_iter=100, penalty=l2, solver=saga, tol=1e-05;, score=0.500 total time=  26.2s\n",
      "[CV 3/5; 90/240] START max_iter=100, penalty=l2, solver=saga, tol=1e-05.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 90/240] END max_iter=100, penalty=l2, solver=saga, tol=1e-05;, score=0.500 total time=  25.7s\n",
      "[CV 4/5; 90/240] START max_iter=100, penalty=l2, solver=saga, tol=1e-05.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 90/240] END max_iter=100, penalty=l2, solver=saga, tol=1e-05;, score=0.499 total time=  26.0s\n",
      "[CV 5/5; 90/240] START max_iter=100, penalty=l2, solver=saga, tol=1e-05.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 90/240] END max_iter=100, penalty=l2, solver=saga, tol=1e-05;, score=0.500 total time=  26.4s\n",
      "[CV 1/5; 91/240] START max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.001\n",
      "[CV 1/5; 91/240] END max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 2/5; 91/240] START max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.001\n",
      "[CV 2/5; 91/240] END max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.001;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 91/240] START max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.001\n",
      "[CV 3/5; 91/240] END max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 4/5; 91/240] START max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.001\n",
      "[CV 4/5; 91/240] END max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 5/5; 91/240] START max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 91/240] END max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 1/5; 92/240] START max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.0001\n",
      "[CV 1/5; 92/240] END max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 2/5; 92/240] START max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.0001\n",
      "[CV 2/5; 92/240] END max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 3/5; 92/240] START max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 92/240] END max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 4/5; 92/240] START max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.0001\n",
      "[CV 4/5; 92/240] END max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 5/5; 92/240] START max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.0001\n",
      "[CV 5/5; 92/240] END max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 1/5; 93/240] START max_iter=100, penalty=elasticnet, solver=newton-cg, tol=1e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV 1/5; 93/240] END max_iter=100, penalty=elasticnet, solver=newton-cg, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 2/5; 93/240] START max_iter=100, penalty=elasticnet, solver=newton-cg, tol=1e-05\n",
      "[CV 2/5; 93/240] END max_iter=100, penalty=elasticnet, solver=newton-cg, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 3/5; 93/240] START max_iter=100, penalty=elasticnet, solver=newton-cg, tol=1e-05\n",
      "[CV 3/5; 93/240] END max_iter=100, penalty=elasticnet, solver=newton-cg, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 4/5; 93/240] START max_iter=100, penalty=elasticnet, solver=newton-cg, tol=1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 93/240] END max_iter=100, penalty=elasticnet, solver=newton-cg, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 5/5; 93/240] START max_iter=100, penalty=elasticnet, solver=newton-cg, tol=1e-05\n",
      "[CV 5/5; 93/240] END max_iter=100, penalty=elasticnet, solver=newton-cg, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 1/5; 94/240] START max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.001\n",
      "[CV 1/5; 94/240] END max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.001;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 94/240] START max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.001\n",
      "[CV 2/5; 94/240] END max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 3/5; 94/240] START max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.001\n",
      "[CV 3/5; 94/240] END max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 4/5; 94/240] START max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.001\n",
      "[CV 4/5; 94/240] END max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 5/5; 94/240] START max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.001"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV 5/5; 94/240] END max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 1/5; 95/240] START max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.0001\n",
      "[CV 1/5; 95/240] END max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 2/5; 95/240] START max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.0001\n",
      "[CV 2/5; 95/240] END max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 3/5; 95/240] START max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 95/240] END max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 4/5; 95/240] START max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.0001\n",
      "[CV 4/5; 95/240] END max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 5/5; 95/240] START max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.0001\n",
      "[CV 5/5; 95/240] END max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 1/5; 96/240] START max_iter=100, penalty=elasticnet, solver=lbfgs, tol=1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 96/240] END max_iter=100, penalty=elasticnet, solver=lbfgs, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 2/5; 96/240] START max_iter=100, penalty=elasticnet, solver=lbfgs, tol=1e-05\n",
      "[CV 2/5; 96/240] END max_iter=100, penalty=elasticnet, solver=lbfgs, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 3/5; 96/240] START max_iter=100, penalty=elasticnet, solver=lbfgs, tol=1e-05\n",
      "[CV 3/5; 96/240] END max_iter=100, penalty=elasticnet, solver=lbfgs, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 4/5; 96/240] START max_iter=100, penalty=elasticnet, solver=lbfgs, tol=1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 96/240] END max_iter=100, penalty=elasticnet, solver=lbfgs, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 5/5; 96/240] START max_iter=100, penalty=elasticnet, solver=lbfgs, tol=1e-05\n",
      "[CV 5/5; 96/240] END max_iter=100, penalty=elasticnet, solver=lbfgs, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 1/5; 97/240] START max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.001\n",
      "[CV 1/5; 97/240] END max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.001;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 97/240] START max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.001\n",
      "[CV 2/5; 97/240] END max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 3/5; 97/240] START max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.001\n",
      "[CV 3/5; 97/240] END max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 4/5; 97/240] START max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.001\n",
      "[CV 4/5; 97/240] END max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 5/5; 97/240] START max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 97/240] END max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 1/5; 98/240] START max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.0001\n",
      "[CV 1/5; 98/240] END max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 2/5; 98/240] START max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.0001\n",
      "[CV 2/5; 98/240] END max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 3/5; 98/240] START max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 98/240] END max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 4/5; 98/240] START max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.0001\n",
      "[CV 4/5; 98/240] END max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 5/5; 98/240] START max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.0001\n",
      "[CV 5/5; 98/240] END max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 1/5; 99/240] START max_iter=100, penalty=elasticnet, solver=liblinear, tol=1e-05\n",
      "[CV 1/5; 99/240] END max_iter=100, penalty=elasticnet, solver=liblinear, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 2/5; 99/240] START max_iter=100, penalty=elasticnet, solver=liblinear, tol=1e-05\n",
      "[CV 2/5; 99/240] END max_iter=100, penalty=elasticnet, solver=liblinear, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 3/5; 99/240] START max_iter=100, penalty=elasticnet, solver=liblinear, tol=1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 99/240] END max_iter=100, penalty=elasticnet, solver=liblinear, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 4/5; 99/240] START max_iter=100, penalty=elasticnet, solver=liblinear, tol=1e-05\n",
      "[CV 4/5; 99/240] END max_iter=100, penalty=elasticnet, solver=liblinear, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 5/5; 99/240] START max_iter=100, penalty=elasticnet, solver=liblinear, tol=1e-05\n",
      "[CV 5/5; 99/240] END max_iter=100, penalty=elasticnet, solver=liblinear, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 1/5; 100/240] START max_iter=100, penalty=elasticnet, solver=sag, tol=0.001."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV 1/5; 100/240] END max_iter=100, penalty=elasticnet, solver=sag, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 2/5; 100/240] START max_iter=100, penalty=elasticnet, solver=sag, tol=0.001.\n",
      "[CV 2/5; 100/240] END max_iter=100, penalty=elasticnet, solver=sag, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 3/5; 100/240] START max_iter=100, penalty=elasticnet, solver=sag, tol=0.001."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV 3/5; 100/240] END max_iter=100, penalty=elasticnet, solver=sag, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 4/5; 100/240] START max_iter=100, penalty=elasticnet, solver=sag, tol=0.001.\n",
      "[CV 4/5; 100/240] END max_iter=100, penalty=elasticnet, solver=sag, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 5/5; 100/240] START max_iter=100, penalty=elasticnet, solver=sag, tol=0.001.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 100/240] END max_iter=100, penalty=elasticnet, solver=sag, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 1/5; 101/240] START max_iter=100, penalty=elasticnet, solver=sag, tol=0.0001\n",
      "[CV 1/5; 101/240] END max_iter=100, penalty=elasticnet, solver=sag, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 2/5; 101/240] START max_iter=100, penalty=elasticnet, solver=sag, tol=0.0001\n",
      "[CV 2/5; 101/240] END max_iter=100, penalty=elasticnet, solver=sag, tol=0.0001;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 101/240] START max_iter=100, penalty=elasticnet, solver=sag, tol=0.0001\n",
      "[CV 3/5; 101/240] END max_iter=100, penalty=elasticnet, solver=sag, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 4/5; 101/240] START max_iter=100, penalty=elasticnet, solver=sag, tol=0.0001\n",
      "[CV 4/5; 101/240] END max_iter=100, penalty=elasticnet, solver=sag, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 5/5; 101/240] START max_iter=100, penalty=elasticnet, solver=sag, tol=0.0001\n",
      "[CV 5/5; 101/240] END max_iter=100, penalty=elasticnet, solver=sag, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 1/5; 102/240] START max_iter=100, penalty=elasticnet, solver=sag, tol=1e-05.\n",
      "[CV 1/5; 102/240] END max_iter=100, penalty=elasticnet, solver=sag, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 2/5; 102/240] START max_iter=100, penalty=elasticnet, solver=sag, tol=1e-05.\n",
      "[CV 2/5; 102/240] END max_iter=100, penalty=elasticnet, solver=sag, tol=1e-05;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 102/240] START max_iter=100, penalty=elasticnet, solver=sag, tol=1e-05.\n",
      "[CV 3/5; 102/240] END max_iter=100, penalty=elasticnet, solver=sag, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 4/5; 102/240] START max_iter=100, penalty=elasticnet, solver=sag, tol=1e-05.\n",
      "[CV 4/5; 102/240] END max_iter=100, penalty=elasticnet, solver=sag, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 5/5; 102/240] START max_iter=100, penalty=elasticnet, solver=sag, tol=1e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1314, in fit\n",
      "    raise ValueError(\"l1_ratio must be between 0 and 1;\"\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 102/240] END max_iter=100, penalty=elasticnet, solver=sag, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 1/5; 103/240] START max_iter=100, penalty=elasticnet, solver=saga, tol=0.001\n",
      "[CV 1/5; 103/240] END max_iter=100, penalty=elasticnet, solver=saga, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 2/5; 103/240] START max_iter=100, penalty=elasticnet, solver=saga, tol=0.001\n",
      "[CV 2/5; 103/240] END max_iter=100, penalty=elasticnet, solver=saga, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 3/5; 103/240] START max_iter=100, penalty=elasticnet, solver=saga, tol=0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1314, in fit\n",
      "    raise ValueError(\"l1_ratio must be between 0 and 1;\"\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1314, in fit\n",
      "    raise ValueError(\"l1_ratio must be between 0 and 1;\"\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1314, in fit\n",
      "    raise ValueError(\"l1_ratio must be between 0 and 1;\"\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 103/240] END max_iter=100, penalty=elasticnet, solver=saga, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 4/5; 103/240] START max_iter=100, penalty=elasticnet, solver=saga, tol=0.001\n",
      "[CV 4/5; 103/240] END max_iter=100, penalty=elasticnet, solver=saga, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 5/5; 103/240] START max_iter=100, penalty=elasticnet, solver=saga, tol=0.001\n",
      "[CV 5/5; 103/240] END max_iter=100, penalty=elasticnet, solver=saga, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 1/5; 104/240] START max_iter=100, penalty=elasticnet, solver=saga, tol=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1314, in fit\n",
      "    raise ValueError(\"l1_ratio must be between 0 and 1;\"\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1314, in fit\n",
      "    raise ValueError(\"l1_ratio must be between 0 and 1;\"\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1314, in fit\n",
      "    raise ValueError(\"l1_ratio must be between 0 and 1;\"\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 104/240] END max_iter=100, penalty=elasticnet, solver=saga, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 2/5; 104/240] START max_iter=100, penalty=elasticnet, solver=saga, tol=0.0001\n",
      "[CV 2/5; 104/240] END max_iter=100, penalty=elasticnet, solver=saga, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 3/5; 104/240] START max_iter=100, penalty=elasticnet, solver=saga, tol=0.0001\n",
      "[CV 3/5; 104/240] END max_iter=100, penalty=elasticnet, solver=saga, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 4/5; 104/240] START max_iter=100, penalty=elasticnet, solver=saga, tol=0.0001"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1314, in fit\n",
      "    raise ValueError(\"l1_ratio must be between 0 and 1;\"\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1314, in fit\n",
      "    raise ValueError(\"l1_ratio must be between 0 and 1;\"\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1314, in fit\n",
      "    raise ValueError(\"l1_ratio must be between 0 and 1;\"\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV 4/5; 104/240] END max_iter=100, penalty=elasticnet, solver=saga, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 5/5; 104/240] START max_iter=100, penalty=elasticnet, solver=saga, tol=0.0001\n",
      "[CV 5/5; 104/240] END max_iter=100, penalty=elasticnet, solver=saga, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 1/5; 105/240] START max_iter=100, penalty=elasticnet, solver=saga, tol=1e-05\n",
      "[CV 1/5; 105/240] END max_iter=100, penalty=elasticnet, solver=saga, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 2/5; 105/240] START max_iter=100, penalty=elasticnet, solver=saga, tol=1e-05\n",
      "[CV 2/5; 105/240] END max_iter=100, penalty=elasticnet, solver=saga, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 3/5; 105/240] START max_iter=100, penalty=elasticnet, solver=saga, tol=1e-05\n",
      "[CV 3/5; 105/240] END max_iter=100, penalty=elasticnet, solver=saga, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 4/5; 105/240] START max_iter=100, penalty=elasticnet, solver=saga, tol=1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1314, in fit\n",
      "    raise ValueError(\"l1_ratio must be between 0 and 1;\"\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1314, in fit\n",
      "    raise ValueError(\"l1_ratio must be between 0 and 1;\"\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1314, in fit\n",
      "    raise ValueError(\"l1_ratio must be between 0 and 1;\"\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1314, in fit\n",
      "    raise ValueError(\"l1_ratio must be between 0 and 1;\"\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1314, in fit\n",
      "    raise ValueError(\"l1_ratio must be between 0 and 1;\"\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 105/240] END max_iter=100, penalty=elasticnet, solver=saga, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 5/5; 105/240] START max_iter=100, penalty=elasticnet, solver=saga, tol=1e-05\n",
      "[CV 5/5; 105/240] END max_iter=100, penalty=elasticnet, solver=saga, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 1/5; 106/240] START max_iter=100, penalty=none, solver=newton-cg, tol=0.001.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"newton-cg failed to converge. Increase the \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 106/240] END max_iter=100, penalty=none, solver=newton-cg, tol=0.001;, score=0.497 total time= 5.0min\n",
      "[CV 2/5; 106/240] START max_iter=100, penalty=none, solver=newton-cg, tol=0.001.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"newton-cg failed to converge. Increase the \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 106/240] END max_iter=100, penalty=none, solver=newton-cg, tol=0.001;, score=0.500 total time= 5.0min\n",
      "[CV 3/5; 106/240] START max_iter=100, penalty=none, solver=newton-cg, tol=0.001.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"newton-cg failed to converge. Increase the \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 106/240] END max_iter=100, penalty=none, solver=newton-cg, tol=0.001;, score=0.499 total time= 4.9min\n",
      "[CV 4/5; 106/240] START max_iter=100, penalty=none, solver=newton-cg, tol=0.001.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"newton-cg failed to converge. Increase the \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 106/240] END max_iter=100, penalty=none, solver=newton-cg, tol=0.001;, score=0.499 total time= 4.7min\n",
      "[CV 5/5; 106/240] START max_iter=100, penalty=none, solver=newton-cg, tol=0.001.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"newton-cg failed to converge. Increase the \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 106/240] END max_iter=100, penalty=none, solver=newton-cg, tol=0.001;, score=0.500 total time= 4.9min\n",
      "[CV 1/5; 107/240] START max_iter=100, penalty=none, solver=newton-cg, tol=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"newton-cg failed to converge. Increase the \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 107/240] END max_iter=100, penalty=none, solver=newton-cg, tol=0.0001;, score=0.497 total time= 4.4min\n",
      "[CV 2/5; 107/240] START max_iter=100, penalty=none, solver=newton-cg, tol=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"newton-cg failed to converge. Increase the \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 107/240] END max_iter=100, penalty=none, solver=newton-cg, tol=0.0001;, score=0.500 total time= 3.4min\n",
      "[CV 3/5; 107/240] START max_iter=100, penalty=none, solver=newton-cg, tol=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"newton-cg failed to converge. Increase the \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 107/240] END max_iter=100, penalty=none, solver=newton-cg, tol=0.0001;, score=0.499 total time= 3.3min\n",
      "[CV 4/5; 107/240] START max_iter=100, penalty=none, solver=newton-cg, tol=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"newton-cg failed to converge. Increase the \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 107/240] END max_iter=100, penalty=none, solver=newton-cg, tol=0.0001;, score=0.499 total time= 3.1min\n",
      "[CV 5/5; 107/240] START max_iter=100, penalty=none, solver=newton-cg, tol=0.0001\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "parameters = {  'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
    "                'tol': [1e-3, 1e-4, 1e-5],\n",
    "                'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "                'max_iter': [50, 100, 150, 200]\n",
    "                 }\n",
    "\n",
    "model = LogisticRegression()\n",
    "\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=parameters, verbose=10, scoring=\"balanced_accuracy\")\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ceab849",
   "metadata": {},
   "source": [
    "Logistic regression didn't have good result on the dataset. It doesn't converge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "14ae7a68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(max_iter=200, penalty='l2', solver='lbfgs', tol=0.0001)\n",
    "model.fit(X_train, y_train)\n",
    "predicted = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54596e7",
   "metadata": {},
   "source": [
    "As we are not getting the wanted result let's check the `learning curve`.\n",
    "\n",
    "We will check it for KNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7f44a728",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-43bacc7f4e84>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKNeighborsClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mleaf_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'uniform'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlearning_curve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlearning_curve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'balanced_accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m__repr__\u001b[1;34m(self, N_CHAR_MAX)\u001b[0m\n\u001b[0;32m    258\u001b[0m             n_max_elements_to_show=N_MAX_ELEMENTS_TO_SHOW)\n\u001b[0;32m    259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 260\u001b[1;33m         \u001b[0mrepr_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    261\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m         \u001b[1;31m# Use bruteforce ellipsis when there are a lot of non-blank characters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\pprint.py\u001b[0m in \u001b[0;36mpformat\u001b[1;34m(self, object)\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m         \u001b[0msio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_StringIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_format\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    154\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0msio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\pprint.py\u001b[0m in \u001b[0;36m_format\u001b[1;34m(self, object, stream, indent, allowance, context, level)\u001b[0m\n\u001b[0;32m    168\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_readable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 170\u001b[1;33m         \u001b[0mrep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    171\u001b[0m         \u001b[0mmax_width\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_width\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mindent\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mallowance\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrep\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mmax_width\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\pprint.py\u001b[0m in \u001b[0;36m_repr\u001b[1;34m(self, object, context, level)\u001b[0m\n\u001b[0;32m    402\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    403\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 404\u001b[1;33m         repr, readable, recursive = self.format(object, context.copy(),\n\u001b[0m\u001b[0;32m    405\u001b[0m                                                 self._depth, level)\n\u001b[0;32m    406\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mreadable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_pprint.py\u001b[0m in \u001b[0;36mformat\u001b[1;34m(self, object, context, maxlevels, level)\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxlevels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 180\u001b[1;33m         return _safe_repr(object, context, maxlevels, level,\n\u001b[0m\u001b[0;32m    181\u001b[0m                           changed_only=self._changed_only)\n\u001b[0;32m    182\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_pprint.py\u001b[0m in \u001b[0;36m_safe_repr\u001b[1;34m(object, context, maxlevels, level, changed_only)\u001b[0m\n\u001b[0;32m    423\u001b[0m         \u001b[0mrecursive\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    424\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mchanged_only\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 425\u001b[1;33m             \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_changed_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    426\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    427\u001b[0m             \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_pprint.py\u001b[0m in \u001b[0;36m_changed_params\u001b[1;34m(estimator)\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 112\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mhas_changed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_pprint.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 112\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mhas_changed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_pprint.py\u001b[0m in \u001b[0;36mhas_changed\u001b[1;34m(k, v)\u001b[0m\n\u001b[0;32m     98\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minit_params\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# happens if k is part of a **kwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0minit_params\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0minspect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_empty\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# k has no default value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m         \u001b[1;31m# try to avoid calling repr on nested estimators\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "from yellowbrick.model_selection import learning_curve\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=5, leaf_size=20, weights='uniform')\n",
    "print(learning_curve(model, X_train, y_train, cv=10, scoring='accuracy'))\n",
    "print(learning_curve(model, X_train, y_train, cv=10, scoring='balanced_accuracy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0bffc0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(100, input_dim=931, activation='relu'))\n",
    "model.add(Dense(60, activation='relu'))\n",
    "model.add(Dense(45, activation='relu'))\n",
    "model.add(Dense(30, activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1de204c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "343241c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ohe = OneHotEncoder()\n",
    "\n",
    "y_train = np.asarray(y_train).reshape((-1,1))\n",
    "y_test = np.asarray(y_test).reshape((-1,1))\n",
    "\n",
    "y_train = ohe.fit_transform(y_train).toarray()\n",
    "y_test = ohe.fit_transform(y_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "67317bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "504/504 [==============================] - 2s 1ms/step - loss: 10.8064 - accuracy: 0.7126\n",
      "Epoch 2/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.6040 - accuracy: 0.7409\n",
      "Epoch 3/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5759 - accuracy: 0.7462\n",
      "Epoch 4/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5683 - accuracy: 0.7465\n",
      "Epoch 5/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5687 - accuracy: 0.7444\n",
      "Epoch 6/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5685 - accuracy: 0.7444\n",
      "Epoch 7/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5676 - accuracy: 0.7452\n",
      "Epoch 8/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5661 - accuracy: 0.7466\n",
      "Epoch 9/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5725 - accuracy: 0.7406\n",
      "Epoch 10/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5675 - accuracy: 0.7453\n",
      "Epoch 11/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5711 - accuracy: 0.7418\n",
      "Epoch 12/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5735 - accuracy: 0.7396\n",
      "Epoch 13/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5666 - accuracy: 0.7461\n",
      "Epoch 14/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5644 - accuracy: 0.7482\n",
      "Epoch 15/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5702 - accuracy: 0.7427\n",
      "Epoch 16/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5654 - accuracy: 0.7472\n",
      "Epoch 17/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5713 - accuracy: 0.7416\n",
      "Epoch 18/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5674 - accuracy: 0.7453\n",
      "Epoch 19/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5662 - accuracy: 0.7465\n",
      "Epoch 20/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5679 - accuracy: 0.7449\n",
      "Epoch 21/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5675 - accuracy: 0.7453\n",
      "Epoch 22/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5679 - accuracy: 0.7449\n",
      "Epoch 23/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5688 - accuracy: 0.7440\n",
      "Epoch 24/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5714 - accuracy: 0.7416\n",
      "Epoch 25/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5665 - accuracy: 0.7462\n",
      "Epoch 26/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5711 - accuracy: 0.7419\n",
      "Epoch 27/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5718 - accuracy: 0.7412\n",
      "Epoch 28/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5686 - accuracy: 0.7443\n",
      "Epoch 29/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5687 - accuracy: 0.7441\n",
      "Epoch 30/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5680 - accuracy: 0.7448\n",
      "Epoch 31/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5695 - accuracy: 0.7434\n",
      "Epoch 32/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5695 - accuracy: 0.7434\n",
      "Epoch 33/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5687 - accuracy: 0.7442\n",
      "Epoch 34/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5677 - accuracy: 0.7451\n",
      "Epoch 35/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5672 - accuracy: 0.7456\n",
      "Epoch 36/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5717 - accuracy: 0.7414\n",
      "Epoch 37/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5664 - accuracy: 0.7462\n",
      "Epoch 38/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5687 - accuracy: 0.7441\n",
      "Epoch 39/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5683 - accuracy: 0.7445\n",
      "Epoch 40/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5701 - accuracy: 0.7429\n",
      "Epoch 41/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5659 - accuracy: 0.7468\n",
      "Epoch 42/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5697 - accuracy: 0.7432\n",
      "Epoch 43/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5668 - accuracy: 0.7460\n",
      "Epoch 44/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5703 - accuracy: 0.7426\n",
      "Epoch 45/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5676 - accuracy: 0.7452\n",
      "Epoch 46/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5685 - accuracy: 0.7443\n",
      "Epoch 47/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5721 - accuracy: 0.7409\n",
      "Epoch 48/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5693 - accuracy: 0.7435\n",
      "Epoch 49/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5658 - accuracy: 0.7469\n",
      "Epoch 50/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5694 - accuracy: 0.7434\n",
      "Epoch 51/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5692 - accuracy: 0.7437\n",
      "Epoch 52/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5708 - accuracy: 0.7422\n",
      "Epoch 53/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5701 - accuracy: 0.7428\n",
      "Epoch 54/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5703 - accuracy: 0.7426\n",
      "Epoch 55/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5666 - accuracy: 0.7461\n",
      "Epoch 56/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5690 - accuracy: 0.7438\n",
      "Epoch 57/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5657 - accuracy: 0.7469\n",
      "Epoch 58/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5757 - accuracy: 0.7375\n",
      "Epoch 59/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5683 - accuracy: 0.7445\n",
      "Epoch 60/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5717 - accuracy: 0.7413\n",
      "Epoch 61/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5696 - accuracy: 0.7433\n",
      "Epoch 62/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5699 - accuracy: 0.7430\n",
      "Epoch 63/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5705 - accuracy: 0.7424\n",
      "Epoch 64/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5717 - accuracy: 0.7413\n",
      "Epoch 65/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5721 - accuracy: 0.7409\n",
      "Epoch 66/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5689 - accuracy: 0.7439\n",
      "Epoch 67/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5660 - accuracy: 0.7466\n",
      "Epoch 68/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5640 - accuracy: 0.7485\n",
      "Epoch 69/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5671 - accuracy: 0.7456\n",
      "Epoch 70/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5690 - accuracy: 0.7438\n",
      "Epoch 71/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5719 - accuracy: 0.7411\n",
      "Epoch 72/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5708 - accuracy: 0.7421\n",
      "Epoch 73/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5720 - accuracy: 0.7410\n",
      "Epoch 74/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5685 - accuracy: 0.7444\n",
      "Epoch 75/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5708 - accuracy: 0.7421\n",
      "Epoch 76/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5654 - accuracy: 0.7472\n",
      "Epoch 77/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5708 - accuracy: 0.7422\n",
      "Epoch 78/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5680 - accuracy: 0.7448\n",
      "Epoch 79/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5725 - accuracy: 0.7405\n",
      "Epoch 80/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5656 - accuracy: 0.7470\n",
      "Epoch 81/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5730 - accuracy: 0.7401: 0s - loss: 0.5742 - accuracy\n",
      "Epoch 82/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5674 - accuracy: 0.7453\n",
      "Epoch 83/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5690 - accuracy: 0.7438\n",
      "Epoch 84/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5656 - accuracy: 0.7470\n",
      "Epoch 85/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5711 - accuracy: 0.7419\n",
      "Epoch 86/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5710 - accuracy: 0.7419\n",
      "Epoch 87/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5641 - accuracy: 0.7484\n",
      "Epoch 88/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5686 - accuracy: 0.7442\n",
      "Epoch 89/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5741 - accuracy: 0.7390\n",
      "Epoch 90/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5700 - accuracy: 0.7429\n",
      "Epoch 91/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5718 - accuracy: 0.7412\n",
      "Epoch 92/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5716 - accuracy: 0.7414\n",
      "Epoch 93/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5687 - accuracy: 0.7441\n",
      "Epoch 94/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5691 - accuracy: 0.7438\n",
      "Epoch 95/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5735 - accuracy: 0.7396\n",
      "Epoch 96/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5697 - accuracy: 0.7432\n",
      "Epoch 97/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5739 - accuracy: 0.7392\n",
      "Epoch 98/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5716 - accuracy: 0.7414\n",
      "Epoch 99/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5669 - accuracy: 0.7458\n",
      "Epoch 100/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5677 - accuracy: 0.7451\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=100, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6cb8635d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>queries</th>\n",
       "      <th>apps</th>\n",
       "      <th>games</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[216, 359, 12329, 3, 45, 4002, 2066, 32, 3931,...</td>\n",
       "      <td>[4, 4, 25, 7, 30, 58, 16, 19, 17, 21, 10, 10, ...</td>\n",
       "      <td>[9151, 208]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[]</td>\n",
       "      <td>[129, 71, 9, 8, 11, 25, 18, 58, 6, 16, 125, 12...</td>\n",
       "      <td>[460, 4939, 14, 232, 6387, 1758, 5834, 3, 2]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[23463, 18831]</td>\n",
       "      <td>[9, 174, 65, 8, 63, 97, 62, 103, 61, 116, 59, ...</td>\n",
       "      <td>[448, 723, 267, 9064, 10634, 166, 782, 224, 27...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1634, 3609, 654]</td>\n",
       "      <td>[99, 73, 9, 8, 59, 37, 131, 3, 89, 6, 24, 16, ...</td>\n",
       "      <td>[78, 2607, 478, 435, 9, 192]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[11064, 227, 623, 1301, 43999, 35411, 2492, 11...</td>\n",
       "      <td>[9, 8, 17, 54, 3, 25, 22, 6, 21, 7, 14, 5, 817...</td>\n",
       "      <td>[1702, 1, 53]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             queries  \\\n",
       "0  [216, 359, 12329, 3, 45, 4002, 2066, 32, 3931,...   \n",
       "1                                                 []   \n",
       "2                                     [23463, 18831]   \n",
       "3                                  [1634, 3609, 654]   \n",
       "4  [11064, 227, 623, 1301, 43999, 35411, 2492, 11...   \n",
       "\n",
       "                                                apps  \\\n",
       "0  [4, 4, 25, 7, 30, 58, 16, 19, 17, 21, 10, 10, ...   \n",
       "1  [129, 71, 9, 8, 11, 25, 18, 58, 6, 16, 125, 12...   \n",
       "2  [9, 174, 65, 8, 63, 97, 62, 103, 61, 116, 59, ...   \n",
       "3  [99, 73, 9, 8, 59, 37, 131, 3, 89, 6, 24, 16, ...   \n",
       "4  [9, 8, 17, 54, 3, 25, 22, 6, 21, 7, 14, 5, 817...   \n",
       "\n",
       "                                               games  gender  \n",
       "0                                        [9151, 208]       1  \n",
       "1       [460, 4939, 14, 232, 6387, 1758, 5834, 3, 2]       0  \n",
       "2  [448, 723, 267, 9064, 10634, 166, 782, 224, 27...       1  \n",
       "3                       [78, 2607, 478, 435, 9, 192]       1  \n",
       "4                                      [1702, 1, 53]       1  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet(DATA_DIR, engine=\"pyarrow\")\n",
    "df[\"birth_year\"] = df[\"birth_year\"].astype(np.uint)\n",
    "valid_birth_year = df[\"birth_year\"][df[\"birth_year\"] != 0]\n",
    "mean_birth_year = round(valid_birth_year.mean())\n",
    "df[\"birth_year\"] = df[\"birth_year\"].replace(0, mean_birth_year)\n",
    "df[\"gender\"] = df[\"gender\"].replace({'M': 1, 'F': 0})\n",
    "df.drop(columns=['birth_year'], inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "02772ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df.pop('apps').apply(pd.Series), df], axis=1)\n",
    "df = pd.concat([df.pop('games').apply(pd.Series), df], axis=1)\n",
    "df = pd.concat([df.pop('queries').apply(pd.Series), df], axis=1)\n",
    "df.fillna(0, inplace=True)\n",
    "\n",
    "X, y =  df.drop(columns=[\"gender\"]), df[\"gender\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2835b4d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32216, 930)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "db72e880",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(100, input_dim=930, activation='relu'))\n",
    "model.add(Dense(60, activation='relu'))\n",
    "model.add(Dense(45, activation='relu'))\n",
    "model.add(Dense(30, activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e3211fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder()\n",
    "\n",
    "y_train = np.asarray(y_train).reshape((-1,1))\n",
    "y_test = np.asarray(y_test).reshape((-1,1))\n",
    "\n",
    "y_train = ohe.fit_transform(y_train).toarray()\n",
    "y_test = ohe.fit_transform(y_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b7b82306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "338/338 [==============================] - 2s 2ms/step - loss: 25.7407 - accuracy: 0.6838 - val_loss: 0.6485 - val_accuracy: 0.7368\n",
      "Epoch 2/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.6222 - accuracy: 0.7432 - val_loss: 0.6089 - val_accuracy: 0.7369\n",
      "Epoch 3/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5889 - accuracy: 0.7503 - val_loss: 0.5943 - val_accuracy: 0.7369\n",
      "Epoch 4/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5735 - accuracy: 0.7485 - val_loss: 0.5882 - val_accuracy: 0.7369\n",
      "Epoch 5/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5721 - accuracy: 0.7433 - val_loss: 0.5863 - val_accuracy: 0.7369\n",
      "Epoch 6/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5668 - accuracy: 0.7467 - val_loss: 0.5858 - val_accuracy: 0.7369\n",
      "Epoch 7/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5663 - accuracy: 0.7466 - val_loss: 0.5859 - val_accuracy: 0.7369\n",
      "Epoch 8/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5662 - accuracy: 0.7465 - val_loss: 0.5859 - val_accuracy: 0.7369\n",
      "Epoch 9/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5602 - accuracy: 0.7520 - val_loss: 0.5860 - val_accuracy: 0.7369\n",
      "Epoch 10/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5650 - accuracy: 0.7476 - val_loss: 0.5859 - val_accuracy: 0.7369\n",
      "Epoch 11/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5612 - accuracy: 0.7511 - val_loss: 0.5859 - val_accuracy: 0.7369\n",
      "Epoch 12/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5649 - accuracy: 0.7476 - val_loss: 0.5860 - val_accuracy: 0.7369\n",
      "Epoch 13/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5684 - accuracy: 0.7444 - val_loss: 0.5860 - val_accuracy: 0.7369\n",
      "Epoch 14/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5652 - accuracy: 0.7473 - val_loss: 0.5859 - val_accuracy: 0.7369\n",
      "Epoch 15/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5642 - accuracy: 0.7483 - val_loss: 0.5859 - val_accuracy: 0.7369\n",
      "Epoch 16/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5656 - accuracy: 0.7470 - val_loss: 0.5859 - val_accuracy: 0.7369\n",
      "Epoch 17/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5713 - accuracy: 0.7419 - val_loss: 0.5842 - val_accuracy: 0.7370\n",
      "Epoch 18/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5636 - accuracy: 0.7489 - val_loss: 0.5839 - val_accuracy: 0.7370\n",
      "Epoch 19/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5666 - accuracy: 0.7461 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 20/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5685 - accuracy: 0.7443 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 21/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5665 - accuracy: 0.7462 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 22/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5651 - accuracy: 0.7475 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 23/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5633 - accuracy: 0.7491 - val_loss: 0.5839 - val_accuracy: 0.7370\n",
      "Epoch 24/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5614 - accuracy: 0.7509 - val_loss: 0.5839 - val_accuracy: 0.7370\n",
      "Epoch 25/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5675 - accuracy: 0.7453 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 26/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5644 - accuracy: 0.7482 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 27/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5689 - accuracy: 0.7440 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 28/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5654 - accuracy: 0.7472 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 29/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5670 - accuracy: 0.7457 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 30/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5736 - accuracy: 0.7396 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 31/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5664 - accuracy: 0.7463 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 32/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5688 - accuracy: 0.7440 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 33/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5576 - accuracy: 0.7543 - val_loss: 0.5839 - val_accuracy: 0.7370\n",
      "Epoch 34/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5572 - accuracy: 0.7548 - val_loss: 0.5839 - val_accuracy: 0.7370\n",
      "Epoch 35/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5634 - accuracy: 0.7491 - val_loss: 0.5839 - val_accuracy: 0.7370\n",
      "Epoch 36/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5717 - accuracy: 0.7413 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 37/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5657 - accuracy: 0.7469 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 38/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5664 - accuracy: 0.7463 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 39/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5639 - accuracy: 0.7486 - val_loss: 0.5839 - val_accuracy: 0.7370\n",
      "Epoch 40/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5659 - accuracy: 0.7467 - val_loss: 0.5839 - val_accuracy: 0.7370\n",
      "Epoch 41/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5711 - accuracy: 0.7420 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 42/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5642 - accuracy: 0.7483 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 43/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5651 - accuracy: 0.7475 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 44/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5653 - accuracy: 0.7473 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 45/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5619 - accuracy: 0.7504 - val_loss: 0.5839 - val_accuracy: 0.7370\n",
      "Epoch 46/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5642 - accuracy: 0.7483 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 47/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5638 - accuracy: 0.7487 - val_loss: 0.5839 - val_accuracy: 0.7370\n",
      "Epoch 48/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5675 - accuracy: 0.7452 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 49/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5677 - accuracy: 0.7451 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 50/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5642 - accuracy: 0.7483 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 51/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5656 - accuracy: 0.7470 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 52/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5654 - accuracy: 0.7472 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 53/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.5656 - accuracy: 0.7470 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 54/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5665 - accuracy: 0.7462 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 55/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5694 - accuracy: 0.7435 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 56/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5689 - accuracy: 0.7440 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 57/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5655 - accuracy: 0.7471 - val_loss: 0.5840 - val_accuracy: 0.7370\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5628 - accuracy: 0.7496 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 59/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5699 - accuracy: 0.7431 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 60/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5691 - accuracy: 0.7437 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 61/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5645 - accuracy: 0.7481 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 62/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5637 - accuracy: 0.7488 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 63/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5680 - accuracy: 0.7448 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 64/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5714 - accuracy: 0.7417 - val_loss: 0.5841 - val_accuracy: 0.7370\n",
      "Epoch 65/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5657 - accuracy: 0.7469 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 66/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5657 - accuracy: 0.7469 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 67/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.5672 - accuracy: 0.7456 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 68/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.5656 - accuracy: 0.7470 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 69/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5619 - accuracy: 0.7504 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 70/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5662 - accuracy: 0.7465 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 71/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5643 - accuracy: 0.7483 - val_loss: 0.5839 - val_accuracy: 0.7370\n",
      "Epoch 72/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5712 - accuracy: 0.7418 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 73/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5663 - accuracy: 0.7464 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 74/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5620 - accuracy: 0.7503 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 75/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5667 - accuracy: 0.7460 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 76/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5676 - accuracy: 0.7452 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 77/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5666 - accuracy: 0.7461 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 78/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5661 - accuracy: 0.7465 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 79/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5683 - accuracy: 0.7445 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 80/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5700 - accuracy: 0.7429 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 81/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5662 - accuracy: 0.7465 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 82/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5659 - accuracy: 0.7467 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 83/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5655 - accuracy: 0.7471 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 84/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5628 - accuracy: 0.7497 - val_loss: 0.5839 - val_accuracy: 0.7370\n",
      "Epoch 85/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5644 - accuracy: 0.7482 - val_loss: 0.5839 - val_accuracy: 0.7370\n",
      "Epoch 86/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5663 - accuracy: 0.7464 - val_loss: 0.5839 - val_accuracy: 0.7370\n",
      "Epoch 87/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.5621 - accuracy: 0.7503 - val_loss: 0.5839 - val_accuracy: 0.7370\n",
      "Epoch 88/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5667 - accuracy: 0.7460 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 89/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5678 - accuracy: 0.7450 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 90/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.5657 - accuracy: 0.7469 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 91/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5645 - accuracy: 0.7481 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 92/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5679 - accuracy: 0.7449 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 93/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.5665 - accuracy: 0.7462 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 94/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.5692 - accuracy: 0.7437 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 95/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5638 - accuracy: 0.7487 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 96/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5670 - accuracy: 0.7458 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 97/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5649 - accuracy: 0.7476 - val_loss: 0.5839 - val_accuracy: 0.7370\n",
      "Epoch 98/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5659 - accuracy: 0.7467 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 99/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.5669 - accuracy: 0.7458 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 100/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5606 - accuracy: 0.7517 - val_loss: 0.5839 - val_accuracy: 0.7370\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, validation_split=0.33, epochs=100, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "33dfe728",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "97f3f2f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1a07d8c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>apps</th>\n",
       "      <th>games</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[4, 4, 25, 7, 30, 58, 16, 19, 17, 21, 10, 10, ...</td>\n",
       "      <td>[9151, 208]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[129, 71, 9, 8, 11, 25, 18, 58, 6, 16, 125, 12...</td>\n",
       "      <td>[460, 4939, 14, 232, 6387, 1758, 5834, 3, 2]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[9, 174, 65, 8, 63, 97, 62, 103, 61, 116, 59, ...</td>\n",
       "      <td>[448, 723, 267, 9064, 10634, 166, 782, 224, 27...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[99, 73, 9, 8, 59, 37, 131, 3, 89, 6, 24, 16, ...</td>\n",
       "      <td>[78, 2607, 478, 435, 9, 192]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[9, 8, 17, 54, 3, 25, 22, 6, 21, 7, 14, 5, 817...</td>\n",
       "      <td>[1702, 1, 53]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                apps  \\\n",
       "0  [4, 4, 25, 7, 30, 58, 16, 19, 17, 21, 10, 10, ...   \n",
       "1  [129, 71, 9, 8, 11, 25, 18, 58, 6, 16, 125, 12...   \n",
       "2  [9, 174, 65, 8, 63, 97, 62, 103, 61, 116, 59, ...   \n",
       "3  [99, 73, 9, 8, 59, 37, 131, 3, 89, 6, 24, 16, ...   \n",
       "4  [9, 8, 17, 54, 3, 25, 22, 6, 21, 7, 14, 5, 817...   \n",
       "\n",
       "                                               games  gender  \n",
       "0                                        [9151, 208]       1  \n",
       "1       [460, 4939, 14, 232, 6387, 1758, 5834, 3, 2]       0  \n",
       "2  [448, 723, 267, 9064, 10634, 166, 782, 224, 27...       1  \n",
       "3                       [78, 2607, 478, 435, 9, 192]       1  \n",
       "4                                      [1702, 1, 53]       1  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet(DATA_DIR, engine=\"pyarrow\")\n",
    "df[\"birth_year\"] = df[\"birth_year\"].astype(np.uint)\n",
    "valid_birth_year = df[\"birth_year\"][df[\"birth_year\"] != 0]\n",
    "mean_birth_year = round(valid_birth_year.mean())\n",
    "df[\"birth_year\"] = df[\"birth_year\"].replace(0, mean_birth_year)\n",
    "df[\"gender\"] = df[\"gender\"].replace({'M': 1, 'F': 0})\n",
    "df.drop(columns=['birth_year', 'queries'], inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "88c4a73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df.pop('apps').apply(pd.Series), df], axis=1)\n",
    "df = pd.concat([df.pop('games').apply(pd.Series), df], axis=1)\n",
    "df.fillna(0, inplace=True)\n",
    "\n",
    "X, y =  df.drop(columns=[\"gender\"]), df[\"gender\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c9671591",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(100, input_dim=834, activation='relu'))\n",
    "model.add(Dense(60, activation='relu'))\n",
    "model.add(Dense(45, activation='relu'))\n",
    "model.add(Dense(30, activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8dc3c8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder()\n",
    "\n",
    "y_train = np.asarray(y_train).reshape((-1,1))\n",
    "y_test = np.asarray(y_test).reshape((-1,1))\n",
    "\n",
    "y_train = ohe.fit_transform(y_train).toarray()\n",
    "y_test = ohe.fit_transform(y_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8f15b477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "338/338 [==============================] - 2s 2ms/step - loss: 28.8057 - accuracy: 0.6787 - val_loss: 0.9474 - val_accuracy: 0.7367\n",
      "Epoch 2/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.7826 - accuracy: 0.7343 - val_loss: 0.6396 - val_accuracy: 0.7371\n",
      "Epoch 3/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.7634 - accuracy: 0.7271 - val_loss: 0.7065 - val_accuracy: 0.7369\n",
      "Epoch 4/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.6757 - accuracy: 0.7304 - val_loss: 0.6433 - val_accuracy: 0.7369\n",
      "Epoch 5/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.6375 - accuracy: 0.7367 - val_loss: 0.7294 - val_accuracy: 0.7369\n",
      "Epoch 6/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.6136 - accuracy: 0.7345 - val_loss: 0.5884 - val_accuracy: 0.7366\n",
      "Epoch 7/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.6386 - accuracy: 0.7371 - val_loss: 0.6286 - val_accuracy: 0.7370\n",
      "Epoch 8/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.6176 - accuracy: 0.7410 - val_loss: 0.6603 - val_accuracy: 0.6810\n",
      "Epoch 9/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.6648 - accuracy: 0.7324 - val_loss: 0.6140 - val_accuracy: 0.7255\n",
      "Epoch 10/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5806 - accuracy: 0.7411 - val_loss: 1.0220 - val_accuracy: 0.5456\n",
      "Epoch 11/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.6374 - accuracy: 0.7344 - val_loss: 0.6814 - val_accuracy: 0.7369\n",
      "Epoch 12/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5931 - accuracy: 0.7449 - val_loss: 0.5968 - val_accuracy: 0.7314\n",
      "Epoch 13/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5811 - accuracy: 0.7423 - val_loss: 0.6049 - val_accuracy: 0.7149\n",
      "Epoch 14/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5807 - accuracy: 0.7418 - val_loss: 0.6300 - val_accuracy: 0.7369\n",
      "Epoch 15/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5794 - accuracy: 0.7447 - val_loss: 1.4932 - val_accuracy: 0.6118\n",
      "Epoch 16/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.6762 - accuracy: 0.7344 - val_loss: 0.5778 - val_accuracy: 0.7369\n",
      "Epoch 17/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.5970 - accuracy: 0.7453 - val_loss: 0.5764 - val_accuracy: 0.7370\n",
      "Epoch 18/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5726 - accuracy: 0.7407 - val_loss: 0.5766 - val_accuracy: 0.7370\n",
      "Epoch 19/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5696 - accuracy: 0.7433 - val_loss: 0.5765 - val_accuracy: 0.7370\n",
      "Epoch 20/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.5664 - accuracy: 0.7463 - val_loss: 0.5764 - val_accuracy: 0.7370\n",
      "Epoch 21/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5630 - accuracy: 0.7493 - val_loss: 0.5764 - val_accuracy: 0.7370\n",
      "Epoch 22/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5702 - accuracy: 0.7428 - val_loss: 0.5766 - val_accuracy: 0.7370\n",
      "Epoch 23/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5688 - accuracy: 0.7443 - val_loss: 0.5766 - val_accuracy: 0.7369\n",
      "Epoch 24/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5702 - accuracy: 0.7429 - val_loss: 0.5765 - val_accuracy: 0.7370\n",
      "Epoch 25/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5673 - accuracy: 0.7455 - val_loss: 0.5765 - val_accuracy: 0.7369\n",
      "Epoch 26/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5682 - accuracy: 0.7446 - val_loss: 0.5764 - val_accuracy: 0.7370\n",
      "Epoch 27/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5624 - accuracy: 0.7508 - val_loss: 0.5763 - val_accuracy: 0.7370\n",
      "Epoch 28/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5637 - accuracy: 0.7488 - val_loss: 0.5767 - val_accuracy: 0.7368\n",
      "Epoch 29/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.5636 - accuracy: 0.7490 - val_loss: 0.5763 - val_accuracy: 0.7370\n",
      "Epoch 30/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5677 - accuracy: 0.7451 - val_loss: 0.5765 - val_accuracy: 0.7370\n",
      "Epoch 31/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5655 - accuracy: 0.7471 - val_loss: 0.5764 - val_accuracy: 0.7370\n",
      "Epoch 32/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5666 - accuracy: 0.7461 - val_loss: 0.5764 - val_accuracy: 0.7370\n",
      "Epoch 33/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5697 - accuracy: 0.7432 - val_loss: 0.5765 - val_accuracy: 0.7370\n",
      "Epoch 34/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5670 - accuracy: 0.7458 - val_loss: 0.5765 - val_accuracy: 0.7370\n",
      "Epoch 35/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5665 - accuracy: 0.7462 - val_loss: 0.5763 - val_accuracy: 0.7370\n",
      "Epoch 36/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5652 - accuracy: 0.7474 - val_loss: 0.5763 - val_accuracy: 0.7370\n",
      "Epoch 37/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5641 - accuracy: 0.7484 - val_loss: 0.5763 - val_accuracy: 0.7370\n",
      "Epoch 38/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5637 - accuracy: 0.7488 - val_loss: 0.5763 - val_accuracy: 0.7370\n",
      "Epoch 39/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5667 - accuracy: 0.7460 - val_loss: 0.5764 - val_accuracy: 0.7370\n",
      "Epoch 40/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5624 - accuracy: 0.7500 - val_loss: 0.5763 - val_accuracy: 0.7370\n",
      "Epoch 41/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.5685 - accuracy: 0.7444 - val_loss: 0.5767 - val_accuracy: 0.7370\n",
      "Epoch 42/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5633 - accuracy: 0.7492 - val_loss: 0.5764 - val_accuracy: 0.7370\n",
      "Epoch 43/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5657 - accuracy: 0.7469 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 44/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5664 - accuracy: 0.7462 - val_loss: 0.5764 - val_accuracy: 0.7370\n",
      "Epoch 45/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.5696 - accuracy: 0.7433 - val_loss: 0.5767 - val_accuracy: 0.7370\n",
      "Epoch 46/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5640 - accuracy: 0.7485 - val_loss: 0.5763 - val_accuracy: 0.7370\n",
      "Epoch 47/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5740 - accuracy: 0.7391 - val_loss: 0.5768 - val_accuracy: 0.7370\n",
      "Epoch 48/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.5657 - accuracy: 0.7469 - val_loss: 0.5764 - val_accuracy: 0.7370\n",
      "Epoch 49/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5680 - accuracy: 0.7447 - val_loss: 0.5763 - val_accuracy: 0.7370\n",
      "Epoch 50/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5620 - accuracy: 0.7505 - val_loss: 0.5763 - val_accuracy: 0.7370\n",
      "Epoch 51/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5663 - accuracy: 0.7464 - val_loss: 0.5765 - val_accuracy: 0.7370\n",
      "Epoch 52/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5668 - accuracy: 0.7459 - val_loss: 0.5764 - val_accuracy: 0.7370\n",
      "Epoch 53/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5700 - accuracy: 0.7430 - val_loss: 0.5764 - val_accuracy: 0.7370\n",
      "Epoch 54/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5686 - accuracy: 0.7442 - val_loss: 0.5765 - val_accuracy: 0.7370\n",
      "Epoch 55/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5644 - accuracy: 0.7482 - val_loss: 0.5764 - val_accuracy: 0.7370\n",
      "Epoch 56/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5640 - accuracy: 0.7485 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 57/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5642 - accuracy: 0.7484 - val_loss: 0.5763 - val_accuracy: 0.7370\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5723 - accuracy: 0.7408 - val_loss: 0.5765 - val_accuracy: 0.7370\n",
      "Epoch 59/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5660 - accuracy: 0.7468 - val_loss: 0.5763 - val_accuracy: 0.7370\n",
      "Epoch 60/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.5642 - accuracy: 0.7484 - val_loss: 0.5763 - val_accuracy: 0.7370\n",
      "Epoch 61/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5711 - accuracy: 0.7418 - val_loss: 0.5769 - val_accuracy: 0.7370\n",
      "Epoch 62/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5686 - accuracy: 0.7444 - val_loss: 0.5765 - val_accuracy: 0.7370\n",
      "Epoch 63/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.5630 - accuracy: 0.7494 - val_loss: 0.5763 - val_accuracy: 0.7370\n",
      "Epoch 64/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.5651 - accuracy: 0.7475 - val_loss: 0.5763 - val_accuracy: 0.7370\n",
      "Epoch 65/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5699 - accuracy: 0.7430 - val_loss: 0.5765 - val_accuracy: 0.7370\n",
      "Epoch 66/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5657 - accuracy: 0.7469 - val_loss: 0.5764 - val_accuracy: 0.7370\n",
      "Epoch 67/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5677 - accuracy: 0.7451 - val_loss: 0.5764 - val_accuracy: 0.7370\n",
      "Epoch 68/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5656 - accuracy: 0.7477 - val_loss: 0.6131 - val_accuracy: 0.7365\n",
      "Epoch 69/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.5736 - accuracy: 0.7476 - val_loss: 0.5763 - val_accuracy: 0.7370\n",
      "Epoch 70/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5631 - accuracy: 0.7494 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 71/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5642 - accuracy: 0.7484 - val_loss: 0.5763 - val_accuracy: 0.7370\n",
      "Epoch 72/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5622 - accuracy: 0.7502 - val_loss: 0.5763 - val_accuracy: 0.7370\n",
      "Epoch 73/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5672 - accuracy: 0.7456 - val_loss: 0.5765 - val_accuracy: 0.7370\n",
      "Epoch 74/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5686 - accuracy: 0.7442 - val_loss: 0.5766 - val_accuracy: 0.7370\n",
      "Epoch 75/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5626 - accuracy: 0.7498 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 76/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5691 - accuracy: 0.7438 - val_loss: 0.5764 - val_accuracy: 0.7370\n",
      "Epoch 77/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5710 - accuracy: 0.7421 - val_loss: 0.5764 - val_accuracy: 0.7370\n",
      "Epoch 78/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5632 - accuracy: 0.7492 - val_loss: 0.5763 - val_accuracy: 0.7370\n",
      "Epoch 79/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5650 - accuracy: 0.7477 - val_loss: 0.5763 - val_accuracy: 0.7370\n",
      "Epoch 80/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5704 - accuracy: 0.7426 - val_loss: 0.5766 - val_accuracy: 0.7370\n",
      "Epoch 81/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5681 - accuracy: 0.7448 - val_loss: 0.5763 - val_accuracy: 0.7370\n",
      "Epoch 82/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5673 - accuracy: 0.7454 - val_loss: 0.5763 - val_accuracy: 0.7370\n",
      "Epoch 83/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5639 - accuracy: 0.7485 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 84/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5651 - accuracy: 0.7475 - val_loss: 0.5764 - val_accuracy: 0.7370\n",
      "Epoch 85/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5645 - accuracy: 0.7481 - val_loss: 0.5763 - val_accuracy: 0.7370\n",
      "Epoch 86/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5663 - accuracy: 0.7464 - val_loss: 0.5764 - val_accuracy: 0.7370\n",
      "Epoch 87/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5668 - accuracy: 0.7460 - val_loss: 0.5767 - val_accuracy: 0.7370\n",
      "Epoch 88/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5764 - val_accuracy: 0.7370\n",
      "Epoch 89/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5760 - accuracy: 0.7472 - val_loss: 0.5763 - val_accuracy: 0.7370\n",
      "Epoch 90/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5683 - accuracy: 0.7445 - val_loss: 0.5764 - val_accuracy: 0.7370\n",
      "Epoch 91/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5687 - accuracy: 0.7442 - val_loss: 0.5767 - val_accuracy: 0.7370\n",
      "Epoch 92/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5676 - accuracy: 0.7452 - val_loss: 0.5764 - val_accuracy: 0.7370\n",
      "Epoch 93/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5656 - accuracy: 0.7470 - val_loss: 0.5763 - val_accuracy: 0.7370\n",
      "Epoch 94/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5737 - accuracy: 0.7395 - val_loss: 0.5766 - val_accuracy: 0.7370\n",
      "Epoch 95/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5614 - accuracy: 0.7509 - val_loss: 0.5763 - val_accuracy: 0.7370\n",
      "Epoch 96/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5705 - accuracy: 0.7424 - val_loss: 0.5766 - val_accuracy: 0.7370\n",
      "Epoch 97/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5630 - accuracy: 0.7494 - val_loss: 0.5764 - val_accuracy: 0.7370\n",
      "Epoch 98/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5658 - accuracy: 0.7469 - val_loss: 0.5763 - val_accuracy: 0.7370\n",
      "Epoch 99/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5655 - accuracy: 0.7471 - val_loss: 0.5765 - val_accuracy: 0.7370\n",
      "Epoch 100/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5640 - accuracy: 0.7485 - val_loss: 0.5764 - val_accuracy: 0.7370\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, validation_split=0.33, epochs=100, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "482bb803",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "3a4ab44d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "27760484",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>411</th>\n",
       "      <th>412</th>\n",
       "      <th>413</th>\n",
       "      <th>414</th>\n",
       "      <th>415</th>\n",
       "      <th>416</th>\n",
       "      <th>417</th>\n",
       "      <th>418</th>\n",
       "      <th>419</th>\n",
       "      <th>420</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9391</th>\n",
       "      <td>336.0</td>\n",
       "      <td>822.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36089</th>\n",
       "      <td>1.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38820</th>\n",
       "      <td>78.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>2726.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33815</th>\n",
       "      <td>771.0</td>\n",
       "      <td>3198.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31187</th>\n",
       "      <td>689.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6265</th>\n",
       "      <td>23.0</td>\n",
       "      <td>947.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>435.0</td>\n",
       "      <td>1327.0</td>\n",
       "      <td>2694.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11284</th>\n",
       "      <td>64.0</td>\n",
       "      <td>361.0</td>\n",
       "      <td>2093.0</td>\n",
       "      <td>2708.0</td>\n",
       "      <td>1228.0</td>\n",
       "      <td>318.0</td>\n",
       "      <td>711.0</td>\n",
       "      <td>1844.0</td>\n",
       "      <td>2392.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38158</th>\n",
       "      <td>35.0</td>\n",
       "      <td>4697.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15795</th>\n",
       "      <td>2.0</td>\n",
       "      <td>889.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32216 rows × 834 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0       1       2       3       4       5      6       7       8    \\\n",
       "9391   336.0   822.0    14.0     0.0     0.0     0.0    0.0     0.0     0.0   \n",
       "36089    1.0   145.0     0.0     0.0     0.0     0.0    0.0     0.0     0.0   \n",
       "38820   78.0    11.0   122.0   113.0   192.0  2726.0   34.0    44.0    17.0   \n",
       "33815  771.0  3198.0     0.0     0.0     0.0     0.0    0.0     0.0     0.0   \n",
       "31187  689.0    45.0     0.0     0.0     0.0     0.0    0.0     0.0     0.0   \n",
       "...      ...     ...     ...     ...     ...     ...    ...     ...     ...   \n",
       "6265    23.0   947.0    35.0   435.0  1327.0  2694.0    2.0     0.0     0.0   \n",
       "11284   64.0   361.0  2093.0  2708.0  1228.0   318.0  711.0  1844.0  2392.0   \n",
       "38158   35.0  4697.0     3.0    47.0     0.0     0.0    0.0     0.0     0.0   \n",
       "860      0.0     0.0     0.0     0.0     0.0     0.0    0.0     0.0     0.0   \n",
       "15795    2.0   889.0     0.0     0.0     0.0     0.0    0.0     0.0     0.0   \n",
       "\n",
       "       9    ...  411  412  413  414  415  416  417  418  419  420  \n",
       "9391   0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "36089  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "38820  4.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "33815  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "31187  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "...    ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  \n",
       "6265   0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "11284  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "38158  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "860    0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "15795  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[32216 rows x 834 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "274cb261",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>825</th>\n",
       "      <th>826</th>\n",
       "      <th>827</th>\n",
       "      <th>828</th>\n",
       "      <th>829</th>\n",
       "      <th>830</th>\n",
       "      <th>831</th>\n",
       "      <th>832</th>\n",
       "      <th>833</th>\n",
       "      <th>834</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.184073</td>\n",
       "      <td>0.004199</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.009253</td>\n",
       "      <td>0.099703</td>\n",
       "      <td>0.000280</td>\n",
       "      <td>0.004739</td>\n",
       "      <td>0.130517</td>\n",
       "      <td>0.035448</td>\n",
       "      <td>0.124714</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.009012</td>\n",
       "      <td>0.014595</td>\n",
       "      <td>0.005346</td>\n",
       "      <td>0.185161</td>\n",
       "      <td>0.217304</td>\n",
       "      <td>0.003347</td>\n",
       "      <td>0.016717</td>\n",
       "      <td>0.004492</td>\n",
       "      <td>0.005472</td>\n",
       "      <td>0.082066</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001569</td>\n",
       "      <td>0.052627</td>\n",
       "      <td>0.009570</td>\n",
       "      <td>0.008886</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>0.003871</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.034236</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.001061</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 835 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0  0.184073  0.004199  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1  0.009253  0.099703  0.000280  0.004739  0.130517  0.035448  0.124714   \n",
       "2  0.009012  0.014595  0.005346  0.185161  0.217304  0.003347  0.016717   \n",
       "3  0.001569  0.052627  0.009570  0.008886  0.000184  0.003871  0.000000   \n",
       "4  0.034236  0.000020  0.001061  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "        7         8         9    ...  825  826  827  828  829  830  831  832  \\\n",
       "0  0.000000  0.000000  0.000000  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1  0.000060  0.000040  0.000000  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2  0.004492  0.005472  0.082066  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "3  0.000000  0.000000  0.000000  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "4  0.000000  0.000000  0.000000  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "   833  834  \n",
       "0  0.0  1.0  \n",
       "1  0.0  0.0  \n",
       "2  0.0  1.0  \n",
       "3  0.0  1.0  \n",
       "4  0.0  1.0  \n",
       "\n",
       "[5 rows x 835 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "x = df.values\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "df = pd.DataFrame(x_scaled)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b8c07cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(100, input_dim=834, activation='relu'))\n",
    "model.add(Dense(60, activation='relu'))\n",
    "model.add(Dense(45, activation='relu'))\n",
    "model.add(Dense(30, activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "fe7bf3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder()\n",
    "\n",
    "y_train = np.asarray(y_train).reshape((-1,1))\n",
    "y_test = np.asarray(y_test).reshape((-1,1))\n",
    "\n",
    "y_train = ohe.fit_transform(y_train).toarray()\n",
    "y_test = ohe.fit_transform(y_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ece33a32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "338/338 [==============================] - 2s 2ms/step - loss: 5.5669 - accuracy: 0.4944 - val_loss: 0.7017 - val_accuracy: 0.5006\n",
      "Epoch 2/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.6940 - accuracy: 0.5091 - val_loss: 0.6960 - val_accuracy: 0.5001\n",
      "Epoch 3/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.4909 - val_loss: 0.6961 - val_accuracy: 0.4999\n",
      "Epoch 4/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5028 - val_loss: 0.6959 - val_accuracy: 0.5001\n",
      "Epoch 5/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.4974 - val_loss: 0.6951 - val_accuracy: 0.4999\n",
      "Epoch 6/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.6937 - accuracy: 0.4955 - val_loss: 0.6984 - val_accuracy: 0.4999\n",
      "Epoch 7/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.6930 - accuracy: 0.5008 - val_loss: 0.6986 - val_accuracy: 0.5000\n",
      "Epoch 8/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.4978 - val_loss: 0.7126 - val_accuracy: 0.4998\n",
      "Epoch 9/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.4986 - val_loss: 0.7127 - val_accuracy: 0.5002\n",
      "Epoch 10/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5004 - val_loss: 0.7126 - val_accuracy: 0.5001\n",
      "Epoch 11/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.6930 - accuracy: 0.4994 - val_loss: 0.7110 - val_accuracy: 0.5001\n",
      "Epoch 12/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.6929 - accuracy: 0.4948 - val_loss: 0.7149 - val_accuracy: 0.5001\n",
      "Epoch 13/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.6931 - accuracy: 0.5009 - val_loss: 0.7183 - val_accuracy: 0.4998\n",
      "Epoch 14/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.6930 - accuracy: 0.4956 - val_loss: 0.7045 - val_accuracy: 0.4999\n",
      "Epoch 15/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.6929 - accuracy: 0.4952 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 16/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.6930 - accuracy: 0.5042 - val_loss: 0.6931 - val_accuracy: 0.5002\n",
      "Epoch 17/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.6930 - accuracy: 0.4992 - val_loss: 0.6961 - val_accuracy: 0.5000\n",
      "Epoch 18/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.6932 - accuracy: 0.5020 - val_loss: 0.6961 - val_accuracy: 0.5000\n",
      "Epoch 19/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5064 - val_loss: 0.6961 - val_accuracy: 0.4999\n",
      "Epoch 20/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.6932 - accuracy: 0.5023 - val_loss: 0.6961 - val_accuracy: 0.5000\n",
      "Epoch 21/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.6932 - accuracy: 0.5021 - val_loss: 0.6961 - val_accuracy: 0.4999\n",
      "Epoch 22/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.4905 - val_loss: 0.6961 - val_accuracy: 0.4999\n",
      "Epoch 23/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.4987 - val_loss: 0.6961 - val_accuracy: 0.4999\n",
      "Epoch 24/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.6932 - accuracy: 0.4929 - val_loss: 0.6961 - val_accuracy: 0.4999\n",
      "Epoch 25/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.6931 - accuracy: 0.5060 - val_loss: 0.6961 - val_accuracy: 0.5000\n",
      "Epoch 26/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5028 - val_loss: 0.6961 - val_accuracy: 0.4999\n",
      "Epoch 27/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.6932 - accuracy: 0.4939 - val_loss: 0.6961 - val_accuracy: 0.4999\n",
      "Epoch 28/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.6932 - accuracy: 0.5048 - val_loss: 0.6961 - val_accuracy: 0.5000\n",
      "Epoch 29/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.6932 - accuracy: 0.5012 - val_loss: 0.6961 - val_accuracy: 0.4999\n",
      "Epoch 30/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.6932 - accuracy: 0.5023 - val_loss: 0.6961 - val_accuracy: 0.4999\n",
      "Epoch 31/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.6932 - accuracy: 0.5021 - val_loss: 0.6961 - val_accuracy: 0.5000\n",
      "Epoch 32/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.4950 - val_loss: 0.6961 - val_accuracy: 0.5000\n",
      "Epoch 33/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.6932 - accuracy: 0.5015 - val_loss: 0.6961 - val_accuracy: 0.4999\n",
      "Epoch 34/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.6932 - accuracy: 0.4935 - val_loss: 0.6961 - val_accuracy: 0.4999\n",
      "Epoch 35/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.4956 - val_loss: 0.6961 - val_accuracy: 0.5000\n",
      "Epoch 36/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.6932 - accuracy: 0.4973 - val_loss: 0.6961 - val_accuracy: 0.4999\n",
      "Epoch 37/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5010 - val_loss: 0.6961 - val_accuracy: 0.4999\n",
      "Epoch 38/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.6932 - accuracy: 0.4947 - val_loss: 0.6961 - val_accuracy: 0.4999\n",
      "Epoch 39/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.6932 - accuracy: 0.5019 - val_loss: 0.6961 - val_accuracy: 0.5000\n",
      "Epoch 40/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5004 - val_loss: 0.6961 - val_accuracy: 0.5000\n",
      "Epoch 41/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.6932 - accuracy: 0.5003 - val_loss: 0.6961 - val_accuracy: 0.5000\n",
      "Epoch 42/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.4955 - val_loss: 0.6961 - val_accuracy: 0.4999\n",
      "Epoch 43/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.6932 - accuracy: 0.5008 - val_loss: 0.6961 - val_accuracy: 0.4999\n",
      "Epoch 44/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.4972 - val_loss: 0.6961 - val_accuracy: 0.4999\n",
      "Epoch 45/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.4844 - val_loss: 0.6961 - val_accuracy: 0.4999\n",
      "Epoch 46/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.4935 - val_loss: 0.6961 - val_accuracy: 0.4999\n",
      "Epoch 47/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5034 - val_loss: 0.6961 - val_accuracy: 0.4999\n",
      "Epoch 48/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5041 - val_loss: 0.6961 - val_accuracy: 0.5000\n",
      "Epoch 49/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.6932 - accuracy: 0.4934 - val_loss: 0.6961 - val_accuracy: 0.4999\n",
      "Epoch 50/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.6932 - accuracy: 0.5004 - val_loss: 0.6961 - val_accuracy: 0.4999\n",
      "Epoch 51/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5029 - val_loss: 0.6961 - val_accuracy: 0.5000\n",
      "Epoch 52/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5058 - val_loss: 0.6961 - val_accuracy: 0.4999\n",
      "Epoch 53/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.6932 - accuracy: 0.4957 - val_loss: 0.6961 - val_accuracy: 0.4999\n",
      "Epoch 54/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.4965 - val_loss: 0.6961 - val_accuracy: 0.4999\n",
      "Epoch 55/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.4944 - val_loss: 0.6961 - val_accuracy: 0.5000\n",
      "Epoch 56/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.6931 - accuracy: 0.5051 - val_loss: 0.6961 - val_accuracy: 0.4999\n",
      "Epoch 57/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5083 - val_loss: 0.6961 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.6931 - accuracy: 0.5063 - val_loss: 0.6961 - val_accuracy: 0.4999\n",
      "Epoch 59/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.6931 - accuracy: 0.5027 - val_loss: 0.6961 - val_accuracy: 0.5000\n",
      "Epoch 60/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.4942 - val_loss: 0.6961 - val_accuracy: 0.5000\n",
      "Epoch 61/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.6932 - accuracy: 0.5024 - val_loss: 0.6961 - val_accuracy: 0.5000\n",
      "Epoch 62/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.6932 - accuracy: 0.4975 - val_loss: 0.6961 - val_accuracy: 0.5000\n",
      "Epoch 63/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.4947 - val_loss: 0.6961 - val_accuracy: 0.4999\n",
      "Epoch 64/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.4956 - val_loss: 0.6961 - val_accuracy: 0.4999\n",
      "Epoch 65/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.6932 - accuracy: 0.4970 - val_loss: 0.6961 - val_accuracy: 0.4999\n",
      "Epoch 66/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.6932 - accuracy: 0.5002 - val_loss: 0.6961 - val_accuracy: 0.5000\n",
      "Epoch 67/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.6932 - accuracy: 0.5024 - val_loss: 0.6961 - val_accuracy: 0.4999\n",
      "Epoch 68/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.6932 - accuracy: 0.5017 - val_loss: 0.6961 - val_accuracy: 0.4999\n",
      "Epoch 69/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.6932 - accuracy: 0.4998 - val_loss: 0.6961 - val_accuracy: 0.5000\n",
      "Epoch 70/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.6932 - accuracy: 0.4979 - val_loss: 0.6961 - val_accuracy: 0.5000\n",
      "Epoch 71/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.6932 - accuracy: 0.5025 - val_loss: 0.6961 - val_accuracy: 0.4999\n",
      "Epoch 72/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.6931 - accuracy: 0.5051 - val_loss: 0.6961 - val_accuracy: 0.5000\n",
      "Epoch 73/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.6932 - accuracy: 0.4985 - val_loss: 0.6961 - val_accuracy: 0.5000\n",
      "Epoch 74/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.6932 - accuracy: 0.4994 - val_loss: 0.6961 - val_accuracy: 0.5000\n",
      "Epoch 75/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.6932 - accuracy: 0.4985 - val_loss: 0.6961 - val_accuracy: 0.5000\n",
      "Epoch 76/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.6932 - accuracy: 0.4947 - val_loss: 0.6961 - val_accuracy: 0.5000\n",
      "Epoch 77/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.6932 - accuracy: 0.5015 - val_loss: 0.6961 - val_accuracy: 0.5000\n",
      "Epoch 78/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.6932 - accuracy: 0.4968 - val_loss: 0.6961 - val_accuracy: 0.5000\n",
      "Epoch 79/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.6932 - accuracy: 0.4966 - val_loss: 0.6961 - val_accuracy: 0.5000\n",
      "Epoch 80/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.6932 - accuracy: 0.4911 - val_loss: 0.6961 - val_accuracy: 0.5000\n",
      "Epoch 81/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.6932 - accuracy: 0.4995 - val_loss: 0.6961 - val_accuracy: 0.5000\n",
      "Epoch 82/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.6931 - accuracy: 0.5100 - val_loss: 0.6961 - val_accuracy: 0.4999\n",
      "Epoch 83/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.6932 - accuracy: 0.4889 - val_loss: 0.6961 - val_accuracy: 0.4999\n",
      "Epoch 84/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.6932 - accuracy: 0.4972 - val_loss: 0.6961 - val_accuracy: 0.4999\n",
      "Epoch 85/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.6932 - accuracy: 0.4974 - val_loss: 0.6961 - val_accuracy: 0.4999\n",
      "Epoch 86/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.6932 - accuracy: 0.4966 - val_loss: 0.6961 - val_accuracy: 0.5000\n",
      "Epoch 87/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.6932 - accuracy: 0.4970 - val_loss: 0.6961 - val_accuracy: 0.5000\n",
      "Epoch 88/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.4986 - val_loss: 0.6961 - val_accuracy: 0.5000\n",
      "Epoch 89/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.6932 - accuracy: 0.4965 - val_loss: 0.6961 - val_accuracy: 0.5000\n",
      "Epoch 90/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.6932 - accuracy: 0.5036 - val_loss: 0.6961 - val_accuracy: 0.5000\n",
      "Epoch 91/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.6932 - accuracy: 0.4970 - val_loss: 0.6961 - val_accuracy: 0.5000\n",
      "Epoch 92/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5015 - val_loss: 0.6961 - val_accuracy: 0.4999\n",
      "Epoch 93/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.4960 - val_loss: 0.6961 - val_accuracy: 0.4999\n",
      "Epoch 94/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.6932 - accuracy: 0.4980 - val_loss: 0.6961 - val_accuracy: 0.5000\n",
      "Epoch 95/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.6932 - accuracy: 0.5003 - val_loss: 0.6961 - val_accuracy: 0.5000\n",
      "Epoch 96/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.6932 - accuracy: 0.5015 - val_loss: 0.6961 - val_accuracy: 0.4999\n",
      "Epoch 97/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.6931 - accuracy: 0.5041 - val_loss: 0.6961 - val_accuracy: 0.5000\n",
      "Epoch 98/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.6932 - accuracy: 0.4968 - val_loss: 0.6961 - val_accuracy: 0.5000\n",
      "Epoch 99/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.6932 - accuracy: 0.4958 - val_loss: 0.6961 - val_accuracy: 0.5000\n",
      "Epoch 100/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.6932 - accuracy: 0.4974 - val_loss: 0.6961 - val_accuracy: 0.4999\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, validation_split=0.33, epochs=100, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954ec411",
   "metadata": {},
   "source": [
    "As it was expected it is not a good idea to normalize columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "8566a4dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    6813\n",
      "0       0\n",
      "dtype: int64\n",
      "10    28302\n",
      "10       28\n",
      "dtype: int64\n",
      "100    32171\n",
      "100    30621\n",
      "dtype: int64\n",
      "400    32215\n",
      "400    32215\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print((X_train[0] == 0).sum())\n",
    "print((X_train[10] == 0).sum())\n",
    "print((X_train[100] == 0).sum())\n",
    "print((X_train[400] == 0).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "82f8f489",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>queries</th>\n",
       "      <th>apps</th>\n",
       "      <th>games</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[216, 359, 12329, 3, 45, 4002, 2066, 32, 3931,...</td>\n",
       "      <td>[4, 4, 25, 7, 30, 58, 16, 19, 17, 21, 10, 10, ...</td>\n",
       "      <td>[9151, 208]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[]</td>\n",
       "      <td>[129, 71, 9, 8, 11, 25, 18, 58, 6, 16, 125, 12...</td>\n",
       "      <td>[460, 4939, 14, 232, 6387, 1758, 5834, 3, 2]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[23463, 18831]</td>\n",
       "      <td>[9, 174, 65, 8, 63, 97, 62, 103, 61, 116, 59, ...</td>\n",
       "      <td>[448, 723, 267, 9064, 10634, 166, 782, 224, 27...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1634, 3609, 654]</td>\n",
       "      <td>[99, 73, 9, 8, 59, 37, 131, 3, 89, 6, 24, 16, ...</td>\n",
       "      <td>[78, 2607, 478, 435, 9, 192]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[11064, 227, 623, 1301, 43999, 35411, 2492, 11...</td>\n",
       "      <td>[9, 8, 17, 54, 3, 25, 22, 6, 21, 7, 14, 5, 817...</td>\n",
       "      <td>[1702, 1, 53]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             queries  \\\n",
       "0  [216, 359, 12329, 3, 45, 4002, 2066, 32, 3931,...   \n",
       "1                                                 []   \n",
       "2                                     [23463, 18831]   \n",
       "3                                  [1634, 3609, 654]   \n",
       "4  [11064, 227, 623, 1301, 43999, 35411, 2492, 11...   \n",
       "\n",
       "                                                apps  \\\n",
       "0  [4, 4, 25, 7, 30, 58, 16, 19, 17, 21, 10, 10, ...   \n",
       "1  [129, 71, 9, 8, 11, 25, 18, 58, 6, 16, 125, 12...   \n",
       "2  [9, 174, 65, 8, 63, 97, 62, 103, 61, 116, 59, ...   \n",
       "3  [99, 73, 9, 8, 59, 37, 131, 3, 89, 6, 24, 16, ...   \n",
       "4  [9, 8, 17, 54, 3, 25, 22, 6, 21, 7, 14, 5, 817...   \n",
       "\n",
       "                                               games  gender  \n",
       "0                                        [9151, 208]       1  \n",
       "1       [460, 4939, 14, 232, 6387, 1758, 5834, 3, 2]       0  \n",
       "2  [448, 723, 267, 9064, 10634, 166, 782, 224, 27...       1  \n",
       "3                       [78, 2607, 478, 435, 9, 192]       1  \n",
       "4                                      [1702, 1, 53]       1  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet(DATA_DIR, engine=\"pyarrow\")\n",
    "df[\"birth_year\"] = df[\"birth_year\"].astype(np.uint)\n",
    "valid_birth_year = df[\"birth_year\"][df[\"birth_year\"] != 0]\n",
    "mean_birth_year = round(valid_birth_year.mean())\n",
    "df[\"birth_year\"] = df[\"birth_year\"].replace(0, mean_birth_year)\n",
    "df[\"gender\"] = df[\"gender\"].replace({'M': 1, 'F': 0})\n",
    "df.drop(columns=['birth_year'], inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7a5befe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df.pop('apps').apply(pd.Series), df], axis=1)\n",
    "df = pd.concat([df.pop('games').apply(pd.Series), df], axis=1)\n",
    "df = pd.concat([df.pop('queries').apply(pd.Series), df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9e716255",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>412</th>\n",
       "      <th>413</th>\n",
       "      <th>414</th>\n",
       "      <th>415</th>\n",
       "      <th>416</th>\n",
       "      <th>417</th>\n",
       "      <th>418</th>\n",
       "      <th>419</th>\n",
       "      <th>420</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>216.0</td>\n",
       "      <td>359.0</td>\n",
       "      <td>12329.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>4002.0</td>\n",
       "      <td>2066.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>3931.0</td>\n",
       "      <td>17104.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23463.0</td>\n",
       "      <td>18831.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1634.0</td>\n",
       "      <td>3609.0</td>\n",
       "      <td>654.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11064.0</td>\n",
       "      <td>227.0</td>\n",
       "      <td>623.0</td>\n",
       "      <td>1301.0</td>\n",
       "      <td>43999.0</td>\n",
       "      <td>35411.0</td>\n",
       "      <td>2492.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>1652.0</td>\n",
       "      <td>27068.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 931 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0        1        2       3        4        5       6      7       8  \\\n",
       "0    216.0    359.0  12329.0     3.0     45.0   4002.0  2066.0   32.0  3931.0   \n",
       "1      NaN      NaN      NaN     NaN      NaN      NaN     NaN    NaN     NaN   \n",
       "2  23463.0  18831.0      NaN     NaN      NaN      NaN     NaN    NaN     NaN   \n",
       "3   1634.0   3609.0    654.0     NaN      NaN      NaN     NaN    NaN     NaN   \n",
       "4  11064.0    227.0    623.0  1301.0  43999.0  35411.0  2492.0  112.0  1652.0   \n",
       "\n",
       "         9  ...  412  413  414  415  416  417  418  419  420  gender  \n",
       "0  17104.0  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN       1  \n",
       "1      NaN  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN       0  \n",
       "2      NaN  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN       1  \n",
       "3      NaN  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN       1  \n",
       "4  27068.0  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN       1  \n",
       "\n",
       "[5 rows x 931 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "710313ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         0.017407\n",
       "1         0.041643\n",
       "2         0.070373\n",
       "3         0.098036\n",
       "4         0.127312\n",
       "            ...   \n",
       "417       0.999975\n",
       "418       0.999975\n",
       "419       0.999975\n",
       "420       0.999975\n",
       "gender    0.000000\n",
       "Length: 931, dtype: float64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ee7169c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([       0,        1,        2,        3,        4,        5,        6,\n",
       "              7,        8,        9,\n",
       "       ...\n",
       "             62,       63,       64,       65,       66,       67,       68,\n",
       "             69,       70, 'gender'],\n",
       "      dtype='object', length=119)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns[df.isnull().mean() < 0.8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "26a2091e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.columns[df.isnull().mean() < 0.8]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b4c31ea9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40271, 355)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9d2af3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "dc1b48b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y =  df.drop(columns=[\"gender\"]), df[\"gender\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b4f94c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder()\n",
    "\n",
    "y_train = np.asarray(y_train).reshape((-1,1))\n",
    "y_test = np.asarray(y_test).reshape((-1,1))\n",
    "\n",
    "y_train = ohe.fit_transform(y_train).toarray()\n",
    "y_test = ohe.fit_transform(y_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "53e44d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(100, input_dim=354, activation='relu'))\n",
    "model.add(Dense(60, activation='relu'))\n",
    "model.add(Dense(45, activation='relu'))\n",
    "model.add(Dense(30, activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "94c20431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "338/338 [==============================] - 2s 2ms/step - loss: 18.2793 - accuracy: 0.7150 - val_loss: 0.6518 - val_accuracy: 0.7369\n",
      "Epoch 2/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.6233 - accuracy: 0.7420 - val_loss: 0.6184 - val_accuracy: 0.7369\n",
      "Epoch 3/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5895 - accuracy: 0.7486 - val_loss: 0.6030 - val_accuracy: 0.7369\n",
      "Epoch 4/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5746 - accuracy: 0.7490 - val_loss: 0.5927 - val_accuracy: 0.7370\n",
      "Epoch 5/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5723 - accuracy: 0.7436 - val_loss: 0.5894 - val_accuracy: 0.7369\n",
      "Epoch 6/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5683 - accuracy: 0.7454 - val_loss: 0.5888 - val_accuracy: 0.7369\n",
      "Epoch 7/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5630 - accuracy: 0.7497 - val_loss: 0.5888 - val_accuracy: 0.7369\n",
      "Epoch 8/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5674 - accuracy: 0.7454 - val_loss: 0.5889 - val_accuracy: 0.7369\n",
      "Epoch 9/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5691 - accuracy: 0.7437 - val_loss: 0.5889 - val_accuracy: 0.7369\n",
      "Epoch 10/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5698 - accuracy: 0.7431 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 11/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5658 - accuracy: 0.7468 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 12/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.5639 - accuracy: 0.7486 - val_loss: 0.5889 - val_accuracy: 0.7369\n",
      "Epoch 13/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5638 - accuracy: 0.7486 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 14/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5693 - accuracy: 0.7436 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 15/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5659 - accuracy: 0.7467 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 16/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5647 - accuracy: 0.7478 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 17/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5663 - accuracy: 0.7464 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 18/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5669 - accuracy: 0.7457 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 19/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5627 - accuracy: 0.7497 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 20/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5697 - accuracy: 0.7432 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 21/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5613 - accuracy: 0.7509 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 22/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5663 - accuracy: 0.7463 - val_loss: 0.5889 - val_accuracy: 0.7369\n",
      "Epoch 23/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5641 - accuracy: 0.7484 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 24/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.5672 - accuracy: 0.7455 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 25/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5680 - accuracy: 0.7448 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 26/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5672 - accuracy: 0.7455 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 27/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5629 - accuracy: 0.7495 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 28/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5684 - accuracy: 0.7444 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 29/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5694 - accuracy: 0.7435 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 30/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5674 - accuracy: 0.7453 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 31/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5664 - accuracy: 0.7463 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 32/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5678 - accuracy: 0.7450 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 33/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5625 - accuracy: 0.7499 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 34/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5674 - accuracy: 0.7453 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 35/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5675 - accuracy: 0.7453 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 36/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5632 - accuracy: 0.7492 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 37/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5634 - accuracy: 0.7490 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 38/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.5610 - accuracy: 0.7513 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 39/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5654 - accuracy: 0.7471 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 40/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5656 - accuracy: 0.7470 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 41/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5634 - accuracy: 0.7491 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 42/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5645 - accuracy: 0.7480 - val_loss: 0.5889 - val_accuracy: 0.7369\n",
      "Epoch 43/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5572 - accuracy: 0.7548 - val_loss: 0.5889 - val_accuracy: 0.7369\n",
      "Epoch 44/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5679 - accuracy: 0.7448 - val_loss: 0.5889 - val_accuracy: 0.7369\n",
      "Epoch 45/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5684 - accuracy: 0.7444 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 46/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.5666 - accuracy: 0.7461 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 47/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5705 - accuracy: 0.7425 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 48/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5681 - accuracy: 0.7447 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 49/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5654 - accuracy: 0.7471 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 50/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.5611 - accuracy: 0.7511 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 51/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5643 - accuracy: 0.7481 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 52/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5691 - accuracy: 0.7437 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 53/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5654 - accuracy: 0.7472 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 54/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5654 - accuracy: 0.7472 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 55/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.5661 - accuracy: 0.7466 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 56/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5672 - accuracy: 0.7455 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 57/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5612 - accuracy: 0.7510 - val_loss: 0.5889 - val_accuracy: 0.7369\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5696 - accuracy: 0.7432 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 59/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5603 - accuracy: 0.7519 - val_loss: 0.5889 - val_accuracy: 0.7369\n",
      "Epoch 60/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5606 - accuracy: 0.7516 - val_loss: 0.5889 - val_accuracy: 0.7369\n",
      "Epoch 61/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5664 - accuracy: 0.7463 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 62/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5647 - accuracy: 0.7478 - val_loss: 0.5889 - val_accuracy: 0.7369\n",
      "Epoch 63/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5684 - accuracy: 0.7443 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 64/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5645 - accuracy: 0.7481 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 65/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5679 - accuracy: 0.7448 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 66/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5660 - accuracy: 0.7466 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 67/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5659 - accuracy: 0.7467 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 68/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.5622 - accuracy: 0.7501 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 69/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.5635 - accuracy: 0.7489 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 70/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5665 - accuracy: 0.7462 - val_loss: 0.5889 - val_accuracy: 0.7369\n",
      "Epoch 71/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.5690 - accuracy: 0.7438 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 72/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5685 - accuracy: 0.7442 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 73/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5730 - accuracy: 0.7402 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 74/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5652 - accuracy: 0.7473 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 75/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5653 - accuracy: 0.7472 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 76/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5702 - accuracy: 0.7427 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 77/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5656 - accuracy: 0.7470 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 78/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5716 - accuracy: 0.7415 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 79/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.5683 - accuracy: 0.7445 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 80/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5681 - accuracy: 0.7446 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 81/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5625 - accuracy: 0.7498 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 82/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5632 - accuracy: 0.7492 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 83/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5666 - accuracy: 0.7461 - val_loss: 0.5889 - val_accuracy: 0.7369\n",
      "Epoch 84/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5667 - accuracy: 0.7460 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 85/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5567 - accuracy: 0.7552 - val_loss: 0.5889 - val_accuracy: 0.7369\n",
      "Epoch 86/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5704 - accuracy: 0.7425 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 87/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5658 - accuracy: 0.7468 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 88/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5572 - accuracy: 0.7547 - val_loss: 0.5889 - val_accuracy: 0.7369\n",
      "Epoch 89/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5658 - accuracy: 0.7467 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 90/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5666 - accuracy: 0.7461 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 91/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5664 - accuracy: 0.7462 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 92/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5603 - accuracy: 0.7519 - val_loss: 0.5889 - val_accuracy: 0.7369\n",
      "Epoch 93/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5598 - accuracy: 0.7524 - val_loss: 0.5889 - val_accuracy: 0.7369\n",
      "Epoch 94/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5630 - accuracy: 0.7494 - val_loss: 0.5889 - val_accuracy: 0.7369\n",
      "Epoch 95/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5609 - accuracy: 0.7513 - val_loss: 0.5889 - val_accuracy: 0.7369\n",
      "Epoch 96/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5679 - accuracy: 0.7448 - val_loss: 0.5889 - val_accuracy: 0.7369\n",
      "Epoch 97/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5594 - accuracy: 0.7527 - val_loss: 0.5889 - val_accuracy: 0.7369\n",
      "Epoch 98/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5700 - accuracy: 0.7429 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 99/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.5667 - accuracy: 0.7460 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 100/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5643 - accuracy: 0.7481 - val_loss: 0.5889 - val_accuracy: 0.7369\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, validation_split=0.33, epochs=100, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "702f7022",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>queries</th>\n",
       "      <th>apps</th>\n",
       "      <th>games</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[216, 359, 12329, 3, 45, 4002, 2066, 32, 3931,...</td>\n",
       "      <td>[4, 4, 25, 7, 30, 58, 16, 19, 17, 21, 10, 10, ...</td>\n",
       "      <td>[9151, 208]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[]</td>\n",
       "      <td>[129, 71, 9, 8, 11, 25, 18, 58, 6, 16, 125, 12...</td>\n",
       "      <td>[460, 4939, 14, 232, 6387, 1758, 5834, 3, 2]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[23463, 18831]</td>\n",
       "      <td>[9, 174, 65, 8, 63, 97, 62, 103, 61, 116, 59, ...</td>\n",
       "      <td>[448, 723, 267, 9064, 10634, 166, 782, 224, 27...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1634, 3609, 654]</td>\n",
       "      <td>[99, 73, 9, 8, 59, 37, 131, 3, 89, 6, 24, 16, ...</td>\n",
       "      <td>[78, 2607, 478, 435, 9, 192]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[11064, 227, 623, 1301, 43999, 35411, 2492, 11...</td>\n",
       "      <td>[9, 8, 17, 54, 3, 25, 22, 6, 21, 7, 14, 5, 817...</td>\n",
       "      <td>[1702, 1, 53]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             queries  \\\n",
       "0  [216, 359, 12329, 3, 45, 4002, 2066, 32, 3931,...   \n",
       "1                                                 []   \n",
       "2                                     [23463, 18831]   \n",
       "3                                  [1634, 3609, 654]   \n",
       "4  [11064, 227, 623, 1301, 43999, 35411, 2492, 11...   \n",
       "\n",
       "                                                apps  \\\n",
       "0  [4, 4, 25, 7, 30, 58, 16, 19, 17, 21, 10, 10, ...   \n",
       "1  [129, 71, 9, 8, 11, 25, 18, 58, 6, 16, 125, 12...   \n",
       "2  [9, 174, 65, 8, 63, 97, 62, 103, 61, 116, 59, ...   \n",
       "3  [99, 73, 9, 8, 59, 37, 131, 3, 89, 6, 24, 16, ...   \n",
       "4  [9, 8, 17, 54, 3, 25, 22, 6, 21, 7, 14, 5, 817...   \n",
       "\n",
       "                                               games  gender  \n",
       "0                                        [9151, 208]       1  \n",
       "1       [460, 4939, 14, 232, 6387, 1758, 5834, 3, 2]       0  \n",
       "2  [448, 723, 267, 9064, 10634, 166, 782, 224, 27...       1  \n",
       "3                       [78, 2607, 478, 435, 9, 192]       1  \n",
       "4                                      [1702, 1, 53]       1  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet(DATA_DIR, engine=\"pyarrow\")\n",
    "df[\"birth_year\"] = df[\"birth_year\"].astype(np.uint)\n",
    "valid_birth_year = df[\"birth_year\"][df[\"birth_year\"] != 0]\n",
    "mean_birth_year = round(valid_birth_year.mean())\n",
    "df[\"birth_year\"] = df[\"birth_year\"].replace(0, mean_birth_year)\n",
    "df[\"gender\"] = df[\"gender\"].replace({'M': 1, 'F': 0})\n",
    "df.drop(columns=['birth_year'], inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7d4c1ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df.pop('apps').apply(pd.Series), df], axis=1)\n",
    "df = pd.concat([df.pop('games').apply(pd.Series), df], axis=1)\n",
    "df = pd.concat([df.pop('queries').apply(pd.Series), df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d3010937",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.columns[df.isnull().mean() < 0.7]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fae8735f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7cfef3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y =  df.drop(columns=[\"gender\"]), df[\"gender\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "144aea61",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder()\n",
    "\n",
    "y_train = np.asarray(y_train).reshape((-1,1))\n",
    "y_test = np.asarray(y_test).reshape((-1,1))\n",
    "\n",
    "y_train = ohe.fit_transform(y_train).toarray()\n",
    "y_test = ohe.fit_transform(y_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "58aa45c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(100, input_dim=291, activation='relu'))\n",
    "model.add(Dense(60, activation='relu'))\n",
    "model.add(Dense(45, activation='relu'))\n",
    "model.add(Dense(30, activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d793764b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "338/338 [==============================] - 2s 2ms/step - loss: 30.9248 - accuracy: 0.6959 - val_loss: 0.6455 - val_accuracy: 0.7371\n",
      "Epoch 2/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.6248 - accuracy: 0.7446 - val_loss: 0.6125 - val_accuracy: 0.7372\n",
      "Epoch 3/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.5937 - accuracy: 0.7395 - val_loss: 0.5944 - val_accuracy: 0.7370\n",
      "Epoch 4/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.5756 - accuracy: 0.7455 - val_loss: 0.5870 - val_accuracy: 0.7370\n",
      "Epoch 5/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5740 - accuracy: 0.7409 - val_loss: 0.5862 - val_accuracy: 0.7371\n",
      "Epoch 6/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5637 - accuracy: 0.7499 - val_loss: 0.5763 - val_accuracy: 0.7370\n",
      "Epoch 7/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5628 - accuracy: 0.7501 - val_loss: 0.5770 - val_accuracy: 0.7371\n",
      "Epoch 8/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5679 - accuracy: 0.7454 - val_loss: 0.5764 - val_accuracy: 0.7370\n",
      "Epoch 9/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.5610 - accuracy: 0.7512 - val_loss: 0.5770 - val_accuracy: 0.7370\n",
      "Epoch 10/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5664 - accuracy: 0.7462 - val_loss: 0.5783 - val_accuracy: 0.7370\n",
      "Epoch 11/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5680 - accuracy: 0.7446 - val_loss: 0.5765 - val_accuracy: 0.7371\n",
      "Epoch 12/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.5690 - accuracy: 0.7438 - val_loss: 0.5766 - val_accuracy: 0.7371\n",
      "Epoch 13/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5684 - accuracy: 0.7444 - val_loss: 0.5766 - val_accuracy: 0.7371\n",
      "Epoch 14/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5673 - accuracy: 0.7454 - val_loss: 0.5766 - val_accuracy: 0.7371\n",
      "Epoch 15/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5701 - accuracy: 0.7428 - val_loss: 0.5766 - val_accuracy: 0.7371\n",
      "Epoch 16/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.5668 - accuracy: 0.7459 - val_loss: 0.5766 - val_accuracy: 0.7371\n",
      "Epoch 17/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5714 - accuracy: 0.7417 - val_loss: 0.5766 - val_accuracy: 0.7371\n",
      "Epoch 18/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5662 - accuracy: 0.7465 - val_loss: 0.5765 - val_accuracy: 0.7371\n",
      "Epoch 19/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5643 - accuracy: 0.7482 - val_loss: 0.5765 - val_accuracy: 0.7371\n",
      "Epoch 20/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5697 - accuracy: 0.7432 - val_loss: 0.5765 - val_accuracy: 0.7371\n",
      "Epoch 21/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5663 - accuracy: 0.7463 - val_loss: 0.5765 - val_accuracy: 0.7371\n",
      "Epoch 22/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5664 - accuracy: 0.7462 - val_loss: 0.5765 - val_accuracy: 0.7371\n",
      "Epoch 23/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5668 - accuracy: 0.7459 - val_loss: 0.5765 - val_accuracy: 0.7371\n",
      "Epoch 24/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5652 - accuracy: 0.7474 - val_loss: 0.5765 - val_accuracy: 0.7371\n",
      "Epoch 25/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5684 - accuracy: 0.7444 - val_loss: 0.5765 - val_accuracy: 0.7371\n",
      "Epoch 26/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5704 - accuracy: 0.7426 - val_loss: 0.5766 - val_accuracy: 0.7371\n",
      "Epoch 27/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5669 - accuracy: 0.7458 - val_loss: 0.5765 - val_accuracy: 0.7371\n",
      "Epoch 28/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5666 - accuracy: 0.7461 - val_loss: 0.5765 - val_accuracy: 0.7371\n",
      "Epoch 29/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5647 - accuracy: 0.7478 - val_loss: 0.5765 - val_accuracy: 0.7371\n",
      "Epoch 30/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5638 - accuracy: 0.7487 - val_loss: 0.5765 - val_accuracy: 0.7371\n",
      "Epoch 31/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5659 - accuracy: 0.7467 - val_loss: 0.5765 - val_accuracy: 0.7371\n",
      "Epoch 32/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5660 - accuracy: 0.7467 - val_loss: 0.5765 - val_accuracy: 0.7371\n",
      "Epoch 33/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.5694 - accuracy: 0.7435 - val_loss: 0.5766 - val_accuracy: 0.7371\n",
      "Epoch 34/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5633 - accuracy: 0.7491 - val_loss: 0.5765 - val_accuracy: 0.7371\n",
      "Epoch 35/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5597 - accuracy: 0.7525 - val_loss: 0.5765 - val_accuracy: 0.7371\n",
      "Epoch 36/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5668 - accuracy: 0.7459 - val_loss: 0.5765 - val_accuracy: 0.7371\n",
      "Epoch 37/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5703 - accuracy: 0.7426 - val_loss: 0.5766 - val_accuracy: 0.7371\n",
      "Epoch 38/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5673 - accuracy: 0.7455 - val_loss: 0.5765 - val_accuracy: 0.7371\n",
      "Epoch 39/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5603 - accuracy: 0.7519 - val_loss: 0.5765 - val_accuracy: 0.7371\n",
      "Epoch 40/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.5665 - accuracy: 0.7461 - val_loss: 0.5765 - val_accuracy: 0.7371\n",
      "Epoch 41/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5677 - accuracy: 0.7451 - val_loss: 0.5765 - val_accuracy: 0.7371\n",
      "Epoch 42/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5685 - accuracy: 0.7443 - val_loss: 0.5766 - val_accuracy: 0.7371\n",
      "Epoch 43/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5642 - accuracy: 0.7483 - val_loss: 0.5766 - val_accuracy: 0.7371\n",
      "Epoch 44/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5671 - accuracy: 0.7456 - val_loss: 0.5766 - val_accuracy: 0.7371\n",
      "Epoch 45/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5618 - accuracy: 0.7505 - val_loss: 0.5765 - val_accuracy: 0.7371\n",
      "Epoch 46/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5649 - accuracy: 0.7477 - val_loss: 0.5765 - val_accuracy: 0.7371\n",
      "Epoch 47/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5663 - accuracy: 0.7464 - val_loss: 0.5765 - val_accuracy: 0.7371\n",
      "Epoch 48/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5663 - accuracy: 0.7463 - val_loss: 0.5765 - val_accuracy: 0.7371\n",
      "Epoch 49/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5696 - accuracy: 0.7433 - val_loss: 0.5765 - val_accuracy: 0.7371\n",
      "Epoch 50/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5654 - accuracy: 0.7472 - val_loss: 0.5765 - val_accuracy: 0.7371\n",
      "Epoch 51/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5620 - accuracy: 0.7503 - val_loss: 0.5765 - val_accuracy: 0.7371\n",
      "Epoch 52/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5677 - accuracy: 0.7451 - val_loss: 0.5765 - val_accuracy: 0.7371\n",
      "Epoch 53/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5712 - accuracy: 0.7418 - val_loss: 0.5766 - val_accuracy: 0.7371\n",
      "Epoch 54/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5677 - accuracy: 0.7450 - val_loss: 0.5765 - val_accuracy: 0.7371\n",
      "Epoch 55/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5654 - accuracy: 0.7472 - val_loss: 0.5765 - val_accuracy: 0.7371\n",
      "Epoch 56/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.5718 - accuracy: 0.7413 - val_loss: 0.5766 - val_accuracy: 0.7371\n",
      "Epoch 57/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5616 - accuracy: 0.7507 - val_loss: 0.5765 - val_accuracy: 0.7371\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5702 - accuracy: 0.7428 - val_loss: 0.5766 - val_accuracy: 0.7371\n",
      "Epoch 59/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5680 - accuracy: 0.7447 - val_loss: 0.5765 - val_accuracy: 0.7371\n",
      "Epoch 60/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5699 - accuracy: 0.7430 - val_loss: 0.5766 - val_accuracy: 0.7371\n",
      "Epoch 61/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5661 - accuracy: 0.7466 - val_loss: 0.5765 - val_accuracy: 0.7371\n",
      "Epoch 62/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5676 - accuracy: 0.7451 - val_loss: 0.5765 - val_accuracy: 0.7371\n",
      "Epoch 63/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5691 - accuracy: 0.7437 - val_loss: 0.5765 - val_accuracy: 0.7371\n",
      "Epoch 64/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5689 - accuracy: 0.7440 - val_loss: 0.5765 - val_accuracy: 0.7371\n",
      "Epoch 65/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.5683 - accuracy: 0.7445 - val_loss: 0.5766 - val_accuracy: 0.7371\n",
      "Epoch 66/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5700 - accuracy: 0.7429 - val_loss: 0.5766 - val_accuracy: 0.7371\n",
      "Epoch 67/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.5635 - accuracy: 0.7489 - val_loss: 0.5766 - val_accuracy: 0.7371\n",
      "Epoch 68/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5685 - accuracy: 0.7443 - val_loss: 0.5766 - val_accuracy: 0.7371\n",
      "Epoch 69/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5594 - accuracy: 0.7528 - val_loss: 0.5765 - val_accuracy: 0.7371\n",
      "Epoch 70/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.5652 - accuracy: 0.7474 - val_loss: 0.5765 - val_accuracy: 0.7371\n",
      "Epoch 71/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5658 - accuracy: 0.7469 - val_loss: 0.5765 - val_accuracy: 0.7371\n",
      "Epoch 72/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5669 - accuracy: 0.7458 - val_loss: 0.5766 - val_accuracy: 0.7371\n",
      "Epoch 73/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5641 - accuracy: 0.7484 - val_loss: 0.5765 - val_accuracy: 0.7371\n",
      "Epoch 74/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.5685 - accuracy: 0.7443 - val_loss: 0.5766 - val_accuracy: 0.7371\n",
      "Epoch 75/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5650 - accuracy: 0.7476 - val_loss: 0.5765 - val_accuracy: 0.7371\n",
      "Epoch 76/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5691 - accuracy: 0.7438 - val_loss: 0.5765 - val_accuracy: 0.7371\n",
      "Epoch 77/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5639 - accuracy: 0.7486 - val_loss: 0.5765 - val_accuracy: 0.7371\n",
      "Epoch 78/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.5649 - accuracy: 0.7476 - val_loss: 0.5765 - val_accuracy: 0.7371\n",
      "Epoch 79/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.5691 - accuracy: 0.7438 - val_loss: 0.5766 - val_accuracy: 0.7371\n",
      "Epoch 80/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.5648 - accuracy: 0.7478 - val_loss: 0.5765 - val_accuracy: 0.7371\n",
      "Epoch 81/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5675 - accuracy: 0.7452 - val_loss: 0.5765 - val_accuracy: 0.7371\n",
      "Epoch 82/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5659 - accuracy: 0.7467 - val_loss: 0.5765 - val_accuracy: 0.7371\n",
      "Epoch 83/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5625 - accuracy: 0.7499 - val_loss: 0.5765 - val_accuracy: 0.7371\n",
      "Epoch 84/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5718 - accuracy: 0.7413 - val_loss: 0.5766 - val_accuracy: 0.7371\n",
      "Epoch 85/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5618 - accuracy: 0.7505 - val_loss: 0.5765 - val_accuracy: 0.7371\n",
      "Epoch 86/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.5658 - accuracy: 0.7468 - val_loss: 0.5765 - val_accuracy: 0.7371\n",
      "Epoch 87/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5657 - accuracy: 0.7469 - val_loss: 0.5765 - val_accuracy: 0.7371\n",
      "Epoch 88/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5663 - accuracy: 0.7464 - val_loss: 0.5766 - val_accuracy: 0.7371\n",
      "Epoch 89/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5689 - accuracy: 0.7439 - val_loss: 0.5766 - val_accuracy: 0.7371\n",
      "Epoch 90/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5617 - accuracy: 0.7506 - val_loss: 0.5765 - val_accuracy: 0.7371\n",
      "Epoch 91/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5669 - accuracy: 0.7458 - val_loss: 0.5765 - val_accuracy: 0.7371\n",
      "Epoch 92/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.5674 - accuracy: 0.7453 - val_loss: 0.5765 - val_accuracy: 0.7371\n",
      "Epoch 93/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5646 - accuracy: 0.7479 - val_loss: 0.5765 - val_accuracy: 0.7371\n",
      "Epoch 94/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5666 - accuracy: 0.7461 - val_loss: 0.5765 - val_accuracy: 0.7371\n",
      "Epoch 95/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5706 - accuracy: 0.7424 - val_loss: 0.5765 - val_accuracy: 0.7371\n",
      "Epoch 96/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.5609 - accuracy: 0.7514 - val_loss: 0.5765 - val_accuracy: 0.7371\n",
      "Epoch 97/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5639 - accuracy: 0.7486 - val_loss: 0.5765 - val_accuracy: 0.7371\n",
      "Epoch 98/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5676 - accuracy: 0.7452 - val_loss: 0.5765 - val_accuracy: 0.7371\n",
      "Epoch 99/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5685 - accuracy: 0.7443 - val_loss: 0.5765 - val_accuracy: 0.7371\n",
      "Epoch 100/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5681 - accuracy: 0.7447 - val_loss: 0.5766 - val_accuracy: 0.7371\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, validation_split=0.33, epochs=100, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b5cb6f2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e1cb1f",
   "metadata": {},
   "source": [
    "It seems that my model has lot of problem. Let's find it out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "75f0e523",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y =  df.drop(columns=[\"gender\"]), df[\"gender\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5ae7baaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kerastuner.engine.hyperparameters import HyperParameters\n",
    "from kerastuner.tuners import RandomSearch\n",
    "import time\n",
    "\n",
    "LOG_DIR = f\"{int(time.time())}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "3db49daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "def build_model(hp):\n",
    "    \n",
    "    model = keras.models.Sequential()\n",
    "    \n",
    "    model.add(Dense(hp.Int(\"input_units\", min_value=100, max_value=500, step=20), input_dim=291, activation='relu'))\n",
    "    \n",
    "    for i in range(hp.Int('n_layers', 1, 4)):\n",
    "        model.add(Dense(hp.Int(\"dense_units\", min_value=10, max_value=300, step=10), activation='relu'))\n",
    "    \n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8618b8a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1 Complete [00h 06m 05s]\n",
      "val_accuracy: 0.741651177406311\n",
      "\n",
      "Best val_accuracy So Far: 0.741651177406311\n",
      "Total elapsed time: 00h 06m 05s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective = \"val_accuracy\",\n",
    "    max_trials = 1,\n",
    "    executions_per_trial = 1,\n",
    "    directory = LOG_DIR\n",
    ")\n",
    "\n",
    "tuner.search(x=X_train, y=y_train, epochs=100, batch_size=10,validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "75ce74a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(f\"tuner_{int(time.time())}.pkl\", \"wb\") as f:\n",
    "    pickle.dump(tuner, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1037e149",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = pickle.load(open(\"tuner_1627669198.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "0335a06c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_units': 260, 'n_layers': 3, 'dense_units': 110}\n",
      "Results summary\n",
      "Results in 1627666980\\untitled_project\n",
      "Showing 10 best trials\n",
      "Objective(name='val_accuracy', direction='max')\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "input_units: 260\n",
      "n_layers: 3\n",
      "dense_units: 110\n",
      "Score: 0.741651177406311\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(tuner.get_best_hyperparameters()[0].values)\n",
    "print(tuner.results_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "04474c4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-0._module.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-0._module.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-1._module.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-1._module.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-2._module.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-2._module.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-3._module.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-3._module.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-4._module.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-4._module.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0._module.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0._module.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1._module.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1._module.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2._module.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2._module.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-3._module.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-3._module.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-4._module.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-4._module.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0._module.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0._module.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1._module.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1._module.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2._module.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2._module.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-3._module.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-3._module.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-4._module.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-4._module.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Epoch 1/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.6063 - accuracy: 0.7459 - val_loss: 0.5990 - val_accuracy: 0.7366\n",
      "Epoch 2/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5933 - accuracy: 0.7462 - val_loss: 0.5815 - val_accuracy: 0.7371\n",
      "Epoch 3/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5813 - val_accuracy: 0.7371\n",
      "Epoch 4/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.6328 - accuracy: 0.7460 - val_loss: 0.5855 - val_accuracy: 0.7368\n",
      "Epoch 5/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5790 - accuracy: 0.7463 - val_loss: 0.5761 - val_accuracy: 0.7370\n",
      "Epoch 6/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5666 - accuracy: 0.7464 - val_loss: 0.5765 - val_accuracy: 0.7370\n",
      "Epoch 7/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5668 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 8/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5667 - accuracy: 0.7464 - val_loss: 0.5768 - val_accuracy: 0.7370\n",
      "Epoch 9/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5667 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 10/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5666 - accuracy: 0.7464 - val_loss: 0.5764 - val_accuracy: 0.7370\n",
      "Epoch 11/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 12/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5772 - val_accuracy: 0.7370\n",
      "Epoch 13/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5667 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 14/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5764 - val_accuracy: 0.7370\n",
      "Epoch 15/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5775 - val_accuracy: 0.7370\n",
      "Epoch 16/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5666 - accuracy: 0.7464 - val_loss: 0.5772 - val_accuracy: 0.7370\n",
      "Epoch 17/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 18/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5666 - accuracy: 0.7464 - val_loss: 0.5763 - val_accuracy: 0.7370\n",
      "Epoch 19/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5666 - accuracy: 0.7464 - val_loss: 0.5771 - val_accuracy: 0.7370\n",
      "Epoch 20/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5666 - accuracy: 0.7464 - val_loss: 0.5773 - val_accuracy: 0.7370\n",
      "Epoch 21/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 22/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5666 - accuracy: 0.7464 - val_loss: 0.5766 - val_accuracy: 0.7370\n",
      "Epoch 23/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5666 - accuracy: 0.7464 - val_loss: 0.5765 - val_accuracy: 0.7370\n",
      "Epoch 24/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5667 - accuracy: 0.7464 - val_loss: 0.5766 - val_accuracy: 0.7370\n",
      "Epoch 25/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5768 - val_accuracy: 0.7370\n",
      "Epoch 26/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 27/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5766 - val_accuracy: 0.7370\n",
      "Epoch 28/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5764 - val_accuracy: 0.7370\n",
      "Epoch 29/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5764 - val_accuracy: 0.7370\n",
      "Epoch 30/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 31/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5769 - val_accuracy: 0.7370\n",
      "Epoch 32/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5663 - accuracy: 0.7464 - val_loss: 0.5763 - val_accuracy: 0.7370\n",
      "Epoch 33/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5767 - val_accuracy: 0.7370\n",
      "Epoch 34/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5773 - val_accuracy: 0.7370\n",
      "Epoch 35/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5764 - val_accuracy: 0.7370\n",
      "Epoch 36/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 37/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 38/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 39/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5761 - val_accuracy: 0.7370\n",
      "Epoch 40/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5764 - val_accuracy: 0.7370\n",
      "Epoch 41/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5767 - val_accuracy: 0.7370\n",
      "Epoch 42/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5763 - val_accuracy: 0.7370\n",
      "Epoch 43/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 44/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 45/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5765 - val_accuracy: 0.7370\n",
      "Epoch 46/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5770 - val_accuracy: 0.7370\n",
      "Epoch 47/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 48/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 49/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5763 - val_accuracy: 0.7370\n",
      "Epoch 50/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 51/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5663 - accuracy: 0.7464 - val_loss: 0.5768 - val_accuracy: 0.7370\n",
      "Epoch 52/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5770 - val_accuracy: 0.7370\n",
      "Epoch 53/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5770 - val_accuracy: 0.7370\n",
      "Epoch 54/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 55/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 56/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5765 - val_accuracy: 0.7370\n",
      "Epoch 57/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5768 - val_accuracy: 0.7370\n",
      "Epoch 58/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5775 - val_accuracy: 0.7370\n",
      "Epoch 59/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 60/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5666 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 61/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5761 - val_accuracy: 0.7370\n",
      "Epoch 62/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 63/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5765 - val_accuracy: 0.7370\n",
      "Epoch 64/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5663 - accuracy: 0.7464 - val_loss: 0.5770 - val_accuracy: 0.7370\n",
      "Epoch 65/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5763 - val_accuracy: 0.7370\n",
      "Epoch 66/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5767 - val_accuracy: 0.7370\n",
      "Epoch 67/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5764 - val_accuracy: 0.7370\n",
      "Epoch 68/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5761 - val_accuracy: 0.7370\n",
      "Epoch 69/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5765 - val_accuracy: 0.7370\n",
      "Epoch 70/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5776 - val_accuracy: 0.7370\n",
      "Epoch 71/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5662 - accuracy: 0.7464 - val_loss: 0.5767 - val_accuracy: 0.7370\n",
      "Epoch 72/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5763 - val_accuracy: 0.7370\n",
      "Epoch 73/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5767 - val_accuracy: 0.7370\n",
      "Epoch 74/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 75/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5764 - val_accuracy: 0.7370\n",
      "Epoch 76/100\n",
      "2159/2159 [==============================] - 3s 2ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5767 - val_accuracy: 0.7370\n",
      "Epoch 77/100\n",
      "2159/2159 [==============================] - 4s 2ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 78/100\n",
      "2159/2159 [==============================] - 4s 2ms/step - loss: 0.5663 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 79/100\n",
      "2159/2159 [==============================] - 4s 2ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5766 - val_accuracy: 0.7370\n",
      "Epoch 80/100\n",
      "2159/2159 [==============================] - 4s 2ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 81/100\n",
      "2159/2159 [==============================] - 4s 2ms/step - loss: 0.5663 - accuracy: 0.7464 - val_loss: 0.5775 - val_accuracy: 0.7370\n",
      "Epoch 82/100\n",
      "2159/2159 [==============================] - 4s 2ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2159/2159 [==============================] - 4s 2ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5766 - val_accuracy: 0.7370\n",
      "Epoch 84/100\n",
      "2159/2159 [==============================] - 4s 2ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5767 - val_accuracy: 0.7370\n",
      "Epoch 85/100\n",
      "2159/2159 [==============================] - 4s 2ms/step - loss: 0.5663 - accuracy: 0.7464 - val_loss: 0.5773 - val_accuracy: 0.7370\n",
      "Epoch 86/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 87/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5663 - accuracy: 0.7464 - val_loss: 0.5771 - val_accuracy: 0.7370\n",
      "Epoch 88/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5663 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 89/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5767 - val_accuracy: 0.7370\n",
      "Epoch 90/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5663 - accuracy: 0.7464 - val_loss: 0.5763 - val_accuracy: 0.7370\n",
      "Epoch 91/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5768 - val_accuracy: 0.7370\n",
      "Epoch 92/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5764 - val_accuracy: 0.7370\n",
      "Epoch 93/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 94/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5764 - val_accuracy: 0.7370\n",
      "Epoch 95/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5763 - val_accuracy: 0.7370\n",
      "Epoch 96/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 97/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5763 - val_accuracy: 0.7370\n",
      "Epoch 98/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5761 - val_accuracy: 0.7370\n",
      "Epoch 99/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5767 - val_accuracy: 0.7370\n",
      "Epoch 100/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5773 - val_accuracy: 0.7370\n"
     ]
    }
   ],
   "source": [
    "model = tuner.get_best_models()[0]\n",
    "history = model.fit(X_train, y_train, validation_split=0.33, epochs=100, batch_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d2121c",
   "metadata": {},
   "source": [
    "Accuracy is not changing one reason can be because of `optimizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "9e1610d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import SGD\n",
    "opt = SGD(learning_rate=0.01)\n",
    "\n",
    "def build_model2(hp):\n",
    "    \n",
    "    model = keras.models.Sequential()\n",
    "    \n",
    "    model.add(Dense(hp.Int(\"input_units\", min_value=100, max_value=500, step=20), input_dim=291, activation='relu'))\n",
    "    \n",
    "    for i in range(hp.Int('n_layers', 1, 4)):\n",
    "        model.add(Dense(hp.Int(\"dense_units\", min_value=10, max_value=300, step=10), activation='relu'))\n",
    "    \n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d401929a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1 Complete [00h 06m 33s]\n",
      "val_accuracy: 0.741651177406311\n",
      "\n",
      "Best val_accuracy So Far: 0.741651177406311\n",
      "Total elapsed time: 00h 06m 33s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "LOG_DIR = f\"{int(time.time())}\"\n",
    "\n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective = \"val_accuracy\",\n",
    "    max_trials = 1,\n",
    "    executions_per_trial = 1,\n",
    "    directory = LOG_DIR\n",
    ")\n",
    "\n",
    "tuner.search(x=X_train, y=y_train, epochs=100, batch_size=10,validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "6739cda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"tuner_{int(time.time())}.pkl\", \"wb\") as f:\n",
    "    pickle.dump(tuner, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "e4b946fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = pickle.load(open(\"tuner_1627670879.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "dd81838a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_units': 140, 'n_layers': 3, 'dense_units': 170}\n",
      "Results summary\n",
      "Results in 1627670169\\untitled_project\n",
      "Showing 10 best trials\n",
      "Objective(name='val_accuracy', direction='max')\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "input_units: 140\n",
      "n_layers: 3\n",
      "dense_units: 170\n",
      "Score: 0.741651177406311\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(tuner.get_best_hyperparameters()[0].values)\n",
    "print(tuner.results_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "7e5ebda1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5675 - accuracy: 0.7463 - val_loss: 0.5761 - val_accuracy: 0.7371\n",
      "Epoch 2/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5686 - accuracy: 0.7463 - val_loss: 0.5762 - val_accuracy: 0.7371\n",
      "Epoch 3/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5704 - accuracy: 0.7462 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 4/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5711 - accuracy: 0.7463 - val_loss: 0.5763 - val_accuracy: 0.7370\n",
      "Epoch 5/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5666 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 6/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5668 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 7/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5668 - accuracy: 0.7464 - val_loss: 0.5763 - val_accuracy: 0.7370\n",
      "Epoch 8/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5666 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 9/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5667 - accuracy: 0.7464 - val_loss: 0.5763 - val_accuracy: 0.7370\n",
      "Epoch 10/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5668 - accuracy: 0.7464 - val_loss: 0.5765 - val_accuracy: 0.7370\n",
      "Epoch 11/100\n",
      "2159/2159 [==============================] - 3s 2ms/step - loss: 0.5667 - accuracy: 0.7464 - val_loss: 0.5768 - val_accuracy: 0.7370\n",
      "Epoch 12/100\n",
      "2159/2159 [==============================] - 4s 2ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5773 - val_accuracy: 0.7370\n",
      "Epoch 13/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5763 - val_accuracy: 0.7370\n",
      "Epoch 14/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5667 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 15/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5667 - accuracy: 0.7464 - val_loss: 0.5766 - val_accuracy: 0.7370\n",
      "Epoch 16/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5666 - accuracy: 0.7464 - val_loss: 0.5768 - val_accuracy: 0.7370\n",
      "Epoch 17/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5666 - accuracy: 0.7464 - val_loss: 0.5764 - val_accuracy: 0.7370\n",
      "Epoch 18/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5663 - accuracy: 0.7464 - val_loss: 0.5770 - val_accuracy: 0.7370\n",
      "Epoch 19/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5666 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 20/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5667 - accuracy: 0.7464 - val_loss: 0.5766 - val_accuracy: 0.7370\n",
      "Epoch 21/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5666 - accuracy: 0.7464 - val_loss: 0.5773 - val_accuracy: 0.7370\n",
      "Epoch 22/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5775 - val_accuracy: 0.7370\n",
      "Epoch 23/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5666 - accuracy: 0.7464 - val_loss: 0.5766 - val_accuracy: 0.7370\n",
      "Epoch 24/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5666 - accuracy: 0.7464 - val_loss: 0.5764 - val_accuracy: 0.7370\n",
      "Epoch 25/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 26/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5794 - val_accuracy: 0.7370\n",
      "Epoch 27/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5666 - accuracy: 0.7464 - val_loss: 0.5783 - val_accuracy: 0.7370\n",
      "Epoch 28/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5767 - val_accuracy: 0.7370\n",
      "Epoch 29/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5666 - accuracy: 0.7464 - val_loss: 0.5763 - val_accuracy: 0.7370\n",
      "Epoch 30/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5770 - val_accuracy: 0.7370\n",
      "Epoch 31/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5666 - accuracy: 0.7464 - val_loss: 0.5764 - val_accuracy: 0.7370\n",
      "Epoch 32/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5666 - accuracy: 0.7464 - val_loss: 0.5761 - val_accuracy: 0.7370\n",
      "Epoch 33/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 34/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 35/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5666 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 36/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5763 - val_accuracy: 0.7370\n",
      "Epoch 37/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5666 - accuracy: 0.7464 - val_loss: 0.5765 - val_accuracy: 0.7370\n",
      "Epoch 38/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5666 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 39/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5765 - val_accuracy: 0.7370\n",
      "Epoch 40/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5666 - accuracy: 0.7464 - val_loss: 0.5765 - val_accuracy: 0.7370\n",
      "Epoch 41/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 42/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5666 - accuracy: 0.7464 - val_loss: 0.5766 - val_accuracy: 0.7370\n",
      "Epoch 43/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5768 - val_accuracy: 0.7370\n",
      "Epoch 44/100\n",
      "2159/2159 [==============================] - 3s 2ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5775 - val_accuracy: 0.7370\n",
      "Epoch 45/100\n",
      "2159/2159 [==============================] - 4s 2ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5770 - val_accuracy: 0.7370\n",
      "Epoch 46/100\n",
      "2159/2159 [==============================] - 4s 2ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5779 - val_accuracy: 0.7370\n",
      "Epoch 47/100\n",
      "2159/2159 [==============================] - 4s 2ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 48/100\n",
      "2159/2159 [==============================] - 4s 2ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 49/100\n",
      "2159/2159 [==============================] - 3s 2ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5769 - val_accuracy: 0.7370\n",
      "Epoch 50/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 51/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5773 - val_accuracy: 0.7370\n",
      "Epoch 52/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5767 - val_accuracy: 0.7370\n",
      "Epoch 53/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 54/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5663 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 55/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 56/100\n",
      "2159/2159 [==============================] - 3s 2ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5769 - val_accuracy: 0.7370\n",
      "Epoch 57/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5765 - val_accuracy: 0.7370\n",
      "Epoch 58/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5764 - val_accuracy: 0.7370\n",
      "Epoch 59/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5763 - val_accuracy: 0.7370\n",
      "Epoch 60/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5766 - val_accuracy: 0.7370\n",
      "Epoch 61/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5663 - accuracy: 0.7464 - val_loss: 0.5765 - val_accuracy: 0.7370\n",
      "Epoch 62/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5763 - val_accuracy: 0.7370\n",
      "Epoch 63/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5663 - accuracy: 0.7464 - val_loss: 0.5770 - val_accuracy: 0.7370\n",
      "Epoch 64/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5769 - val_accuracy: 0.7370\n",
      "Epoch 65/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5663 - accuracy: 0.7464 - val_loss: 0.5765 - val_accuracy: 0.7370\n",
      "Epoch 66/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5764 - val_accuracy: 0.7370\n",
      "Epoch 67/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 68/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 69/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5663 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 70/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 71/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5768 - val_accuracy: 0.7370\n",
      "Epoch 72/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5763 - val_accuracy: 0.7370\n",
      "Epoch 73/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 74/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5769 - val_accuracy: 0.7370\n",
      "Epoch 75/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5765 - val_accuracy: 0.7370\n",
      "Epoch 76/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5773 - val_accuracy: 0.7370\n",
      "Epoch 77/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5768 - val_accuracy: 0.7370\n",
      "Epoch 78/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 79/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5764 - val_accuracy: 0.7370\n",
      "Epoch 80/100\n",
      "2159/2159 [==============================] - 3s 2ms/step - loss: 0.5663 - accuracy: 0.7464 - val_loss: 0.5769 - val_accuracy: 0.7370\n",
      "Epoch 81/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5766 - val_accuracy: 0.7370\n",
      "Epoch 82/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 83/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5767 - val_accuracy: 0.7370\n",
      "Epoch 84/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5663 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 85/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5663 - accuracy: 0.7464 - val_loss: 0.5764 - val_accuracy: 0.7370\n",
      "Epoch 86/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5766 - val_accuracy: 0.7370\n",
      "Epoch 87/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5663 - accuracy: 0.7464 - val_loss: 0.5763 - val_accuracy: 0.7370\n",
      "Epoch 88/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5763 - val_accuracy: 0.7370\n",
      "Epoch 89/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5767 - val_accuracy: 0.7370\n",
      "Epoch 90/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5765 - val_accuracy: 0.7370\n",
      "Epoch 91/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5763 - val_accuracy: 0.7370\n",
      "Epoch 92/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 93/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 94/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5663 - accuracy: 0.7464 - val_loss: 0.5773 - val_accuracy: 0.7370\n",
      "Epoch 95/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5766 - val_accuracy: 0.7370\n",
      "Epoch 96/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 97/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 98/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 99/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5767 - val_accuracy: 0.7370\n",
      "Epoch 100/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5771 - val_accuracy: 0.7370\n"
     ]
    }
   ],
   "source": [
    "model = tuner.get_best_models()[0]\n",
    "history = model.fit(X_train, y_train, validation_split=0.33, epochs=100, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "e46691be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.741651148355059\n",
      "Balanced Accuracy:  0.5\n",
      "Precision:  0.741651148355059\n",
      "Recall:  1.0\n",
      "F1:  0.8516644094375936\n"
     ]
    }
   ],
   "source": [
    "predicted = model.predict_classes(X_test)\n",
    "evaluate(predicted, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "75cf718f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There 0 0 values in prediction.\n",
      "There 8055 1 values in prediction.\n",
      "There 2081 0 values in test dataset.\n",
      "There 5974 1 values in test dataset.\n"
     ]
    }
   ],
   "source": [
    "count_0_predicted = 0\n",
    "count_1_predicted = 0\n",
    "count_0_actual = 0\n",
    "count_1_actual = 0\n",
    "for i in range(len(predicted)):\n",
    "    if predicted[i] == 0:\n",
    "        count_0_predicted += 1\n",
    "    else:\n",
    "        count_1_predicted += 1\n",
    "    if y_test.iloc[i] == 0:\n",
    "        count_0_actual += 1\n",
    "    else:\n",
    "        count_1_actual += 1\n",
    "print(f\"There {count_0_predicted} 0 values in prediction.\")\n",
    "print(f\"There {count_1_predicted} 1 values in prediction.\")\n",
    "\n",
    "print(f\"There {count_0_actual} 0 values in test dataset.\")\n",
    "print(f\"There {count_1_actual} 1 values in test dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "0e5c7d18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.74301676, 0.74518932, 0.74239603, 0.74239603, 0.74332713,\n",
       "       0.74208566, 0.74262651, 0.74293698, 0.74293698, 0.74138466])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "model = RandomForestClassifier(random_state=0, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100)\n",
    "cross_val_score(model, X_train, y_train, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "a0ab8ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)\n",
    "predicted = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "77758b29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7415270018621974\n",
      "Balanced Accuracy:  0.5017951810078175\n",
      "Precision:  0.7423412204234122\n",
      "Recall:  0.9978239035821895\n",
      "F1:  0.8513281919451585\n"
     ]
    }
   ],
   "source": [
    "evaluate(predicted, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "c55815a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There 25 0 values in prediction.\n",
      "There 8030 1 values in prediction.\n",
      "There 2081 0 values in test dataset.\n",
      "There 5974 1 values in test dataset.\n"
     ]
    }
   ],
   "source": [
    "count_0_predicted = 0\n",
    "count_1_predicted = 0\n",
    "count_0_actual = 0\n",
    "count_1_actual = 0\n",
    "for i in range(len(predicted)):\n",
    "    if predicted[i] == 0:\n",
    "        count_0_predicted += 1\n",
    "    else:\n",
    "        count_1_predicted += 1\n",
    "    if y_test.iloc[i] == 0:\n",
    "        count_0_actual += 1\n",
    "    else:\n",
    "        count_1_actual += 1\n",
    "print(f\"There {count_0_predicted} 0 values in prediction.\")\n",
    "print(f\"There {count_1_predicted} 1 values in prediction.\")\n",
    "\n",
    "print(f\"There {count_0_actual} 0 values in test dataset.\")\n",
    "print(f\"There {count_1_actual} 1 values in test dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad05cc84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>queries</th>\n",
       "      <th>apps</th>\n",
       "      <th>games</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[216, 359, 12329, 3, 45, 4002, 2066, 32, 3931,...</td>\n",
       "      <td>[4, 4, 25, 7, 30, 58, 16, 19, 17, 21, 10, 10, ...</td>\n",
       "      <td>[9151, 208]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[]</td>\n",
       "      <td>[129, 71, 9, 8, 11, 25, 18, 58, 6, 16, 125, 12...</td>\n",
       "      <td>[460, 4939, 14, 232, 6387, 1758, 5834, 3, 2]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[23463, 18831]</td>\n",
       "      <td>[9, 174, 65, 8, 63, 97, 62, 103, 61, 116, 59, ...</td>\n",
       "      <td>[448, 723, 267, 9064, 10634, 166, 782, 224, 27...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1634, 3609, 654]</td>\n",
       "      <td>[99, 73, 9, 8, 59, 37, 131, 3, 89, 6, 24, 16, ...</td>\n",
       "      <td>[78, 2607, 478, 435, 9, 192]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[11064, 227, 623, 1301, 43999, 35411, 2492, 11...</td>\n",
       "      <td>[9, 8, 17, 54, 3, 25, 22, 6, 21, 7, 14, 5, 817...</td>\n",
       "      <td>[1702, 1, 53]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             queries  \\\n",
       "0  [216, 359, 12329, 3, 45, 4002, 2066, 32, 3931,...   \n",
       "1                                                 []   \n",
       "2                                     [23463, 18831]   \n",
       "3                                  [1634, 3609, 654]   \n",
       "4  [11064, 227, 623, 1301, 43999, 35411, 2492, 11...   \n",
       "\n",
       "                                                apps  \\\n",
       "0  [4, 4, 25, 7, 30, 58, 16, 19, 17, 21, 10, 10, ...   \n",
       "1  [129, 71, 9, 8, 11, 25, 18, 58, 6, 16, 125, 12...   \n",
       "2  [9, 174, 65, 8, 63, 97, 62, 103, 61, 116, 59, ...   \n",
       "3  [99, 73, 9, 8, 59, 37, 131, 3, 89, 6, 24, 16, ...   \n",
       "4  [9, 8, 17, 54, 3, 25, 22, 6, 21, 7, 14, 5, 817...   \n",
       "\n",
       "                                               games  gender  \n",
       "0                                        [9151, 208]       1  \n",
       "1       [460, 4939, 14, 232, 6387, 1758, 5834, 3, 2]       0  \n",
       "2  [448, 723, 267, 9064, 10634, 166, 782, 224, 27...       1  \n",
       "3                       [78, 2607, 478, 435, 9, 192]       1  \n",
       "4                                      [1702, 1, 53]       1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(columns=['birth_year'], inplace=True)\n",
    "df[\"gender\"] = df[\"gender\"].replace({'M': 1, 'F': 0})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15b8af3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y =  df.drop(columns=[\"gender\"]), df[\"gender\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05f2a522",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>queries</th>\n",
       "      <th>apps</th>\n",
       "      <th>games</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9391</th>\n",
       "      <td>[2504, 30655, 32035, 3, 4]</td>\n",
       "      <td>[9, 10, 10, 39, 17, 3, 21, 12, 7, 41, 58, 6, 1...</td>\n",
       "      <td>[336, 822, 14]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36089</th>\n",
       "      <td>[1400, 4, 9, 18236, 16200, 10739, 9713, 70, 14...</td>\n",
       "      <td>[9, 8, 10, 10, 39, 17, 48, 54, 3, 25, 22, 6, 2...</td>\n",
       "      <td>[1, 145]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38820</th>\n",
       "      <td>[5327, 12, 3, 10462, 30102, 921, 1247, 6869, 7...</td>\n",
       "      <td>[9, 17, 3, 25, 22, 6, 21, 7, 14, 23, 2, 19, 10...</td>\n",
       "      <td>[78, 11, 122, 113, 192, 2726, 34, 44, 17, 4, 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33815</th>\n",
       "      <td>[479, 1717, 1205, 875, 3570, 4]</td>\n",
       "      <td>[73, 9, 8, 59, 37, 131, 3, 89, 6, 16, 85, 12, ...</td>\n",
       "      <td>[771, 3198]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31187</th>\n",
       "      <td>[163, 18284, 143, 1082, 258, 28721]</td>\n",
       "      <td>[25, 71, 125, 16, 7, 5, 10, 10, 48, 3, 79, 47,...</td>\n",
       "      <td>[689, 45]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6265</th>\n",
       "      <td>[824, 197, 42, 259, 4127, 894, 719, 344]</td>\n",
       "      <td>[9, 8, 105, 10, 10, 17, 54, 3, 25, 95, 22, 6, ...</td>\n",
       "      <td>[23, 947, 35, 435, 1327, 2694, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11284</th>\n",
       "      <td>[1565, 712, 24838, 39622, 20862, 22, 238, 599,...</td>\n",
       "      <td>[9, 8, 105, 10, 10, 39, 17, 3, 25, 22, 6, 24, ...</td>\n",
       "      <td>[64, 361, 2093, 2708, 1228, 318, 711, 1844, 2392]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38158</th>\n",
       "      <td>[4118, 12355, 723, 41687, 1678, 30560, 184, 85...</td>\n",
       "      <td>[9, 8, 17, 3, 25, 22, 6, 21, 7, 14, 5, 23, 2, ...</td>\n",
       "      <td>[35, 4697, 3, 47]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>[134, 12, 16458, 459, 118, 13249, 241, 10469, ...</td>\n",
       "      <td>[9, 8, 17, 3, 25, 22, 6, 24, 21, 7, 14, 5, 23,...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15795</th>\n",
       "      <td>[12904, 2555, 39, 976, 3716, 10283, 10193, 102...</td>\n",
       "      <td>[9, 8, 105, 10, 10, 39, 17, 3, 25, 22, 6, 24, ...</td>\n",
       "      <td>[2, 889]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32216 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 queries  \\\n",
       "9391                          [2504, 30655, 32035, 3, 4]   \n",
       "36089  [1400, 4, 9, 18236, 16200, 10739, 9713, 70, 14...   \n",
       "38820  [5327, 12, 3, 10462, 30102, 921, 1247, 6869, 7...   \n",
       "33815                    [479, 1717, 1205, 875, 3570, 4]   \n",
       "31187                [163, 18284, 143, 1082, 258, 28721]   \n",
       "...                                                  ...   \n",
       "6265            [824, 197, 42, 259, 4127, 894, 719, 344]   \n",
       "11284  [1565, 712, 24838, 39622, 20862, 22, 238, 599,...   \n",
       "38158  [4118, 12355, 723, 41687, 1678, 30560, 184, 85...   \n",
       "860    [134, 12, 16458, 459, 118, 13249, 241, 10469, ...   \n",
       "15795  [12904, 2555, 39, 976, 3716, 10283, 10193, 102...   \n",
       "\n",
       "                                                    apps  \\\n",
       "9391   [9, 10, 10, 39, 17, 3, 21, 12, 7, 41, 58, 6, 1...   \n",
       "36089  [9, 8, 10, 10, 39, 17, 48, 54, 3, 25, 22, 6, 2...   \n",
       "38820  [9, 17, 3, 25, 22, 6, 21, 7, 14, 23, 2, 19, 10...   \n",
       "33815  [73, 9, 8, 59, 37, 131, 3, 89, 6, 16, 85, 12, ...   \n",
       "31187  [25, 71, 125, 16, 7, 5, 10, 10, 48, 3, 79, 47,...   \n",
       "...                                                  ...   \n",
       "6265   [9, 8, 105, 10, 10, 17, 54, 3, 25, 95, 22, 6, ...   \n",
       "11284  [9, 8, 105, 10, 10, 39, 17, 3, 25, 22, 6, 24, ...   \n",
       "38158  [9, 8, 17, 3, 25, 22, 6, 21, 7, 14, 5, 23, 2, ...   \n",
       "860    [9, 8, 17, 3, 25, 22, 6, 24, 21, 7, 14, 5, 23,...   \n",
       "15795  [9, 8, 105, 10, 10, 39, 17, 3, 25, 22, 6, 24, ...   \n",
       "\n",
       "                                                   games  \n",
       "9391                                      [336, 822, 14]  \n",
       "36089                                           [1, 145]  \n",
       "38820  [78, 11, 122, 113, 192, 2726, 34, 44, 17, 4, 9...  \n",
       "33815                                        [771, 3198]  \n",
       "31187                                          [689, 45]  \n",
       "...                                                  ...  \n",
       "6265                   [23, 947, 35, 435, 1327, 2694, 2]  \n",
       "11284  [64, 361, 2093, 2708, 1228, 318, 711, 1844, 2392]  \n",
       "38158                                  [35, 4697, 3, 47]  \n",
       "860                                                   []  \n",
       "15795                                           [2, 889]  \n",
       "\n",
       "[32216 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ad72d499",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;31mTypeError\u001b[0m: only size-1 arrays can be converted to Python scalars",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-866bb70b5a7c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_samples_leaf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_samples_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    302\u001b[0m                 \u001b[1;34m\"sparse multilabel-indicator for y is not supported.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    303\u001b[0m             )\n\u001b[1;32m--> 304\u001b[1;33m         X, y = self._validate_data(X, y, multi_output=True,\n\u001b[0m\u001b[0;32m    305\u001b[0m                                    accept_sparse=\"csc\", dtype=DTYPE)\n\u001b[0;32m    306\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    431\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    432\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 433\u001b[1;33m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    434\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    435\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m    869\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"y cannot be None\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    870\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 871\u001b[1;33m     X = check_array(X, accept_sparse=accept_sparse,\n\u001b[0m\u001b[0;32m    872\u001b[0m                     \u001b[0maccept_large_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_large_sparse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    873\u001b[0m                     \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    671\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"unsafe\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    672\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 673\u001b[1;33m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    674\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    675\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m     \"\"\"\n\u001b[1;32m---> 83\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   1988\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1989\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mNpDtype\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1990\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1991\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1992\u001b[0m     def __array_wrap__(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m     \"\"\"\n\u001b[1;32m---> 83\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "model = RandomForestClassifier(random_state=0, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b2023c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_1D(series):\n",
    "    return pd.Series([x for _list in series for x in _list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54fa37e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = to_1D(df['queries'])\n",
    "apps = to_1D(df['apps'])\n",
    "games = to_1D(df['games'])\n",
    "\n",
    "queries_value_count = queries.value_counts()\n",
    "games_value_count = games.value_counts()\n",
    "apps_value_count = apps.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7beec0cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queries completed\n",
      "Apps completed\n",
      "Games completed\n"
     ]
    }
   ],
   "source": [
    "features = dict()\n",
    "\n",
    "for query in queries:\n",
    "    if (queries_value_count[query] > len(df) * 0.05):\n",
    "        features[f\"q{query}\"] = 0 \n",
    "print(\"Queries completed\")\n",
    "for app in apps:\n",
    "    if (apps_value_count[app] > len(df) * 0.05):\n",
    "        features[f\"a{app}\"] = 0\n",
    "print(\"Apps completed\")\n",
    "for game in games:\n",
    "    if (games_value_count[game] > len(df) * 0.05):\n",
    "        features[f\"g{game}\"] = 0\n",
    "print(\"Games completed\")\n",
    "    \n",
    "features[\"gender\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc7ee917",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_key(dict, key):\n",
    "    if key in dict.keys():\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "517a0784",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 40271/40271 [00:05<00:00, 8037.25it/s]\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "from tqdm import tqdm\n",
    "\n",
    "new_dataset = []\n",
    "for index, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "    new_item = copy.copy(features)\n",
    "    for query in row['queries']:\n",
    "        if check_key(new_item, f\"q{query}\"):\n",
    "            new_item[f\"q{query}\"] = 1\n",
    "    for game in row['games']:\n",
    "        if check_key(new_item, f\"g{game}\"):\n",
    "            new_item[f\"g{game}\"] = 1\n",
    "    for app in row['apps']:\n",
    "        if check_key(new_item, f\"a{app}\"):\n",
    "            new_item[f\"a{app}\"] = 1\n",
    "    new_item['gender'] = row['gender']\n",
    "    assert len(new_item) == len(features), \"Featues count error\"\n",
    "    new_dataset.append(copy.copy(new_item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "396eb96e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q3</th>\n",
       "      <th>q1</th>\n",
       "      <th>q15</th>\n",
       "      <th>q2</th>\n",
       "      <th>q12</th>\n",
       "      <th>q8</th>\n",
       "      <th>q40</th>\n",
       "      <th>q21</th>\n",
       "      <th>q27</th>\n",
       "      <th>q13</th>\n",
       "      <th>...</th>\n",
       "      <th>a33</th>\n",
       "      <th>a152</th>\n",
       "      <th>g3</th>\n",
       "      <th>g2</th>\n",
       "      <th>g9</th>\n",
       "      <th>g1</th>\n",
       "      <th>g16</th>\n",
       "      <th>g4</th>\n",
       "      <th>g5</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 220 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   q3  q1  q15  q2  q12  q8  q40  q21  q27  q13  ...  a33  a152  g3  g2  g9  \\\n",
       "0   1   1    1   1    1   1    1    1    0    0  ...    0     0   0   0   0   \n",
       "1   0   0    0   0    0   0    0    0    0    0  ...    0     0   1   1   0   \n",
       "2   0   0    0   0    0   0    0    0    0    0  ...    0     0   0   0   0   \n",
       "3   0   0    0   0    0   0    0    0    0    0  ...    0     0   0   0   1   \n",
       "4   0   0    0   0    0   0    0    0    1    1  ...    0     0   0   0   0   \n",
       "\n",
       "   g1  g16  g4  g5  gender  \n",
       "0   0    0   0   0       1  \n",
       "1   0    0   0   0       0  \n",
       "2   0    0   0   0       1  \n",
       "3   0    0   0   0       1  \n",
       "4   1    0   0   0       1  \n",
       "\n",
       "[5 rows x 220 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df = pd.DataFrame.from_dict(new_dataset, orient='columns')\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2030d0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y =  new_df.drop(columns=[\"gender\"]), new_df[\"gender\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d9f973b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.80633147, 0.81315953, 0.81750466, 0.80726257, 0.80819367,\n",
       "       0.82091868, 0.80565042, 0.81527476, 0.81837939, 0.80844458])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "model = RandomForestClassifier(random_state=0, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100)\n",
    "cross_val_score(model, X_train, y_train, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "784cd5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)\n",
    "predicted = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8a1efe9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8120422098075729\n",
      "Balanced Accuracy:  0.6615974203126249\n",
      "Precision:  0.8112786152987158\n",
      "Recall:  0.9728824907934382\n",
      "F1:  0.8847617597807885\n"
     ]
    }
   ],
   "source": [
    "evaluate(predicted, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5626a243",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "opt = SGD(learning_rate=0.01)\n",
    "\n",
    "def build_model(hp):\n",
    "    model = keras.models.Sequential()\n",
    "    \n",
    "    model.add(Dense(hp.Int(\"input_units\", min_value=100, max_value=500, step=20), input_dim=219, activation='relu'))\n",
    "    \n",
    "    for i in range(hp.Int('n_layers', 1, 10)):\n",
    "        model.add(Dense(hp.Int(f\"dense_units_{i}\", min_value=10, max_value=300, step=10), activation='relu'))\n",
    "    \n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ba6b7e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1 Complete [00h 04m 54s]\n",
      "val_accuracy: 0.8227187991142273\n",
      "\n",
      "Best val_accuracy So Far: 0.8227187991142273\n",
      "Total elapsed time: 00h 04m 54s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "from kerastuner.engine.hyperparameters import HyperParameters\n",
    "from kerastuner.tuners import RandomSearch\n",
    "import time\n",
    "\n",
    "LOG_DIR = f\"{int(time.time())}\"\n",
    "\n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective = \"val_accuracy\",\n",
    "    max_trials = 1,\n",
    "    executions_per_trial = 1,\n",
    "    directory = LOG_DIR\n",
    ")\n",
    "\n",
    "tuner.search(x=X_train, y=y_train, epochs=100, batch_size=10,validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2b367d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"tuner_{int(time.time())}.pkl\", \"wb\") as f:\n",
    "    pickle.dump(tuner, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e7857df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = pickle.load(open(\"tuner_1627738330.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a7162657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_units': 280, 'n_layers': 8, 'dense_units_0': 30, 'dense_units_1': 10, 'dense_units_2': 10, 'dense_units_3': 10, 'dense_units_4': 10, 'dense_units_5': 10, 'dense_units_6': 10, 'dense_units_7': 10}\n",
      "Results summary\n",
      "Results in 1627737908\\untitled_project\n",
      "Showing 10 best trials\n",
      "Objective(name='val_accuracy', direction='max')\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "input_units: 280\n",
      "n_layers: 8\n",
      "dense_units_0: 30\n",
      "dense_units_1: 10\n",
      "dense_units_2: 10\n",
      "dense_units_3: 10\n",
      "dense_units_4: 10\n",
      "dense_units_5: 10\n",
      "dense_units_6: 10\n",
      "dense_units_7: 10\n",
      "Score: 0.8227187991142273\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(tuner.get_best_hyperparameters()[0].values)\n",
    "print(tuner.results_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4d06c26c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2900/2900 [==============================] - 3s 869us/step - loss: 0.3878 - accuracy: 0.8319 - val_loss: 0.3908 - val_accuracy: 0.8312\n",
      "Epoch 2/100\n",
      "2900/2900 [==============================] - 2s 827us/step - loss: 0.3822 - accuracy: 0.8360 - val_loss: 0.3909 - val_accuracy: 0.8274\n",
      "Epoch 3/100\n",
      "2900/2900 [==============================] - 2s 843us/step - loss: 0.3769 - accuracy: 0.8384 - val_loss: 0.4322 - val_accuracy: 0.8060\n",
      "Epoch 4/100\n",
      "2900/2900 [==============================] - 2s 831us/step - loss: 0.3697 - accuracy: 0.8432 - val_loss: 0.4084 - val_accuracy: 0.8191\n"
     ]
    }
   ],
   "source": [
    "callback = keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "model = tuner.get_best_models()[0]\n",
    "history = model.fit(X_train, y_train, validation_split=0.1, epochs=100, batch_size=10, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ee28e33b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "81415eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.810552451893234\n",
      "Balanced Accuracy:  0.7355915759899496\n",
      "Precision:  0.8590571520826606\n",
      "Recall:  0.8906930030130565\n",
      "F1:  0.8745890861275476\n"
     ]
    }
   ],
   "source": [
    "predicted = model.predict_classes(X_test)\n",
    "evaluate(predicted, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "41fdb0fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There 1969 0 values in prediction.\n",
      "There 6086 1 values in prediction.\n",
      "There 2081 0 values in test dataset.\n",
      "There 5974 1 values in test dataset.\n"
     ]
    }
   ],
   "source": [
    "count_0_predicted = 0\n",
    "count_1_predicted = 0\n",
    "count_0_actual = 0\n",
    "count_1_actual = 0\n",
    "for i in range(len(predicted)):\n",
    "    if predicted[i] == 0:\n",
    "        count_0_predicted += 1\n",
    "    else:\n",
    "        count_1_predicted += 1\n",
    "    if y_test.iloc[i] == 0:\n",
    "        count_0_actual += 1\n",
    "    else:\n",
    "        count_1_actual += 1\n",
    "print(f\"There {count_0_predicted} 0 values in prediction.\")\n",
    "print(f\"There {count_1_predicted} 1 values in prediction.\")\n",
    "\n",
    "print(f\"There {count_0_actual} 0 values in test dataset.\")\n",
    "print(f\"There {count_1_actual} 1 values in test dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0e08ddb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 88 candidates, totalling 440 fits\n",
      "[CV 1/5; 1/88] START leaf_size=20, n_neighbors=3, weights=uniform...............\n",
      "[CV 1/5; 1/88] END leaf_size=20, n_neighbors=3, weights=uniform;, score=0.589 total time=   2.1s\n",
      "[CV 2/5; 1/88] START leaf_size=20, n_neighbors=3, weights=uniform...............\n",
      "[CV 2/5; 1/88] END leaf_size=20, n_neighbors=3, weights=uniform;, score=0.581 total time=   2.1s\n",
      "[CV 3/5; 1/88] START leaf_size=20, n_neighbors=3, weights=uniform...............\n",
      "[CV 3/5; 1/88] END leaf_size=20, n_neighbors=3, weights=uniform;, score=0.589 total time=   2.1s\n",
      "[CV 4/5; 1/88] START leaf_size=20, n_neighbors=3, weights=uniform...............\n",
      "[CV 4/5; 1/88] END leaf_size=20, n_neighbors=3, weights=uniform;, score=0.590 total time=   2.1s\n",
      "[CV 5/5; 1/88] START leaf_size=20, n_neighbors=3, weights=uniform...............\n",
      "[CV 5/5; 1/88] END leaf_size=20, n_neighbors=3, weights=uniform;, score=0.581 total time=   2.0s\n",
      "[CV 1/5; 2/88] START leaf_size=20, n_neighbors=3, weights=distance..............\n",
      "[CV 1/5; 2/88] END leaf_size=20, n_neighbors=3, weights=distance;, score=0.589 total time=   1.9s\n",
      "[CV 2/5; 2/88] START leaf_size=20, n_neighbors=3, weights=distance..............\n",
      "[CV 2/5; 2/88] END leaf_size=20, n_neighbors=3, weights=distance;, score=0.581 total time=   2.0s\n",
      "[CV 3/5; 2/88] START leaf_size=20, n_neighbors=3, weights=distance..............\n",
      "[CV 3/5; 2/88] END leaf_size=20, n_neighbors=3, weights=distance;, score=0.589 total time=   1.9s\n",
      "[CV 4/5; 2/88] START leaf_size=20, n_neighbors=3, weights=distance..............\n",
      "[CV 4/5; 2/88] END leaf_size=20, n_neighbors=3, weights=distance;, score=0.590 total time=   1.9s\n",
      "[CV 5/5; 2/88] START leaf_size=20, n_neighbors=3, weights=distance..............\n",
      "[CV 5/5; 2/88] END leaf_size=20, n_neighbors=3, weights=distance;, score=0.581 total time=   2.0s\n",
      "[CV 1/5; 3/88] START leaf_size=20, n_neighbors=5, weights=uniform...............\n",
      "[CV 1/5; 3/88] END leaf_size=20, n_neighbors=5, weights=uniform;, score=0.592 total time=   2.6s\n",
      "[CV 2/5; 3/88] START leaf_size=20, n_neighbors=5, weights=uniform...............\n",
      "[CV 2/5; 3/88] END leaf_size=20, n_neighbors=5, weights=uniform;, score=0.577 total time=   2.5s\n",
      "[CV 3/5; 3/88] START leaf_size=20, n_neighbors=5, weights=uniform...............\n",
      "[CV 3/5; 3/88] END leaf_size=20, n_neighbors=5, weights=uniform;, score=0.589 total time=   2.7s\n",
      "[CV 4/5; 3/88] START leaf_size=20, n_neighbors=5, weights=uniform...............\n",
      "[CV 4/5; 3/88] END leaf_size=20, n_neighbors=5, weights=uniform;, score=0.588 total time=   2.6s\n",
      "[CV 5/5; 3/88] START leaf_size=20, n_neighbors=5, weights=uniform...............\n",
      "[CV 5/5; 3/88] END leaf_size=20, n_neighbors=5, weights=uniform;, score=0.585 total time=   2.7s\n",
      "[CV 1/5; 4/88] START leaf_size=20, n_neighbors=5, weights=distance..............\n",
      "[CV 1/5; 4/88] END leaf_size=20, n_neighbors=5, weights=distance;, score=0.592 total time=   2.5s\n",
      "[CV 2/5; 4/88] START leaf_size=20, n_neighbors=5, weights=distance..............\n",
      "[CV 2/5; 4/88] END leaf_size=20, n_neighbors=5, weights=distance;, score=0.577 total time=   2.4s\n",
      "[CV 3/5; 4/88] START leaf_size=20, n_neighbors=5, weights=distance..............\n",
      "[CV 3/5; 4/88] END leaf_size=20, n_neighbors=5, weights=distance;, score=0.589 total time=   2.6s\n",
      "[CV 4/5; 4/88] START leaf_size=20, n_neighbors=5, weights=distance..............\n",
      "[CV 4/5; 4/88] END leaf_size=20, n_neighbors=5, weights=distance;, score=0.588 total time=   2.5s\n",
      "[CV 5/5; 4/88] START leaf_size=20, n_neighbors=5, weights=distance..............\n",
      "[CV 5/5; 4/88] END leaf_size=20, n_neighbors=5, weights=distance;, score=0.585 total time=   2.6s\n",
      "[CV 1/5; 5/88] START leaf_size=20, n_neighbors=7, weights=uniform...............\n",
      "[CV 1/5; 5/88] END leaf_size=20, n_neighbors=7, weights=uniform;, score=0.582 total time=   2.7s\n",
      "[CV 2/5; 5/88] START leaf_size=20, n_neighbors=7, weights=uniform...............\n",
      "[CV 2/5; 5/88] END leaf_size=20, n_neighbors=7, weights=uniform;, score=0.574 total time=   2.6s\n",
      "[CV 3/5; 5/88] START leaf_size=20, n_neighbors=7, weights=uniform...............\n",
      "[CV 3/5; 5/88] END leaf_size=20, n_neighbors=7, weights=uniform;, score=0.581 total time=   2.7s\n",
      "[CV 4/5; 5/88] START leaf_size=20, n_neighbors=7, weights=uniform...............\n",
      "[CV 4/5; 5/88] END leaf_size=20, n_neighbors=7, weights=uniform;, score=0.584 total time=   2.7s\n",
      "[CV 5/5; 5/88] START leaf_size=20, n_neighbors=7, weights=uniform...............\n",
      "[CV 5/5; 5/88] END leaf_size=20, n_neighbors=7, weights=uniform;, score=0.583 total time=   2.7s\n",
      "[CV 1/5; 6/88] START leaf_size=20, n_neighbors=7, weights=distance..............\n",
      "[CV 1/5; 6/88] END leaf_size=20, n_neighbors=7, weights=distance;, score=0.582 total time=   2.6s\n",
      "[CV 2/5; 6/88] START leaf_size=20, n_neighbors=7, weights=distance..............\n",
      "[CV 2/5; 6/88] END leaf_size=20, n_neighbors=7, weights=distance;, score=0.574 total time=   2.5s\n",
      "[CV 3/5; 6/88] START leaf_size=20, n_neighbors=7, weights=distance..............\n",
      "[CV 3/5; 6/88] END leaf_size=20, n_neighbors=7, weights=distance;, score=0.581 total time=   2.8s\n",
      "[CV 4/5; 6/88] START leaf_size=20, n_neighbors=7, weights=distance..............\n",
      "[CV 4/5; 6/88] END leaf_size=20, n_neighbors=7, weights=distance;, score=0.585 total time=   2.7s\n",
      "[CV 5/5; 6/88] START leaf_size=20, n_neighbors=7, weights=distance..............\n",
      "[CV 5/5; 6/88] END leaf_size=20, n_neighbors=7, weights=distance;, score=0.583 total time=   2.5s\n",
      "[CV 1/5; 7/88] START leaf_size=20, n_neighbors=9, weights=uniform...............\n",
      "[CV 1/5; 7/88] END leaf_size=20, n_neighbors=9, weights=uniform;, score=0.575 total time=   2.6s\n",
      "[CV 2/5; 7/88] START leaf_size=20, n_neighbors=9, weights=uniform...............\n",
      "[CV 2/5; 7/88] END leaf_size=20, n_neighbors=9, weights=uniform;, score=0.572 total time=   2.5s\n",
      "[CV 3/5; 7/88] START leaf_size=20, n_neighbors=9, weights=uniform...............\n",
      "[CV 3/5; 7/88] END leaf_size=20, n_neighbors=9, weights=uniform;, score=0.581 total time=   2.7s\n",
      "[CV 4/5; 7/88] START leaf_size=20, n_neighbors=9, weights=uniform...............\n",
      "[CV 4/5; 7/88] END leaf_size=20, n_neighbors=9, weights=uniform;, score=0.584 total time=   2.7s\n",
      "[CV 5/5; 7/88] START leaf_size=20, n_neighbors=9, weights=uniform...............\n",
      "[CV 5/5; 7/88] END leaf_size=20, n_neighbors=9, weights=uniform;, score=0.580 total time=   2.7s\n",
      "[CV 1/5; 8/88] START leaf_size=20, n_neighbors=9, weights=distance..............\n",
      "[CV 1/5; 8/88] END leaf_size=20, n_neighbors=9, weights=distance;, score=0.575 total time=   2.5s\n",
      "[CV 2/5; 8/88] START leaf_size=20, n_neighbors=9, weights=distance..............\n",
      "[CV 2/5; 8/88] END leaf_size=20, n_neighbors=9, weights=distance;, score=0.572 total time=   2.5s\n",
      "[CV 3/5; 8/88] START leaf_size=20, n_neighbors=9, weights=distance..............\n",
      "[CV 3/5; 8/88] END leaf_size=20, n_neighbors=9, weights=distance;, score=0.581 total time=   2.6s\n",
      "[CV 4/5; 8/88] START leaf_size=20, n_neighbors=9, weights=distance..............\n",
      "[CV 4/5; 8/88] END leaf_size=20, n_neighbors=9, weights=distance;, score=0.584 total time=   2.6s\n",
      "[CV 5/5; 8/88] START leaf_size=20, n_neighbors=9, weights=distance..............\n",
      "[CV 5/5; 8/88] END leaf_size=20, n_neighbors=9, weights=distance;, score=0.580 total time=   2.7s\n",
      "[CV 1/5; 9/88] START leaf_size=20, n_neighbors=15, weights=uniform..............\n",
      "[CV 1/5; 9/88] END leaf_size=20, n_neighbors=15, weights=uniform;, score=0.569 total time=   2.8s\n",
      "[CV 2/5; 9/88] START leaf_size=20, n_neighbors=15, weights=uniform..............\n",
      "[CV 2/5; 9/88] END leaf_size=20, n_neighbors=15, weights=uniform;, score=0.563 total time=   2.5s\n",
      "[CV 3/5; 9/88] START leaf_size=20, n_neighbors=15, weights=uniform..............\n",
      "[CV 3/5; 9/88] END leaf_size=20, n_neighbors=15, weights=uniform;, score=0.578 total time=   2.6s\n",
      "[CV 4/5; 9/88] START leaf_size=20, n_neighbors=15, weights=uniform..............\n",
      "[CV 4/5; 9/88] END leaf_size=20, n_neighbors=15, weights=uniform;, score=0.568 total time=   2.8s\n",
      "[CV 5/5; 9/88] START leaf_size=20, n_neighbors=15, weights=uniform..............\n",
      "[CV 5/5; 9/88] END leaf_size=20, n_neighbors=15, weights=uniform;, score=0.567 total time=   2.8s\n",
      "[CV 1/5; 10/88] START leaf_size=20, n_neighbors=15, weights=distance............\n",
      "[CV 1/5; 10/88] END leaf_size=20, n_neighbors=15, weights=distance;, score=0.569 total time=   2.5s\n",
      "[CV 2/5; 10/88] START leaf_size=20, n_neighbors=15, weights=distance............\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 10/88] END leaf_size=20, n_neighbors=15, weights=distance;, score=0.563 total time=   2.4s\n",
      "[CV 3/5; 10/88] START leaf_size=20, n_neighbors=15, weights=distance............\n",
      "[CV 3/5; 10/88] END leaf_size=20, n_neighbors=15, weights=distance;, score=0.578 total time=   2.6s\n",
      "[CV 4/5; 10/88] START leaf_size=20, n_neighbors=15, weights=distance............\n",
      "[CV 4/5; 10/88] END leaf_size=20, n_neighbors=15, weights=distance;, score=0.568 total time=   2.7s\n",
      "[CV 5/5; 10/88] START leaf_size=20, n_neighbors=15, weights=distance............\n",
      "[CV 5/5; 10/88] END leaf_size=20, n_neighbors=15, weights=distance;, score=0.567 total time=   2.8s\n",
      "[CV 1/5; 11/88] START leaf_size=20, n_neighbors=19, weights=uniform.............\n",
      "[CV 1/5; 11/88] END leaf_size=20, n_neighbors=19, weights=uniform;, score=0.560 total time=   2.7s\n",
      "[CV 2/5; 11/88] START leaf_size=20, n_neighbors=19, weights=uniform.............\n",
      "[CV 2/5; 11/88] END leaf_size=20, n_neighbors=19, weights=uniform;, score=0.556 total time=   2.6s\n",
      "[CV 3/5; 11/88] START leaf_size=20, n_neighbors=19, weights=uniform.............\n",
      "[CV 3/5; 11/88] END leaf_size=20, n_neighbors=19, weights=uniform;, score=0.567 total time=   2.7s\n",
      "[CV 4/5; 11/88] START leaf_size=20, n_neighbors=19, weights=uniform.............\n",
      "[CV 4/5; 11/88] END leaf_size=20, n_neighbors=19, weights=uniform;, score=0.563 total time=   2.7s\n",
      "[CV 5/5; 11/88] START leaf_size=20, n_neighbors=19, weights=uniform.............\n",
      "[CV 5/5; 11/88] END leaf_size=20, n_neighbors=19, weights=uniform;, score=0.560 total time=   2.7s\n",
      "[CV 1/5; 12/88] START leaf_size=20, n_neighbors=19, weights=distance............\n",
      "[CV 1/5; 12/88] END leaf_size=20, n_neighbors=19, weights=distance;, score=0.560 total time=   2.5s\n",
      "[CV 2/5; 12/88] START leaf_size=20, n_neighbors=19, weights=distance............\n",
      "[CV 2/5; 12/88] END leaf_size=20, n_neighbors=19, weights=distance;, score=0.556 total time=   2.4s\n",
      "[CV 3/5; 12/88] START leaf_size=20, n_neighbors=19, weights=distance............\n",
      "[CV 3/5; 12/88] END leaf_size=20, n_neighbors=19, weights=distance;, score=0.567 total time=   2.6s\n",
      "[CV 4/5; 12/88] START leaf_size=20, n_neighbors=19, weights=distance............\n",
      "[CV 4/5; 12/88] END leaf_size=20, n_neighbors=19, weights=distance;, score=0.563 total time=   2.5s\n",
      "[CV 5/5; 12/88] START leaf_size=20, n_neighbors=19, weights=distance............\n",
      "[CV 5/5; 12/88] END leaf_size=20, n_neighbors=19, weights=distance;, score=0.560 total time=   2.6s\n",
      "[CV 1/5; 13/88] START leaf_size=20, n_neighbors=25, weights=uniform.............\n",
      "[CV 1/5; 13/88] END leaf_size=20, n_neighbors=25, weights=uniform;, score=0.556 total time=   2.8s\n",
      "[CV 2/5; 13/88] START leaf_size=20, n_neighbors=25, weights=uniform.............\n",
      "[CV 2/5; 13/88] END leaf_size=20, n_neighbors=25, weights=uniform;, score=0.550 total time=   2.7s\n",
      "[CV 3/5; 13/88] START leaf_size=20, n_neighbors=25, weights=uniform.............\n",
      "[CV 3/5; 13/88] END leaf_size=20, n_neighbors=25, weights=uniform;, score=0.563 total time=   2.9s\n",
      "[CV 4/5; 13/88] START leaf_size=20, n_neighbors=25, weights=uniform.............\n",
      "[CV 4/5; 13/88] END leaf_size=20, n_neighbors=25, weights=uniform;, score=0.560 total time=   2.8s\n",
      "[CV 5/5; 13/88] START leaf_size=20, n_neighbors=25, weights=uniform.............\n",
      "[CV 5/5; 13/88] END leaf_size=20, n_neighbors=25, weights=uniform;, score=0.557 total time=   2.8s\n",
      "[CV 1/5; 14/88] START leaf_size=20, n_neighbors=25, weights=distance............\n",
      "[CV 1/5; 14/88] END leaf_size=20, n_neighbors=25, weights=distance;, score=0.556 total time=   2.6s\n",
      "[CV 2/5; 14/88] START leaf_size=20, n_neighbors=25, weights=distance............\n",
      "[CV 2/5; 14/88] END leaf_size=20, n_neighbors=25, weights=distance;, score=0.550 total time=   2.5s\n",
      "[CV 3/5; 14/88] START leaf_size=20, n_neighbors=25, weights=distance............\n",
      "[CV 3/5; 14/88] END leaf_size=20, n_neighbors=25, weights=distance;, score=0.563 total time=   2.6s\n",
      "[CV 4/5; 14/88] START leaf_size=20, n_neighbors=25, weights=distance............\n",
      "[CV 4/5; 14/88] END leaf_size=20, n_neighbors=25, weights=distance;, score=0.560 total time=   2.5s\n",
      "[CV 5/5; 14/88] START leaf_size=20, n_neighbors=25, weights=distance............\n",
      "[CV 5/5; 14/88] END leaf_size=20, n_neighbors=25, weights=distance;, score=0.557 total time=   2.6s\n",
      "[CV 1/5; 15/88] START leaf_size=20, n_neighbors=35, weights=uniform.............\n",
      "[CV 1/5; 15/88] END leaf_size=20, n_neighbors=35, weights=uniform;, score=0.547 total time=   2.7s\n",
      "[CV 2/5; 15/88] START leaf_size=20, n_neighbors=35, weights=uniform.............\n",
      "[CV 2/5; 15/88] END leaf_size=20, n_neighbors=35, weights=uniform;, score=0.546 total time=   2.6s\n",
      "[CV 3/5; 15/88] START leaf_size=20, n_neighbors=35, weights=uniform.............\n",
      "[CV 3/5; 15/88] END leaf_size=20, n_neighbors=35, weights=uniform;, score=0.553 total time=   2.8s\n",
      "[CV 4/5; 15/88] START leaf_size=20, n_neighbors=35, weights=uniform.............\n",
      "[CV 4/5; 15/88] END leaf_size=20, n_neighbors=35, weights=uniform;, score=0.547 total time=   2.7s\n",
      "[CV 5/5; 15/88] START leaf_size=20, n_neighbors=35, weights=uniform.............\n",
      "[CV 5/5; 15/88] END leaf_size=20, n_neighbors=35, weights=uniform;, score=0.550 total time=   2.8s\n",
      "[CV 1/5; 16/88] START leaf_size=20, n_neighbors=35, weights=distance............\n",
      "[CV 1/5; 16/88] END leaf_size=20, n_neighbors=35, weights=distance;, score=0.547 total time=   2.5s\n",
      "[CV 2/5; 16/88] START leaf_size=20, n_neighbors=35, weights=distance............\n",
      "[CV 2/5; 16/88] END leaf_size=20, n_neighbors=35, weights=distance;, score=0.546 total time=   2.5s\n",
      "[CV 3/5; 16/88] START leaf_size=20, n_neighbors=35, weights=distance............\n",
      "[CV 3/5; 16/88] END leaf_size=20, n_neighbors=35, weights=distance;, score=0.554 total time=   2.6s\n",
      "[CV 4/5; 16/88] START leaf_size=20, n_neighbors=35, weights=distance............\n",
      "[CV 4/5; 16/88] END leaf_size=20, n_neighbors=35, weights=distance;, score=0.547 total time=   2.6s\n",
      "[CV 5/5; 16/88] START leaf_size=20, n_neighbors=35, weights=distance............\n",
      "[CV 5/5; 16/88] END leaf_size=20, n_neighbors=35, weights=distance;, score=0.550 total time=   2.6s\n",
      "[CV 1/5; 17/88] START leaf_size=20, n_neighbors=55, weights=uniform.............\n",
      "[CV 1/5; 17/88] END leaf_size=20, n_neighbors=55, weights=uniform;, score=0.533 total time=   2.7s\n",
      "[CV 2/5; 17/88] START leaf_size=20, n_neighbors=55, weights=uniform.............\n",
      "[CV 2/5; 17/88] END leaf_size=20, n_neighbors=55, weights=uniform;, score=0.535 total time=   2.6s\n",
      "[CV 3/5; 17/88] START leaf_size=20, n_neighbors=55, weights=uniform.............\n",
      "[CV 3/5; 17/88] END leaf_size=20, n_neighbors=55, weights=uniform;, score=0.540 total time=   2.7s\n",
      "[CV 4/5; 17/88] START leaf_size=20, n_neighbors=55, weights=uniform.............\n",
      "[CV 4/5; 17/88] END leaf_size=20, n_neighbors=55, weights=uniform;, score=0.538 total time=   2.7s\n",
      "[CV 5/5; 17/88] START leaf_size=20, n_neighbors=55, weights=uniform.............\n",
      "[CV 5/5; 17/88] END leaf_size=20, n_neighbors=55, weights=uniform;, score=0.532 total time=   2.7s\n",
      "[CV 1/5; 18/88] START leaf_size=20, n_neighbors=55, weights=distance............\n",
      "[CV 1/5; 18/88] END leaf_size=20, n_neighbors=55, weights=distance;, score=0.533 total time=   2.6s\n",
      "[CV 2/5; 18/88] START leaf_size=20, n_neighbors=55, weights=distance............\n",
      "[CV 2/5; 18/88] END leaf_size=20, n_neighbors=55, weights=distance;, score=0.535 total time=   2.5s\n",
      "[CV 3/5; 18/88] START leaf_size=20, n_neighbors=55, weights=distance............\n",
      "[CV 3/5; 18/88] END leaf_size=20, n_neighbors=55, weights=distance;, score=0.540 total time=   2.6s\n",
      "[CV 4/5; 18/88] START leaf_size=20, n_neighbors=55, weights=distance............\n",
      "[CV 4/5; 18/88] END leaf_size=20, n_neighbors=55, weights=distance;, score=0.538 total time=   2.6s\n",
      "[CV 5/5; 18/88] START leaf_size=20, n_neighbors=55, weights=distance............\n",
      "[CV 5/5; 18/88] END leaf_size=20, n_neighbors=55, weights=distance;, score=0.532 total time=   2.6s\n",
      "[CV 1/5; 19/88] START leaf_size=20, n_neighbors=75, weights=uniform.............\n",
      "[CV 1/5; 19/88] END leaf_size=20, n_neighbors=75, weights=uniform;, score=0.528 total time=   2.7s\n",
      "[CV 2/5; 19/88] START leaf_size=20, n_neighbors=75, weights=uniform.............\n",
      "[CV 2/5; 19/88] END leaf_size=20, n_neighbors=75, weights=uniform;, score=0.525 total time=   2.6s\n",
      "[CV 3/5; 19/88] START leaf_size=20, n_neighbors=75, weights=uniform.............\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 19/88] END leaf_size=20, n_neighbors=75, weights=uniform;, score=0.529 total time=   2.7s\n",
      "[CV 4/5; 19/88] START leaf_size=20, n_neighbors=75, weights=uniform.............\n",
      "[CV 4/5; 19/88] END leaf_size=20, n_neighbors=75, weights=uniform;, score=0.533 total time=   2.8s\n",
      "[CV 5/5; 19/88] START leaf_size=20, n_neighbors=75, weights=uniform.............\n",
      "[CV 5/5; 19/88] END leaf_size=20, n_neighbors=75, weights=uniform;, score=0.524 total time=   2.7s\n",
      "[CV 1/5; 20/88] START leaf_size=20, n_neighbors=75, weights=distance............\n",
      "[CV 1/5; 20/88] END leaf_size=20, n_neighbors=75, weights=distance;, score=0.528 total time=   2.6s\n",
      "[CV 2/5; 20/88] START leaf_size=20, n_neighbors=75, weights=distance............\n",
      "[CV 2/5; 20/88] END leaf_size=20, n_neighbors=75, weights=distance;, score=0.525 total time=   2.6s\n",
      "[CV 3/5; 20/88] START leaf_size=20, n_neighbors=75, weights=distance............\n",
      "[CV 3/5; 20/88] END leaf_size=20, n_neighbors=75, weights=distance;, score=0.529 total time=   2.8s\n",
      "[CV 4/5; 20/88] START leaf_size=20, n_neighbors=75, weights=distance............\n",
      "[CV 4/5; 20/88] END leaf_size=20, n_neighbors=75, weights=distance;, score=0.533 total time=   2.7s\n",
      "[CV 5/5; 20/88] START leaf_size=20, n_neighbors=75, weights=distance............\n",
      "[CV 5/5; 20/88] END leaf_size=20, n_neighbors=75, weights=distance;, score=0.525 total time=   3.1s\n",
      "[CV 1/5; 21/88] START leaf_size=20, n_neighbors=99, weights=uniform.............\n",
      "[CV 1/5; 21/88] END leaf_size=20, n_neighbors=99, weights=uniform;, score=0.523 total time=   3.2s\n",
      "[CV 2/5; 21/88] START leaf_size=20, n_neighbors=99, weights=uniform.............\n",
      "[CV 2/5; 21/88] END leaf_size=20, n_neighbors=99, weights=uniform;, score=0.523 total time=   3.0s\n",
      "[CV 3/5; 21/88] START leaf_size=20, n_neighbors=99, weights=uniform.............\n",
      "[CV 3/5; 21/88] END leaf_size=20, n_neighbors=99, weights=uniform;, score=0.523 total time=   3.0s\n",
      "[CV 4/5; 21/88] START leaf_size=20, n_neighbors=99, weights=uniform.............\n",
      "[CV 4/5; 21/88] END leaf_size=20, n_neighbors=99, weights=uniform;, score=0.526 total time=   2.9s\n",
      "[CV 5/5; 21/88] START leaf_size=20, n_neighbors=99, weights=uniform.............\n",
      "[CV 5/5; 21/88] END leaf_size=20, n_neighbors=99, weights=uniform;, score=0.520 total time=   2.9s\n",
      "[CV 1/5; 22/88] START leaf_size=20, n_neighbors=99, weights=distance............\n",
      "[CV 1/5; 22/88] END leaf_size=20, n_neighbors=99, weights=distance;, score=0.524 total time=   2.8s\n",
      "[CV 2/5; 22/88] START leaf_size=20, n_neighbors=99, weights=distance............\n",
      "[CV 2/5; 22/88] END leaf_size=20, n_neighbors=99, weights=distance;, score=0.523 total time=   2.9s\n",
      "[CV 3/5; 22/88] START leaf_size=20, n_neighbors=99, weights=distance............\n",
      "[CV 3/5; 22/88] END leaf_size=20, n_neighbors=99, weights=distance;, score=0.523 total time=   3.1s\n",
      "[CV 4/5; 22/88] START leaf_size=20, n_neighbors=99, weights=distance............\n",
      "[CV 4/5; 22/88] END leaf_size=20, n_neighbors=99, weights=distance;, score=0.527 total time=   3.1s\n",
      "[CV 5/5; 22/88] START leaf_size=20, n_neighbors=99, weights=distance............\n",
      "[CV 5/5; 22/88] END leaf_size=20, n_neighbors=99, weights=distance;, score=0.521 total time=   2.8s\n",
      "[CV 1/5; 23/88] START leaf_size=30, n_neighbors=3, weights=uniform..............\n",
      "[CV 1/5; 23/88] END leaf_size=30, n_neighbors=3, weights=uniform;, score=0.589 total time=   2.2s\n",
      "[CV 2/5; 23/88] START leaf_size=30, n_neighbors=3, weights=uniform..............\n",
      "[CV 2/5; 23/88] END leaf_size=30, n_neighbors=3, weights=uniform;, score=0.581 total time=   2.2s\n",
      "[CV 3/5; 23/88] START leaf_size=30, n_neighbors=3, weights=uniform..............\n",
      "[CV 3/5; 23/88] END leaf_size=30, n_neighbors=3, weights=uniform;, score=0.589 total time=   2.2s\n",
      "[CV 4/5; 23/88] START leaf_size=30, n_neighbors=3, weights=uniform..............\n",
      "[CV 4/5; 23/88] END leaf_size=30, n_neighbors=3, weights=uniform;, score=0.590 total time=   2.2s\n",
      "[CV 5/5; 23/88] START leaf_size=30, n_neighbors=3, weights=uniform..............\n",
      "[CV 5/5; 23/88] END leaf_size=30, n_neighbors=3, weights=uniform;, score=0.581 total time=   2.2s\n",
      "[CV 1/5; 24/88] START leaf_size=30, n_neighbors=3, weights=distance.............\n",
      "[CV 1/5; 24/88] END leaf_size=30, n_neighbors=3, weights=distance;, score=0.589 total time=   2.0s\n",
      "[CV 2/5; 24/88] START leaf_size=30, n_neighbors=3, weights=distance.............\n",
      "[CV 2/5; 24/88] END leaf_size=30, n_neighbors=3, weights=distance;, score=0.581 total time=   2.0s\n",
      "[CV 3/5; 24/88] START leaf_size=30, n_neighbors=3, weights=distance.............\n",
      "[CV 3/5; 24/88] END leaf_size=30, n_neighbors=3, weights=distance;, score=0.589 total time=   2.0s\n",
      "[CV 4/5; 24/88] START leaf_size=30, n_neighbors=3, weights=distance.............\n",
      "[CV 4/5; 24/88] END leaf_size=30, n_neighbors=3, weights=distance;, score=0.590 total time=   2.1s\n",
      "[CV 5/5; 24/88] START leaf_size=30, n_neighbors=3, weights=distance.............\n",
      "[CV 5/5; 24/88] END leaf_size=30, n_neighbors=3, weights=distance;, score=0.581 total time=   2.0s\n",
      "[CV 1/5; 25/88] START leaf_size=30, n_neighbors=5, weights=uniform..............\n",
      "[CV 1/5; 25/88] END leaf_size=30, n_neighbors=5, weights=uniform;, score=0.592 total time=   2.9s\n",
      "[CV 2/5; 25/88] START leaf_size=30, n_neighbors=5, weights=uniform..............\n",
      "[CV 2/5; 25/88] END leaf_size=30, n_neighbors=5, weights=uniform;, score=0.577 total time=   2.9s\n",
      "[CV 3/5; 25/88] START leaf_size=30, n_neighbors=5, weights=uniform..............\n",
      "[CV 3/5; 25/88] END leaf_size=30, n_neighbors=5, weights=uniform;, score=0.589 total time=   2.8s\n",
      "[CV 4/5; 25/88] START leaf_size=30, n_neighbors=5, weights=uniform..............\n",
      "[CV 4/5; 25/88] END leaf_size=30, n_neighbors=5, weights=uniform;, score=0.588 total time=   2.7s\n",
      "[CV 5/5; 25/88] START leaf_size=30, n_neighbors=5, weights=uniform..............\n",
      "[CV 5/5; 25/88] END leaf_size=30, n_neighbors=5, weights=uniform;, score=0.585 total time=   2.7s\n",
      "[CV 1/5; 26/88] START leaf_size=30, n_neighbors=5, weights=distance.............\n",
      "[CV 1/5; 26/88] END leaf_size=30, n_neighbors=5, weights=distance;, score=0.592 total time=   2.5s\n",
      "[CV 2/5; 26/88] START leaf_size=30, n_neighbors=5, weights=distance.............\n",
      "[CV 2/5; 26/88] END leaf_size=30, n_neighbors=5, weights=distance;, score=0.577 total time=   2.3s\n",
      "[CV 3/5; 26/88] START leaf_size=30, n_neighbors=5, weights=distance.............\n",
      "[CV 3/5; 26/88] END leaf_size=30, n_neighbors=5, weights=distance;, score=0.589 total time=   2.5s\n",
      "[CV 4/5; 26/88] START leaf_size=30, n_neighbors=5, weights=distance.............\n",
      "[CV 4/5; 26/88] END leaf_size=30, n_neighbors=5, weights=distance;, score=0.588 total time=   2.5s\n",
      "[CV 5/5; 26/88] START leaf_size=30, n_neighbors=5, weights=distance.............\n",
      "[CV 5/5; 26/88] END leaf_size=30, n_neighbors=5, weights=distance;, score=0.585 total time=   2.6s\n",
      "[CV 1/5; 27/88] START leaf_size=30, n_neighbors=7, weights=uniform..............\n",
      "[CV 1/5; 27/88] END leaf_size=30, n_neighbors=7, weights=uniform;, score=0.582 total time=   2.7s\n",
      "[CV 2/5; 27/88] START leaf_size=30, n_neighbors=7, weights=uniform..............\n",
      "[CV 2/5; 27/88] END leaf_size=30, n_neighbors=7, weights=uniform;, score=0.574 total time=   2.7s\n",
      "[CV 3/5; 27/88] START leaf_size=30, n_neighbors=7, weights=uniform..............\n",
      "[CV 3/5; 27/88] END leaf_size=30, n_neighbors=7, weights=uniform;, score=0.581 total time=   2.9s\n",
      "[CV 4/5; 27/88] START leaf_size=30, n_neighbors=7, weights=uniform..............\n",
      "[CV 4/5; 27/88] END leaf_size=30, n_neighbors=7, weights=uniform;, score=0.584 total time=   2.9s\n",
      "[CV 5/5; 27/88] START leaf_size=30, n_neighbors=7, weights=uniform..............\n",
      "[CV 5/5; 27/88] END leaf_size=30, n_neighbors=7, weights=uniform;, score=0.583 total time=   2.8s\n",
      "[CV 1/5; 28/88] START leaf_size=30, n_neighbors=7, weights=distance.............\n",
      "[CV 1/5; 28/88] END leaf_size=30, n_neighbors=7, weights=distance;, score=0.582 total time=   2.5s\n",
      "[CV 2/5; 28/88] START leaf_size=30, n_neighbors=7, weights=distance.............\n",
      "[CV 2/5; 28/88] END leaf_size=30, n_neighbors=7, weights=distance;, score=0.574 total time=   2.4s\n",
      "[CV 3/5; 28/88] START leaf_size=30, n_neighbors=7, weights=distance.............\n",
      "[CV 3/5; 28/88] END leaf_size=30, n_neighbors=7, weights=distance;, score=0.581 total time=   2.6s\n",
      "[CV 4/5; 28/88] START leaf_size=30, n_neighbors=7, weights=distance.............\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 28/88] END leaf_size=30, n_neighbors=7, weights=distance;, score=0.585 total time=   2.5s\n",
      "[CV 5/5; 28/88] START leaf_size=30, n_neighbors=7, weights=distance.............\n",
      "[CV 5/5; 28/88] END leaf_size=30, n_neighbors=7, weights=distance;, score=0.583 total time=   2.6s\n",
      "[CV 1/5; 29/88] START leaf_size=30, n_neighbors=9, weights=uniform..............\n",
      "[CV 1/5; 29/88] END leaf_size=30, n_neighbors=9, weights=uniform;, score=0.575 total time=   2.7s\n",
      "[CV 2/5; 29/88] START leaf_size=30, n_neighbors=9, weights=uniform..............\n",
      "[CV 2/5; 29/88] END leaf_size=30, n_neighbors=9, weights=uniform;, score=0.572 total time=   2.5s\n",
      "[CV 3/5; 29/88] START leaf_size=30, n_neighbors=9, weights=uniform..............\n",
      "[CV 3/5; 29/88] END leaf_size=30, n_neighbors=9, weights=uniform;, score=0.581 total time=   2.7s\n",
      "[CV 4/5; 29/88] START leaf_size=30, n_neighbors=9, weights=uniform..............\n",
      "[CV 4/5; 29/88] END leaf_size=30, n_neighbors=9, weights=uniform;, score=0.584 total time=   2.6s\n",
      "[CV 5/5; 29/88] START leaf_size=30, n_neighbors=9, weights=uniform..............\n",
      "[CV 5/5; 29/88] END leaf_size=30, n_neighbors=9, weights=uniform;, score=0.580 total time=   2.8s\n",
      "[CV 1/5; 30/88] START leaf_size=30, n_neighbors=9, weights=distance.............\n",
      "[CV 1/5; 30/88] END leaf_size=30, n_neighbors=9, weights=distance;, score=0.575 total time=   2.7s\n",
      "[CV 2/5; 30/88] START leaf_size=30, n_neighbors=9, weights=distance.............\n",
      "[CV 2/5; 30/88] END leaf_size=30, n_neighbors=9, weights=distance;, score=0.572 total time=   2.5s\n",
      "[CV 3/5; 30/88] START leaf_size=30, n_neighbors=9, weights=distance.............\n",
      "[CV 3/5; 30/88] END leaf_size=30, n_neighbors=9, weights=distance;, score=0.581 total time=   2.5s\n",
      "[CV 4/5; 30/88] START leaf_size=30, n_neighbors=9, weights=distance.............\n",
      "[CV 4/5; 30/88] END leaf_size=30, n_neighbors=9, weights=distance;, score=0.584 total time=   2.5s\n",
      "[CV 5/5; 30/88] START leaf_size=30, n_neighbors=9, weights=distance.............\n",
      "[CV 5/5; 30/88] END leaf_size=30, n_neighbors=9, weights=distance;, score=0.580 total time=   2.5s\n",
      "[CV 1/5; 31/88] START leaf_size=30, n_neighbors=15, weights=uniform.............\n",
      "[CV 1/5; 31/88] END leaf_size=30, n_neighbors=15, weights=uniform;, score=0.569 total time=   2.6s\n",
      "[CV 2/5; 31/88] START leaf_size=30, n_neighbors=15, weights=uniform.............\n",
      "[CV 2/5; 31/88] END leaf_size=30, n_neighbors=15, weights=uniform;, score=0.563 total time=   2.6s\n",
      "[CV 3/5; 31/88] START leaf_size=30, n_neighbors=15, weights=uniform.............\n",
      "[CV 3/5; 31/88] END leaf_size=30, n_neighbors=15, weights=uniform;, score=0.578 total time=   2.9s\n",
      "[CV 4/5; 31/88] START leaf_size=30, n_neighbors=15, weights=uniform.............\n",
      "[CV 4/5; 31/88] END leaf_size=30, n_neighbors=15, weights=uniform;, score=0.568 total time=   2.8s\n",
      "[CV 5/5; 31/88] START leaf_size=30, n_neighbors=15, weights=uniform.............\n",
      "[CV 5/5; 31/88] END leaf_size=30, n_neighbors=15, weights=uniform;, score=0.567 total time=   2.7s\n",
      "[CV 1/5; 32/88] START leaf_size=30, n_neighbors=15, weights=distance............\n",
      "[CV 1/5; 32/88] END leaf_size=30, n_neighbors=15, weights=distance;, score=0.569 total time=   2.6s\n",
      "[CV 2/5; 32/88] START leaf_size=30, n_neighbors=15, weights=distance............\n",
      "[CV 2/5; 32/88] END leaf_size=30, n_neighbors=15, weights=distance;, score=0.563 total time=   2.4s\n",
      "[CV 3/5; 32/88] START leaf_size=30, n_neighbors=15, weights=distance............\n",
      "[CV 3/5; 32/88] END leaf_size=30, n_neighbors=15, weights=distance;, score=0.578 total time=   2.5s\n",
      "[CV 4/5; 32/88] START leaf_size=30, n_neighbors=15, weights=distance............\n",
      "[CV 4/5; 32/88] END leaf_size=30, n_neighbors=15, weights=distance;, score=0.568 total time=   2.5s\n",
      "[CV 5/5; 32/88] START leaf_size=30, n_neighbors=15, weights=distance............\n",
      "[CV 5/5; 32/88] END leaf_size=30, n_neighbors=15, weights=distance;, score=0.567 total time=   2.5s\n",
      "[CV 1/5; 33/88] START leaf_size=30, n_neighbors=19, weights=uniform.............\n",
      "[CV 1/5; 33/88] END leaf_size=30, n_neighbors=19, weights=uniform;, score=0.560 total time=   2.6s\n",
      "[CV 2/5; 33/88] START leaf_size=30, n_neighbors=19, weights=uniform.............\n",
      "[CV 2/5; 33/88] END leaf_size=30, n_neighbors=19, weights=uniform;, score=0.556 total time=   2.5s\n",
      "[CV 3/5; 33/88] START leaf_size=30, n_neighbors=19, weights=uniform.............\n",
      "[CV 3/5; 33/88] END leaf_size=30, n_neighbors=19, weights=uniform;, score=0.567 total time=   2.7s\n",
      "[CV 4/5; 33/88] START leaf_size=30, n_neighbors=19, weights=uniform.............\n",
      "[CV 4/5; 33/88] END leaf_size=30, n_neighbors=19, weights=uniform;, score=0.563 total time=   2.9s\n",
      "[CV 5/5; 33/88] START leaf_size=30, n_neighbors=19, weights=uniform.............\n",
      "[CV 5/5; 33/88] END leaf_size=30, n_neighbors=19, weights=uniform;, score=0.560 total time=   2.8s\n",
      "[CV 1/5; 34/88] START leaf_size=30, n_neighbors=19, weights=distance............\n",
      "[CV 1/5; 34/88] END leaf_size=30, n_neighbors=19, weights=distance;, score=0.560 total time=   2.6s\n",
      "[CV 2/5; 34/88] START leaf_size=30, n_neighbors=19, weights=distance............\n",
      "[CV 2/5; 34/88] END leaf_size=30, n_neighbors=19, weights=distance;, score=0.556 total time=   2.5s\n",
      "[CV 3/5; 34/88] START leaf_size=30, n_neighbors=19, weights=distance............\n",
      "[CV 3/5; 34/88] END leaf_size=30, n_neighbors=19, weights=distance;, score=0.567 total time=   2.6s\n",
      "[CV 4/5; 34/88] START leaf_size=30, n_neighbors=19, weights=distance............\n",
      "[CV 4/5; 34/88] END leaf_size=30, n_neighbors=19, weights=distance;, score=0.563 total time=   2.5s\n",
      "[CV 5/5; 34/88] START leaf_size=30, n_neighbors=19, weights=distance............\n",
      "[CV 5/5; 34/88] END leaf_size=30, n_neighbors=19, weights=distance;, score=0.560 total time=   2.7s\n",
      "[CV 1/5; 35/88] START leaf_size=30, n_neighbors=25, weights=uniform.............\n",
      "[CV 1/5; 35/88] END leaf_size=30, n_neighbors=25, weights=uniform;, score=0.556 total time=   2.8s\n",
      "[CV 2/5; 35/88] START leaf_size=30, n_neighbors=25, weights=uniform.............\n",
      "[CV 2/5; 35/88] END leaf_size=30, n_neighbors=25, weights=uniform;, score=0.550 total time=   2.6s\n",
      "[CV 3/5; 35/88] START leaf_size=30, n_neighbors=25, weights=uniform.............\n",
      "[CV 3/5; 35/88] END leaf_size=30, n_neighbors=25, weights=uniform;, score=0.563 total time=   2.7s\n",
      "[CV 4/5; 35/88] START leaf_size=30, n_neighbors=25, weights=uniform.............\n",
      "[CV 4/5; 35/88] END leaf_size=30, n_neighbors=25, weights=uniform;, score=0.560 total time=   2.7s\n",
      "[CV 5/5; 35/88] START leaf_size=30, n_neighbors=25, weights=uniform.............\n",
      "[CV 5/5; 35/88] END leaf_size=30, n_neighbors=25, weights=uniform;, score=0.557 total time=   2.9s\n",
      "[CV 1/5; 36/88] START leaf_size=30, n_neighbors=25, weights=distance............\n",
      "[CV 1/5; 36/88] END leaf_size=30, n_neighbors=25, weights=distance;, score=0.556 total time=   2.9s\n",
      "[CV 2/5; 36/88] START leaf_size=30, n_neighbors=25, weights=distance............\n",
      "[CV 2/5; 36/88] END leaf_size=30, n_neighbors=25, weights=distance;, score=0.550 total time=   2.8s\n",
      "[CV 3/5; 36/88] START leaf_size=30, n_neighbors=25, weights=distance............\n",
      "[CV 3/5; 36/88] END leaf_size=30, n_neighbors=25, weights=distance;, score=0.563 total time=   3.2s\n",
      "[CV 4/5; 36/88] START leaf_size=30, n_neighbors=25, weights=distance............\n",
      "[CV 4/5; 36/88] END leaf_size=30, n_neighbors=25, weights=distance;, score=0.560 total time=   2.8s\n",
      "[CV 5/5; 36/88] START leaf_size=30, n_neighbors=25, weights=distance............\n",
      "[CV 5/5; 36/88] END leaf_size=30, n_neighbors=25, weights=distance;, score=0.557 total time=   3.0s\n",
      "[CV 1/5; 37/88] START leaf_size=30, n_neighbors=35, weights=uniform.............\n",
      "[CV 1/5; 37/88] END leaf_size=30, n_neighbors=35, weights=uniform;, score=0.547 total time=   3.1s\n",
      "[CV 2/5; 37/88] START leaf_size=30, n_neighbors=35, weights=uniform.............\n",
      "[CV 2/5; 37/88] END leaf_size=30, n_neighbors=35, weights=uniform;, score=0.546 total time=   2.9s\n",
      "[CV 3/5; 37/88] START leaf_size=30, n_neighbors=35, weights=uniform.............\n",
      "[CV 3/5; 37/88] END leaf_size=30, n_neighbors=35, weights=uniform;, score=0.553 total time=   3.0s\n",
      "[CV 4/5; 37/88] START leaf_size=30, n_neighbors=35, weights=uniform.............\n",
      "[CV 4/5; 37/88] END leaf_size=30, n_neighbors=35, weights=uniform;, score=0.547 total time=   2.8s\n",
      "[CV 5/5; 37/88] START leaf_size=30, n_neighbors=35, weights=uniform.............\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 37/88] END leaf_size=30, n_neighbors=35, weights=uniform;, score=0.550 total time=   2.8s\n",
      "[CV 1/5; 38/88] START leaf_size=30, n_neighbors=35, weights=distance............\n",
      "[CV 1/5; 38/88] END leaf_size=30, n_neighbors=35, weights=distance;, score=0.547 total time=   2.7s\n",
      "[CV 2/5; 38/88] START leaf_size=30, n_neighbors=35, weights=distance............\n",
      "[CV 2/5; 38/88] END leaf_size=30, n_neighbors=35, weights=distance;, score=0.546 total time=   2.6s\n",
      "[CV 3/5; 38/88] START leaf_size=30, n_neighbors=35, weights=distance............\n",
      "[CV 3/5; 38/88] END leaf_size=30, n_neighbors=35, weights=distance;, score=0.554 total time=   2.6s\n",
      "[CV 4/5; 38/88] START leaf_size=30, n_neighbors=35, weights=distance............\n",
      "[CV 4/5; 38/88] END leaf_size=30, n_neighbors=35, weights=distance;, score=0.547 total time=   2.6s\n",
      "[CV 5/5; 38/88] START leaf_size=30, n_neighbors=35, weights=distance............\n",
      "[CV 5/5; 38/88] END leaf_size=30, n_neighbors=35, weights=distance;, score=0.550 total time=   2.7s\n",
      "[CV 1/5; 39/88] START leaf_size=30, n_neighbors=55, weights=uniform.............\n",
      "[CV 1/5; 39/88] END leaf_size=30, n_neighbors=55, weights=uniform;, score=0.533 total time=   2.7s\n",
      "[CV 2/5; 39/88] START leaf_size=30, n_neighbors=55, weights=uniform.............\n",
      "[CV 2/5; 39/88] END leaf_size=30, n_neighbors=55, weights=uniform;, score=0.535 total time=   2.7s\n",
      "[CV 3/5; 39/88] START leaf_size=30, n_neighbors=55, weights=uniform.............\n",
      "[CV 3/5; 39/88] END leaf_size=30, n_neighbors=55, weights=uniform;, score=0.540 total time=   2.9s\n",
      "[CV 4/5; 39/88] START leaf_size=30, n_neighbors=55, weights=uniform.............\n",
      "[CV 4/5; 39/88] END leaf_size=30, n_neighbors=55, weights=uniform;, score=0.538 total time=   2.8s\n",
      "[CV 5/5; 39/88] START leaf_size=30, n_neighbors=55, weights=uniform.............\n",
      "[CV 5/5; 39/88] END leaf_size=30, n_neighbors=55, weights=uniform;, score=0.532 total time=   2.7s\n",
      "[CV 1/5; 40/88] START leaf_size=30, n_neighbors=55, weights=distance............\n",
      "[CV 1/5; 40/88] END leaf_size=30, n_neighbors=55, weights=distance;, score=0.533 total time=   2.6s\n",
      "[CV 2/5; 40/88] START leaf_size=30, n_neighbors=55, weights=distance............\n",
      "[CV 2/5; 40/88] END leaf_size=30, n_neighbors=55, weights=distance;, score=0.535 total time=   2.5s\n",
      "[CV 3/5; 40/88] START leaf_size=30, n_neighbors=55, weights=distance............\n",
      "[CV 3/5; 40/88] END leaf_size=30, n_neighbors=55, weights=distance;, score=0.540 total time=   2.6s\n",
      "[CV 4/5; 40/88] START leaf_size=30, n_neighbors=55, weights=distance............\n",
      "[CV 4/5; 40/88] END leaf_size=30, n_neighbors=55, weights=distance;, score=0.538 total time=   2.6s\n",
      "[CV 5/5; 40/88] START leaf_size=30, n_neighbors=55, weights=distance............\n",
      "[CV 5/5; 40/88] END leaf_size=30, n_neighbors=55, weights=distance;, score=0.532 total time=   2.6s\n",
      "[CV 1/5; 41/88] START leaf_size=30, n_neighbors=75, weights=uniform.............\n",
      "[CV 1/5; 41/88] END leaf_size=30, n_neighbors=75, weights=uniform;, score=0.528 total time=   2.7s\n",
      "[CV 2/5; 41/88] START leaf_size=30, n_neighbors=75, weights=uniform.............\n",
      "[CV 2/5; 41/88] END leaf_size=30, n_neighbors=75, weights=uniform;, score=0.525 total time=   2.7s\n",
      "[CV 3/5; 41/88] START leaf_size=30, n_neighbors=75, weights=uniform.............\n",
      "[CV 3/5; 41/88] END leaf_size=30, n_neighbors=75, weights=uniform;, score=0.529 total time=   2.9s\n",
      "[CV 4/5; 41/88] START leaf_size=30, n_neighbors=75, weights=uniform.............\n",
      "[CV 4/5; 41/88] END leaf_size=30, n_neighbors=75, weights=uniform;, score=0.533 total time=   2.8s\n",
      "[CV 5/5; 41/88] START leaf_size=30, n_neighbors=75, weights=uniform.............\n",
      "[CV 5/5; 41/88] END leaf_size=30, n_neighbors=75, weights=uniform;, score=0.524 total time=   3.0s\n",
      "[CV 1/5; 42/88] START leaf_size=30, n_neighbors=75, weights=distance............\n",
      "[CV 1/5; 42/88] END leaf_size=30, n_neighbors=75, weights=distance;, score=0.528 total time=   2.7s\n",
      "[CV 2/5; 42/88] START leaf_size=30, n_neighbors=75, weights=distance............\n",
      "[CV 2/5; 42/88] END leaf_size=30, n_neighbors=75, weights=distance;, score=0.525 total time=   2.5s\n",
      "[CV 3/5; 42/88] START leaf_size=30, n_neighbors=75, weights=distance............\n",
      "[CV 3/5; 42/88] END leaf_size=30, n_neighbors=75, weights=distance;, score=0.529 total time=   2.8s\n",
      "[CV 4/5; 42/88] START leaf_size=30, n_neighbors=75, weights=distance............\n",
      "[CV 4/5; 42/88] END leaf_size=30, n_neighbors=75, weights=distance;, score=0.533 total time=   2.8s\n",
      "[CV 5/5; 42/88] START leaf_size=30, n_neighbors=75, weights=distance............\n",
      "[CV 5/5; 42/88] END leaf_size=30, n_neighbors=75, weights=distance;, score=0.525 total time=   2.7s\n",
      "[CV 1/5; 43/88] START leaf_size=30, n_neighbors=99, weights=uniform.............\n",
      "[CV 1/5; 43/88] END leaf_size=30, n_neighbors=99, weights=uniform;, score=0.523 total time=   2.8s\n",
      "[CV 2/5; 43/88] START leaf_size=30, n_neighbors=99, weights=uniform.............\n",
      "[CV 2/5; 43/88] END leaf_size=30, n_neighbors=99, weights=uniform;, score=0.523 total time=   2.8s\n",
      "[CV 3/5; 43/88] START leaf_size=30, n_neighbors=99, weights=uniform.............\n",
      "[CV 3/5; 43/88] END leaf_size=30, n_neighbors=99, weights=uniform;, score=0.523 total time=   2.7s\n",
      "[CV 4/5; 43/88] START leaf_size=30, n_neighbors=99, weights=uniform.............\n",
      "[CV 4/5; 43/88] END leaf_size=30, n_neighbors=99, weights=uniform;, score=0.526 total time=   2.7s\n",
      "[CV 5/5; 43/88] START leaf_size=30, n_neighbors=99, weights=uniform.............\n",
      "[CV 5/5; 43/88] END leaf_size=30, n_neighbors=99, weights=uniform;, score=0.520 total time=   2.8s\n",
      "[CV 1/5; 44/88] START leaf_size=30, n_neighbors=99, weights=distance............\n",
      "[CV 1/5; 44/88] END leaf_size=30, n_neighbors=99, weights=distance;, score=0.524 total time=   2.9s\n",
      "[CV 2/5; 44/88] START leaf_size=30, n_neighbors=99, weights=distance............\n",
      "[CV 2/5; 44/88] END leaf_size=30, n_neighbors=99, weights=distance;, score=0.523 total time=   2.7s\n",
      "[CV 3/5; 44/88] START leaf_size=30, n_neighbors=99, weights=distance............\n",
      "[CV 3/5; 44/88] END leaf_size=30, n_neighbors=99, weights=distance;, score=0.523 total time=   3.0s\n",
      "[CV 4/5; 44/88] START leaf_size=30, n_neighbors=99, weights=distance............\n",
      "[CV 4/5; 44/88] END leaf_size=30, n_neighbors=99, weights=distance;, score=0.527 total time=   2.8s\n",
      "[CV 5/5; 44/88] START leaf_size=30, n_neighbors=99, weights=distance............\n",
      "[CV 5/5; 44/88] END leaf_size=30, n_neighbors=99, weights=distance;, score=0.521 total time=   2.8s\n",
      "[CV 1/5; 45/88] START leaf_size=50, n_neighbors=3, weights=uniform..............\n",
      "[CV 1/5; 45/88] END leaf_size=50, n_neighbors=3, weights=uniform;, score=0.589 total time=   2.2s\n",
      "[CV 2/5; 45/88] START leaf_size=50, n_neighbors=3, weights=uniform..............\n",
      "[CV 2/5; 45/88] END leaf_size=50, n_neighbors=3, weights=uniform;, score=0.581 total time=   2.5s\n",
      "[CV 3/5; 45/88] START leaf_size=50, n_neighbors=3, weights=uniform..............\n",
      "[CV 3/5; 45/88] END leaf_size=50, n_neighbors=3, weights=uniform;, score=0.589 total time=   2.3s\n",
      "[CV 4/5; 45/88] START leaf_size=50, n_neighbors=3, weights=uniform..............\n",
      "[CV 4/5; 45/88] END leaf_size=50, n_neighbors=3, weights=uniform;, score=0.590 total time=   2.2s\n",
      "[CV 5/5; 45/88] START leaf_size=50, n_neighbors=3, weights=uniform..............\n",
      "[CV 5/5; 45/88] END leaf_size=50, n_neighbors=3, weights=uniform;, score=0.581 total time=   2.2s\n",
      "[CV 1/5; 46/88] START leaf_size=50, n_neighbors=3, weights=distance.............\n",
      "[CV 1/5; 46/88] END leaf_size=50, n_neighbors=3, weights=distance;, score=0.589 total time=   2.0s\n",
      "[CV 2/5; 46/88] START leaf_size=50, n_neighbors=3, weights=distance.............\n",
      "[CV 2/5; 46/88] END leaf_size=50, n_neighbors=3, weights=distance;, score=0.581 total time=   2.1s\n",
      "[CV 3/5; 46/88] START leaf_size=50, n_neighbors=3, weights=distance.............\n",
      "[CV 3/5; 46/88] END leaf_size=50, n_neighbors=3, weights=distance;, score=0.589 total time=   2.0s\n",
      "[CV 4/5; 46/88] START leaf_size=50, n_neighbors=3, weights=distance.............\n",
      "[CV 4/5; 46/88] END leaf_size=50, n_neighbors=3, weights=distance;, score=0.590 total time=   2.0s\n",
      "[CV 5/5; 46/88] START leaf_size=50, n_neighbors=3, weights=distance.............\n",
      "[CV 5/5; 46/88] END leaf_size=50, n_neighbors=3, weights=distance;, score=0.581 total time=   2.1s\n",
      "[CV 1/5; 47/88] START leaf_size=50, n_neighbors=5, weights=uniform..............\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 47/88] END leaf_size=50, n_neighbors=5, weights=uniform;, score=0.592 total time=   2.7s\n",
      "[CV 2/5; 47/88] START leaf_size=50, n_neighbors=5, weights=uniform..............\n",
      "[CV 2/5; 47/88] END leaf_size=50, n_neighbors=5, weights=uniform;, score=0.577 total time=   2.6s\n",
      "[CV 3/5; 47/88] START leaf_size=50, n_neighbors=5, weights=uniform..............\n",
      "[CV 3/5; 47/88] END leaf_size=50, n_neighbors=5, weights=uniform;, score=0.589 total time=   2.7s\n",
      "[CV 4/5; 47/88] START leaf_size=50, n_neighbors=5, weights=uniform..............\n",
      "[CV 4/5; 47/88] END leaf_size=50, n_neighbors=5, weights=uniform;, score=0.588 total time=   2.7s\n",
      "[CV 5/5; 47/88] START leaf_size=50, n_neighbors=5, weights=uniform..............\n",
      "[CV 5/5; 47/88] END leaf_size=50, n_neighbors=5, weights=uniform;, score=0.585 total time=   2.7s\n",
      "[CV 1/5; 48/88] START leaf_size=50, n_neighbors=5, weights=distance.............\n",
      "[CV 1/5; 48/88] END leaf_size=50, n_neighbors=5, weights=distance;, score=0.592 total time=   2.5s\n",
      "[CV 2/5; 48/88] START leaf_size=50, n_neighbors=5, weights=distance.............\n",
      "[CV 2/5; 48/88] END leaf_size=50, n_neighbors=5, weights=distance;, score=0.577 total time=   2.4s\n",
      "[CV 3/5; 48/88] START leaf_size=50, n_neighbors=5, weights=distance.............\n",
      "[CV 3/5; 48/88] END leaf_size=50, n_neighbors=5, weights=distance;, score=0.589 total time=   2.6s\n",
      "[CV 4/5; 48/88] START leaf_size=50, n_neighbors=5, weights=distance.............\n",
      "[CV 4/5; 48/88] END leaf_size=50, n_neighbors=5, weights=distance;, score=0.588 total time=   2.5s\n",
      "[CV 5/5; 48/88] START leaf_size=50, n_neighbors=5, weights=distance.............\n",
      "[CV 5/5; 48/88] END leaf_size=50, n_neighbors=5, weights=distance;, score=0.585 total time=   2.6s\n",
      "[CV 1/5; 49/88] START leaf_size=50, n_neighbors=7, weights=uniform..............\n",
      "[CV 1/5; 49/88] END leaf_size=50, n_neighbors=7, weights=uniform;, score=0.582 total time=   2.8s\n",
      "[CV 2/5; 49/88] START leaf_size=50, n_neighbors=7, weights=uniform..............\n",
      "[CV 2/5; 49/88] END leaf_size=50, n_neighbors=7, weights=uniform;, score=0.574 total time=   2.7s\n",
      "[CV 3/5; 49/88] START leaf_size=50, n_neighbors=7, weights=uniform..............\n",
      "[CV 3/5; 49/88] END leaf_size=50, n_neighbors=7, weights=uniform;, score=0.581 total time=   2.8s\n",
      "[CV 4/5; 49/88] START leaf_size=50, n_neighbors=7, weights=uniform..............\n",
      "[CV 4/5; 49/88] END leaf_size=50, n_neighbors=7, weights=uniform;, score=0.584 total time=   2.7s\n",
      "[CV 5/5; 49/88] START leaf_size=50, n_neighbors=7, weights=uniform..............\n",
      "[CV 5/5; 49/88] END leaf_size=50, n_neighbors=7, weights=uniform;, score=0.583 total time=   2.9s\n",
      "[CV 1/5; 50/88] START leaf_size=50, n_neighbors=7, weights=distance.............\n",
      "[CV 1/5; 50/88] END leaf_size=50, n_neighbors=7, weights=distance;, score=0.582 total time=   2.6s\n",
      "[CV 2/5; 50/88] START leaf_size=50, n_neighbors=7, weights=distance.............\n",
      "[CV 2/5; 50/88] END leaf_size=50, n_neighbors=7, weights=distance;, score=0.574 total time=   2.4s\n",
      "[CV 3/5; 50/88] START leaf_size=50, n_neighbors=7, weights=distance.............\n",
      "[CV 3/5; 50/88] END leaf_size=50, n_neighbors=7, weights=distance;, score=0.581 total time=   2.6s\n",
      "[CV 4/5; 50/88] START leaf_size=50, n_neighbors=7, weights=distance.............\n",
      "[CV 4/5; 50/88] END leaf_size=50, n_neighbors=7, weights=distance;, score=0.585 total time=   2.7s\n",
      "[CV 5/5; 50/88] START leaf_size=50, n_neighbors=7, weights=distance.............\n",
      "[CV 5/5; 50/88] END leaf_size=50, n_neighbors=7, weights=distance;, score=0.583 total time=   2.6s\n",
      "[CV 1/5; 51/88] START leaf_size=50, n_neighbors=9, weights=uniform..............\n",
      "[CV 1/5; 51/88] END leaf_size=50, n_neighbors=9, weights=uniform;, score=0.575 total time=   3.2s\n",
      "[CV 2/5; 51/88] START leaf_size=50, n_neighbors=9, weights=uniform..............\n",
      "[CV 2/5; 51/88] END leaf_size=50, n_neighbors=9, weights=uniform;, score=0.572 total time=   2.7s\n",
      "[CV 3/5; 51/88] START leaf_size=50, n_neighbors=9, weights=uniform..............\n",
      "[CV 3/5; 51/88] END leaf_size=50, n_neighbors=9, weights=uniform;, score=0.581 total time=   2.8s\n",
      "[CV 4/5; 51/88] START leaf_size=50, n_neighbors=9, weights=uniform..............\n",
      "[CV 4/5; 51/88] END leaf_size=50, n_neighbors=9, weights=uniform;, score=0.584 total time=   2.7s\n",
      "[CV 5/5; 51/88] START leaf_size=50, n_neighbors=9, weights=uniform..............\n",
      "[CV 5/5; 51/88] END leaf_size=50, n_neighbors=9, weights=uniform;, score=0.580 total time=   2.7s\n",
      "[CV 1/5; 52/88] START leaf_size=50, n_neighbors=9, weights=distance.............\n",
      "[CV 1/5; 52/88] END leaf_size=50, n_neighbors=9, weights=distance;, score=0.575 total time=   2.6s\n",
      "[CV 2/5; 52/88] START leaf_size=50, n_neighbors=9, weights=distance.............\n",
      "[CV 2/5; 52/88] END leaf_size=50, n_neighbors=9, weights=distance;, score=0.572 total time=   2.5s\n",
      "[CV 3/5; 52/88] START leaf_size=50, n_neighbors=9, weights=distance.............\n",
      "[CV 3/5; 52/88] END leaf_size=50, n_neighbors=9, weights=distance;, score=0.581 total time=   2.6s\n",
      "[CV 4/5; 52/88] START leaf_size=50, n_neighbors=9, weights=distance.............\n",
      "[CV 4/5; 52/88] END leaf_size=50, n_neighbors=9, weights=distance;, score=0.584 total time=   2.6s\n",
      "[CV 5/5; 52/88] START leaf_size=50, n_neighbors=9, weights=distance.............\n",
      "[CV 5/5; 52/88] END leaf_size=50, n_neighbors=9, weights=distance;, score=0.580 total time=   2.7s\n",
      "[CV 1/5; 53/88] START leaf_size=50, n_neighbors=15, weights=uniform.............\n",
      "[CV 1/5; 53/88] END leaf_size=50, n_neighbors=15, weights=uniform;, score=0.569 total time=   2.7s\n",
      "[CV 2/5; 53/88] START leaf_size=50, n_neighbors=15, weights=uniform.............\n",
      "[CV 2/5; 53/88] END leaf_size=50, n_neighbors=15, weights=uniform;, score=0.563 total time=   2.6s\n",
      "[CV 3/5; 53/88] START leaf_size=50, n_neighbors=15, weights=uniform.............\n",
      "[CV 3/5; 53/88] END leaf_size=50, n_neighbors=15, weights=uniform;, score=0.578 total time=   2.8s\n",
      "[CV 4/5; 53/88] START leaf_size=50, n_neighbors=15, weights=uniform.............\n",
      "[CV 4/5; 53/88] END leaf_size=50, n_neighbors=15, weights=uniform;, score=0.568 total time=   2.8s\n",
      "[CV 5/5; 53/88] START leaf_size=50, n_neighbors=15, weights=uniform.............\n",
      "[CV 5/5; 53/88] END leaf_size=50, n_neighbors=15, weights=uniform;, score=0.567 total time=   3.0s\n",
      "[CV 1/5; 54/88] START leaf_size=50, n_neighbors=15, weights=distance............\n",
      "[CV 1/5; 54/88] END leaf_size=50, n_neighbors=15, weights=distance;, score=0.569 total time=   2.7s\n",
      "[CV 2/5; 54/88] START leaf_size=50, n_neighbors=15, weights=distance............\n",
      "[CV 2/5; 54/88] END leaf_size=50, n_neighbors=15, weights=distance;, score=0.563 total time=   2.6s\n",
      "[CV 3/5; 54/88] START leaf_size=50, n_neighbors=15, weights=distance............\n",
      "[CV 3/5; 54/88] END leaf_size=50, n_neighbors=15, weights=distance;, score=0.578 total time=   2.7s\n",
      "[CV 4/5; 54/88] START leaf_size=50, n_neighbors=15, weights=distance............\n",
      "[CV 4/5; 54/88] END leaf_size=50, n_neighbors=15, weights=distance;, score=0.568 total time=   2.7s\n",
      "[CV 5/5; 54/88] START leaf_size=50, n_neighbors=15, weights=distance............\n",
      "[CV 5/5; 54/88] END leaf_size=50, n_neighbors=15, weights=distance;, score=0.567 total time=   2.8s\n",
      "[CV 1/5; 55/88] START leaf_size=50, n_neighbors=19, weights=uniform.............\n",
      "[CV 1/5; 55/88] END leaf_size=50, n_neighbors=19, weights=uniform;, score=0.560 total time=   2.7s\n",
      "[CV 2/5; 55/88] START leaf_size=50, n_neighbors=19, weights=uniform.............\n",
      "[CV 2/5; 55/88] END leaf_size=50, n_neighbors=19, weights=uniform;, score=0.556 total time=   2.6s\n",
      "[CV 3/5; 55/88] START leaf_size=50, n_neighbors=19, weights=uniform.............\n",
      "[CV 3/5; 55/88] END leaf_size=50, n_neighbors=19, weights=uniform;, score=0.567 total time=   2.8s\n",
      "[CV 4/5; 55/88] START leaf_size=50, n_neighbors=19, weights=uniform.............\n",
      "[CV 4/5; 55/88] END leaf_size=50, n_neighbors=19, weights=uniform;, score=0.563 total time=   2.7s\n",
      "[CV 5/5; 55/88] START leaf_size=50, n_neighbors=19, weights=uniform.............\n",
      "[CV 5/5; 55/88] END leaf_size=50, n_neighbors=19, weights=uniform;, score=0.560 total time=   2.7s\n",
      "[CV 1/5; 56/88] START leaf_size=50, n_neighbors=19, weights=distance............\n",
      "[CV 1/5; 56/88] END leaf_size=50, n_neighbors=19, weights=distance;, score=0.560 total time=   2.6s\n",
      "[CV 2/5; 56/88] START leaf_size=50, n_neighbors=19, weights=distance............\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 56/88] END leaf_size=50, n_neighbors=19, weights=distance;, score=0.556 total time=   2.6s\n",
      "[CV 3/5; 56/88] START leaf_size=50, n_neighbors=19, weights=distance............\n",
      "[CV 3/5; 56/88] END leaf_size=50, n_neighbors=19, weights=distance;, score=0.567 total time=   2.9s\n",
      "[CV 4/5; 56/88] START leaf_size=50, n_neighbors=19, weights=distance............\n",
      "[CV 4/5; 56/88] END leaf_size=50, n_neighbors=19, weights=distance;, score=0.563 total time=   3.0s\n",
      "[CV 5/5; 56/88] START leaf_size=50, n_neighbors=19, weights=distance............\n",
      "[CV 5/5; 56/88] END leaf_size=50, n_neighbors=19, weights=distance;, score=0.560 total time=   2.9s\n",
      "[CV 1/5; 57/88] START leaf_size=50, n_neighbors=25, weights=uniform.............\n",
      "[CV 1/5; 57/88] END leaf_size=50, n_neighbors=25, weights=uniform;, score=0.556 total time=   2.8s\n",
      "[CV 2/5; 57/88] START leaf_size=50, n_neighbors=25, weights=uniform.............\n",
      "[CV 2/5; 57/88] END leaf_size=50, n_neighbors=25, weights=uniform;, score=0.550 total time=   2.7s\n",
      "[CV 3/5; 57/88] START leaf_size=50, n_neighbors=25, weights=uniform.............\n",
      "[CV 3/5; 57/88] END leaf_size=50, n_neighbors=25, weights=uniform;, score=0.563 total time=   2.9s\n",
      "[CV 4/5; 57/88] START leaf_size=50, n_neighbors=25, weights=uniform.............\n",
      "[CV 4/5; 57/88] END leaf_size=50, n_neighbors=25, weights=uniform;, score=0.560 total time=   2.8s\n",
      "[CV 5/5; 57/88] START leaf_size=50, n_neighbors=25, weights=uniform.............\n",
      "[CV 5/5; 57/88] END leaf_size=50, n_neighbors=25, weights=uniform;, score=0.557 total time=   2.9s\n",
      "[CV 1/5; 58/88] START leaf_size=50, n_neighbors=25, weights=distance............\n",
      "[CV 1/5; 58/88] END leaf_size=50, n_neighbors=25, weights=distance;, score=0.556 total time=   2.6s\n",
      "[CV 2/5; 58/88] START leaf_size=50, n_neighbors=25, weights=distance............\n",
      "[CV 2/5; 58/88] END leaf_size=50, n_neighbors=25, weights=distance;, score=0.550 total time=   2.5s\n",
      "[CV 3/5; 58/88] START leaf_size=50, n_neighbors=25, weights=distance............\n",
      "[CV 3/5; 58/88] END leaf_size=50, n_neighbors=25, weights=distance;, score=0.563 total time=   2.9s\n",
      "[CV 4/5; 58/88] START leaf_size=50, n_neighbors=25, weights=distance............\n",
      "[CV 4/5; 58/88] END leaf_size=50, n_neighbors=25, weights=distance;, score=0.560 total time=   2.8s\n",
      "[CV 5/5; 58/88] START leaf_size=50, n_neighbors=25, weights=distance............\n",
      "[CV 5/5; 58/88] END leaf_size=50, n_neighbors=25, weights=distance;, score=0.557 total time=   2.7s\n",
      "[CV 1/5; 59/88] START leaf_size=50, n_neighbors=35, weights=uniform.............\n",
      "[CV 1/5; 59/88] END leaf_size=50, n_neighbors=35, weights=uniform;, score=0.547 total time=   2.7s\n",
      "[CV 2/5; 59/88] START leaf_size=50, n_neighbors=35, weights=uniform.............\n",
      "[CV 2/5; 59/88] END leaf_size=50, n_neighbors=35, weights=uniform;, score=0.546 total time=   2.7s\n",
      "[CV 3/5; 59/88] START leaf_size=50, n_neighbors=35, weights=uniform.............\n",
      "[CV 3/5; 59/88] END leaf_size=50, n_neighbors=35, weights=uniform;, score=0.553 total time=   2.8s\n",
      "[CV 4/5; 59/88] START leaf_size=50, n_neighbors=35, weights=uniform.............\n",
      "[CV 4/5; 59/88] END leaf_size=50, n_neighbors=35, weights=uniform;, score=0.547 total time=   2.8s\n",
      "[CV 5/5; 59/88] START leaf_size=50, n_neighbors=35, weights=uniform.............\n",
      "[CV 5/5; 59/88] END leaf_size=50, n_neighbors=35, weights=uniform;, score=0.550 total time=   2.8s\n",
      "[CV 1/5; 60/88] START leaf_size=50, n_neighbors=35, weights=distance............\n",
      "[CV 1/5; 60/88] END leaf_size=50, n_neighbors=35, weights=distance;, score=0.547 total time=   2.7s\n",
      "[CV 2/5; 60/88] START leaf_size=50, n_neighbors=35, weights=distance............\n",
      "[CV 2/5; 60/88] END leaf_size=50, n_neighbors=35, weights=distance;, score=0.546 total time=   2.5s\n",
      "[CV 3/5; 60/88] START leaf_size=50, n_neighbors=35, weights=distance............\n",
      "[CV 3/5; 60/88] END leaf_size=50, n_neighbors=35, weights=distance;, score=0.554 total time=   2.7s\n",
      "[CV 4/5; 60/88] START leaf_size=50, n_neighbors=35, weights=distance............\n",
      "[CV 4/5; 60/88] END leaf_size=50, n_neighbors=35, weights=distance;, score=0.547 total time=   2.7s\n",
      "[CV 5/5; 60/88] START leaf_size=50, n_neighbors=35, weights=distance............\n",
      "[CV 5/5; 60/88] END leaf_size=50, n_neighbors=35, weights=distance;, score=0.550 total time=   2.7s\n",
      "[CV 1/5; 61/88] START leaf_size=50, n_neighbors=55, weights=uniform.............\n",
      "[CV 1/5; 61/88] END leaf_size=50, n_neighbors=55, weights=uniform;, score=0.533 total time=   2.8s\n",
      "[CV 2/5; 61/88] START leaf_size=50, n_neighbors=55, weights=uniform.............\n",
      "[CV 2/5; 61/88] END leaf_size=50, n_neighbors=55, weights=uniform;, score=0.535 total time=   2.6s\n",
      "[CV 3/5; 61/88] START leaf_size=50, n_neighbors=55, weights=uniform.............\n",
      "[CV 3/5; 61/88] END leaf_size=50, n_neighbors=55, weights=uniform;, score=0.540 total time=   2.8s\n",
      "[CV 4/5; 61/88] START leaf_size=50, n_neighbors=55, weights=uniform.............\n",
      "[CV 4/5; 61/88] END leaf_size=50, n_neighbors=55, weights=uniform;, score=0.538 total time=   2.7s\n",
      "[CV 5/5; 61/88] START leaf_size=50, n_neighbors=55, weights=uniform.............\n",
      "[CV 5/5; 61/88] END leaf_size=50, n_neighbors=55, weights=uniform;, score=0.532 total time=   2.8s\n",
      "[CV 1/5; 62/88] START leaf_size=50, n_neighbors=55, weights=distance............\n",
      "[CV 1/5; 62/88] END leaf_size=50, n_neighbors=55, weights=distance;, score=0.533 total time=   2.6s\n",
      "[CV 2/5; 62/88] START leaf_size=50, n_neighbors=55, weights=distance............\n",
      "[CV 2/5; 62/88] END leaf_size=50, n_neighbors=55, weights=distance;, score=0.535 total time=   2.5s\n",
      "[CV 3/5; 62/88] START leaf_size=50, n_neighbors=55, weights=distance............\n",
      "[CV 3/5; 62/88] END leaf_size=50, n_neighbors=55, weights=distance;, score=0.540 total time=   2.7s\n",
      "[CV 4/5; 62/88] START leaf_size=50, n_neighbors=55, weights=distance............\n",
      "[CV 4/5; 62/88] END leaf_size=50, n_neighbors=55, weights=distance;, score=0.538 total time=   2.6s\n",
      "[CV 5/5; 62/88] START leaf_size=50, n_neighbors=55, weights=distance............\n",
      "[CV 5/5; 62/88] END leaf_size=50, n_neighbors=55, weights=distance;, score=0.532 total time=   2.6s\n",
      "[CV 1/5; 63/88] START leaf_size=50, n_neighbors=75, weights=uniform.............\n",
      "[CV 1/5; 63/88] END leaf_size=50, n_neighbors=75, weights=uniform;, score=0.528 total time=   2.8s\n",
      "[CV 2/5; 63/88] START leaf_size=50, n_neighbors=75, weights=uniform.............\n",
      "[CV 2/5; 63/88] END leaf_size=50, n_neighbors=75, weights=uniform;, score=0.525 total time=   2.8s\n",
      "[CV 3/5; 63/88] START leaf_size=50, n_neighbors=75, weights=uniform.............\n",
      "[CV 3/5; 63/88] END leaf_size=50, n_neighbors=75, weights=uniform;, score=0.529 total time=   2.9s\n",
      "[CV 4/5; 63/88] START leaf_size=50, n_neighbors=75, weights=uniform.............\n",
      "[CV 4/5; 63/88] END leaf_size=50, n_neighbors=75, weights=uniform;, score=0.533 total time=   2.8s\n",
      "[CV 5/5; 63/88] START leaf_size=50, n_neighbors=75, weights=uniform.............\n",
      "[CV 5/5; 63/88] END leaf_size=50, n_neighbors=75, weights=uniform;, score=0.524 total time=   2.8s\n",
      "[CV 1/5; 64/88] START leaf_size=50, n_neighbors=75, weights=distance............\n",
      "[CV 1/5; 64/88] END leaf_size=50, n_neighbors=75, weights=distance;, score=0.528 total time=   2.6s\n",
      "[CV 2/5; 64/88] START leaf_size=50, n_neighbors=75, weights=distance............\n",
      "[CV 2/5; 64/88] END leaf_size=50, n_neighbors=75, weights=distance;, score=0.525 total time=   2.5s\n",
      "[CV 3/5; 64/88] START leaf_size=50, n_neighbors=75, weights=distance............\n",
      "[CV 3/5; 64/88] END leaf_size=50, n_neighbors=75, weights=distance;, score=0.529 total time=   2.7s\n",
      "[CV 4/5; 64/88] START leaf_size=50, n_neighbors=75, weights=distance............\n",
      "[CV 4/5; 64/88] END leaf_size=50, n_neighbors=75, weights=distance;, score=0.533 total time=   2.7s\n",
      "[CV 5/5; 64/88] START leaf_size=50, n_neighbors=75, weights=distance............\n",
      "[CV 5/5; 64/88] END leaf_size=50, n_neighbors=75, weights=distance;, score=0.525 total time=   2.7s\n",
      "[CV 1/5; 65/88] START leaf_size=50, n_neighbors=99, weights=uniform.............\n",
      "[CV 1/5; 65/88] END leaf_size=50, n_neighbors=99, weights=uniform;, score=0.523 total time=   2.8s\n",
      "[CV 2/5; 65/88] START leaf_size=50, n_neighbors=99, weights=uniform.............\n",
      "[CV 2/5; 65/88] END leaf_size=50, n_neighbors=99, weights=uniform;, score=0.523 total time=   2.7s\n",
      "[CV 3/5; 65/88] START leaf_size=50, n_neighbors=99, weights=uniform.............\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 65/88] END leaf_size=50, n_neighbors=99, weights=uniform;, score=0.523 total time=   2.8s\n",
      "[CV 4/5; 65/88] START leaf_size=50, n_neighbors=99, weights=uniform.............\n",
      "[CV 4/5; 65/88] END leaf_size=50, n_neighbors=99, weights=uniform;, score=0.526 total time=   2.9s\n",
      "[CV 5/5; 65/88] START leaf_size=50, n_neighbors=99, weights=uniform.............\n",
      "[CV 5/5; 65/88] END leaf_size=50, n_neighbors=99, weights=uniform;, score=0.520 total time=   2.8s\n",
      "[CV 1/5; 66/88] START leaf_size=50, n_neighbors=99, weights=distance............\n",
      "[CV 1/5; 66/88] END leaf_size=50, n_neighbors=99, weights=distance;, score=0.524 total time=   2.6s\n",
      "[CV 2/5; 66/88] START leaf_size=50, n_neighbors=99, weights=distance............\n",
      "[CV 2/5; 66/88] END leaf_size=50, n_neighbors=99, weights=distance;, score=0.523 total time=   2.6s\n",
      "[CV 3/5; 66/88] START leaf_size=50, n_neighbors=99, weights=distance............\n",
      "[CV 3/5; 66/88] END leaf_size=50, n_neighbors=99, weights=distance;, score=0.523 total time=   2.7s\n",
      "[CV 4/5; 66/88] START leaf_size=50, n_neighbors=99, weights=distance............\n",
      "[CV 4/5; 66/88] END leaf_size=50, n_neighbors=99, weights=distance;, score=0.527 total time=   2.7s\n",
      "[CV 5/5; 66/88] START leaf_size=50, n_neighbors=99, weights=distance............\n",
      "[CV 5/5; 66/88] END leaf_size=50, n_neighbors=99, weights=distance;, score=0.521 total time=   2.7s\n",
      "[CV 1/5; 67/88] START leaf_size=70, n_neighbors=3, weights=uniform..............\n",
      "[CV 1/5; 67/88] END leaf_size=70, n_neighbors=3, weights=uniform;, score=0.589 total time=   2.1s\n",
      "[CV 2/5; 67/88] START leaf_size=70, n_neighbors=3, weights=uniform..............\n",
      "[CV 2/5; 67/88] END leaf_size=70, n_neighbors=3, weights=uniform;, score=0.581 total time=   2.1s\n",
      "[CV 3/5; 67/88] START leaf_size=70, n_neighbors=3, weights=uniform..............\n",
      "[CV 3/5; 67/88] END leaf_size=70, n_neighbors=3, weights=uniform;, score=0.589 total time=   2.2s\n",
      "[CV 4/5; 67/88] START leaf_size=70, n_neighbors=3, weights=uniform..............\n",
      "[CV 4/5; 67/88] END leaf_size=70, n_neighbors=3, weights=uniform;, score=0.590 total time=   2.1s\n",
      "[CV 5/5; 67/88] START leaf_size=70, n_neighbors=3, weights=uniform..............\n",
      "[CV 5/5; 67/88] END leaf_size=70, n_neighbors=3, weights=uniform;, score=0.581 total time=   2.1s\n",
      "[CV 1/5; 68/88] START leaf_size=70, n_neighbors=3, weights=distance.............\n",
      "[CV 1/5; 68/88] END leaf_size=70, n_neighbors=3, weights=distance;, score=0.589 total time=   2.2s\n",
      "[CV 2/5; 68/88] START leaf_size=70, n_neighbors=3, weights=distance.............\n",
      "[CV 2/5; 68/88] END leaf_size=70, n_neighbors=3, weights=distance;, score=0.581 total time=   2.3s\n",
      "[CV 3/5; 68/88] START leaf_size=70, n_neighbors=3, weights=distance.............\n",
      "[CV 3/5; 68/88] END leaf_size=70, n_neighbors=3, weights=distance;, score=0.589 total time=   2.2s\n",
      "[CV 4/5; 68/88] START leaf_size=70, n_neighbors=3, weights=distance.............\n",
      "[CV 4/5; 68/88] END leaf_size=70, n_neighbors=3, weights=distance;, score=0.590 total time=   2.0s\n",
      "[CV 5/5; 68/88] START leaf_size=70, n_neighbors=3, weights=distance.............\n",
      "[CV 5/5; 68/88] END leaf_size=70, n_neighbors=3, weights=distance;, score=0.581 total time=   2.0s\n",
      "[CV 1/5; 69/88] START leaf_size=70, n_neighbors=5, weights=uniform..............\n",
      "[CV 1/5; 69/88] END leaf_size=70, n_neighbors=5, weights=uniform;, score=0.592 total time=   2.7s\n",
      "[CV 2/5; 69/88] START leaf_size=70, n_neighbors=5, weights=uniform..............\n",
      "[CV 2/5; 69/88] END leaf_size=70, n_neighbors=5, weights=uniform;, score=0.577 total time=   2.8s\n",
      "[CV 3/5; 69/88] START leaf_size=70, n_neighbors=5, weights=uniform..............\n",
      "[CV 3/5; 69/88] END leaf_size=70, n_neighbors=5, weights=uniform;, score=0.589 total time=   2.9s\n",
      "[CV 4/5; 69/88] START leaf_size=70, n_neighbors=5, weights=uniform..............\n",
      "[CV 4/5; 69/88] END leaf_size=70, n_neighbors=5, weights=uniform;, score=0.588 total time=   2.8s\n",
      "[CV 5/5; 69/88] START leaf_size=70, n_neighbors=5, weights=uniform..............\n",
      "[CV 5/5; 69/88] END leaf_size=70, n_neighbors=5, weights=uniform;, score=0.585 total time=   2.9s\n",
      "[CV 1/5; 70/88] START leaf_size=70, n_neighbors=5, weights=distance.............\n",
      "[CV 1/5; 70/88] END leaf_size=70, n_neighbors=5, weights=distance;, score=0.592 total time=   2.6s\n",
      "[CV 2/5; 70/88] START leaf_size=70, n_neighbors=5, weights=distance.............\n",
      "[CV 2/5; 70/88] END leaf_size=70, n_neighbors=5, weights=distance;, score=0.577 total time=   2.5s\n",
      "[CV 3/5; 70/88] START leaf_size=70, n_neighbors=5, weights=distance.............\n",
      "[CV 3/5; 70/88] END leaf_size=70, n_neighbors=5, weights=distance;, score=0.589 total time=   2.7s\n",
      "[CV 4/5; 70/88] START leaf_size=70, n_neighbors=5, weights=distance.............\n",
      "[CV 4/5; 70/88] END leaf_size=70, n_neighbors=5, weights=distance;, score=0.588 total time=   2.7s\n",
      "[CV 5/5; 70/88] START leaf_size=70, n_neighbors=5, weights=distance.............\n",
      "[CV 5/5; 70/88] END leaf_size=70, n_neighbors=5, weights=distance;, score=0.585 total time=   2.7s\n",
      "[CV 1/5; 71/88] START leaf_size=70, n_neighbors=7, weights=uniform..............\n",
      "[CV 1/5; 71/88] END leaf_size=70, n_neighbors=7, weights=uniform;, score=0.582 total time=   2.7s\n",
      "[CV 2/5; 71/88] START leaf_size=70, n_neighbors=7, weights=uniform..............\n",
      "[CV 2/5; 71/88] END leaf_size=70, n_neighbors=7, weights=uniform;, score=0.574 total time=   2.7s\n",
      "[CV 3/5; 71/88] START leaf_size=70, n_neighbors=7, weights=uniform..............\n",
      "[CV 3/5; 71/88] END leaf_size=70, n_neighbors=7, weights=uniform;, score=0.581 total time=   2.9s\n",
      "[CV 4/5; 71/88] START leaf_size=70, n_neighbors=7, weights=uniform..............\n",
      "[CV 4/5; 71/88] END leaf_size=70, n_neighbors=7, weights=uniform;, score=0.584 total time=   2.7s\n",
      "[CV 5/5; 71/88] START leaf_size=70, n_neighbors=7, weights=uniform..............\n",
      "[CV 5/5; 71/88] END leaf_size=70, n_neighbors=7, weights=uniform;, score=0.583 total time=   2.7s\n",
      "[CV 1/5; 72/88] START leaf_size=70, n_neighbors=7, weights=distance.............\n",
      "[CV 1/5; 72/88] END leaf_size=70, n_neighbors=7, weights=distance;, score=0.582 total time=   2.5s\n",
      "[CV 2/5; 72/88] START leaf_size=70, n_neighbors=7, weights=distance.............\n",
      "[CV 2/5; 72/88] END leaf_size=70, n_neighbors=7, weights=distance;, score=0.574 total time=   2.4s\n",
      "[CV 3/5; 72/88] START leaf_size=70, n_neighbors=7, weights=distance.............\n",
      "[CV 3/5; 72/88] END leaf_size=70, n_neighbors=7, weights=distance;, score=0.581 total time=   2.6s\n",
      "[CV 4/5; 72/88] START leaf_size=70, n_neighbors=7, weights=distance.............\n",
      "[CV 4/5; 72/88] END leaf_size=70, n_neighbors=7, weights=distance;, score=0.585 total time=   2.5s\n",
      "[CV 5/5; 72/88] START leaf_size=70, n_neighbors=7, weights=distance.............\n",
      "[CV 5/5; 72/88] END leaf_size=70, n_neighbors=7, weights=distance;, score=0.583 total time=   2.6s\n",
      "[CV 1/5; 73/88] START leaf_size=70, n_neighbors=9, weights=uniform..............\n",
      "[CV 1/5; 73/88] END leaf_size=70, n_neighbors=9, weights=uniform;, score=0.575 total time=   2.8s\n",
      "[CV 2/5; 73/88] START leaf_size=70, n_neighbors=9, weights=uniform..............\n",
      "[CV 2/5; 73/88] END leaf_size=70, n_neighbors=9, weights=uniform;, score=0.572 total time=   2.8s\n",
      "[CV 3/5; 73/88] START leaf_size=70, n_neighbors=9, weights=uniform..............\n",
      "[CV 3/5; 73/88] END leaf_size=70, n_neighbors=9, weights=uniform;, score=0.581 total time=   3.0s\n",
      "[CV 4/5; 73/88] START leaf_size=70, n_neighbors=9, weights=uniform..............\n",
      "[CV 4/5; 73/88] END leaf_size=70, n_neighbors=9, weights=uniform;, score=0.584 total time=   2.8s\n",
      "[CV 5/5; 73/88] START leaf_size=70, n_neighbors=9, weights=uniform..............\n",
      "[CV 5/5; 73/88] END leaf_size=70, n_neighbors=9, weights=uniform;, score=0.580 total time=   2.8s\n",
      "[CV 1/5; 74/88] START leaf_size=70, n_neighbors=9, weights=distance.............\n",
      "[CV 1/5; 74/88] END leaf_size=70, n_neighbors=9, weights=distance;, score=0.575 total time=   2.7s\n",
      "[CV 2/5; 74/88] START leaf_size=70, n_neighbors=9, weights=distance.............\n",
      "[CV 2/5; 74/88] END leaf_size=70, n_neighbors=9, weights=distance;, score=0.572 total time=   2.6s\n",
      "[CV 3/5; 74/88] START leaf_size=70, n_neighbors=9, weights=distance.............\n",
      "[CV 3/5; 74/88] END leaf_size=70, n_neighbors=9, weights=distance;, score=0.581 total time=   2.8s\n",
      "[CV 4/5; 74/88] START leaf_size=70, n_neighbors=9, weights=distance.............\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 74/88] END leaf_size=70, n_neighbors=9, weights=distance;, score=0.584 total time=   2.8s\n",
      "[CV 5/5; 74/88] START leaf_size=70, n_neighbors=9, weights=distance.............\n",
      "[CV 5/5; 74/88] END leaf_size=70, n_neighbors=9, weights=distance;, score=0.580 total time=   2.6s\n",
      "[CV 1/5; 75/88] START leaf_size=70, n_neighbors=15, weights=uniform.............\n",
      "[CV 1/5; 75/88] END leaf_size=70, n_neighbors=15, weights=uniform;, score=0.569 total time=   2.8s\n",
      "[CV 2/5; 75/88] START leaf_size=70, n_neighbors=15, weights=uniform.............\n",
      "[CV 2/5; 75/88] END leaf_size=70, n_neighbors=15, weights=uniform;, score=0.563 total time=   2.8s\n",
      "[CV 3/5; 75/88] START leaf_size=70, n_neighbors=15, weights=uniform.............\n",
      "[CV 3/5; 75/88] END leaf_size=70, n_neighbors=15, weights=uniform;, score=0.578 total time=   2.8s\n",
      "[CV 4/5; 75/88] START leaf_size=70, n_neighbors=15, weights=uniform.............\n",
      "[CV 4/5; 75/88] END leaf_size=70, n_neighbors=15, weights=uniform;, score=0.568 total time=   2.7s\n",
      "[CV 5/5; 75/88] START leaf_size=70, n_neighbors=15, weights=uniform.............\n",
      "[CV 5/5; 75/88] END leaf_size=70, n_neighbors=15, weights=uniform;, score=0.567 total time=   2.8s\n",
      "[CV 1/5; 76/88] START leaf_size=70, n_neighbors=15, weights=distance............\n",
      "[CV 1/5; 76/88] END leaf_size=70, n_neighbors=15, weights=distance;, score=0.569 total time=   2.6s\n",
      "[CV 2/5; 76/88] START leaf_size=70, n_neighbors=15, weights=distance............\n",
      "[CV 2/5; 76/88] END leaf_size=70, n_neighbors=15, weights=distance;, score=0.563 total time=   2.5s\n",
      "[CV 3/5; 76/88] START leaf_size=70, n_neighbors=15, weights=distance............\n",
      "[CV 3/5; 76/88] END leaf_size=70, n_neighbors=15, weights=distance;, score=0.578 total time=   2.6s\n",
      "[CV 4/5; 76/88] START leaf_size=70, n_neighbors=15, weights=distance............\n",
      "[CV 4/5; 76/88] END leaf_size=70, n_neighbors=15, weights=distance;, score=0.568 total time=   2.6s\n",
      "[CV 5/5; 76/88] START leaf_size=70, n_neighbors=15, weights=distance............\n",
      "[CV 5/5; 76/88] END leaf_size=70, n_neighbors=15, weights=distance;, score=0.567 total time=   2.7s\n",
      "[CV 1/5; 77/88] START leaf_size=70, n_neighbors=19, weights=uniform.............\n",
      "[CV 1/5; 77/88] END leaf_size=70, n_neighbors=19, weights=uniform;, score=0.560 total time=   2.8s\n",
      "[CV 2/5; 77/88] START leaf_size=70, n_neighbors=19, weights=uniform.............\n",
      "[CV 2/5; 77/88] END leaf_size=70, n_neighbors=19, weights=uniform;, score=0.556 total time=   2.7s\n",
      "[CV 3/5; 77/88] START leaf_size=70, n_neighbors=19, weights=uniform.............\n",
      "[CV 3/5; 77/88] END leaf_size=70, n_neighbors=19, weights=uniform;, score=0.567 total time=   2.8s\n",
      "[CV 4/5; 77/88] START leaf_size=70, n_neighbors=19, weights=uniform.............\n",
      "[CV 4/5; 77/88] END leaf_size=70, n_neighbors=19, weights=uniform;, score=0.563 total time=   3.0s\n",
      "[CV 5/5; 77/88] START leaf_size=70, n_neighbors=19, weights=uniform.............\n",
      "[CV 5/5; 77/88] END leaf_size=70, n_neighbors=19, weights=uniform;, score=0.560 total time=   2.9s\n",
      "[CV 1/5; 78/88] START leaf_size=70, n_neighbors=19, weights=distance............\n",
      "[CV 1/5; 78/88] END leaf_size=70, n_neighbors=19, weights=distance;, score=0.560 total time=   2.6s\n",
      "[CV 2/5; 78/88] START leaf_size=70, n_neighbors=19, weights=distance............\n",
      "[CV 2/5; 78/88] END leaf_size=70, n_neighbors=19, weights=distance;, score=0.556 total time=   2.5s\n",
      "[CV 3/5; 78/88] START leaf_size=70, n_neighbors=19, weights=distance............\n",
      "[CV 3/5; 78/88] END leaf_size=70, n_neighbors=19, weights=distance;, score=0.567 total time=   2.7s\n",
      "[CV 4/5; 78/88] START leaf_size=70, n_neighbors=19, weights=distance............\n",
      "[CV 4/5; 78/88] END leaf_size=70, n_neighbors=19, weights=distance;, score=0.563 total time=   2.6s\n",
      "[CV 5/5; 78/88] START leaf_size=70, n_neighbors=19, weights=distance............\n",
      "[CV 5/5; 78/88] END leaf_size=70, n_neighbors=19, weights=distance;, score=0.560 total time=   2.7s\n",
      "[CV 1/5; 79/88] START leaf_size=70, n_neighbors=25, weights=uniform.............\n",
      "[CV 1/5; 79/88] END leaf_size=70, n_neighbors=25, weights=uniform;, score=0.556 total time=   2.8s\n",
      "[CV 2/5; 79/88] START leaf_size=70, n_neighbors=25, weights=uniform.............\n",
      "[CV 2/5; 79/88] END leaf_size=70, n_neighbors=25, weights=uniform;, score=0.550 total time=   2.6s\n",
      "[CV 3/5; 79/88] START leaf_size=70, n_neighbors=25, weights=uniform.............\n",
      "[CV 3/5; 79/88] END leaf_size=70, n_neighbors=25, weights=uniform;, score=0.563 total time=   2.8s\n",
      "[CV 4/5; 79/88] START leaf_size=70, n_neighbors=25, weights=uniform.............\n",
      "[CV 4/5; 79/88] END leaf_size=70, n_neighbors=25, weights=uniform;, score=0.560 total time=   2.8s\n",
      "[CV 5/5; 79/88] START leaf_size=70, n_neighbors=25, weights=uniform.............\n",
      "[CV 5/5; 79/88] END leaf_size=70, n_neighbors=25, weights=uniform;, score=0.557 total time=   2.8s\n",
      "[CV 1/5; 80/88] START leaf_size=70, n_neighbors=25, weights=distance............\n",
      "[CV 1/5; 80/88] END leaf_size=70, n_neighbors=25, weights=distance;, score=0.556 total time=   2.6s\n",
      "[CV 2/5; 80/88] START leaf_size=70, n_neighbors=25, weights=distance............\n",
      "[CV 2/5; 80/88] END leaf_size=70, n_neighbors=25, weights=distance;, score=0.550 total time=   2.5s\n",
      "[CV 3/5; 80/88] START leaf_size=70, n_neighbors=25, weights=distance............\n",
      "[CV 3/5; 80/88] END leaf_size=70, n_neighbors=25, weights=distance;, score=0.563 total time=   2.7s\n",
      "[CV 4/5; 80/88] START leaf_size=70, n_neighbors=25, weights=distance............\n",
      "[CV 4/5; 80/88] END leaf_size=70, n_neighbors=25, weights=distance;, score=0.560 total time=   2.6s\n",
      "[CV 5/5; 80/88] START leaf_size=70, n_neighbors=25, weights=distance............\n",
      "[CV 5/5; 80/88] END leaf_size=70, n_neighbors=25, weights=distance;, score=0.557 total time=   2.7s\n",
      "[CV 1/5; 81/88] START leaf_size=70, n_neighbors=35, weights=uniform.............\n",
      "[CV 1/5; 81/88] END leaf_size=70, n_neighbors=35, weights=uniform;, score=0.547 total time=   2.7s\n",
      "[CV 2/5; 81/88] START leaf_size=70, n_neighbors=35, weights=uniform.............\n",
      "[CV 2/5; 81/88] END leaf_size=70, n_neighbors=35, weights=uniform;, score=0.546 total time=   2.6s\n",
      "[CV 3/5; 81/88] START leaf_size=70, n_neighbors=35, weights=uniform.............\n",
      "[CV 3/5; 81/88] END leaf_size=70, n_neighbors=35, weights=uniform;, score=0.553 total time=   2.8s\n",
      "[CV 4/5; 81/88] START leaf_size=70, n_neighbors=35, weights=uniform.............\n",
      "[CV 4/5; 81/88] END leaf_size=70, n_neighbors=35, weights=uniform;, score=0.547 total time=   2.7s\n",
      "[CV 5/5; 81/88] START leaf_size=70, n_neighbors=35, weights=uniform.............\n",
      "[CV 5/5; 81/88] END leaf_size=70, n_neighbors=35, weights=uniform;, score=0.550 total time=   2.8s\n",
      "[CV 1/5; 82/88] START leaf_size=70, n_neighbors=35, weights=distance............\n",
      "[CV 1/5; 82/88] END leaf_size=70, n_neighbors=35, weights=distance;, score=0.547 total time=   2.6s\n",
      "[CV 2/5; 82/88] START leaf_size=70, n_neighbors=35, weights=distance............\n",
      "[CV 2/5; 82/88] END leaf_size=70, n_neighbors=35, weights=distance;, score=0.546 total time=   2.7s\n",
      "[CV 3/5; 82/88] START leaf_size=70, n_neighbors=35, weights=distance............\n",
      "[CV 3/5; 82/88] END leaf_size=70, n_neighbors=35, weights=distance;, score=0.554 total time=   2.8s\n",
      "[CV 4/5; 82/88] START leaf_size=70, n_neighbors=35, weights=distance............\n",
      "[CV 4/5; 82/88] END leaf_size=70, n_neighbors=35, weights=distance;, score=0.547 total time=   2.7s\n",
      "[CV 5/5; 82/88] START leaf_size=70, n_neighbors=35, weights=distance............\n",
      "[CV 5/5; 82/88] END leaf_size=70, n_neighbors=35, weights=distance;, score=0.550 total time=   2.8s\n",
      "[CV 1/5; 83/88] START leaf_size=70, n_neighbors=55, weights=uniform.............\n",
      "[CV 1/5; 83/88] END leaf_size=70, n_neighbors=55, weights=uniform;, score=0.533 total time=   2.9s\n",
      "[CV 2/5; 83/88] START leaf_size=70, n_neighbors=55, weights=uniform.............\n",
      "[CV 2/5; 83/88] END leaf_size=70, n_neighbors=55, weights=uniform;, score=0.535 total time=   2.9s\n",
      "[CV 3/5; 83/88] START leaf_size=70, n_neighbors=55, weights=uniform.............\n",
      "[CV 3/5; 83/88] END leaf_size=70, n_neighbors=55, weights=uniform;, score=0.540 total time=   2.9s\n",
      "[CV 4/5; 83/88] START leaf_size=70, n_neighbors=55, weights=uniform.............\n",
      "[CV 4/5; 83/88] END leaf_size=70, n_neighbors=55, weights=uniform;, score=0.538 total time=   2.8s\n",
      "[CV 5/5; 83/88] START leaf_size=70, n_neighbors=55, weights=uniform.............\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 83/88] END leaf_size=70, n_neighbors=55, weights=uniform;, score=0.532 total time=   2.8s\n",
      "[CV 1/5; 84/88] START leaf_size=70, n_neighbors=55, weights=distance............\n",
      "[CV 1/5; 84/88] END leaf_size=70, n_neighbors=55, weights=distance;, score=0.533 total time=   2.7s\n",
      "[CV 2/5; 84/88] START leaf_size=70, n_neighbors=55, weights=distance............\n",
      "[CV 2/5; 84/88] END leaf_size=70, n_neighbors=55, weights=distance;, score=0.535 total time=   2.5s\n",
      "[CV 3/5; 84/88] START leaf_size=70, n_neighbors=55, weights=distance............\n",
      "[CV 3/5; 84/88] END leaf_size=70, n_neighbors=55, weights=distance;, score=0.540 total time=   2.7s\n",
      "[CV 4/5; 84/88] START leaf_size=70, n_neighbors=55, weights=distance............\n",
      "[CV 4/5; 84/88] END leaf_size=70, n_neighbors=55, weights=distance;, score=0.538 total time=   2.7s\n",
      "[CV 5/5; 84/88] START leaf_size=70, n_neighbors=55, weights=distance............\n",
      "[CV 5/5; 84/88] END leaf_size=70, n_neighbors=55, weights=distance;, score=0.532 total time=   2.8s\n",
      "[CV 1/5; 85/88] START leaf_size=70, n_neighbors=75, weights=uniform.............\n",
      "[CV 1/5; 85/88] END leaf_size=70, n_neighbors=75, weights=uniform;, score=0.528 total time=   2.7s\n",
      "[CV 2/5; 85/88] START leaf_size=70, n_neighbors=75, weights=uniform.............\n",
      "[CV 2/5; 85/88] END leaf_size=70, n_neighbors=75, weights=uniform;, score=0.525 total time=   2.7s\n",
      "[CV 3/5; 85/88] START leaf_size=70, n_neighbors=75, weights=uniform.............\n",
      "[CV 3/5; 85/88] END leaf_size=70, n_neighbors=75, weights=uniform;, score=0.529 total time=   2.7s\n",
      "[CV 4/5; 85/88] START leaf_size=70, n_neighbors=75, weights=uniform.............\n",
      "[CV 4/5; 85/88] END leaf_size=70, n_neighbors=75, weights=uniform;, score=0.533 total time=   2.7s\n",
      "[CV 5/5; 85/88] START leaf_size=70, n_neighbors=75, weights=uniform.............\n",
      "[CV 5/5; 85/88] END leaf_size=70, n_neighbors=75, weights=uniform;, score=0.524 total time=   2.7s\n",
      "[CV 1/5; 86/88] START leaf_size=70, n_neighbors=75, weights=distance............\n",
      "[CV 1/5; 86/88] END leaf_size=70, n_neighbors=75, weights=distance;, score=0.528 total time=   2.6s\n",
      "[CV 2/5; 86/88] START leaf_size=70, n_neighbors=75, weights=distance............\n",
      "[CV 2/5; 86/88] END leaf_size=70, n_neighbors=75, weights=distance;, score=0.525 total time=   2.5s\n",
      "[CV 3/5; 86/88] START leaf_size=70, n_neighbors=75, weights=distance............\n",
      "[CV 3/5; 86/88] END leaf_size=70, n_neighbors=75, weights=distance;, score=0.529 total time=   2.6s\n",
      "[CV 4/5; 86/88] START leaf_size=70, n_neighbors=75, weights=distance............\n",
      "[CV 4/5; 86/88] END leaf_size=70, n_neighbors=75, weights=distance;, score=0.533 total time=   2.7s\n",
      "[CV 5/5; 86/88] START leaf_size=70, n_neighbors=75, weights=distance............\n",
      "[CV 5/5; 86/88] END leaf_size=70, n_neighbors=75, weights=distance;, score=0.525 total time=   2.9s\n",
      "[CV 1/5; 87/88] START leaf_size=70, n_neighbors=99, weights=uniform.............\n",
      "[CV 1/5; 87/88] END leaf_size=70, n_neighbors=99, weights=uniform;, score=0.523 total time=   3.2s\n",
      "[CV 2/5; 87/88] START leaf_size=70, n_neighbors=99, weights=uniform.............\n",
      "[CV 2/5; 87/88] END leaf_size=70, n_neighbors=99, weights=uniform;, score=0.523 total time=   2.9s\n",
      "[CV 3/5; 87/88] START leaf_size=70, n_neighbors=99, weights=uniform.............\n",
      "[CV 3/5; 87/88] END leaf_size=70, n_neighbors=99, weights=uniform;, score=0.523 total time=   3.0s\n",
      "[CV 4/5; 87/88] START leaf_size=70, n_neighbors=99, weights=uniform.............\n",
      "[CV 4/5; 87/88] END leaf_size=70, n_neighbors=99, weights=uniform;, score=0.526 total time=   3.2s\n",
      "[CV 5/5; 87/88] START leaf_size=70, n_neighbors=99, weights=uniform.............\n",
      "[CV 5/5; 87/88] END leaf_size=70, n_neighbors=99, weights=uniform;, score=0.520 total time=   2.9s\n",
      "[CV 1/5; 88/88] START leaf_size=70, n_neighbors=99, weights=distance............\n",
      "[CV 1/5; 88/88] END leaf_size=70, n_neighbors=99, weights=distance;, score=0.524 total time=   2.9s\n",
      "[CV 2/5; 88/88] START leaf_size=70, n_neighbors=99, weights=distance............\n",
      "[CV 2/5; 88/88] END leaf_size=70, n_neighbors=99, weights=distance;, score=0.523 total time=   2.6s\n",
      "[CV 3/5; 88/88] START leaf_size=70, n_neighbors=99, weights=distance............\n",
      "[CV 3/5; 88/88] END leaf_size=70, n_neighbors=99, weights=distance;, score=0.523 total time=   2.9s\n",
      "[CV 4/5; 88/88] START leaf_size=70, n_neighbors=99, weights=distance............\n",
      "[CV 4/5; 88/88] END leaf_size=70, n_neighbors=99, weights=distance;, score=0.527 total time=   2.7s\n",
      "[CV 5/5; 88/88] START leaf_size=70, n_neighbors=99, weights=distance............\n",
      "[CV 5/5; 88/88] END leaf_size=70, n_neighbors=99, weights=distance;, score=0.521 total time=   2.8s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=KNeighborsClassifier(),\n",
       "             param_grid={'leaf_size': [20, 30, 50, 70],\n",
       "                         'n_neighbors': [3, 5, 7, 9, 15, 19, 25, 35, 55, 75,\n",
       "                                         99],\n",
       "                         'weights': ['uniform', 'distance']},\n",
       "             scoring='balanced_accuracy', verbose=10)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "parameters = { 'n_neighbors': [3, 5, 7, 9, 15, 19, 25, 35, 55,75, 99],\n",
    "                'leaf_size': [20, 30, 50, 70],\n",
    "              'weights': ['uniform', 'distance']\n",
    "                 }\n",
    "\n",
    "model = KNeighborsClassifier()\n",
    "\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=parameters, verbose=10, scoring=\"balanced_accuracy\")\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "398b4b62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'leaf_size': 20, 'n_neighbors': 5, 'weights': 'distance'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f64680c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7340782122905027\n",
      "Balanced Accuracy:  0.5893081134700795\n",
      "Precision:  0.7822628167354154\n",
      "Recall:  0.8888516906595246\n",
      "F1:  0.8321579689703809\n"
     ]
    }
   ],
   "source": [
    "model = KNeighborsClassifier(leaf_size=20, n_neighbors=5, weights='distance')\n",
    "model.fit(X_train, y_train)\n",
    "predicted = model.predict(X_test)\n",
    "evaluate(predicted, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "234e2228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "[CV 1/5; 1/48] START max_iter=50, penalty=l1, tol=0.001.........................\n",
      "[CV 1/5; 1/48] END max_iter=50, penalty=l1, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 2/5; 1/48] START max_iter=50, penalty=l1, tol=0.001.........................\n",
      "[CV 2/5; 1/48] END max_iter=50, penalty=l1, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 3/5; 1/48] START max_iter=50, penalty=l1, tol=0.001.........................\n",
      "[CV 3/5; 1/48] END max_iter=50, penalty=l1, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 4/5; 1/48] START max_iter=50, penalty=l1, tol=0.001.........................\n",
      "[CV 4/5; 1/48] END max_iter=50, penalty=l1, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 5/5; 1/48] START max_iter=50, penalty=l1, tol=0.001.........................\n",
      "[CV 5/5; 1/48] END max_iter=50, penalty=l1, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 1/5; 2/48] START max_iter=50, penalty=l1, tol=0.0001........................\n",
      "[CV 1/5; 2/48] END max_iter=50, penalty=l1, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 2/5; 2/48] START max_iter=50, penalty=l1, tol=0.0001........................\n",
      "[CV 2/5; 2/48] END max_iter=50, penalty=l1, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 3/5; 2/48] START max_iter=50, penalty=l1, tol=0.0001........................\n",
      "[CV 3/5; 2/48] END max_iter=50, penalty=l1, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 4/5; 2/48] START max_iter=50, penalty=l1, tol=0.0001........................\n",
      "[CV 4/5; 2/48] END max_iter=50, penalty=l1, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 5/5; 2/48] START max_iter=50, penalty=l1, tol=0.0001........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 2/48] END max_iter=50, penalty=l1, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 1/5; 3/48] START max_iter=50, penalty=l1, tol=1e-05.........................\n",
      "[CV 1/5; 3/48] END max_iter=50, penalty=l1, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 2/5; 3/48] START max_iter=50, penalty=l1, tol=1e-05.........................\n",
      "[CV 2/5; 3/48] END max_iter=50, penalty=l1, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 3/5; 3/48] START max_iter=50, penalty=l1, tol=1e-05.........................\n",
      "[CV 3/5; 3/48] END max_iter=50, penalty=l1, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 4/5; 3/48] START max_iter=50, penalty=l1, tol=1e-05.........................\n",
      "[CV 4/5; 3/48] END max_iter=50, penalty=l1, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 5/5; 3/48] START max_iter=50, penalty=l1, tol=1e-05.........................\n",
      "[CV 5/5; 3/48] END max_iter=50, penalty=l1, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 1/5; 4/48] START max_iter=50, penalty=l2, tol=0.001.........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 4/48] END max_iter=50, penalty=l2, tol=0.001;, score=0.705 total time=   0.5s\n",
      "[CV 2/5; 4/48] START max_iter=50, penalty=l2, tol=0.001.........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 4/48] END max_iter=50, penalty=l2, tol=0.001;, score=0.727 total time=   0.3s\n",
      "[CV 3/5; 4/48] START max_iter=50, penalty=l2, tol=0.001.........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 4/48] END max_iter=50, penalty=l2, tol=0.001;, score=0.719 total time=   0.3s\n",
      "[CV 4/5; 4/48] START max_iter=50, penalty=l2, tol=0.001.........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 4/48] END max_iter=50, penalty=l2, tol=0.001;, score=0.713 total time=   0.3s\n",
      "[CV 5/5; 4/48] START max_iter=50, penalty=l2, tol=0.001.........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 4/48] END max_iter=50, penalty=l2, tol=0.001;, score=0.721 total time=   0.3s\n",
      "[CV 1/5; 5/48] START max_iter=50, penalty=l2, tol=0.0001........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 5/48] END max_iter=50, penalty=l2, tol=0.0001;, score=0.705 total time=   0.3s\n",
      "[CV 2/5; 5/48] START max_iter=50, penalty=l2, tol=0.0001........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 5/48] END max_iter=50, penalty=l2, tol=0.0001;, score=0.727 total time=   0.3s\n",
      "[CV 3/5; 5/48] START max_iter=50, penalty=l2, tol=0.0001........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 5/48] END max_iter=50, penalty=l2, tol=0.0001;, score=0.719 total time=   0.3s\n",
      "[CV 4/5; 5/48] START max_iter=50, penalty=l2, tol=0.0001........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 5/48] END max_iter=50, penalty=l2, tol=0.0001;, score=0.713 total time=   0.3s\n",
      "[CV 5/5; 5/48] START max_iter=50, penalty=l2, tol=0.0001........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 5/48] END max_iter=50, penalty=l2, tol=0.0001;, score=0.721 total time=   0.3s\n",
      "[CV 1/5; 6/48] START max_iter=50, penalty=l2, tol=1e-05.........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 6/48] END max_iter=50, penalty=l2, tol=1e-05;, score=0.705 total time=   0.3s\n",
      "[CV 2/5; 6/48] START max_iter=50, penalty=l2, tol=1e-05.........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 6/48] END max_iter=50, penalty=l2, tol=1e-05;, score=0.727 total time=   0.3s\n",
      "[CV 3/5; 6/48] START max_iter=50, penalty=l2, tol=1e-05.........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 6/48] END max_iter=50, penalty=l2, tol=1e-05;, score=0.719 total time=   0.3s\n",
      "[CV 4/5; 6/48] START max_iter=50, penalty=l2, tol=1e-05.........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 6/48] END max_iter=50, penalty=l2, tol=1e-05;, score=0.713 total time=   0.3s\n",
      "[CV 5/5; 6/48] START max_iter=50, penalty=l2, tol=1e-05.........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 6/48] END max_iter=50, penalty=l2, tol=1e-05;, score=0.721 total time=   0.3s\n",
      "[CV 1/5; 7/48] START max_iter=50, penalty=elasticnet, tol=0.001.................\n",
      "[CV 1/5; 7/48] END max_iter=50, penalty=elasticnet, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 2/5; 7/48] START max_iter=50, penalty=elasticnet, tol=0.001.................\n",
      "[CV 2/5; 7/48] END max_iter=50, penalty=elasticnet, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 3/5; 7/48] START max_iter=50, penalty=elasticnet, tol=0.001.................\n",
      "[CV 3/5; 7/48] END max_iter=50, penalty=elasticnet, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 4/5; 7/48] START max_iter=50, penalty=elasticnet, tol=0.001.................\n",
      "[CV 4/5; 7/48] END max_iter=50, penalty=elasticnet, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 5/5; 7/48] START max_iter=50, penalty=elasticnet, tol=0.001.................\n",
      "[CV 5/5; 7/48] END max_iter=50, penalty=elasticnet, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 1/5; 8/48] START max_iter=50, penalty=elasticnet, tol=0.0001................\n",
      "[CV 1/5; 8/48] END max_iter=50, penalty=elasticnet, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 2/5; 8/48] START max_iter=50, penalty=elasticnet, tol=0.0001................\n",
      "[CV 2/5; 8/48] END max_iter=50, penalty=elasticnet, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 3/5; 8/48] START max_iter=50, penalty=elasticnet, tol=0.0001................\n",
      "[CV 3/5; 8/48] END max_iter=50, penalty=elasticnet, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 4/5; 8/48] START max_iter=50, penalty=elasticnet, tol=0.0001................\n",
      "[CV 4/5; 8/48] END max_iter=50, penalty=elasticnet, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 5/5; 8/48] START max_iter=50, penalty=elasticnet, tol=0.0001................\n",
      "[CV 5/5; 8/48] END max_iter=50, penalty=elasticnet, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 1/5; 9/48] START max_iter=50, penalty=elasticnet, tol=1e-05.................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 9/48] END max_iter=50, penalty=elasticnet, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 2/5; 9/48] START max_iter=50, penalty=elasticnet, tol=1e-05.................\n",
      "[CV 2/5; 9/48] END max_iter=50, penalty=elasticnet, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 3/5; 9/48] START max_iter=50, penalty=elasticnet, tol=1e-05.................\n",
      "[CV 3/5; 9/48] END max_iter=50, penalty=elasticnet, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 4/5; 9/48] START max_iter=50, penalty=elasticnet, tol=1e-05.................\n",
      "[CV 4/5; 9/48] END max_iter=50, penalty=elasticnet, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 5/5; 9/48] START max_iter=50, penalty=elasticnet, tol=1e-05.................\n",
      "[CV 5/5; 9/48] END max_iter=50, penalty=elasticnet, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 1/5; 10/48] START max_iter=50, penalty=none, tol=0.001......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 10/48] END max_iter=50, penalty=none, tol=0.001;, score=0.707 total time=   0.3s\n",
      "[CV 2/5; 10/48] START max_iter=50, penalty=none, tol=0.001......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 10/48] END max_iter=50, penalty=none, tol=0.001;, score=0.727 total time=   0.3s\n",
      "[CV 3/5; 10/48] START max_iter=50, penalty=none, tol=0.001......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 10/48] END max_iter=50, penalty=none, tol=0.001;, score=0.718 total time=   0.3s\n",
      "[CV 4/5; 10/48] START max_iter=50, penalty=none, tol=0.001......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 10/48] END max_iter=50, penalty=none, tol=0.001;, score=0.713 total time=   0.3s\n",
      "[CV 5/5; 10/48] START max_iter=50, penalty=none, tol=0.001......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 10/48] END max_iter=50, penalty=none, tol=0.001;, score=0.720 total time=   0.3s\n",
      "[CV 1/5; 11/48] START max_iter=50, penalty=none, tol=0.0001.....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 11/48] END max_iter=50, penalty=none, tol=0.0001;, score=0.707 total time=   0.3s\n",
      "[CV 2/5; 11/48] START max_iter=50, penalty=none, tol=0.0001.....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 11/48] END max_iter=50, penalty=none, tol=0.0001;, score=0.727 total time=   0.3s\n",
      "[CV 3/5; 11/48] START max_iter=50, penalty=none, tol=0.0001.....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 11/48] END max_iter=50, penalty=none, tol=0.0001;, score=0.718 total time=   0.3s\n",
      "[CV 4/5; 11/48] START max_iter=50, penalty=none, tol=0.0001.....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 11/48] END max_iter=50, penalty=none, tol=0.0001;, score=0.713 total time=   0.2s\n",
      "[CV 5/5; 11/48] START max_iter=50, penalty=none, tol=0.0001.....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 11/48] END max_iter=50, penalty=none, tol=0.0001;, score=0.720 total time=   0.3s\n",
      "[CV 1/5; 12/48] START max_iter=50, penalty=none, tol=1e-05......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 12/48] END max_iter=50, penalty=none, tol=1e-05;, score=0.707 total time=   0.3s\n",
      "[CV 2/5; 12/48] START max_iter=50, penalty=none, tol=1e-05......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 12/48] END max_iter=50, penalty=none, tol=1e-05;, score=0.727 total time=   0.3s\n",
      "[CV 3/5; 12/48] START max_iter=50, penalty=none, tol=1e-05......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 12/48] END max_iter=50, penalty=none, tol=1e-05;, score=0.718 total time=   0.4s\n",
      "[CV 4/5; 12/48] START max_iter=50, penalty=none, tol=1e-05......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 12/48] END max_iter=50, penalty=none, tol=1e-05;, score=0.713 total time=   0.3s\n",
      "[CV 5/5; 12/48] START max_iter=50, penalty=none, tol=1e-05......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 12/48] END max_iter=50, penalty=none, tol=1e-05;, score=0.720 total time=   0.3s\n",
      "[CV 1/5; 13/48] START max_iter=100, penalty=l1, tol=0.001.......................\n",
      "[CV 1/5; 13/48] END max_iter=100, penalty=l1, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 2/5; 13/48] START max_iter=100, penalty=l1, tol=0.001.......................\n",
      "[CV 2/5; 13/48] END max_iter=100, penalty=l1, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 3/5; 13/48] START max_iter=100, penalty=l1, tol=0.001.......................\n",
      "[CV 3/5; 13/48] END max_iter=100, penalty=l1, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 4/5; 13/48] START max_iter=100, penalty=l1, tol=0.001.......................\n",
      "[CV 4/5; 13/48] END max_iter=100, penalty=l1, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 5/5; 13/48] START max_iter=100, penalty=l1, tol=0.001.......................\n",
      "[CV 5/5; 13/48] END max_iter=100, penalty=l1, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 1/5; 14/48] START max_iter=100, penalty=l1, tol=0.0001......................\n",
      "[CV 1/5; 14/48] END max_iter=100, penalty=l1, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 2/5; 14/48] START max_iter=100, penalty=l1, tol=0.0001......................\n",
      "[CV 2/5; 14/48] END max_iter=100, penalty=l1, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 3/5; 14/48] START max_iter=100, penalty=l1, tol=0.0001......................\n",
      "[CV 3/5; 14/48] END max_iter=100, penalty=l1, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 4/5; 14/48] START max_iter=100, penalty=l1, tol=0.0001......................\n",
      "[CV 4/5; 14/48] END max_iter=100, penalty=l1, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 5/5; 14/48] START max_iter=100, penalty=l1, tol=0.0001......................\n",
      "[CV 5/5; 14/48] END max_iter=100, penalty=l1, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 1/5; 15/48] START max_iter=100, penalty=l1, tol=1e-05......................."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV 1/5; 15/48] END max_iter=100, penalty=l1, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 2/5; 15/48] START max_iter=100, penalty=l1, tol=1e-05.......................\n",
      "[CV 2/5; 15/48] END max_iter=100, penalty=l1, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 3/5; 15/48] START max_iter=100, penalty=l1, tol=1e-05.......................\n",
      "[CV 3/5; 15/48] END max_iter=100, penalty=l1, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 4/5; 15/48] START max_iter=100, penalty=l1, tol=1e-05.......................\n",
      "[CV 4/5; 15/48] END max_iter=100, penalty=l1, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 5/5; 15/48] START max_iter=100, penalty=l1, tol=1e-05.......................\n",
      "[CV 5/5; 15/48] END max_iter=100, penalty=l1, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 1/5; 16/48] START max_iter=100, penalty=l2, tol=0.001.......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 16/48] END max_iter=100, penalty=l2, tol=0.001;, score=0.706 total time=   0.6s\n",
      "[CV 2/5; 16/48] START max_iter=100, penalty=l2, tol=0.001.......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 16/48] END max_iter=100, penalty=l2, tol=0.001;, score=0.726 total time=   0.7s\n",
      "[CV 3/5; 16/48] START max_iter=100, penalty=l2, tol=0.001.......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 16/48] END max_iter=100, penalty=l2, tol=0.001;, score=0.717 total time=   0.6s\n",
      "[CV 4/5; 16/48] START max_iter=100, penalty=l2, tol=0.001.......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 16/48] END max_iter=100, penalty=l2, tol=0.001;, score=0.712 total time=   0.6s\n",
      "[CV 5/5; 16/48] START max_iter=100, penalty=l2, tol=0.001.......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 16/48] END max_iter=100, penalty=l2, tol=0.001;, score=0.721 total time=   0.6s\n",
      "[CV 1/5; 17/48] START max_iter=100, penalty=l2, tol=0.0001......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 17/48] END max_iter=100, penalty=l2, tol=0.0001;, score=0.706 total time=   0.7s\n",
      "[CV 2/5; 17/48] START max_iter=100, penalty=l2, tol=0.0001......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 17/48] END max_iter=100, penalty=l2, tol=0.0001;, score=0.726 total time=   0.6s\n",
      "[CV 3/5; 17/48] START max_iter=100, penalty=l2, tol=0.0001......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 17/48] END max_iter=100, penalty=l2, tol=0.0001;, score=0.717 total time=   0.5s\n",
      "[CV 4/5; 17/48] START max_iter=100, penalty=l2, tol=0.0001......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 17/48] END max_iter=100, penalty=l2, tol=0.0001;, score=0.712 total time=   0.6s\n",
      "[CV 5/5; 17/48] START max_iter=100, penalty=l2, tol=0.0001......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 17/48] END max_iter=100, penalty=l2, tol=0.0001;, score=0.721 total time=   0.7s\n",
      "[CV 1/5; 18/48] START max_iter=100, penalty=l2, tol=1e-05.......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 18/48] END max_iter=100, penalty=l2, tol=1e-05;, score=0.706 total time=   0.6s\n",
      "[CV 2/5; 18/48] START max_iter=100, penalty=l2, tol=1e-05.......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 18/48] END max_iter=100, penalty=l2, tol=1e-05;, score=0.726 total time=   0.7s\n",
      "[CV 3/5; 18/48] START max_iter=100, penalty=l2, tol=1e-05.......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 18/48] END max_iter=100, penalty=l2, tol=1e-05;, score=0.717 total time=   0.6s\n",
      "[CV 4/5; 18/48] START max_iter=100, penalty=l2, tol=1e-05.......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 18/48] END max_iter=100, penalty=l2, tol=1e-05;, score=0.712 total time=   0.6s\n",
      "[CV 5/5; 18/48] START max_iter=100, penalty=l2, tol=1e-05.......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 18/48] END max_iter=100, penalty=l2, tol=1e-05;, score=0.721 total time=   0.6s\n",
      "[CV 1/5; 19/48] START max_iter=100, penalty=elasticnet, tol=0.001...............\n",
      "[CV 1/5; 19/48] END max_iter=100, penalty=elasticnet, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 2/5; 19/48] START max_iter=100, penalty=elasticnet, tol=0.001...............\n",
      "[CV 2/5; 19/48] END max_iter=100, penalty=elasticnet, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 3/5; 19/48] START max_iter=100, penalty=elasticnet, tol=0.001...............\n",
      "[CV 3/5; 19/48] END max_iter=100, penalty=elasticnet, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 4/5; 19/48] START max_iter=100, penalty=elasticnet, tol=0.001...............\n",
      "[CV 4/5; 19/48] END max_iter=100, penalty=elasticnet, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 5/5; 19/48] START max_iter=100, penalty=elasticnet, tol=0.001...............\n",
      "[CV 5/5; 19/48] END max_iter=100, penalty=elasticnet, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 1/5; 20/48] START max_iter=100, penalty=elasticnet, tol=0.0001..............\n",
      "[CV 1/5; 20/48] END max_iter=100, penalty=elasticnet, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 2/5; 20/48] START max_iter=100, penalty=elasticnet, tol=0.0001..............\n",
      "[CV 2/5; 20/48] END max_iter=100, penalty=elasticnet, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 3/5; 20/48] START max_iter=100, penalty=elasticnet, tol=0.0001..............\n",
      "[CV 3/5; 20/48] END max_iter=100, penalty=elasticnet, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 4/5; 20/48] START max_iter=100, penalty=elasticnet, tol=0.0001..............\n",
      "[CV 4/5; 20/48] END max_iter=100, penalty=elasticnet, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 5/5; 20/48] START max_iter=100, penalty=elasticnet, tol=0.0001..............\n",
      "[CV 5/5; 20/48] END max_iter=100, penalty=elasticnet, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 1/5; 21/48] START max_iter=100, penalty=elasticnet, tol=1e-05...............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 21/48] END max_iter=100, penalty=elasticnet, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 2/5; 21/48] START max_iter=100, penalty=elasticnet, tol=1e-05...............\n",
      "[CV 2/5; 21/48] END max_iter=100, penalty=elasticnet, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 3/5; 21/48] START max_iter=100, penalty=elasticnet, tol=1e-05...............\n",
      "[CV 3/5; 21/48] END max_iter=100, penalty=elasticnet, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 4/5; 21/48] START max_iter=100, penalty=elasticnet, tol=1e-05...............\n",
      "[CV 4/5; 21/48] END max_iter=100, penalty=elasticnet, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 5/5; 21/48] START max_iter=100, penalty=elasticnet, tol=1e-05...............\n",
      "[CV 5/5; 21/48] END max_iter=100, penalty=elasticnet, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 1/5; 22/48] START max_iter=100, penalty=none, tol=0.001.....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 22/48] END max_iter=100, penalty=none, tol=0.001;, score=0.706 total time=   0.6s\n",
      "[CV 2/5; 22/48] START max_iter=100, penalty=none, tol=0.001.....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 22/48] END max_iter=100, penalty=none, tol=0.001;, score=0.725 total time=   0.7s\n",
      "[CV 3/5; 22/48] START max_iter=100, penalty=none, tol=0.001.....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 22/48] END max_iter=100, penalty=none, tol=0.001;, score=0.719 total time=   0.7s\n",
      "[CV 4/5; 22/48] START max_iter=100, penalty=none, tol=0.001.....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 22/48] END max_iter=100, penalty=none, tol=0.001;, score=0.712 total time=   0.6s\n",
      "[CV 5/5; 22/48] START max_iter=100, penalty=none, tol=0.001.....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 22/48] END max_iter=100, penalty=none, tol=0.001;, score=0.721 total time=   0.7s\n",
      "[CV 1/5; 23/48] START max_iter=100, penalty=none, tol=0.0001....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 23/48] END max_iter=100, penalty=none, tol=0.0001;, score=0.706 total time=   0.6s\n",
      "[CV 2/5; 23/48] START max_iter=100, penalty=none, tol=0.0001....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 23/48] END max_iter=100, penalty=none, tol=0.0001;, score=0.725 total time=   0.7s\n",
      "[CV 3/5; 23/48] START max_iter=100, penalty=none, tol=0.0001....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 23/48] END max_iter=100, penalty=none, tol=0.0001;, score=0.719 total time=   0.7s\n",
      "[CV 4/5; 23/48] START max_iter=100, penalty=none, tol=0.0001....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 23/48] END max_iter=100, penalty=none, tol=0.0001;, score=0.712 total time=   0.7s\n",
      "[CV 5/5; 23/48] START max_iter=100, penalty=none, tol=0.0001....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 23/48] END max_iter=100, penalty=none, tol=0.0001;, score=0.721 total time=   0.6s\n",
      "[CV 1/5; 24/48] START max_iter=100, penalty=none, tol=1e-05.....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 24/48] END max_iter=100, penalty=none, tol=1e-05;, score=0.706 total time=   0.7s\n",
      "[CV 2/5; 24/48] START max_iter=100, penalty=none, tol=1e-05.....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 24/48] END max_iter=100, penalty=none, tol=1e-05;, score=0.725 total time=   0.6s\n",
      "[CV 3/5; 24/48] START max_iter=100, penalty=none, tol=1e-05.....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 24/48] END max_iter=100, penalty=none, tol=1e-05;, score=0.719 total time=   0.7s\n",
      "[CV 4/5; 24/48] START max_iter=100, penalty=none, tol=1e-05.....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 24/48] END max_iter=100, penalty=none, tol=1e-05;, score=0.712 total time=   0.6s\n",
      "[CV 5/5; 24/48] START max_iter=100, penalty=none, tol=1e-05.....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 24/48] END max_iter=100, penalty=none, tol=1e-05;, score=0.721 total time=   0.6s\n",
      "[CV 1/5; 25/48] START max_iter=150, penalty=l1, tol=0.001.......................\n",
      "[CV 1/5; 25/48] END max_iter=150, penalty=l1, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 2/5; 25/48] START max_iter=150, penalty=l1, tol=0.001.......................\n",
      "[CV 2/5; 25/48] END max_iter=150, penalty=l1, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 3/5; 25/48] START max_iter=150, penalty=l1, tol=0.001.......................\n",
      "[CV 3/5; 25/48] END max_iter=150, penalty=l1, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 4/5; 25/48] START max_iter=150, penalty=l1, tol=0.001.......................\n",
      "[CV 4/5; 25/48] END max_iter=150, penalty=l1, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 5/5; 25/48] START max_iter=150, penalty=l1, tol=0.001.......................\n",
      "[CV 5/5; 25/48] END max_iter=150, penalty=l1, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 1/5; 26/48] START max_iter=150, penalty=l1, tol=0.0001......................\n",
      "[CV 1/5; 26/48] END max_iter=150, penalty=l1, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 2/5; 26/48] START max_iter=150, penalty=l1, tol=0.0001......................\n",
      "[CV 2/5; 26/48] END max_iter=150, penalty=l1, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 3/5; 26/48] START max_iter=150, penalty=l1, tol=0.0001......................\n",
      "[CV 3/5; 26/48] END max_iter=150, penalty=l1, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 4/5; 26/48] START max_iter=150, penalty=l1, tol=0.0001......................\n",
      "[CV 4/5; 26/48] END max_iter=150, penalty=l1, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 5/5; 26/48] START max_iter=150, penalty=l1, tol=0.0001......................\n",
      "[CV 5/5; 26/48] END max_iter=150, penalty=l1, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 1/5; 27/48] START max_iter=150, penalty=l1, tol=1e-05.......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 27/48] END max_iter=150, penalty=l1, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 2/5; 27/48] START max_iter=150, penalty=l1, tol=1e-05.......................\n",
      "[CV 2/5; 27/48] END max_iter=150, penalty=l1, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 3/5; 27/48] START max_iter=150, penalty=l1, tol=1e-05.......................\n",
      "[CV 3/5; 27/48] END max_iter=150, penalty=l1, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 4/5; 27/48] START max_iter=150, penalty=l1, tol=1e-05.......................\n",
      "[CV 4/5; 27/48] END max_iter=150, penalty=l1, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 5/5; 27/48] START max_iter=150, penalty=l1, tol=1e-05.......................\n",
      "[CV 5/5; 27/48] END max_iter=150, penalty=l1, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 1/5; 28/48] START max_iter=150, penalty=l2, tol=0.001.......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 28/48] END max_iter=150, penalty=l2, tol=0.001;, score=0.705 total time=   0.9s\n",
      "[CV 2/5; 28/48] START max_iter=150, penalty=l2, tol=0.001.......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 28/48] END max_iter=150, penalty=l2, tol=0.001;, score=0.726 total time=   1.0s\n",
      "[CV 3/5; 28/48] START max_iter=150, penalty=l2, tol=0.001.......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 28/48] END max_iter=150, penalty=l2, tol=0.001;, score=0.718 total time=   0.9s\n",
      "[CV 4/5; 28/48] START max_iter=150, penalty=l2, tol=0.001.......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 28/48] END max_iter=150, penalty=l2, tol=0.001;, score=0.712 total time=   0.9s\n",
      "[CV 5/5; 28/48] START max_iter=150, penalty=l2, tol=0.001.......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 28/48] END max_iter=150, penalty=l2, tol=0.001;, score=0.722 total time=   1.1s\n",
      "[CV 1/5; 29/48] START max_iter=150, penalty=l2, tol=0.0001......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 29/48] END max_iter=150, penalty=l2, tol=0.0001;, score=0.705 total time=   0.9s\n",
      "[CV 2/5; 29/48] START max_iter=150, penalty=l2, tol=0.0001......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 29/48] END max_iter=150, penalty=l2, tol=0.0001;, score=0.726 total time=   0.8s\n",
      "[CV 3/5; 29/48] START max_iter=150, penalty=l2, tol=0.0001......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 29/48] END max_iter=150, penalty=l2, tol=0.0001;, score=0.718 total time=   0.9s\n",
      "[CV 4/5; 29/48] START max_iter=150, penalty=l2, tol=0.0001......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 29/48] END max_iter=150, penalty=l2, tol=0.0001;, score=0.712 total time=   0.9s\n",
      "[CV 5/5; 29/48] START max_iter=150, penalty=l2, tol=0.0001......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 29/48] END max_iter=150, penalty=l2, tol=0.0001;, score=0.722 total time=   1.0s\n",
      "[CV 1/5; 30/48] START max_iter=150, penalty=l2, tol=1e-05.......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 30/48] END max_iter=150, penalty=l2, tol=1e-05;, score=0.705 total time=   1.0s\n",
      "[CV 2/5; 30/48] START max_iter=150, penalty=l2, tol=1e-05.......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 30/48] END max_iter=150, penalty=l2, tol=1e-05;, score=0.726 total time=   1.0s\n",
      "[CV 3/5; 30/48] START max_iter=150, penalty=l2, tol=1e-05.......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 30/48] END max_iter=150, penalty=l2, tol=1e-05;, score=0.718 total time=   0.9s\n",
      "[CV 4/5; 30/48] START max_iter=150, penalty=l2, tol=1e-05.......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 30/48] END max_iter=150, penalty=l2, tol=1e-05;, score=0.712 total time=   0.9s\n",
      "[CV 5/5; 30/48] START max_iter=150, penalty=l2, tol=1e-05.......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 30/48] END max_iter=150, penalty=l2, tol=1e-05;, score=0.722 total time=   1.0s\n",
      "[CV 1/5; 31/48] START max_iter=150, penalty=elasticnet, tol=0.001...............\n",
      "[CV 1/5; 31/48] END max_iter=150, penalty=elasticnet, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 2/5; 31/48] START max_iter=150, penalty=elasticnet, tol=0.001...............\n",
      "[CV 2/5; 31/48] END max_iter=150, penalty=elasticnet, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 3/5; 31/48] START max_iter=150, penalty=elasticnet, tol=0.001...............\n",
      "[CV 3/5; 31/48] END max_iter=150, penalty=elasticnet, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 4/5; 31/48] START max_iter=150, penalty=elasticnet, tol=0.001...............\n",
      "[CV 4/5; 31/48] END max_iter=150, penalty=elasticnet, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 5/5; 31/48] START max_iter=150, penalty=elasticnet, tol=0.001...............\n",
      "[CV 5/5; 31/48] END max_iter=150, penalty=elasticnet, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 1/5; 32/48] START max_iter=150, penalty=elasticnet, tol=0.0001..............\n",
      "[CV 1/5; 32/48] END max_iter=150, penalty=elasticnet, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 2/5; 32/48] START max_iter=150, penalty=elasticnet, tol=0.0001..............\n",
      "[CV 2/5; 32/48] END max_iter=150, penalty=elasticnet, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 3/5; 32/48] START max_iter=150, penalty=elasticnet, tol=0.0001..............\n",
      "[CV 3/5; 32/48] END max_iter=150, penalty=elasticnet, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 4/5; 32/48] START max_iter=150, penalty=elasticnet, tol=0.0001..............\n",
      "[CV 4/5; 32/48] END max_iter=150, penalty=elasticnet, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 5/5; 32/48] START max_iter=150, penalty=elasticnet, tol=0.0001..............\n",
      "[CV 5/5; 32/48] END max_iter=150, penalty=elasticnet, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 1/5; 33/48] START max_iter=150, penalty=elasticnet, tol=1e-05..............."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV 1/5; 33/48] END max_iter=150, penalty=elasticnet, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 2/5; 33/48] START max_iter=150, penalty=elasticnet, tol=1e-05...............\n",
      "[CV 2/5; 33/48] END max_iter=150, penalty=elasticnet, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 3/5; 33/48] START max_iter=150, penalty=elasticnet, tol=1e-05...............\n",
      "[CV 3/5; 33/48] END max_iter=150, penalty=elasticnet, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 4/5; 33/48] START max_iter=150, penalty=elasticnet, tol=1e-05...............\n",
      "[CV 4/5; 33/48] END max_iter=150, penalty=elasticnet, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 5/5; 33/48] START max_iter=150, penalty=elasticnet, tol=1e-05...............\n",
      "[CV 5/5; 33/48] END max_iter=150, penalty=elasticnet, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 1/5; 34/48] START max_iter=150, penalty=none, tol=0.001.....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 34/48] END max_iter=150, penalty=none, tol=0.001;, score=0.706 total time=   0.9s\n",
      "[CV 2/5; 34/48] START max_iter=150, penalty=none, tol=0.001.....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 34/48] END max_iter=150, penalty=none, tol=0.001;, score=0.726 total time=   0.9s\n",
      "[CV 3/5; 34/48] START max_iter=150, penalty=none, tol=0.001.....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 34/48] END max_iter=150, penalty=none, tol=0.001;, score=0.719 total time=   0.9s\n",
      "[CV 4/5; 34/48] START max_iter=150, penalty=none, tol=0.001.....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 34/48] END max_iter=150, penalty=none, tol=0.001;, score=0.712 total time=   0.9s\n",
      "[CV 5/5; 34/48] START max_iter=150, penalty=none, tol=0.001.....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 34/48] END max_iter=150, penalty=none, tol=0.001;, score=0.720 total time=   0.9s\n",
      "[CV 1/5; 35/48] START max_iter=150, penalty=none, tol=0.0001....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 35/48] END max_iter=150, penalty=none, tol=0.0001;, score=0.706 total time=   0.8s\n",
      "[CV 2/5; 35/48] START max_iter=150, penalty=none, tol=0.0001....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 35/48] END max_iter=150, penalty=none, tol=0.0001;, score=0.726 total time=   0.8s\n",
      "[CV 3/5; 35/48] START max_iter=150, penalty=none, tol=0.0001....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 35/48] END max_iter=150, penalty=none, tol=0.0001;, score=0.719 total time=   0.8s\n",
      "[CV 4/5; 35/48] START max_iter=150, penalty=none, tol=0.0001....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 35/48] END max_iter=150, penalty=none, tol=0.0001;, score=0.712 total time=   0.8s\n",
      "[CV 5/5; 35/48] START max_iter=150, penalty=none, tol=0.0001....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 35/48] END max_iter=150, penalty=none, tol=0.0001;, score=0.720 total time=   0.9s\n",
      "[CV 1/5; 36/48] START max_iter=150, penalty=none, tol=1e-05.....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 36/48] END max_iter=150, penalty=none, tol=1e-05;, score=0.706 total time=   0.9s\n",
      "[CV 2/5; 36/48] START max_iter=150, penalty=none, tol=1e-05.....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 36/48] END max_iter=150, penalty=none, tol=1e-05;, score=0.726 total time=   1.0s\n",
      "[CV 3/5; 36/48] START max_iter=150, penalty=none, tol=1e-05.....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 36/48] END max_iter=150, penalty=none, tol=1e-05;, score=0.719 total time=   0.9s\n",
      "[CV 4/5; 36/48] START max_iter=150, penalty=none, tol=1e-05.....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 36/48] END max_iter=150, penalty=none, tol=1e-05;, score=0.712 total time=   0.9s\n",
      "[CV 5/5; 36/48] START max_iter=150, penalty=none, tol=1e-05.....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 36/48] END max_iter=150, penalty=none, tol=1e-05;, score=0.720 total time=   1.1s\n",
      "[CV 1/5; 37/48] START max_iter=200, penalty=l1, tol=0.001.......................\n",
      "[CV 1/5; 37/48] END max_iter=200, penalty=l1, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 2/5; 37/48] START max_iter=200, penalty=l1, tol=0.001.......................\n",
      "[CV 2/5; 37/48] END max_iter=200, penalty=l1, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 3/5; 37/48] START max_iter=200, penalty=l1, tol=0.001.......................\n",
      "[CV 3/5; 37/48] END max_iter=200, penalty=l1, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 4/5; 37/48] START max_iter=200, penalty=l1, tol=0.001.......................\n",
      "[CV 4/5; 37/48] END max_iter=200, penalty=l1, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 5/5; 37/48] START max_iter=200, penalty=l1, tol=0.001.......................\n",
      "[CV 5/5; 37/48] END max_iter=200, penalty=l1, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 1/5; 38/48] START max_iter=200, penalty=l1, tol=0.0001......................\n",
      "[CV 1/5; 38/48] END max_iter=200, penalty=l1, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 2/5; 38/48] START max_iter=200, penalty=l1, tol=0.0001......................\n",
      "[CV 2/5; 38/48] END max_iter=200, penalty=l1, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 3/5; 38/48] START max_iter=200, penalty=l1, tol=0.0001......................\n",
      "[CV 3/5; 38/48] END max_iter=200, penalty=l1, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 4/5; 38/48] START max_iter=200, penalty=l1, tol=0.0001......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 38/48] END max_iter=200, penalty=l1, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 5/5; 38/48] START max_iter=200, penalty=l1, tol=0.0001......................\n",
      "[CV 5/5; 38/48] END max_iter=200, penalty=l1, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 1/5; 39/48] START max_iter=200, penalty=l1, tol=1e-05.......................\n",
      "[CV 1/5; 39/48] END max_iter=200, penalty=l1, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 2/5; 39/48] START max_iter=200, penalty=l1, tol=1e-05.......................\n",
      "[CV 2/5; 39/48] END max_iter=200, penalty=l1, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 3/5; 39/48] START max_iter=200, penalty=l1, tol=1e-05.......................\n",
      "[CV 3/5; 39/48] END max_iter=200, penalty=l1, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 4/5; 39/48] START max_iter=200, penalty=l1, tol=1e-05.......................\n",
      "[CV 4/5; 39/48] END max_iter=200, penalty=l1, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 5/5; 39/48] START max_iter=200, penalty=l1, tol=1e-05.......................\n",
      "[CV 5/5; 39/48] END max_iter=200, penalty=l1, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 1/5; 40/48] START max_iter=200, penalty=l2, tol=0.001.......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 40/48] END max_iter=200, penalty=l2, tol=0.001;, score=0.705 total time=   1.2s\n",
      "[CV 2/5; 40/48] START max_iter=200, penalty=l2, tol=0.001.......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 40/48] END max_iter=200, penalty=l2, tol=0.001;, score=0.726 total time=   1.1s\n",
      "[CV 3/5; 40/48] START max_iter=200, penalty=l2, tol=0.001.......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 40/48] END max_iter=200, penalty=l2, tol=0.001;, score=0.719 total time=   1.1s\n",
      "[CV 4/5; 40/48] START max_iter=200, penalty=l2, tol=0.001.......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 40/48] END max_iter=200, penalty=l2, tol=0.001;, score=0.712 total time=   1.1s\n",
      "[CV 5/5; 40/48] START max_iter=200, penalty=l2, tol=0.001.......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 40/48] END max_iter=200, penalty=l2, tol=0.001;, score=0.722 total time=   1.1s\n",
      "[CV 1/5; 41/48] START max_iter=200, penalty=l2, tol=0.0001......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 41/48] END max_iter=200, penalty=l2, tol=0.0001;, score=0.705 total time=   1.2s\n",
      "[CV 2/5; 41/48] START max_iter=200, penalty=l2, tol=0.0001......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 41/48] END max_iter=200, penalty=l2, tol=0.0001;, score=0.726 total time=   1.1s\n",
      "[CV 3/5; 41/48] START max_iter=200, penalty=l2, tol=0.0001......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 41/48] END max_iter=200, penalty=l2, tol=0.0001;, score=0.719 total time=   1.1s\n",
      "[CV 4/5; 41/48] START max_iter=200, penalty=l2, tol=0.0001......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 41/48] END max_iter=200, penalty=l2, tol=0.0001;, score=0.712 total time=   1.1s\n",
      "[CV 5/5; 41/48] START max_iter=200, penalty=l2, tol=0.0001......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 41/48] END max_iter=200, penalty=l2, tol=0.0001;, score=0.722 total time=   1.3s\n",
      "[CV 1/5; 42/48] START max_iter=200, penalty=l2, tol=1e-05.......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 42/48] END max_iter=200, penalty=l2, tol=1e-05;, score=0.705 total time=   1.1s\n",
      "[CV 2/5; 42/48] START max_iter=200, penalty=l2, tol=1e-05.......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 42/48] END max_iter=200, penalty=l2, tol=1e-05;, score=0.726 total time=   1.4s\n",
      "[CV 3/5; 42/48] START max_iter=200, penalty=l2, tol=1e-05.......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 42/48] END max_iter=200, penalty=l2, tol=1e-05;, score=0.719 total time=   1.3s\n",
      "[CV 4/5; 42/48] START max_iter=200, penalty=l2, tol=1e-05.......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 42/48] END max_iter=200, penalty=l2, tol=1e-05;, score=0.712 total time=   1.2s\n",
      "[CV 5/5; 42/48] START max_iter=200, penalty=l2, tol=1e-05.......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 42/48] END max_iter=200, penalty=l2, tol=1e-05;, score=0.722 total time=   1.4s\n",
      "[CV 1/5; 43/48] START max_iter=200, penalty=elasticnet, tol=0.001...............\n",
      "[CV 1/5; 43/48] END max_iter=200, penalty=elasticnet, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 2/5; 43/48] START max_iter=200, penalty=elasticnet, tol=0.001...............\n",
      "[CV 2/5; 43/48] END max_iter=200, penalty=elasticnet, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 3/5; 43/48] START max_iter=200, penalty=elasticnet, tol=0.001...............\n",
      "[CV 3/5; 43/48] END max_iter=200, penalty=elasticnet, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 4/5; 43/48] START max_iter=200, penalty=elasticnet, tol=0.001...............\n",
      "[CV 4/5; 43/48] END max_iter=200, penalty=elasticnet, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 5/5; 43/48] START max_iter=200, penalty=elasticnet, tol=0.001...............\n",
      "[CV 5/5; 43/48] END max_iter=200, penalty=elasticnet, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 1/5; 44/48] START max_iter=200, penalty=elasticnet, tol=0.0001..............\n",
      "[CV 1/5; 44/48] END max_iter=200, penalty=elasticnet, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 2/5; 44/48] START max_iter=200, penalty=elasticnet, tol=0.0001..............\n",
      "[CV 2/5; 44/48] END max_iter=200, penalty=elasticnet, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 3/5; 44/48] START max_iter=200, penalty=elasticnet, tol=0.0001..............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 44/48] END max_iter=200, penalty=elasticnet, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 4/5; 44/48] START max_iter=200, penalty=elasticnet, tol=0.0001..............\n",
      "[CV 4/5; 44/48] END max_iter=200, penalty=elasticnet, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 5/5; 44/48] START max_iter=200, penalty=elasticnet, tol=0.0001..............\n",
      "[CV 5/5; 44/48] END max_iter=200, penalty=elasticnet, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 1/5; 45/48] START max_iter=200, penalty=elasticnet, tol=1e-05...............\n",
      "[CV 1/5; 45/48] END max_iter=200, penalty=elasticnet, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 2/5; 45/48] START max_iter=200, penalty=elasticnet, tol=1e-05...............\n",
      "[CV 2/5; 45/48] END max_iter=200, penalty=elasticnet, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 3/5; 45/48] START max_iter=200, penalty=elasticnet, tol=1e-05...............\n",
      "[CV 3/5; 45/48] END max_iter=200, penalty=elasticnet, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 4/5; 45/48] START max_iter=200, penalty=elasticnet, tol=1e-05...............\n",
      "[CV 4/5; 45/48] END max_iter=200, penalty=elasticnet, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 5/5; 45/48] START max_iter=200, penalty=elasticnet, tol=1e-05...............\n",
      "[CV 5/5; 45/48] END max_iter=200, penalty=elasticnet, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 1/5; 46/48] START max_iter=200, penalty=none, tol=0.001.....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 46/48] END max_iter=200, penalty=none, tol=0.001;, score=0.706 total time=   1.2s\n",
      "[CV 2/5; 46/48] START max_iter=200, penalty=none, tol=0.001.....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 46/48] END max_iter=200, penalty=none, tol=0.001;, score=0.726 total time=   1.3s\n",
      "[CV 3/5; 46/48] START max_iter=200, penalty=none, tol=0.001.....................\n",
      "[CV 3/5; 46/48] END max_iter=200, penalty=none, tol=0.001;, score=0.719 total time=   1.1s\n",
      "[CV 4/5; 46/48] START max_iter=200, penalty=none, tol=0.001.....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 46/48] END max_iter=200, penalty=none, tol=0.001;, score=0.712 total time=   1.3s\n",
      "[CV 5/5; 46/48] START max_iter=200, penalty=none, tol=0.001.....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 46/48] END max_iter=200, penalty=none, tol=0.001;, score=0.720 total time=   1.3s\n",
      "[CV 1/5; 47/48] START max_iter=200, penalty=none, tol=0.0001....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 47/48] END max_iter=200, penalty=none, tol=0.0001;, score=0.706 total time=   1.2s\n",
      "[CV 2/5; 47/48] START max_iter=200, penalty=none, tol=0.0001....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 47/48] END max_iter=200, penalty=none, tol=0.0001;, score=0.726 total time=   1.4s\n",
      "[CV 3/5; 47/48] START max_iter=200, penalty=none, tol=0.0001....................\n",
      "[CV 3/5; 47/48] END max_iter=200, penalty=none, tol=0.0001;, score=0.719 total time=   1.2s\n",
      "[CV 4/5; 47/48] START max_iter=200, penalty=none, tol=0.0001....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 47/48] END max_iter=200, penalty=none, tol=0.0001;, score=0.712 total time=   1.5s\n",
      "[CV 5/5; 47/48] START max_iter=200, penalty=none, tol=0.0001....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 47/48] END max_iter=200, penalty=none, tol=0.0001;, score=0.720 total time=   1.3s\n",
      "[CV 1/5; 48/48] START max_iter=200, penalty=none, tol=1e-05.....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 48/48] END max_iter=200, penalty=none, tol=1e-05;, score=0.706 total time=   1.4s\n",
      "[CV 2/5; 48/48] START max_iter=200, penalty=none, tol=1e-05.....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 48/48] END max_iter=200, penalty=none, tol=1e-05;, score=0.726 total time=   1.4s\n",
      "[CV 3/5; 48/48] START max_iter=200, penalty=none, tol=1e-05.....................\n",
      "[CV 3/5; 48/48] END max_iter=200, penalty=none, tol=1e-05;, score=0.719 total time=   1.1s\n",
      "[CV 4/5; 48/48] START max_iter=200, penalty=none, tol=1e-05.....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 48/48] END max_iter=200, penalty=none, tol=1e-05;, score=0.712 total time=   1.2s\n",
      "[CV 5/5; 48/48] START max_iter=200, penalty=none, tol=1e-05.....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:922: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan 0.71695346 0.71695346 0.71695346\n",
      "        nan        nan        nan 0.71706572 0.71706572 0.71706572\n",
      "        nan        nan        nan 0.71649056 0.71649056 0.71649056\n",
      "        nan        nan        nan 0.71652794 0.71652794 0.71652794\n",
      "        nan        nan        nan 0.71663451 0.71663451 0.71663451\n",
      "        nan        nan        nan 0.71670507 0.71670507 0.71670507\n",
      "        nan        nan        nan 0.7168368  0.7168368  0.7168368\n",
      "        nan        nan        nan 0.71662587 0.71662587 0.71662587]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 48/48] END max_iter=200, penalty=none, tol=1e-05;, score=0.720 total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=LogisticRegression(),\n",
       "             param_grid={'max_iter': [50, 100, 150, 200],\n",
       "                         'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
       "                         'tol': [0.001, 0.0001, 1e-05]},\n",
       "             scoring='balanced_accuracy', verbose=10)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "parameters = {  'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
    "                'tol': [1e-3, 1e-4, 1e-5],\n",
    "                'max_iter': [50, 100, 150, 200]\n",
    "                 }\n",
    "\n",
    "model = LogisticRegression()\n",
    "\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=parameters, verbose=10, scoring=\"balanced_accuracy\")\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7014ea4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_iter': 50, 'penalty': 'none', 'tol': 0.001}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8bd0fedc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8268156424581006\n",
      "Balanced Accuracy:  0.7205646219313002\n",
      "Precision:  0.8439236893495569\n",
      "Recall:  0.9404084365584198\n",
      "F1:  0.8895574380492439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(max_iter=50, penalty='none', tol=0.001)\n",
    "model.fit(X_train, y_train)\n",
    "predicted = model.predict(X_test)\n",
    "evaluate(predicted, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4666ad94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 56 candidates, totalling 280 fits\n",
      "[CV 1/5; 1/56] START criterion=entropy, max_depth=10, min_samples_split=2.......\n",
      "[CV 1/5; 1/56] END criterion=entropy, max_depth=10, min_samples_split=2;, score=0.657 total time=   0.3s\n",
      "[CV 2/5; 1/56] START criterion=entropy, max_depth=10, min_samples_split=2.......\n",
      "[CV 2/5; 1/56] END criterion=entropy, max_depth=10, min_samples_split=2;, score=0.677 total time=   0.3s\n",
      "[CV 3/5; 1/56] START criterion=entropy, max_depth=10, min_samples_split=2.......\n",
      "[CV 3/5; 1/56] END criterion=entropy, max_depth=10, min_samples_split=2;, score=0.660 total time=   0.3s\n",
      "[CV 4/5; 1/56] START criterion=entropy, max_depth=10, min_samples_split=2.......\n",
      "[CV 4/5; 1/56] END criterion=entropy, max_depth=10, min_samples_split=2;, score=0.656 total time=   0.3s\n",
      "[CV 5/5; 1/56] START criterion=entropy, max_depth=10, min_samples_split=2.......\n",
      "[CV 5/5; 1/56] END criterion=entropy, max_depth=10, min_samples_split=2;, score=0.661 total time=   0.3s\n",
      "[CV 1/5; 2/56] START criterion=entropy, max_depth=10, min_samples_split=4.......\n",
      "[CV 1/5; 2/56] END criterion=entropy, max_depth=10, min_samples_split=4;, score=0.657 total time=   0.4s\n",
      "[CV 2/5; 2/56] START criterion=entropy, max_depth=10, min_samples_split=4.......\n",
      "[CV 2/5; 2/56] END criterion=entropy, max_depth=10, min_samples_split=4;, score=0.677 total time=   0.3s\n",
      "[CV 3/5; 2/56] START criterion=entropy, max_depth=10, min_samples_split=4.......\n",
      "[CV 3/5; 2/56] END criterion=entropy, max_depth=10, min_samples_split=4;, score=0.661 total time=   0.4s\n",
      "[CV 4/5; 2/56] START criterion=entropy, max_depth=10, min_samples_split=4.......\n",
      "[CV 4/5; 2/56] END criterion=entropy, max_depth=10, min_samples_split=4;, score=0.656 total time=   0.4s\n",
      "[CV 5/5; 2/56] START criterion=entropy, max_depth=10, min_samples_split=4.......\n",
      "[CV 5/5; 2/56] END criterion=entropy, max_depth=10, min_samples_split=4;, score=0.661 total time=   0.4s\n",
      "[CV 1/5; 3/56] START criterion=entropy, max_depth=10, min_samples_split=8.......\n",
      "[CV 1/5; 3/56] END criterion=entropy, max_depth=10, min_samples_split=8;, score=0.657 total time=   0.3s\n",
      "[CV 2/5; 3/56] START criterion=entropy, max_depth=10, min_samples_split=8.......\n",
      "[CV 2/5; 3/56] END criterion=entropy, max_depth=10, min_samples_split=8;, score=0.678 total time=   0.3s\n",
      "[CV 3/5; 3/56] START criterion=entropy, max_depth=10, min_samples_split=8.......\n",
      "[CV 3/5; 3/56] END criterion=entropy, max_depth=10, min_samples_split=8;, score=0.662 total time=   0.3s\n",
      "[CV 4/5; 3/56] START criterion=entropy, max_depth=10, min_samples_split=8.......\n",
      "[CV 4/5; 3/56] END criterion=entropy, max_depth=10, min_samples_split=8;, score=0.656 total time=   0.3s\n",
      "[CV 5/5; 3/56] START criterion=entropy, max_depth=10, min_samples_split=8.......\n",
      "[CV 5/5; 3/56] END criterion=entropy, max_depth=10, min_samples_split=8;, score=0.661 total time=   0.3s\n",
      "[CV 1/5; 4/56] START criterion=entropy, max_depth=10, min_samples_split=10......\n",
      "[CV 1/5; 4/56] END criterion=entropy, max_depth=10, min_samples_split=10;, score=0.657 total time=   0.4s\n",
      "[CV 2/5; 4/56] START criterion=entropy, max_depth=10, min_samples_split=10......\n",
      "[CV 2/5; 4/56] END criterion=entropy, max_depth=10, min_samples_split=10;, score=0.677 total time=   0.3s\n",
      "[CV 3/5; 4/56] START criterion=entropy, max_depth=10, min_samples_split=10......\n",
      "[CV 3/5; 4/56] END criterion=entropy, max_depth=10, min_samples_split=10;, score=0.660 total time=   0.3s\n",
      "[CV 4/5; 4/56] START criterion=entropy, max_depth=10, min_samples_split=10......\n",
      "[CV 4/5; 4/56] END criterion=entropy, max_depth=10, min_samples_split=10;, score=0.657 total time=   0.4s\n",
      "[CV 5/5; 4/56] START criterion=entropy, max_depth=10, min_samples_split=10......\n",
      "[CV 5/5; 4/56] END criterion=entropy, max_depth=10, min_samples_split=10;, score=0.661 total time=   0.4s\n",
      "[CV 1/5; 5/56] START criterion=entropy, max_depth=30, min_samples_split=2.......\n",
      "[CV 1/5; 5/56] END criterion=entropy, max_depth=30, min_samples_split=2;, score=0.638 total time=   0.8s\n",
      "[CV 2/5; 5/56] START criterion=entropy, max_depth=30, min_samples_split=2.......\n",
      "[CV 2/5; 5/56] END criterion=entropy, max_depth=30, min_samples_split=2;, score=0.634 total time=   0.7s\n",
      "[CV 3/5; 5/56] START criterion=entropy, max_depth=30, min_samples_split=2.......\n",
      "[CV 3/5; 5/56] END criterion=entropy, max_depth=30, min_samples_split=2;, score=0.640 total time=   0.8s\n",
      "[CV 4/5; 5/56] START criterion=entropy, max_depth=30, min_samples_split=2.......\n",
      "[CV 4/5; 5/56] END criterion=entropy, max_depth=30, min_samples_split=2;, score=0.648 total time=   0.8s\n",
      "[CV 5/5; 5/56] START criterion=entropy, max_depth=30, min_samples_split=2.......\n",
      "[CV 5/5; 5/56] END criterion=entropy, max_depth=30, min_samples_split=2;, score=0.647 total time=   0.8s\n",
      "[CV 1/5; 6/56] START criterion=entropy, max_depth=30, min_samples_split=4.......\n",
      "[CV 1/5; 6/56] END criterion=entropy, max_depth=30, min_samples_split=4;, score=0.639 total time=   0.8s\n",
      "[CV 2/5; 6/56] START criterion=entropy, max_depth=30, min_samples_split=4.......\n",
      "[CV 2/5; 6/56] END criterion=entropy, max_depth=30, min_samples_split=4;, score=0.639 total time=   0.8s\n",
      "[CV 3/5; 6/56] START criterion=entropy, max_depth=30, min_samples_split=4.......\n",
      "[CV 3/5; 6/56] END criterion=entropy, max_depth=30, min_samples_split=4;, score=0.644 total time=   0.8s\n",
      "[CV 4/5; 6/56] START criterion=entropy, max_depth=30, min_samples_split=4.......\n",
      "[CV 4/5; 6/56] END criterion=entropy, max_depth=30, min_samples_split=4;, score=0.647 total time=   0.8s\n",
      "[CV 5/5; 6/56] START criterion=entropy, max_depth=30, min_samples_split=4.......\n",
      "[CV 5/5; 6/56] END criterion=entropy, max_depth=30, min_samples_split=4;, score=0.647 total time=   0.9s\n",
      "[CV 1/5; 7/56] START criterion=entropy, max_depth=30, min_samples_split=8.......\n",
      "[CV 1/5; 7/56] END criterion=entropy, max_depth=30, min_samples_split=8;, score=0.647 total time=   0.8s\n",
      "[CV 2/5; 7/56] START criterion=entropy, max_depth=30, min_samples_split=8.......\n",
      "[CV 2/5; 7/56] END criterion=entropy, max_depth=30, min_samples_split=8;, score=0.645 total time=   0.8s\n",
      "[CV 3/5; 7/56] START criterion=entropy, max_depth=30, min_samples_split=8.......\n",
      "[CV 3/5; 7/56] END criterion=entropy, max_depth=30, min_samples_split=8;, score=0.644 total time=   0.8s\n",
      "[CV 4/5; 7/56] START criterion=entropy, max_depth=30, min_samples_split=8.......\n",
      "[CV 4/5; 7/56] END criterion=entropy, max_depth=30, min_samples_split=8;, score=0.647 total time=   0.8s\n",
      "[CV 5/5; 7/56] START criterion=entropy, max_depth=30, min_samples_split=8.......\n",
      "[CV 5/5; 7/56] END criterion=entropy, max_depth=30, min_samples_split=8;, score=0.648 total time=   0.8s\n",
      "[CV 1/5; 8/56] START criterion=entropy, max_depth=30, min_samples_split=10......\n",
      "[CV 1/5; 8/56] END criterion=entropy, max_depth=30, min_samples_split=10;, score=0.645 total time=   0.8s\n",
      "[CV 2/5; 8/56] START criterion=entropy, max_depth=30, min_samples_split=10......\n",
      "[CV 2/5; 8/56] END criterion=entropy, max_depth=30, min_samples_split=10;, score=0.641 total time=   0.7s\n",
      "[CV 3/5; 8/56] START criterion=entropy, max_depth=30, min_samples_split=10......\n",
      "[CV 3/5; 8/56] END criterion=entropy, max_depth=30, min_samples_split=10;, score=0.644 total time=   0.8s\n",
      "[CV 4/5; 8/56] START criterion=entropy, max_depth=30, min_samples_split=10......\n",
      "[CV 4/5; 8/56] END criterion=entropy, max_depth=30, min_samples_split=10;, score=0.650 total time=   0.8s\n",
      "[CV 5/5; 8/56] START criterion=entropy, max_depth=30, min_samples_split=10......\n",
      "[CV 5/5; 8/56] END criterion=entropy, max_depth=30, min_samples_split=10;, score=0.644 total time=   0.8s\n",
      "[CV 1/5; 9/56] START criterion=entropy, max_depth=70, min_samples_split=2.......\n",
      "[CV 1/5; 9/56] END criterion=entropy, max_depth=70, min_samples_split=2;, score=0.640 total time=   0.8s\n",
      "[CV 2/5; 9/56] START criterion=entropy, max_depth=70, min_samples_split=2.......\n",
      "[CV 2/5; 9/56] END criterion=entropy, max_depth=70, min_samples_split=2;, score=0.644 total time=   0.8s\n",
      "[CV 3/5; 9/56] START criterion=entropy, max_depth=70, min_samples_split=2.......\n",
      "[CV 3/5; 9/56] END criterion=entropy, max_depth=70, min_samples_split=2;, score=0.644 total time=   0.8s\n",
      "[CV 4/5; 9/56] START criterion=entropy, max_depth=70, min_samples_split=2.......\n",
      "[CV 4/5; 9/56] END criterion=entropy, max_depth=70, min_samples_split=2;, score=0.651 total time=   0.8s\n",
      "[CV 5/5; 9/56] START criterion=entropy, max_depth=70, min_samples_split=2.......\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 9/56] END criterion=entropy, max_depth=70, min_samples_split=2;, score=0.652 total time=   0.8s\n",
      "[CV 1/5; 10/56] START criterion=entropy, max_depth=70, min_samples_split=4......\n",
      "[CV 1/5; 10/56] END criterion=entropy, max_depth=70, min_samples_split=4;, score=0.639 total time=   0.8s\n",
      "[CV 2/5; 10/56] START criterion=entropy, max_depth=70, min_samples_split=4......\n",
      "[CV 2/5; 10/56] END criterion=entropy, max_depth=70, min_samples_split=4;, score=0.641 total time=   0.8s\n",
      "[CV 3/5; 10/56] START criterion=entropy, max_depth=70, min_samples_split=4......\n",
      "[CV 3/5; 10/56] END criterion=entropy, max_depth=70, min_samples_split=4;, score=0.644 total time=   0.8s\n",
      "[CV 4/5; 10/56] START criterion=entropy, max_depth=70, min_samples_split=4......\n",
      "[CV 4/5; 10/56] END criterion=entropy, max_depth=70, min_samples_split=4;, score=0.655 total time=   0.8s\n",
      "[CV 5/5; 10/56] START criterion=entropy, max_depth=70, min_samples_split=4......\n",
      "[CV 5/5; 10/56] END criterion=entropy, max_depth=70, min_samples_split=4;, score=0.647 total time=   0.8s\n",
      "[CV 1/5; 11/56] START criterion=entropy, max_depth=70, min_samples_split=8......\n",
      "[CV 1/5; 11/56] END criterion=entropy, max_depth=70, min_samples_split=8;, score=0.636 total time=   0.8s\n",
      "[CV 2/5; 11/56] START criterion=entropy, max_depth=70, min_samples_split=8......\n",
      "[CV 2/5; 11/56] END criterion=entropy, max_depth=70, min_samples_split=8;, score=0.646 total time=   0.8s\n",
      "[CV 3/5; 11/56] START criterion=entropy, max_depth=70, min_samples_split=8......\n",
      "[CV 3/5; 11/56] END criterion=entropy, max_depth=70, min_samples_split=8;, score=0.647 total time=   0.8s\n",
      "[CV 4/5; 11/56] START criterion=entropy, max_depth=70, min_samples_split=8......\n",
      "[CV 4/5; 11/56] END criterion=entropy, max_depth=70, min_samples_split=8;, score=0.658 total time=   0.8s\n",
      "[CV 5/5; 11/56] START criterion=entropy, max_depth=70, min_samples_split=8......\n",
      "[CV 5/5; 11/56] END criterion=entropy, max_depth=70, min_samples_split=8;, score=0.653 total time=   0.7s\n",
      "[CV 1/5; 12/56] START criterion=entropy, max_depth=70, min_samples_split=10.....\n",
      "[CV 1/5; 12/56] END criterion=entropy, max_depth=70, min_samples_split=10;, score=0.644 total time=   0.8s\n",
      "[CV 2/5; 12/56] START criterion=entropy, max_depth=70, min_samples_split=10.....\n",
      "[CV 2/5; 12/56] END criterion=entropy, max_depth=70, min_samples_split=10;, score=0.651 total time=   0.8s\n",
      "[CV 3/5; 12/56] START criterion=entropy, max_depth=70, min_samples_split=10.....\n",
      "[CV 3/5; 12/56] END criterion=entropy, max_depth=70, min_samples_split=10;, score=0.644 total time=   0.8s\n",
      "[CV 4/5; 12/56] START criterion=entropy, max_depth=70, min_samples_split=10.....\n",
      "[CV 4/5; 12/56] END criterion=entropy, max_depth=70, min_samples_split=10;, score=0.655 total time=   0.8s\n",
      "[CV 5/5; 12/56] START criterion=entropy, max_depth=70, min_samples_split=10.....\n",
      "[CV 5/5; 12/56] END criterion=entropy, max_depth=70, min_samples_split=10;, score=0.652 total time=   0.7s\n",
      "[CV 1/5; 13/56] START criterion=entropy, max_depth=90, min_samples_split=2......\n",
      "[CV 1/5; 13/56] END criterion=entropy, max_depth=90, min_samples_split=2;, score=0.639 total time=   0.8s\n",
      "[CV 2/5; 13/56] START criterion=entropy, max_depth=90, min_samples_split=2......\n",
      "[CV 2/5; 13/56] END criterion=entropy, max_depth=90, min_samples_split=2;, score=0.642 total time=   0.8s\n",
      "[CV 3/5; 13/56] START criterion=entropy, max_depth=90, min_samples_split=2......\n",
      "[CV 3/5; 13/56] END criterion=entropy, max_depth=90, min_samples_split=2;, score=0.645 total time=   0.8s\n",
      "[CV 4/5; 13/56] START criterion=entropy, max_depth=90, min_samples_split=2......\n",
      "[CV 4/5; 13/56] END criterion=entropy, max_depth=90, min_samples_split=2;, score=0.650 total time=   0.8s\n",
      "[CV 5/5; 13/56] START criterion=entropy, max_depth=90, min_samples_split=2......\n",
      "[CV 5/5; 13/56] END criterion=entropy, max_depth=90, min_samples_split=2;, score=0.653 total time=   0.8s\n",
      "[CV 1/5; 14/56] START criterion=entropy, max_depth=90, min_samples_split=4......\n",
      "[CV 1/5; 14/56] END criterion=entropy, max_depth=90, min_samples_split=4;, score=0.639 total time=   0.8s\n",
      "[CV 2/5; 14/56] START criterion=entropy, max_depth=90, min_samples_split=4......\n",
      "[CV 2/5; 14/56] END criterion=entropy, max_depth=90, min_samples_split=4;, score=0.643 total time=   0.8s\n",
      "[CV 3/5; 14/56] START criterion=entropy, max_depth=90, min_samples_split=4......\n",
      "[CV 3/5; 14/56] END criterion=entropy, max_depth=90, min_samples_split=4;, score=0.646 total time=   0.8s\n",
      "[CV 4/5; 14/56] START criterion=entropy, max_depth=90, min_samples_split=4......\n",
      "[CV 4/5; 14/56] END criterion=entropy, max_depth=90, min_samples_split=4;, score=0.653 total time=   0.9s\n",
      "[CV 5/5; 14/56] START criterion=entropy, max_depth=90, min_samples_split=4......\n",
      "[CV 5/5; 14/56] END criterion=entropy, max_depth=90, min_samples_split=4;, score=0.647 total time=   0.8s\n",
      "[CV 1/5; 15/56] START criterion=entropy, max_depth=90, min_samples_split=8......\n",
      "[CV 1/5; 15/56] END criterion=entropy, max_depth=90, min_samples_split=8;, score=0.641 total time=   0.8s\n",
      "[CV 2/5; 15/56] START criterion=entropy, max_depth=90, min_samples_split=8......\n",
      "[CV 2/5; 15/56] END criterion=entropy, max_depth=90, min_samples_split=8;, score=0.643 total time=   0.8s\n",
      "[CV 3/5; 15/56] START criterion=entropy, max_depth=90, min_samples_split=8......\n",
      "[CV 3/5; 15/56] END criterion=entropy, max_depth=90, min_samples_split=8;, score=0.647 total time=   0.8s\n",
      "[CV 4/5; 15/56] START criterion=entropy, max_depth=90, min_samples_split=8......\n",
      "[CV 4/5; 15/56] END criterion=entropy, max_depth=90, min_samples_split=8;, score=0.657 total time=   0.8s\n",
      "[CV 5/5; 15/56] START criterion=entropy, max_depth=90, min_samples_split=8......\n",
      "[CV 5/5; 15/56] END criterion=entropy, max_depth=90, min_samples_split=8;, score=0.655 total time=   0.8s\n",
      "[CV 1/5; 16/56] START criterion=entropy, max_depth=90, min_samples_split=10.....\n",
      "[CV 1/5; 16/56] END criterion=entropy, max_depth=90, min_samples_split=10;, score=0.647 total time=   0.8s\n",
      "[CV 2/5; 16/56] START criterion=entropy, max_depth=90, min_samples_split=10.....\n",
      "[CV 2/5; 16/56] END criterion=entropy, max_depth=90, min_samples_split=10;, score=0.650 total time=   0.8s\n",
      "[CV 3/5; 16/56] START criterion=entropy, max_depth=90, min_samples_split=10.....\n",
      "[CV 3/5; 16/56] END criterion=entropy, max_depth=90, min_samples_split=10;, score=0.649 total time=   0.8s\n",
      "[CV 4/5; 16/56] START criterion=entropy, max_depth=90, min_samples_split=10.....\n",
      "[CV 4/5; 16/56] END criterion=entropy, max_depth=90, min_samples_split=10;, score=0.652 total time=   0.8s\n",
      "[CV 5/5; 16/56] START criterion=entropy, max_depth=90, min_samples_split=10.....\n",
      "[CV 5/5; 16/56] END criterion=entropy, max_depth=90, min_samples_split=10;, score=0.653 total time=   0.7s\n",
      "[CV 1/5; 17/56] START criterion=entropy, max_depth=150, min_samples_split=2.....\n",
      "[CV 1/5; 17/56] END criterion=entropy, max_depth=150, min_samples_split=2;, score=0.643 total time=   0.8s\n",
      "[CV 2/5; 17/56] START criterion=entropy, max_depth=150, min_samples_split=2.....\n",
      "[CV 2/5; 17/56] END criterion=entropy, max_depth=150, min_samples_split=2;, score=0.644 total time=   0.8s\n",
      "[CV 3/5; 17/56] START criterion=entropy, max_depth=150, min_samples_split=2.....\n",
      "[CV 3/5; 17/56] END criterion=entropy, max_depth=150, min_samples_split=2;, score=0.643 total time=   0.8s\n",
      "[CV 4/5; 17/56] START criterion=entropy, max_depth=150, min_samples_split=2.....\n",
      "[CV 4/5; 17/56] END criterion=entropy, max_depth=150, min_samples_split=2;, score=0.652 total time=   0.8s\n",
      "[CV 5/5; 17/56] START criterion=entropy, max_depth=150, min_samples_split=2.....\n",
      "[CV 5/5; 17/56] END criterion=entropy, max_depth=150, min_samples_split=2;, score=0.645 total time=   0.8s\n",
      "[CV 1/5; 18/56] START criterion=entropy, max_depth=150, min_samples_split=4.....\n",
      "[CV 1/5; 18/56] END criterion=entropy, max_depth=150, min_samples_split=4;, score=0.632 total time=   0.8s\n",
      "[CV 2/5; 18/56] START criterion=entropy, max_depth=150, min_samples_split=4.....\n",
      "[CV 2/5; 18/56] END criterion=entropy, max_depth=150, min_samples_split=4;, score=0.641 total time=   0.8s\n",
      "[CV 3/5; 18/56] START criterion=entropy, max_depth=150, min_samples_split=4.....\n",
      "[CV 3/5; 18/56] END criterion=entropy, max_depth=150, min_samples_split=4;, score=0.649 total time=   0.8s\n",
      "[CV 4/5; 18/56] START criterion=entropy, max_depth=150, min_samples_split=4.....\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 18/56] END criterion=entropy, max_depth=150, min_samples_split=4;, score=0.655 total time=   0.8s\n",
      "[CV 5/5; 18/56] START criterion=entropy, max_depth=150, min_samples_split=4.....\n",
      "[CV 5/5; 18/56] END criterion=entropy, max_depth=150, min_samples_split=4;, score=0.647 total time=   0.8s\n",
      "[CV 1/5; 19/56] START criterion=entropy, max_depth=150, min_samples_split=8.....\n",
      "[CV 1/5; 19/56] END criterion=entropy, max_depth=150, min_samples_split=8;, score=0.648 total time=   0.8s\n",
      "[CV 2/5; 19/56] START criterion=entropy, max_depth=150, min_samples_split=8.....\n",
      "[CV 2/5; 19/56] END criterion=entropy, max_depth=150, min_samples_split=8;, score=0.645 total time=   0.8s\n",
      "[CV 3/5; 19/56] START criterion=entropy, max_depth=150, min_samples_split=8.....\n",
      "[CV 3/5; 19/56] END criterion=entropy, max_depth=150, min_samples_split=8;, score=0.644 total time=   0.8s\n",
      "[CV 4/5; 19/56] START criterion=entropy, max_depth=150, min_samples_split=8.....\n",
      "[CV 4/5; 19/56] END criterion=entropy, max_depth=150, min_samples_split=8;, score=0.656 total time=   0.8s\n",
      "[CV 5/5; 19/56] START criterion=entropy, max_depth=150, min_samples_split=8.....\n",
      "[CV 5/5; 19/56] END criterion=entropy, max_depth=150, min_samples_split=8;, score=0.651 total time=   0.8s\n",
      "[CV 1/5; 20/56] START criterion=entropy, max_depth=150, min_samples_split=10....\n",
      "[CV 1/5; 20/56] END criterion=entropy, max_depth=150, min_samples_split=10;, score=0.643 total time=   0.8s\n",
      "[CV 2/5; 20/56] START criterion=entropy, max_depth=150, min_samples_split=10....\n",
      "[CV 2/5; 20/56] END criterion=entropy, max_depth=150, min_samples_split=10;, score=0.650 total time=   0.8s\n",
      "[CV 3/5; 20/56] START criterion=entropy, max_depth=150, min_samples_split=10....\n",
      "[CV 3/5; 20/56] END criterion=entropy, max_depth=150, min_samples_split=10;, score=0.649 total time=   0.9s\n",
      "[CV 4/5; 20/56] START criterion=entropy, max_depth=150, min_samples_split=10....\n",
      "[CV 4/5; 20/56] END criterion=entropy, max_depth=150, min_samples_split=10;, score=0.654 total time=   0.8s\n",
      "[CV 5/5; 20/56] START criterion=entropy, max_depth=150, min_samples_split=10....\n",
      "[CV 5/5; 20/56] END criterion=entropy, max_depth=150, min_samples_split=10;, score=0.652 total time=   0.8s\n",
      "[CV 1/5; 21/56] START criterion=entropy, max_depth=200, min_samples_split=2.....\n",
      "[CV 1/5; 21/56] END criterion=entropy, max_depth=200, min_samples_split=2;, score=0.647 total time=   0.8s\n",
      "[CV 2/5; 21/56] START criterion=entropy, max_depth=200, min_samples_split=2.....\n",
      "[CV 2/5; 21/56] END criterion=entropy, max_depth=200, min_samples_split=2;, score=0.646 total time=   0.8s\n",
      "[CV 3/5; 21/56] START criterion=entropy, max_depth=200, min_samples_split=2.....\n",
      "[CV 3/5; 21/56] END criterion=entropy, max_depth=200, min_samples_split=2;, score=0.643 total time=   0.8s\n",
      "[CV 4/5; 21/56] START criterion=entropy, max_depth=200, min_samples_split=2.....\n",
      "[CV 4/5; 21/56] END criterion=entropy, max_depth=200, min_samples_split=2;, score=0.650 total time=   0.8s\n",
      "[CV 5/5; 21/56] START criterion=entropy, max_depth=200, min_samples_split=2.....\n",
      "[CV 5/5; 21/56] END criterion=entropy, max_depth=200, min_samples_split=2;, score=0.652 total time=   0.8s\n",
      "[CV 1/5; 22/56] START criterion=entropy, max_depth=200, min_samples_split=4.....\n",
      "[CV 1/5; 22/56] END criterion=entropy, max_depth=200, min_samples_split=4;, score=0.636 total time=   0.8s\n",
      "[CV 2/5; 22/56] START criterion=entropy, max_depth=200, min_samples_split=4.....\n",
      "[CV 2/5; 22/56] END criterion=entropy, max_depth=200, min_samples_split=4;, score=0.643 total time=   0.8s\n",
      "[CV 3/5; 22/56] START criterion=entropy, max_depth=200, min_samples_split=4.....\n",
      "[CV 3/5; 22/56] END criterion=entropy, max_depth=200, min_samples_split=4;, score=0.644 total time=   0.8s\n",
      "[CV 4/5; 22/56] START criterion=entropy, max_depth=200, min_samples_split=4.....\n",
      "[CV 4/5; 22/56] END criterion=entropy, max_depth=200, min_samples_split=4;, score=0.653 total time=   0.8s\n",
      "[CV 5/5; 22/56] START criterion=entropy, max_depth=200, min_samples_split=4.....\n",
      "[CV 5/5; 22/56] END criterion=entropy, max_depth=200, min_samples_split=4;, score=0.651 total time=   0.8s\n",
      "[CV 1/5; 23/56] START criterion=entropy, max_depth=200, min_samples_split=8.....\n",
      "[CV 1/5; 23/56] END criterion=entropy, max_depth=200, min_samples_split=8;, score=0.648 total time=   0.8s\n",
      "[CV 2/5; 23/56] START criterion=entropy, max_depth=200, min_samples_split=8.....\n",
      "[CV 2/5; 23/56] END criterion=entropy, max_depth=200, min_samples_split=8;, score=0.644 total time=   0.8s\n",
      "[CV 3/5; 23/56] START criterion=entropy, max_depth=200, min_samples_split=8.....\n",
      "[CV 3/5; 23/56] END criterion=entropy, max_depth=200, min_samples_split=8;, score=0.641 total time=   0.8s\n",
      "[CV 4/5; 23/56] START criterion=entropy, max_depth=200, min_samples_split=8.....\n",
      "[CV 4/5; 23/56] END criterion=entropy, max_depth=200, min_samples_split=8;, score=0.655 total time=   0.8s\n",
      "[CV 5/5; 23/56] START criterion=entropy, max_depth=200, min_samples_split=8.....\n",
      "[CV 5/5; 23/56] END criterion=entropy, max_depth=200, min_samples_split=8;, score=0.651 total time=   0.8s\n",
      "[CV 1/5; 24/56] START criterion=entropy, max_depth=200, min_samples_split=10....\n",
      "[CV 1/5; 24/56] END criterion=entropy, max_depth=200, min_samples_split=10;, score=0.649 total time=   0.8s\n",
      "[CV 2/5; 24/56] START criterion=entropy, max_depth=200, min_samples_split=10....\n",
      "[CV 2/5; 24/56] END criterion=entropy, max_depth=200, min_samples_split=10;, score=0.644 total time=   0.8s\n",
      "[CV 3/5; 24/56] START criterion=entropy, max_depth=200, min_samples_split=10....\n",
      "[CV 3/5; 24/56] END criterion=entropy, max_depth=200, min_samples_split=10;, score=0.652 total time=   0.7s\n",
      "[CV 4/5; 24/56] START criterion=entropy, max_depth=200, min_samples_split=10....\n",
      "[CV 4/5; 24/56] END criterion=entropy, max_depth=200, min_samples_split=10;, score=0.659 total time=   0.8s\n",
      "[CV 5/5; 24/56] START criterion=entropy, max_depth=200, min_samples_split=10....\n",
      "[CV 5/5; 24/56] END criterion=entropy, max_depth=200, min_samples_split=10;, score=0.647 total time=   0.8s\n",
      "[CV 1/5; 25/56] START criterion=entropy, max_depth=300, min_samples_split=2.....\n",
      "[CV 1/5; 25/56] END criterion=entropy, max_depth=300, min_samples_split=2;, score=0.641 total time=   0.8s\n",
      "[CV 2/5; 25/56] START criterion=entropy, max_depth=300, min_samples_split=2.....\n",
      "[CV 2/5; 25/56] END criterion=entropy, max_depth=300, min_samples_split=2;, score=0.643 total time=   0.8s\n",
      "[CV 3/5; 25/56] START criterion=entropy, max_depth=300, min_samples_split=2.....\n",
      "[CV 3/5; 25/56] END criterion=entropy, max_depth=300, min_samples_split=2;, score=0.646 total time=   0.8s\n",
      "[CV 4/5; 25/56] START criterion=entropy, max_depth=300, min_samples_split=2.....\n",
      "[CV 4/5; 25/56] END criterion=entropy, max_depth=300, min_samples_split=2;, score=0.652 total time=   0.8s\n",
      "[CV 5/5; 25/56] START criterion=entropy, max_depth=300, min_samples_split=2.....\n",
      "[CV 5/5; 25/56] END criterion=entropy, max_depth=300, min_samples_split=2;, score=0.651 total time=   0.8s\n",
      "[CV 1/5; 26/56] START criterion=entropy, max_depth=300, min_samples_split=4.....\n",
      "[CV 1/5; 26/56] END criterion=entropy, max_depth=300, min_samples_split=4;, score=0.634 total time=   0.8s\n",
      "[CV 2/5; 26/56] START criterion=entropy, max_depth=300, min_samples_split=4.....\n",
      "[CV 2/5; 26/56] END criterion=entropy, max_depth=300, min_samples_split=4;, score=0.639 total time=   0.8s\n",
      "[CV 3/5; 26/56] START criterion=entropy, max_depth=300, min_samples_split=4.....\n",
      "[CV 3/5; 26/56] END criterion=entropy, max_depth=300, min_samples_split=4;, score=0.652 total time=   0.8s\n",
      "[CV 4/5; 26/56] START criterion=entropy, max_depth=300, min_samples_split=4.....\n",
      "[CV 4/5; 26/56] END criterion=entropy, max_depth=300, min_samples_split=4;, score=0.651 total time=   0.8s\n",
      "[CV 5/5; 26/56] START criterion=entropy, max_depth=300, min_samples_split=4.....\n",
      "[CV 5/5; 26/56] END criterion=entropy, max_depth=300, min_samples_split=4;, score=0.648 total time=   0.8s\n",
      "[CV 1/5; 27/56] START criterion=entropy, max_depth=300, min_samples_split=8.....\n",
      "[CV 1/5; 27/56] END criterion=entropy, max_depth=300, min_samples_split=8;, score=0.643 total time=   0.8s\n",
      "[CV 2/5; 27/56] START criterion=entropy, max_depth=300, min_samples_split=8.....\n",
      "[CV 2/5; 27/56] END criterion=entropy, max_depth=300, min_samples_split=8;, score=0.639 total time=   0.8s\n",
      "[CV 3/5; 27/56] START criterion=entropy, max_depth=300, min_samples_split=8.....\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 27/56] END criterion=entropy, max_depth=300, min_samples_split=8;, score=0.645 total time=   0.8s\n",
      "[CV 4/5; 27/56] START criterion=entropy, max_depth=300, min_samples_split=8.....\n",
      "[CV 4/5; 27/56] END criterion=entropy, max_depth=300, min_samples_split=8;, score=0.655 total time=   0.8s\n",
      "[CV 5/5; 27/56] START criterion=entropy, max_depth=300, min_samples_split=8.....\n",
      "[CV 5/5; 27/56] END criterion=entropy, max_depth=300, min_samples_split=8;, score=0.650 total time=   0.8s\n",
      "[CV 1/5; 28/56] START criterion=entropy, max_depth=300, min_samples_split=10....\n",
      "[CV 1/5; 28/56] END criterion=entropy, max_depth=300, min_samples_split=10;, score=0.642 total time=   0.8s\n",
      "[CV 2/5; 28/56] START criterion=entropy, max_depth=300, min_samples_split=10....\n",
      "[CV 2/5; 28/56] END criterion=entropy, max_depth=300, min_samples_split=10;, score=0.651 total time=   0.8s\n",
      "[CV 3/5; 28/56] START criterion=entropy, max_depth=300, min_samples_split=10....\n",
      "[CV 3/5; 28/56] END criterion=entropy, max_depth=300, min_samples_split=10;, score=0.647 total time=   0.8s\n",
      "[CV 4/5; 28/56] START criterion=entropy, max_depth=300, min_samples_split=10....\n",
      "[CV 4/5; 28/56] END criterion=entropy, max_depth=300, min_samples_split=10;, score=0.650 total time=   0.8s\n",
      "[CV 5/5; 28/56] START criterion=entropy, max_depth=300, min_samples_split=10....\n",
      "[CV 5/5; 28/56] END criterion=entropy, max_depth=300, min_samples_split=10;, score=0.653 total time=   0.8s\n",
      "[CV 1/5; 29/56] START criterion=gini, max_depth=10, min_samples_split=2.........\n",
      "[CV 1/5; 29/56] END criterion=gini, max_depth=10, min_samples_split=2;, score=0.665 total time=   0.3s\n",
      "[CV 2/5; 29/56] START criterion=gini, max_depth=10, min_samples_split=2.........\n",
      "[CV 2/5; 29/56] END criterion=gini, max_depth=10, min_samples_split=2;, score=0.672 total time=   0.3s\n",
      "[CV 3/5; 29/56] START criterion=gini, max_depth=10, min_samples_split=2.........\n",
      "[CV 3/5; 29/56] END criterion=gini, max_depth=10, min_samples_split=2;, score=0.671 total time=   0.3s\n",
      "[CV 4/5; 29/56] START criterion=gini, max_depth=10, min_samples_split=2.........\n",
      "[CV 4/5; 29/56] END criterion=gini, max_depth=10, min_samples_split=2;, score=0.662 total time=   0.3s\n",
      "[CV 5/5; 29/56] START criterion=gini, max_depth=10, min_samples_split=2.........\n",
      "[CV 5/5; 29/56] END criterion=gini, max_depth=10, min_samples_split=2;, score=0.658 total time=   0.4s\n",
      "[CV 1/5; 30/56] START criterion=gini, max_depth=10, min_samples_split=4.........\n",
      "[CV 1/5; 30/56] END criterion=gini, max_depth=10, min_samples_split=4;, score=0.663 total time=   0.3s\n",
      "[CV 2/5; 30/56] START criterion=gini, max_depth=10, min_samples_split=4.........\n",
      "[CV 2/5; 30/56] END criterion=gini, max_depth=10, min_samples_split=4;, score=0.675 total time=   0.4s\n",
      "[CV 3/5; 30/56] START criterion=gini, max_depth=10, min_samples_split=4.........\n",
      "[CV 3/5; 30/56] END criterion=gini, max_depth=10, min_samples_split=4;, score=0.672 total time=   0.3s\n",
      "[CV 4/5; 30/56] START criterion=gini, max_depth=10, min_samples_split=4.........\n",
      "[CV 4/5; 30/56] END criterion=gini, max_depth=10, min_samples_split=4;, score=0.661 total time=   0.3s\n",
      "[CV 5/5; 30/56] START criterion=gini, max_depth=10, min_samples_split=4.........\n",
      "[CV 5/5; 30/56] END criterion=gini, max_depth=10, min_samples_split=4;, score=0.655 total time=   0.3s\n",
      "[CV 1/5; 31/56] START criterion=gini, max_depth=10, min_samples_split=8.........\n",
      "[CV 1/5; 31/56] END criterion=gini, max_depth=10, min_samples_split=8;, score=0.663 total time=   0.3s\n",
      "[CV 2/5; 31/56] START criterion=gini, max_depth=10, min_samples_split=8.........\n",
      "[CV 2/5; 31/56] END criterion=gini, max_depth=10, min_samples_split=8;, score=0.673 total time=   0.3s\n",
      "[CV 3/5; 31/56] START criterion=gini, max_depth=10, min_samples_split=8.........\n",
      "[CV 3/5; 31/56] END criterion=gini, max_depth=10, min_samples_split=8;, score=0.672 total time=   0.4s\n",
      "[CV 4/5; 31/56] START criterion=gini, max_depth=10, min_samples_split=8.........\n",
      "[CV 4/5; 31/56] END criterion=gini, max_depth=10, min_samples_split=8;, score=0.661 total time=   0.3s\n",
      "[CV 5/5; 31/56] START criterion=gini, max_depth=10, min_samples_split=8.........\n",
      "[CV 5/5; 31/56] END criterion=gini, max_depth=10, min_samples_split=8;, score=0.657 total time=   0.3s\n",
      "[CV 1/5; 32/56] START criterion=gini, max_depth=10, min_samples_split=10........\n",
      "[CV 1/5; 32/56] END criterion=gini, max_depth=10, min_samples_split=10;, score=0.663 total time=   0.3s\n",
      "[CV 2/5; 32/56] START criterion=gini, max_depth=10, min_samples_split=10........\n",
      "[CV 2/5; 32/56] END criterion=gini, max_depth=10, min_samples_split=10;, score=0.672 total time=   0.3s\n",
      "[CV 3/5; 32/56] START criterion=gini, max_depth=10, min_samples_split=10........\n",
      "[CV 3/5; 32/56] END criterion=gini, max_depth=10, min_samples_split=10;, score=0.672 total time=   0.3s\n",
      "[CV 4/5; 32/56] START criterion=gini, max_depth=10, min_samples_split=10........\n",
      "[CV 4/5; 32/56] END criterion=gini, max_depth=10, min_samples_split=10;, score=0.660 total time=   0.3s\n",
      "[CV 5/5; 32/56] START criterion=gini, max_depth=10, min_samples_split=10........\n",
      "[CV 5/5; 32/56] END criterion=gini, max_depth=10, min_samples_split=10;, score=0.658 total time=   0.3s\n",
      "[CV 1/5; 33/56] START criterion=gini, max_depth=30, min_samples_split=2.........\n",
      "[CV 1/5; 33/56] END criterion=gini, max_depth=30, min_samples_split=2;, score=0.628 total time=   0.8s\n",
      "[CV 2/5; 33/56] START criterion=gini, max_depth=30, min_samples_split=2.........\n",
      "[CV 2/5; 33/56] END criterion=gini, max_depth=30, min_samples_split=2;, score=0.646 total time=   0.7s\n",
      "[CV 3/5; 33/56] START criterion=gini, max_depth=30, min_samples_split=2.........\n",
      "[CV 3/5; 33/56] END criterion=gini, max_depth=30, min_samples_split=2;, score=0.632 total time=   0.8s\n",
      "[CV 4/5; 33/56] START criterion=gini, max_depth=30, min_samples_split=2.........\n",
      "[CV 4/5; 33/56] END criterion=gini, max_depth=30, min_samples_split=2;, score=0.648 total time=   0.8s\n",
      "[CV 5/5; 33/56] START criterion=gini, max_depth=30, min_samples_split=2.........\n",
      "[CV 5/5; 33/56] END criterion=gini, max_depth=30, min_samples_split=2;, score=0.635 total time=   0.7s\n",
      "[CV 1/5; 34/56] START criterion=gini, max_depth=30, min_samples_split=4.........\n",
      "[CV 1/5; 34/56] END criterion=gini, max_depth=30, min_samples_split=4;, score=0.633 total time=   0.7s\n",
      "[CV 2/5; 34/56] START criterion=gini, max_depth=30, min_samples_split=4.........\n",
      "[CV 2/5; 34/56] END criterion=gini, max_depth=30, min_samples_split=4;, score=0.644 total time=   0.7s\n",
      "[CV 3/5; 34/56] START criterion=gini, max_depth=30, min_samples_split=4.........\n",
      "[CV 3/5; 34/56] END criterion=gini, max_depth=30, min_samples_split=4;, score=0.629 total time=   0.8s\n",
      "[CV 4/5; 34/56] START criterion=gini, max_depth=30, min_samples_split=4.........\n",
      "[CV 4/5; 34/56] END criterion=gini, max_depth=30, min_samples_split=4;, score=0.646 total time=   0.7s\n",
      "[CV 5/5; 34/56] START criterion=gini, max_depth=30, min_samples_split=4.........\n",
      "[CV 5/5; 34/56] END criterion=gini, max_depth=30, min_samples_split=4;, score=0.634 total time=   0.7s\n",
      "[CV 1/5; 35/56] START criterion=gini, max_depth=30, min_samples_split=8.........\n",
      "[CV 1/5; 35/56] END criterion=gini, max_depth=30, min_samples_split=8;, score=0.639 total time=   0.8s\n",
      "[CV 2/5; 35/56] START criterion=gini, max_depth=30, min_samples_split=8.........\n",
      "[CV 2/5; 35/56] END criterion=gini, max_depth=30, min_samples_split=8;, score=0.652 total time=   0.7s\n",
      "[CV 3/5; 35/56] START criterion=gini, max_depth=30, min_samples_split=8.........\n",
      "[CV 3/5; 35/56] END criterion=gini, max_depth=30, min_samples_split=8;, score=0.638 total time=   0.7s\n",
      "[CV 4/5; 35/56] START criterion=gini, max_depth=30, min_samples_split=8.........\n",
      "[CV 4/5; 35/56] END criterion=gini, max_depth=30, min_samples_split=8;, score=0.648 total time=   0.7s\n",
      "[CV 5/5; 35/56] START criterion=gini, max_depth=30, min_samples_split=8.........\n",
      "[CV 5/5; 35/56] END criterion=gini, max_depth=30, min_samples_split=8;, score=0.641 total time=   0.7s\n",
      "[CV 1/5; 36/56] START criterion=gini, max_depth=30, min_samples_split=10........\n",
      "[CV 1/5; 36/56] END criterion=gini, max_depth=30, min_samples_split=10;, score=0.637 total time=   0.7s\n",
      "[CV 2/5; 36/56] START criterion=gini, max_depth=30, min_samples_split=10........\n",
      "[CV 2/5; 36/56] END criterion=gini, max_depth=30, min_samples_split=10;, score=0.652 total time=   0.7s\n",
      "[CV 3/5; 36/56] START criterion=gini, max_depth=30, min_samples_split=10........\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 36/56] END criterion=gini, max_depth=30, min_samples_split=10;, score=0.649 total time=   0.7s\n",
      "[CV 4/5; 36/56] START criterion=gini, max_depth=30, min_samples_split=10........\n",
      "[CV 4/5; 36/56] END criterion=gini, max_depth=30, min_samples_split=10;, score=0.648 total time=   0.7s\n",
      "[CV 5/5; 36/56] START criterion=gini, max_depth=30, min_samples_split=10........\n",
      "[CV 5/5; 36/56] END criterion=gini, max_depth=30, min_samples_split=10;, score=0.648 total time=   0.7s\n",
      "[CV 1/5; 37/56] START criterion=gini, max_depth=70, min_samples_split=2.........\n",
      "[CV 1/5; 37/56] END criterion=gini, max_depth=70, min_samples_split=2;, score=0.626 total time=   0.8s\n",
      "[CV 2/5; 37/56] START criterion=gini, max_depth=70, min_samples_split=2.........\n",
      "[CV 2/5; 37/56] END criterion=gini, max_depth=70, min_samples_split=2;, score=0.650 total time=   0.8s\n",
      "[CV 3/5; 37/56] START criterion=gini, max_depth=70, min_samples_split=2.........\n",
      "[CV 3/5; 37/56] END criterion=gini, max_depth=70, min_samples_split=2;, score=0.644 total time=   0.8s\n",
      "[CV 4/5; 37/56] START criterion=gini, max_depth=70, min_samples_split=2.........\n",
      "[CV 4/5; 37/56] END criterion=gini, max_depth=70, min_samples_split=2;, score=0.649 total time=   0.8s\n",
      "[CV 5/5; 37/56] START criterion=gini, max_depth=70, min_samples_split=2.........\n",
      "[CV 5/5; 37/56] END criterion=gini, max_depth=70, min_samples_split=2;, score=0.641 total time=   0.8s\n",
      "[CV 1/5; 38/56] START criterion=gini, max_depth=70, min_samples_split=4.........\n",
      "[CV 1/5; 38/56] END criterion=gini, max_depth=70, min_samples_split=4;, score=0.634 total time=   0.8s\n",
      "[CV 2/5; 38/56] START criterion=gini, max_depth=70, min_samples_split=4.........\n",
      "[CV 2/5; 38/56] END criterion=gini, max_depth=70, min_samples_split=4;, score=0.653 total time=   0.8s\n",
      "[CV 3/5; 38/56] START criterion=gini, max_depth=70, min_samples_split=4.........\n",
      "[CV 3/5; 38/56] END criterion=gini, max_depth=70, min_samples_split=4;, score=0.630 total time=   0.7s\n",
      "[CV 4/5; 38/56] START criterion=gini, max_depth=70, min_samples_split=4.........\n",
      "[CV 4/5; 38/56] END criterion=gini, max_depth=70, min_samples_split=4;, score=0.645 total time=   0.8s\n",
      "[CV 5/5; 38/56] START criterion=gini, max_depth=70, min_samples_split=4.........\n",
      "[CV 5/5; 38/56] END criterion=gini, max_depth=70, min_samples_split=4;, score=0.638 total time=   0.8s\n",
      "[CV 1/5; 39/56] START criterion=gini, max_depth=70, min_samples_split=8.........\n",
      "[CV 1/5; 39/56] END criterion=gini, max_depth=70, min_samples_split=8;, score=0.635 total time=   0.8s\n",
      "[CV 2/5; 39/56] START criterion=gini, max_depth=70, min_samples_split=8.........\n",
      "[CV 2/5; 39/56] END criterion=gini, max_depth=70, min_samples_split=8;, score=0.651 total time=   0.8s\n",
      "[CV 3/5; 39/56] START criterion=gini, max_depth=70, min_samples_split=8.........\n",
      "[CV 3/5; 39/56] END criterion=gini, max_depth=70, min_samples_split=8;, score=0.647 total time=   0.7s\n",
      "[CV 4/5; 39/56] START criterion=gini, max_depth=70, min_samples_split=8.........\n",
      "[CV 4/5; 39/56] END criterion=gini, max_depth=70, min_samples_split=8;, score=0.651 total time=   0.8s\n",
      "[CV 5/5; 39/56] START criterion=gini, max_depth=70, min_samples_split=8.........\n",
      "[CV 5/5; 39/56] END criterion=gini, max_depth=70, min_samples_split=8;, score=0.642 total time=   0.7s\n",
      "[CV 1/5; 40/56] START criterion=gini, max_depth=70, min_samples_split=10........\n",
      "[CV 1/5; 40/56] END criterion=gini, max_depth=70, min_samples_split=10;, score=0.635 total time=   0.8s\n",
      "[CV 2/5; 40/56] START criterion=gini, max_depth=70, min_samples_split=10........\n",
      "[CV 2/5; 40/56] END criterion=gini, max_depth=70, min_samples_split=10;, score=0.655 total time=   0.8s\n",
      "[CV 3/5; 40/56] START criterion=gini, max_depth=70, min_samples_split=10........\n",
      "[CV 3/5; 40/56] END criterion=gini, max_depth=70, min_samples_split=10;, score=0.652 total time=   0.8s\n",
      "[CV 4/5; 40/56] START criterion=gini, max_depth=70, min_samples_split=10........\n",
      "[CV 4/5; 40/56] END criterion=gini, max_depth=70, min_samples_split=10;, score=0.650 total time=   0.8s\n",
      "[CV 5/5; 40/56] START criterion=gini, max_depth=70, min_samples_split=10........\n",
      "[CV 5/5; 40/56] END criterion=gini, max_depth=70, min_samples_split=10;, score=0.637 total time=   0.7s\n",
      "[CV 1/5; 41/56] START criterion=gini, max_depth=90, min_samples_split=2.........\n",
      "[CV 1/5; 41/56] END criterion=gini, max_depth=90, min_samples_split=2;, score=0.626 total time=   0.8s\n",
      "[CV 2/5; 41/56] START criterion=gini, max_depth=90, min_samples_split=2.........\n",
      "[CV 2/5; 41/56] END criterion=gini, max_depth=90, min_samples_split=2;, score=0.655 total time=   0.7s\n",
      "[CV 3/5; 41/56] START criterion=gini, max_depth=90, min_samples_split=2.........\n",
      "[CV 3/5; 41/56] END criterion=gini, max_depth=90, min_samples_split=2;, score=0.639 total time=   0.8s\n",
      "[CV 4/5; 41/56] START criterion=gini, max_depth=90, min_samples_split=2.........\n",
      "[CV 4/5; 41/56] END criterion=gini, max_depth=90, min_samples_split=2;, score=0.643 total time=   0.8s\n",
      "[CV 5/5; 41/56] START criterion=gini, max_depth=90, min_samples_split=2.........\n",
      "[CV 5/5; 41/56] END criterion=gini, max_depth=90, min_samples_split=2;, score=0.638 total time=   0.8s\n",
      "[CV 1/5; 42/56] START criterion=gini, max_depth=90, min_samples_split=4.........\n",
      "[CV 1/5; 42/56] END criterion=gini, max_depth=90, min_samples_split=4;, score=0.633 total time=   0.8s\n",
      "[CV 2/5; 42/56] START criterion=gini, max_depth=90, min_samples_split=4.........\n",
      "[CV 2/5; 42/56] END criterion=gini, max_depth=90, min_samples_split=4;, score=0.648 total time=   0.7s\n",
      "[CV 3/5; 42/56] START criterion=gini, max_depth=90, min_samples_split=4.........\n",
      "[CV 3/5; 42/56] END criterion=gini, max_depth=90, min_samples_split=4;, score=0.637 total time=   0.8s\n",
      "[CV 4/5; 42/56] START criterion=gini, max_depth=90, min_samples_split=4.........\n",
      "[CV 4/5; 42/56] END criterion=gini, max_depth=90, min_samples_split=4;, score=0.647 total time=   0.7s\n",
      "[CV 5/5; 42/56] START criterion=gini, max_depth=90, min_samples_split=4.........\n",
      "[CV 5/5; 42/56] END criterion=gini, max_depth=90, min_samples_split=4;, score=0.637 total time=   0.8s\n",
      "[CV 1/5; 43/56] START criterion=gini, max_depth=90, min_samples_split=8.........\n",
      "[CV 1/5; 43/56] END criterion=gini, max_depth=90, min_samples_split=8;, score=0.644 total time=   0.8s\n",
      "[CV 2/5; 43/56] START criterion=gini, max_depth=90, min_samples_split=8.........\n",
      "[CV 2/5; 43/56] END criterion=gini, max_depth=90, min_samples_split=8;, score=0.656 total time=   0.7s\n",
      "[CV 3/5; 43/56] START criterion=gini, max_depth=90, min_samples_split=8.........\n",
      "[CV 3/5; 43/56] END criterion=gini, max_depth=90, min_samples_split=8;, score=0.639 total time=   0.8s\n",
      "[CV 4/5; 43/56] START criterion=gini, max_depth=90, min_samples_split=8.........\n",
      "[CV 4/5; 43/56] END criterion=gini, max_depth=90, min_samples_split=8;, score=0.652 total time=   0.8s\n",
      "[CV 5/5; 43/56] START criterion=gini, max_depth=90, min_samples_split=8.........\n",
      "[CV 5/5; 43/56] END criterion=gini, max_depth=90, min_samples_split=8;, score=0.640 total time=   0.8s\n",
      "[CV 1/5; 44/56] START criterion=gini, max_depth=90, min_samples_split=10........\n",
      "[CV 1/5; 44/56] END criterion=gini, max_depth=90, min_samples_split=10;, score=0.643 total time=   0.7s\n",
      "[CV 2/5; 44/56] START criterion=gini, max_depth=90, min_samples_split=10........\n",
      "[CV 2/5; 44/56] END criterion=gini, max_depth=90, min_samples_split=10;, score=0.651 total time=   0.7s\n",
      "[CV 3/5; 44/56] START criterion=gini, max_depth=90, min_samples_split=10........\n",
      "[CV 3/5; 44/56] END criterion=gini, max_depth=90, min_samples_split=10;, score=0.660 total time=   0.8s\n",
      "[CV 4/5; 44/56] START criterion=gini, max_depth=90, min_samples_split=10........\n",
      "[CV 4/5; 44/56] END criterion=gini, max_depth=90, min_samples_split=10;, score=0.649 total time=   0.8s\n",
      "[CV 5/5; 44/56] START criterion=gini, max_depth=90, min_samples_split=10........\n",
      "[CV 5/5; 44/56] END criterion=gini, max_depth=90, min_samples_split=10;, score=0.645 total time=   0.8s\n",
      "[CV 1/5; 45/56] START criterion=gini, max_depth=150, min_samples_split=2........\n",
      "[CV 1/5; 45/56] END criterion=gini, max_depth=150, min_samples_split=2;, score=0.629 total time=   0.8s\n",
      "[CV 2/5; 45/56] START criterion=gini, max_depth=150, min_samples_split=2........\n",
      "[CV 2/5; 45/56] END criterion=gini, max_depth=150, min_samples_split=2;, score=0.645 total time=   0.8s\n",
      "[CV 3/5; 45/56] START criterion=gini, max_depth=150, min_samples_split=2........\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 45/56] END criterion=gini, max_depth=150, min_samples_split=2;, score=0.636 total time=   0.8s\n",
      "[CV 4/5; 45/56] START criterion=gini, max_depth=150, min_samples_split=2........\n",
      "[CV 4/5; 45/56] END criterion=gini, max_depth=150, min_samples_split=2;, score=0.640 total time=   0.8s\n",
      "[CV 5/5; 45/56] START criterion=gini, max_depth=150, min_samples_split=2........\n",
      "[CV 5/5; 45/56] END criterion=gini, max_depth=150, min_samples_split=2;, score=0.644 total time=   0.8s\n",
      "[CV 1/5; 46/56] START criterion=gini, max_depth=150, min_samples_split=4........\n",
      "[CV 1/5; 46/56] END criterion=gini, max_depth=150, min_samples_split=4;, score=0.629 total time=   0.8s\n",
      "[CV 2/5; 46/56] START criterion=gini, max_depth=150, min_samples_split=4........\n",
      "[CV 2/5; 46/56] END criterion=gini, max_depth=150, min_samples_split=4;, score=0.642 total time=   0.7s\n",
      "[CV 3/5; 46/56] START criterion=gini, max_depth=150, min_samples_split=4........\n",
      "[CV 3/5; 46/56] END criterion=gini, max_depth=150, min_samples_split=4;, score=0.646 total time=   0.8s\n",
      "[CV 4/5; 46/56] START criterion=gini, max_depth=150, min_samples_split=4........\n",
      "[CV 4/5; 46/56] END criterion=gini, max_depth=150, min_samples_split=4;, score=0.645 total time=   0.8s\n",
      "[CV 5/5; 46/56] START criterion=gini, max_depth=150, min_samples_split=4........\n",
      "[CV 5/5; 46/56] END criterion=gini, max_depth=150, min_samples_split=4;, score=0.642 total time=   0.9s\n",
      "[CV 1/5; 47/56] START criterion=gini, max_depth=150, min_samples_split=8........\n",
      "[CV 1/5; 47/56] END criterion=gini, max_depth=150, min_samples_split=8;, score=0.645 total time=   0.9s\n",
      "[CV 2/5; 47/56] START criterion=gini, max_depth=150, min_samples_split=8........\n",
      "[CV 2/5; 47/56] END criterion=gini, max_depth=150, min_samples_split=8;, score=0.654 total time=   0.8s\n",
      "[CV 3/5; 47/56] START criterion=gini, max_depth=150, min_samples_split=8........\n",
      "[CV 3/5; 47/56] END criterion=gini, max_depth=150, min_samples_split=8;, score=0.646 total time=   0.8s\n",
      "[CV 4/5; 47/56] START criterion=gini, max_depth=150, min_samples_split=8........\n",
      "[CV 4/5; 47/56] END criterion=gini, max_depth=150, min_samples_split=8;, score=0.651 total time=   0.8s\n",
      "[CV 5/5; 47/56] START criterion=gini, max_depth=150, min_samples_split=8........\n",
      "[CV 5/5; 47/56] END criterion=gini, max_depth=150, min_samples_split=8;, score=0.641 total time=   0.8s\n",
      "[CV 1/5; 48/56] START criterion=gini, max_depth=150, min_samples_split=10.......\n",
      "[CV 1/5; 48/56] END criterion=gini, max_depth=150, min_samples_split=10;, score=0.642 total time=   0.8s\n",
      "[CV 2/5; 48/56] START criterion=gini, max_depth=150, min_samples_split=10.......\n",
      "[CV 2/5; 48/56] END criterion=gini, max_depth=150, min_samples_split=10;, score=0.655 total time=   0.8s\n",
      "[CV 3/5; 48/56] START criterion=gini, max_depth=150, min_samples_split=10.......\n",
      "[CV 3/5; 48/56] END criterion=gini, max_depth=150, min_samples_split=10;, score=0.652 total time=   0.8s\n",
      "[CV 4/5; 48/56] START criterion=gini, max_depth=150, min_samples_split=10.......\n",
      "[CV 4/5; 48/56] END criterion=gini, max_depth=150, min_samples_split=10;, score=0.651 total time=   0.7s\n",
      "[CV 5/5; 48/56] START criterion=gini, max_depth=150, min_samples_split=10.......\n",
      "[CV 5/5; 48/56] END criterion=gini, max_depth=150, min_samples_split=10;, score=0.647 total time=   0.7s\n",
      "[CV 1/5; 49/56] START criterion=gini, max_depth=200, min_samples_split=2........\n",
      "[CV 1/5; 49/56] END criterion=gini, max_depth=200, min_samples_split=2;, score=0.630 total time=   0.8s\n",
      "[CV 2/5; 49/56] START criterion=gini, max_depth=200, min_samples_split=2........\n",
      "[CV 2/5; 49/56] END criterion=gini, max_depth=200, min_samples_split=2;, score=0.643 total time=   0.8s\n",
      "[CV 3/5; 49/56] START criterion=gini, max_depth=200, min_samples_split=2........\n",
      "[CV 3/5; 49/56] END criterion=gini, max_depth=200, min_samples_split=2;, score=0.640 total time=   0.8s\n",
      "[CV 4/5; 49/56] START criterion=gini, max_depth=200, min_samples_split=2........\n",
      "[CV 4/5; 49/56] END criterion=gini, max_depth=200, min_samples_split=2;, score=0.644 total time=   0.8s\n",
      "[CV 5/5; 49/56] START criterion=gini, max_depth=200, min_samples_split=2........\n",
      "[CV 5/5; 49/56] END criterion=gini, max_depth=200, min_samples_split=2;, score=0.640 total time=   0.8s\n",
      "[CV 1/5; 50/56] START criterion=gini, max_depth=200, min_samples_split=4........\n",
      "[CV 1/5; 50/56] END criterion=gini, max_depth=200, min_samples_split=4;, score=0.634 total time=   0.8s\n",
      "[CV 2/5; 50/56] START criterion=gini, max_depth=200, min_samples_split=4........\n",
      "[CV 2/5; 50/56] END criterion=gini, max_depth=200, min_samples_split=4;, score=0.646 total time=   0.8s\n",
      "[CV 3/5; 50/56] START criterion=gini, max_depth=200, min_samples_split=4........\n",
      "[CV 3/5; 50/56] END criterion=gini, max_depth=200, min_samples_split=4;, score=0.636 total time=   0.8s\n",
      "[CV 4/5; 50/56] START criterion=gini, max_depth=200, min_samples_split=4........\n",
      "[CV 4/5; 50/56] END criterion=gini, max_depth=200, min_samples_split=4;, score=0.645 total time=   0.8s\n",
      "[CV 5/5; 50/56] START criterion=gini, max_depth=200, min_samples_split=4........\n",
      "[CV 5/5; 50/56] END criterion=gini, max_depth=200, min_samples_split=4;, score=0.637 total time=   0.7s\n",
      "[CV 1/5; 51/56] START criterion=gini, max_depth=200, min_samples_split=8........\n",
      "[CV 1/5; 51/56] END criterion=gini, max_depth=200, min_samples_split=8;, score=0.638 total time=   0.8s\n",
      "[CV 2/5; 51/56] START criterion=gini, max_depth=200, min_samples_split=8........\n",
      "[CV 2/5; 51/56] END criterion=gini, max_depth=200, min_samples_split=8;, score=0.654 total time=   0.7s\n",
      "[CV 3/5; 51/56] START criterion=gini, max_depth=200, min_samples_split=8........\n",
      "[CV 3/5; 51/56] END criterion=gini, max_depth=200, min_samples_split=8;, score=0.639 total time=   0.7s\n",
      "[CV 4/5; 51/56] START criterion=gini, max_depth=200, min_samples_split=8........\n",
      "[CV 4/5; 51/56] END criterion=gini, max_depth=200, min_samples_split=8;, score=0.652 total time=   0.8s\n",
      "[CV 5/5; 51/56] START criterion=gini, max_depth=200, min_samples_split=8........\n",
      "[CV 5/5; 51/56] END criterion=gini, max_depth=200, min_samples_split=8;, score=0.645 total time=   0.7s\n",
      "[CV 1/5; 52/56] START criterion=gini, max_depth=200, min_samples_split=10.......\n",
      "[CV 1/5; 52/56] END criterion=gini, max_depth=200, min_samples_split=10;, score=0.640 total time=   0.8s\n",
      "[CV 2/5; 52/56] START criterion=gini, max_depth=200, min_samples_split=10.......\n",
      "[CV 2/5; 52/56] END criterion=gini, max_depth=200, min_samples_split=10;, score=0.654 total time=   0.7s\n",
      "[CV 3/5; 52/56] START criterion=gini, max_depth=200, min_samples_split=10.......\n",
      "[CV 3/5; 52/56] END criterion=gini, max_depth=200, min_samples_split=10;, score=0.651 total time=   0.8s\n",
      "[CV 4/5; 52/56] START criterion=gini, max_depth=200, min_samples_split=10.......\n",
      "[CV 4/5; 52/56] END criterion=gini, max_depth=200, min_samples_split=10;, score=0.652 total time=   0.8s\n",
      "[CV 5/5; 52/56] START criterion=gini, max_depth=200, min_samples_split=10.......\n",
      "[CV 5/5; 52/56] END criterion=gini, max_depth=200, min_samples_split=10;, score=0.644 total time=   0.7s\n",
      "[CV 1/5; 53/56] START criterion=gini, max_depth=300, min_samples_split=2........\n",
      "[CV 1/5; 53/56] END criterion=gini, max_depth=300, min_samples_split=2;, score=0.630 total time=   0.8s\n",
      "[CV 2/5; 53/56] START criterion=gini, max_depth=300, min_samples_split=2........\n",
      "[CV 2/5; 53/56] END criterion=gini, max_depth=300, min_samples_split=2;, score=0.644 total time=   0.7s\n",
      "[CV 3/5; 53/56] START criterion=gini, max_depth=300, min_samples_split=2........\n",
      "[CV 3/5; 53/56] END criterion=gini, max_depth=300, min_samples_split=2;, score=0.633 total time=   0.8s\n",
      "[CV 4/5; 53/56] START criterion=gini, max_depth=300, min_samples_split=2........\n",
      "[CV 4/5; 53/56] END criterion=gini, max_depth=300, min_samples_split=2;, score=0.648 total time=   0.7s\n",
      "[CV 5/5; 53/56] START criterion=gini, max_depth=300, min_samples_split=2........\n",
      "[CV 5/5; 53/56] END criterion=gini, max_depth=300, min_samples_split=2;, score=0.640 total time=   0.8s\n",
      "[CV 1/5; 54/56] START criterion=gini, max_depth=300, min_samples_split=4........\n",
      "[CV 1/5; 54/56] END criterion=gini, max_depth=300, min_samples_split=4;, score=0.625 total time=   0.8s\n",
      "[CV 2/5; 54/56] START criterion=gini, max_depth=300, min_samples_split=4........\n",
      "[CV 2/5; 54/56] END criterion=gini, max_depth=300, min_samples_split=4;, score=0.648 total time=   0.8s\n",
      "[CV 3/5; 54/56] START criterion=gini, max_depth=300, min_samples_split=4........\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 54/56] END criterion=gini, max_depth=300, min_samples_split=4;, score=0.639 total time=   0.9s\n",
      "[CV 4/5; 54/56] START criterion=gini, max_depth=300, min_samples_split=4........\n",
      "[CV 4/5; 54/56] END criterion=gini, max_depth=300, min_samples_split=4;, score=0.652 total time=   0.8s\n",
      "[CV 5/5; 54/56] START criterion=gini, max_depth=300, min_samples_split=4........\n",
      "[CV 5/5; 54/56] END criterion=gini, max_depth=300, min_samples_split=4;, score=0.643 total time=   0.9s\n",
      "[CV 1/5; 55/56] START criterion=gini, max_depth=300, min_samples_split=8........\n",
      "[CV 1/5; 55/56] END criterion=gini, max_depth=300, min_samples_split=8;, score=0.644 total time=   0.9s\n",
      "[CV 2/5; 55/56] START criterion=gini, max_depth=300, min_samples_split=8........\n",
      "[CV 2/5; 55/56] END criterion=gini, max_depth=300, min_samples_split=8;, score=0.650 total time=   0.8s\n",
      "[CV 3/5; 55/56] START criterion=gini, max_depth=300, min_samples_split=8........\n",
      "[CV 3/5; 55/56] END criterion=gini, max_depth=300, min_samples_split=8;, score=0.647 total time=   0.9s\n",
      "[CV 4/5; 55/56] START criterion=gini, max_depth=300, min_samples_split=8........\n",
      "[CV 4/5; 55/56] END criterion=gini, max_depth=300, min_samples_split=8;, score=0.651 total time=   0.8s\n",
      "[CV 5/5; 55/56] START criterion=gini, max_depth=300, min_samples_split=8........\n",
      "[CV 5/5; 55/56] END criterion=gini, max_depth=300, min_samples_split=8;, score=0.642 total time=   0.7s\n",
      "[CV 1/5; 56/56] START criterion=gini, max_depth=300, min_samples_split=10.......\n",
      "[CV 1/5; 56/56] END criterion=gini, max_depth=300, min_samples_split=10;, score=0.642 total time=   0.8s\n",
      "[CV 2/5; 56/56] START criterion=gini, max_depth=300, min_samples_split=10.......\n",
      "[CV 2/5; 56/56] END criterion=gini, max_depth=300, min_samples_split=10;, score=0.655 total time=   0.8s\n",
      "[CV 3/5; 56/56] START criterion=gini, max_depth=300, min_samples_split=10.......\n",
      "[CV 3/5; 56/56] END criterion=gini, max_depth=300, min_samples_split=10;, score=0.654 total time=   0.8s\n",
      "[CV 4/5; 56/56] START criterion=gini, max_depth=300, min_samples_split=10.......\n",
      "[CV 4/5; 56/56] END criterion=gini, max_depth=300, min_samples_split=10;, score=0.654 total time=   0.8s\n",
      "[CV 5/5; 56/56] START criterion=gini, max_depth=300, min_samples_split=10.......\n",
      "[CV 5/5; 56/56] END criterion=gini, max_depth=300, min_samples_split=10;, score=0.644 total time=   0.9s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=DecisionTreeClassifier(),\n",
       "             param_grid={'criterion': ['entropy', 'gini'],\n",
       "                         'max_depth': [10, 30, 70, 90, 150, 200, 300],\n",
       "                         'min_samples_split': [2, 4, 8, 10]},\n",
       "             scoring='balanced_accuracy', verbose=10)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "parameters = {  'max_depth': [10, 30, 70, 90, 150, 200, 300],\n",
    "                'criterion': ['entropy', 'gini'],\n",
    "                'min_samples_split': [2, 4, 8, 10]\n",
    "                 }\n",
    "\n",
    "model = DecisionTreeClassifier()\n",
    "\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=parameters, verbose=10, scoring=\"balanced_accuracy\")\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9242cfc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 4}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "752e66ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7927995034140286\n",
      "Balanced Accuracy:  0.6675698811460264\n",
      "Precision:  0.8180877789271465\n",
      "Recall:  0.9266822899229996\n",
      "F1:  0.8690055725610235\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeClassifier(criterion='gini', max_depth=10, min_samples_split=4)\n",
    "model.fit(X_train, y_train)\n",
    "predicted = model.predict(X_test)\n",
    "evaluate(predicted, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda73345",
   "metadata": {},
   "source": [
    "As we can see `Logistic regression` has the best `Accuracy` and Out neural network has the best `Balanced Accuracy` and `F1 score`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613934d9",
   "metadata": {},
   "source": [
    "Now let's test another model which is going to be `Naive Bayes`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "631fc745",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "model = GaussianNB()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6fe72064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.6862818125387958\n",
      "Balanced Accuracy:  0.7106833439860412\n",
      "Precision:  0.8880882684080162\n",
      "Recall:  0.6601941747572816\n",
      "F1:  0.7573691790686511\n"
     ]
    }
   ],
   "source": [
    "predicted = model.predict(X_test)\n",
    "evaluate(predicted, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3e23f74f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There 3614 0 values in prediction.\n",
      "There 4441 1 values in prediction.\n",
      "There 2081 0 values in test dataset.\n",
      "There 5974 1 values in test dataset.\n"
     ]
    }
   ],
   "source": [
    "count_0_predicted = 0\n",
    "count_1_predicted = 0\n",
    "count_0_actual = 0\n",
    "count_1_actual = 0\n",
    "for i in range(len(predicted)):\n",
    "    if predicted[i] == 0:\n",
    "        count_0_predicted += 1\n",
    "    else:\n",
    "        count_1_predicted += 1\n",
    "    if y_test.iloc[i] == 0:\n",
    "        count_0_actual += 1\n",
    "    else:\n",
    "        count_1_actual += 1\n",
    "print(f\"There {count_0_predicted} 0 values in prediction.\")\n",
    "print(f\"There {count_1_predicted} 1 values in prediction.\")\n",
    "\n",
    "print(f\"There {count_0_actual} 0 values in test dataset.\")\n",
    "print(f\"There {count_1_actual} 1 values in test dataset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42936a7",
   "metadata": {},
   "source": [
    "Also it has good balanced_accuracy but it's just like a guess between genders, and as a result we got 68% accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e19e95",
   "metadata": {},
   "source": [
    "Lets now focus on ANN.\n",
    "\n",
    "We will change number of features here to see what will happen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4dd6f8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from tqdm import tqdm\n",
    "\n",
    "def create_new_dataset(percentage):\n",
    "    features = dict()\n",
    "\n",
    "    for query in queries:\n",
    "        if (queries_value_count[query] > len(df) * percentage):\n",
    "            features[f\"q{query}\"] = 0 \n",
    "    print(\"Queries completed\")\n",
    "    for app in apps:\n",
    "        if (apps_value_count[app] > len(df) * percentage):\n",
    "            features[f\"a{app}\"] = 0\n",
    "    print(\"Apps completed\")\n",
    "    for game in games:\n",
    "        if (games_value_count[game] > len(df) * percentage):\n",
    "            features[f\"g{game}\"] = 0\n",
    "    print(\"Games completed\")\n",
    "\n",
    "    features[\"gender\"] = 0\n",
    "    \n",
    "    new_dataset = []\n",
    "    for index, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "        new_item = copy.copy(features)\n",
    "        for query in row['queries']:\n",
    "            if check_key(new_item, f\"q{query}\"):\n",
    "                new_item[f\"q{query}\"] = 1\n",
    "        for game in row['games']:\n",
    "            if check_key(new_item, f\"g{game}\"):\n",
    "                new_item[f\"g{game}\"] = 1\n",
    "        for app in row['apps']:\n",
    "            if check_key(new_item, f\"a{app}\"):\n",
    "                new_item[f\"a{app}\"] = 1\n",
    "        new_item['gender'] = row['gender']\n",
    "        assert len(new_item) == len(features), \"Featues count error\"\n",
    "        new_dataset.append(copy.copy(new_item))\n",
    "    \n",
    "    new_df = pd.DataFrame.from_dict(new_dataset, orient='columns')\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ec1d158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queries completed\n",
      "Apps completed\n",
      "Games completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 40271/40271 [00:04<00:00, 8223.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queries completed\n",
      "Apps completed\n",
      "Games completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 40271/40271 [00:05<00:00, 7851.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queries completed\n",
      "Apps completed\n",
      "Games completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 40271/40271 [00:04<00:00, 8059.71it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset_3_percent = create_new_dataset(0.03)\n",
    "dataset_10_percent = create_new_dataset(0.1)\n",
    "dataset_20_percent = create_new_dataset(0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46917fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40271, 315)\n",
      "(40271, 114)\n",
      "(40271, 58)\n"
     ]
    }
   ],
   "source": [
    "print(dataset_3_percent.shape)\n",
    "print(dataset_10_percent.shape)\n",
    "print(dataset_20_percent.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3cef8643",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_3_percent['gender'] = dataset_3_percent['gender'].replace({'M':0, 'F':1})\n",
    "dataset_10_percent['gender'] = dataset_10_percent['gender'].replace({'M':0, 'F':1})\n",
    "dataset_20_percent['gender'] = dataset_20_percent['gender'].replace({'M':0, 'F':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fc88fbdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1 Complete [00h 06m 07s]\n",
      "val_accuracy: 0.8269397616386414\n",
      "\n",
      "Best val_accuracy So Far: 0.8269397616386414\n",
      "Total elapsed time: 00h 06m 07s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from kerastuner.engine.hyperparameters import HyperParameters\n",
    "from kerastuner.tuners import RandomSearch\n",
    "import time\n",
    "\n",
    "X, y =  dataset_3_percent.drop(columns=[\"gender\"]), dataset_3_percent[\"gender\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "opt = SGD(learning_rate=0.01)\n",
    "input_d = dataset_3_percent.shape[1]\n",
    "\n",
    "def build_model(hp):\n",
    "    model = keras.models.Sequential()\n",
    "    \n",
    "    model.add(Dense(hp.Int(\"input_units\", min_value=100, max_value=500, step=20), input_dim=input_d, activation='relu'))\n",
    "    \n",
    "    for i in range(hp.Int('n_layers', 1, 10)):\n",
    "        model.add(Dense(hp.Int(f\"dense_units_{i}\", min_value=10, max_value=300, step=10), activation='relu'))\n",
    "    \n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "t = time.time()\n",
    "LOG_DIR = f\"{int(t)}\"\n",
    "\n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective = \"val_accuracy\",\n",
    "    max_trials = 1,\n",
    "    executions_per_trial = 1,\n",
    "    directory = LOG_DIR\n",
    ")\n",
    "\n",
    "tuner.search(x=X_train, y=y_train, epochs=100, batch_size=10,validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "baeded13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1627980159.3318021"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "50c0140f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_units': 340, 'n_layers': 6, 'dense_units_0': 100, 'dense_units_1': 10, 'dense_units_2': 10, 'dense_units_3': 10, 'dense_units_4': 10, 'dense_units_5': 10}\n",
      "Results summary\n",
      "Results in 1627980159\\untitled_project\n",
      "Showing 10 best trials\n",
      "Objective(name='val_accuracy', direction='max')\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "input_units: 340\n",
      "n_layers: 6\n",
      "dense_units_0: 100\n",
      "dense_units_1: 10\n",
      "dense_units_2: 10\n",
      "dense_units_3: 10\n",
      "dense_units_4: 10\n",
      "dense_units_5: 10\n",
      "Score: 0.8269397616386414\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "with open(f\"tuner_{int(t)}.pkl\", \"wb\") as f:\n",
    "    pickle.dump(tuner, f)\n",
    "    \n",
    "tuner = pickle.load(open(\"tuner_1627980159.pkl\", \"rb\"))\n",
    "print(tuner.get_best_hyperparameters()[0].values)\n",
    "print(tuner.results_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dbf772e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2900/2900 [==============================] - 4s 1ms/step - loss: 0.3753 - accuracy: 0.8380 - val_loss: 0.3886 - val_accuracy: 0.8293\n",
      "Epoch 2/100\n",
      "2900/2900 [==============================] - 3s 1ms/step - loss: 0.3681 - accuracy: 0.8426 - val_loss: 0.3858 - val_accuracy: 0.8318\n",
      "Epoch 3/100\n",
      "2900/2900 [==============================] - 3s 1ms/step - loss: 0.3621 - accuracy: 0.8439 - val_loss: 0.3822 - val_accuracy: 0.8302\n",
      "Epoch 4/100\n",
      "2900/2900 [==============================] - 3s 1ms/step - loss: 0.3531 - accuracy: 0.8492 - val_loss: 0.3987 - val_accuracy: 0.8187\n",
      "Epoch 5/100\n",
      "2900/2900 [==============================] - 3s 1ms/step - loss: 0.3446 - accuracy: 0.8529 - val_loss: 0.3842 - val_accuracy: 0.8309\n",
      "Epoch 6/100\n",
      "2900/2900 [==============================] - 3s 1ms/step - loss: 0.3321 - accuracy: 0.8616 - val_loss: 0.4112 - val_accuracy: 0.8203\n"
     ]
    }
   ],
   "source": [
    "callback = keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "model = tuner.get_best_models()[0]\n",
    "history = model.fit(X_train, y_train, validation_split=0.1, epochs=100, batch_size=10, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ecaf36fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b176b445",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8176288019863439\n",
      "Balanced Accuracy:  0.6836827920186578\n",
      "Precision:  0.7833333333333333\n",
      "Recall:  0.40653531955790484\n",
      "F1:  0.5352736475798798\n"
     ]
    }
   ],
   "source": [
    "predicted = model.predict_classes(X_test)\n",
    "evaluate(predicted, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7aaaeec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1 Complete [00h 04m 35s]\n",
      "val_accuracy: 0.791558027267456\n",
      "\n",
      "Best val_accuracy So Far: 0.791558027267456\n",
      "Total elapsed time: 00h 04m 35s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from kerastuner.engine.hyperparameters import HyperParameters\n",
    "from kerastuner.tuners import RandomSearch\n",
    "import time\n",
    "\n",
    "X, y =  dataset_10_percent.drop(columns=[\"gender\"]), dataset_10_percent[\"gender\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "opt = SGD(learning_rate=0.01)\n",
    "input_d = dataset_10_percent.shape[1]\n",
    "\n",
    "def build_model(hp):\n",
    "    model = keras.models.Sequential()\n",
    "    \n",
    "    model.add(Dense(hp.Int(\"input_units\", min_value=100, max_value=500, step=20), input_dim=input_d, activation='relu'))\n",
    "    \n",
    "    for i in range(hp.Int('n_layers', 1, 10)):\n",
    "        model.add(Dense(hp.Int(f\"dense_units_{i}\", min_value=10, max_value=300, step=10), activation='relu'))\n",
    "    \n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "t = time.time()\n",
    "LOG_DIR = f\"{int(t)}\"\n",
    "\n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective = \"val_accuracy\",\n",
    "    max_trials = 1,\n",
    "    executions_per_trial = 1,\n",
    "    directory = LOG_DIR\n",
    ")\n",
    "\n",
    "tuner.search(x=X_train, y=y_train, epochs=100, batch_size=10,validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a19985c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1627981259.7144318"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "67a0c915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_units': 100, 'n_layers': 7, 'dense_units_0': 210, 'dense_units_1': 10, 'dense_units_2': 10, 'dense_units_3': 10, 'dense_units_4': 10, 'dense_units_5': 10, 'dense_units_6': 10}\n",
      "Results summary\n",
      "Results in 1627981259\\untitled_project\n",
      "Showing 10 best trials\n",
      "Objective(name='val_accuracy', direction='max')\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "input_units: 100\n",
      "n_layers: 7\n",
      "dense_units_0: 210\n",
      "dense_units_1: 10\n",
      "dense_units_2: 10\n",
      "dense_units_3: 10\n",
      "dense_units_4: 10\n",
      "dense_units_5: 10\n",
      "dense_units_6: 10\n",
      "Score: 0.791558027267456\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "with open(f\"tuner_{int(t)}.pkl\", \"wb\") as f:\n",
    "    pickle.dump(tuner, f)\n",
    "    \n",
    "tuner = pickle.load(open(\"tuner_1627981259.pkl\", \"rb\"))\n",
    "print(tuner.get_best_hyperparameters()[0].values)\n",
    "print(tuner.results_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7a9449d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2900/2900 [==============================] - 3s 844us/step - loss: 0.4472 - accuracy: 0.7966 - val_loss: 0.4569 - val_accuracy: 0.7908\n",
      "Epoch 2/100\n",
      "2900/2900 [==============================] - 2s 809us/step - loss: 0.4451 - accuracy: 0.7982 - val_loss: 0.4531 - val_accuracy: 0.7908\n",
      "Epoch 3/100\n",
      "2900/2900 [==============================] - 2s 808us/step - loss: 0.4426 - accuracy: 0.7979 - val_loss: 0.4556 - val_accuracy: 0.7877\n",
      "Epoch 4/100\n",
      "2900/2900 [==============================] - 2s 815us/step - loss: 0.4400 - accuracy: 0.8002 - val_loss: 0.4549 - val_accuracy: 0.7917\n",
      "Epoch 5/100\n",
      "2900/2900 [==============================] - 2s 822us/step - loss: 0.4379 - accuracy: 0.8021 - val_loss: 0.4609 - val_accuracy: 0.7880\n"
     ]
    }
   ],
   "source": [
    "callback = keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "model = tuner.get_best_models()[0]\n",
    "history = model.fit(X_train, y_train, validation_split=0.1, epochs=100, batch_size=10, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f30670c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "95f92e02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.786219739292365\n",
      "Balanced Accuracy:  0.6177277975503974\n",
      "Precision:  0.735873850197109\n",
      "Recall:  0.2691013935607881\n",
      "F1:  0.39408866995073893\n"
     ]
    }
   ],
   "source": [
    "predicted = model.predict_classes(X_test)\n",
    "evaluate(predicted, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "755f62ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1 Complete [00h 04m 32s]\n",
      "val_accuracy: 0.751334547996521\n",
      "\n",
      "Best val_accuracy So Far: 0.751334547996521\n",
      "Total elapsed time: 00h 04m 32s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from kerastuner.engine.hyperparameters import HyperParameters\n",
    "from kerastuner.tuners import RandomSearch\n",
    "import time\n",
    "\n",
    "X, y =  dataset_20_percent.drop(columns=[\"gender\"]), dataset_20_percent[\"gender\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "opt = SGD(learning_rate=0.01)\n",
    "input_d = dataset_20_percent.shape[1]\n",
    "\n",
    "def build_model(hp):\n",
    "    model = keras.models.Sequential()\n",
    "    \n",
    "    model.add(Dense(hp.Int(\"input_units\", min_value=100, max_value=500, step=20), input_dim=input_d, activation='relu'))\n",
    "    \n",
    "    for i in range(hp.Int('n_layers', 1, 10)):\n",
    "        model.add(Dense(hp.Int(f\"dense_units_{i}\", min_value=10, max_value=300, step=10), activation='relu'))\n",
    "    \n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "t = time.time()\n",
    "LOG_DIR = f\"{int(t)}\"\n",
    "\n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective = \"val_accuracy\",\n",
    "    max_trials = 1,\n",
    "    executions_per_trial = 1,\n",
    "    directory = LOG_DIR\n",
    ")\n",
    "\n",
    "tuner.search(x=X_train, y=y_train, epochs=100, batch_size=10,validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7c0a3185",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1627981770.58637"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f0daddc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_units': 260, 'n_layers': 3, 'dense_units_0': 190, 'dense_units_1': 10, 'dense_units_2': 10}\n",
      "Results summary\n",
      "Results in 1627981770\\untitled_project\n",
      "Showing 10 best trials\n",
      "Objective(name='val_accuracy', direction='max')\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "input_units: 260\n",
      "n_layers: 3\n",
      "dense_units_0: 190\n",
      "dense_units_1: 10\n",
      "dense_units_2: 10\n",
      "Score: 0.751334547996521\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "with open(f\"tuner_{int(t)}.pkl\", \"wb\") as f:\n",
    "    pickle.dump(tuner, f)\n",
    "    \n",
    "tuner = pickle.load(open(\"tuner_1627981770.pkl\", \"rb\"))\n",
    "print(tuner.get_best_hyperparameters()[0].values)\n",
    "print(tuner.results_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "da42e483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2900/2900 [==============================] - 3s 813us/step - loss: 0.5061 - accuracy: 0.7584 - val_loss: 0.5062 - val_accuracy: 0.7598\n",
      "Epoch 2/100\n",
      "2900/2900 [==============================] - 2s 764us/step - loss: 0.5041 - accuracy: 0.7597 - val_loss: 0.5031 - val_accuracy: 0.7598\n",
      "Epoch 3/100\n",
      "2900/2900 [==============================] - 2s 772us/step - loss: 0.5027 - accuracy: 0.7601 - val_loss: 0.5028 - val_accuracy: 0.7573\n",
      "Epoch 4/100\n",
      "2900/2900 [==============================] - 2s 787us/step - loss: 0.5008 - accuracy: 0.7630 - val_loss: 0.5079 - val_accuracy: 0.7604\n",
      "Epoch 5/100\n",
      "2900/2900 [==============================] - 2s 745us/step - loss: 0.4992 - accuracy: 0.7637 - val_loss: 0.5087 - val_accuracy: 0.7573\n",
      "Epoch 6/100\n",
      "2900/2900 [==============================] - 2s 749us/step - loss: 0.4974 - accuracy: 0.7642 - val_loss: 0.5037 - val_accuracy: 0.7595\n"
     ]
    }
   ],
   "source": [
    "callback = keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "model = tuner.get_best_models()[0]\n",
    "history = model.fit(X_train, y_train, validation_split=0.1, epochs=100, batch_size=10, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "49a8dbde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "494874e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.748975791433892\n",
      "Balanced Accuracy:  0.571325053125453\n",
      "Precision:  0.5373891001267427\n",
      "Recall:  0.20374819798173954\n",
      "F1:  0.2954703832752613\n"
     ]
    }
   ],
   "source": [
    "predicted = model.predict_classes(X_test)\n",
    "evaluate(predicted, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
