{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf102f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50da8a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"data/gender.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49fe7f6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>queries</th>\n",
       "      <th>apps</th>\n",
       "      <th>games</th>\n",
       "      <th>gender</th>\n",
       "      <th>birth_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[216, 359, 12329, 3, 45, 4002, 2066, 32, 3931,...</td>\n",
       "      <td>[4, 4, 25, 7, 30, 58, 16, 19, 17, 21, 10, 10, ...</td>\n",
       "      <td>[9151, 208]</td>\n",
       "      <td>M</td>\n",
       "      <td>1366.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[]</td>\n",
       "      <td>[129, 71, 9, 8, 11, 25, 18, 58, 6, 16, 125, 12...</td>\n",
       "      <td>[460, 4939, 14, 232, 6387, 1758, 5834, 3, 2]</td>\n",
       "      <td>F</td>\n",
       "      <td>1359.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[23463, 18831]</td>\n",
       "      <td>[9, 174, 65, 8, 63, 97, 62, 103, 61, 116, 59, ...</td>\n",
       "      <td>[448, 723, 267, 9064, 10634, 166, 782, 224, 27...</td>\n",
       "      <td>M</td>\n",
       "      <td>1373.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1634, 3609, 654]</td>\n",
       "      <td>[99, 73, 9, 8, 59, 37, 131, 3, 89, 6, 24, 16, ...</td>\n",
       "      <td>[78, 2607, 478, 435, 9, 192]</td>\n",
       "      <td>M</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[11064, 227, 623, 1301, 43999, 35411, 2492, 11...</td>\n",
       "      <td>[9, 8, 17, 54, 3, 25, 22, 6, 21, 7, 14, 5, 817...</td>\n",
       "      <td>[1702, 1, 53]</td>\n",
       "      <td>M</td>\n",
       "      <td>1364.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             queries  \\\n",
       "0  [216, 359, 12329, 3, 45, 4002, 2066, 32, 3931,...   \n",
       "1                                                 []   \n",
       "2                                     [23463, 18831]   \n",
       "3                                  [1634, 3609, 654]   \n",
       "4  [11064, 227, 623, 1301, 43999, 35411, 2492, 11...   \n",
       "\n",
       "                                                apps  \\\n",
       "0  [4, 4, 25, 7, 30, 58, 16, 19, 17, 21, 10, 10, ...   \n",
       "1  [129, 71, 9, 8, 11, 25, 18, 58, 6, 16, 125, 12...   \n",
       "2  [9, 174, 65, 8, 63, 97, 62, 103, 61, 116, 59, ...   \n",
       "3  [99, 73, 9, 8, 59, 37, 131, 3, 89, 6, 24, 16, ...   \n",
       "4  [9, 8, 17, 54, 3, 25, 22, 6, 21, 7, 14, 5, 817...   \n",
       "\n",
       "                                               games gender  birth_year  \n",
       "0                                        [9151, 208]      M      1366.0  \n",
       "1       [460, 4939, 14, 232, 6387, 1758, 5834, 3, 2]      F      1359.0  \n",
       "2  [448, 723, 267, 9064, 10634, 166, 782, 224, 27...      M      1373.0  \n",
       "3                       [78, 2607, 478, 435, 9, 192]      M         0.0  \n",
       "4                                      [1702, 1, 53]      M      1364.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet(DATA_DIR, engine=\"pyarrow\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "514c97b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>queries</th>\n",
       "      <th>apps</th>\n",
       "      <th>games</th>\n",
       "      <th>gender</th>\n",
       "      <th>birth_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40266</th>\n",
       "      <td>[13388, 10571, 122, 1961, 42946, 823, 3349, 10...</td>\n",
       "      <td>[9, 8, 17, 3, 25, 22, 6, 24, 12, 7, 14, 5, 4, ...</td>\n",
       "      <td>[3, 55, 1115, 135, 410, 38, 1426, 107, 374]</td>\n",
       "      <td>M</td>\n",
       "      <td>1394.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40267</th>\n",
       "      <td>[2655, 11, 1732, 2847, 15222, 884, 39, 1433, 2...</td>\n",
       "      <td>[8, 11, 10, 10, 39, 17, 771, 48, 3, 25, 95, 22...</td>\n",
       "      <td>[717]</td>\n",
       "      <td>M</td>\n",
       "      <td>1354.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40268</th>\n",
       "      <td>[9, 33200, 5028, 357, 4, 233, 262, 2180, 376, ...</td>\n",
       "      <td>[54, 9, 8, 10, 10, 39, 17, 48, 3, 25, 6, 21, 1...</td>\n",
       "      <td>[312, 22]</td>\n",
       "      <td>M</td>\n",
       "      <td>1364.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40269</th>\n",
       "      <td>[9, 276, 27, 1074]</td>\n",
       "      <td>[9, 8, 17, 48, 54, 3, 25, 22, 6, 21, 7, 45, 14...</td>\n",
       "      <td>[73, 2, 53, 75]</td>\n",
       "      <td>M</td>\n",
       "      <td>1365.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40270</th>\n",
       "      <td>[6421, 11377, 6980, 852, 31, 185, 2348, 534, 4...</td>\n",
       "      <td>[43, 8, 10, 10, 39, 17, 48, 54, 3, 25, 22, 6, ...</td>\n",
       "      <td>[355, 278, 185]</td>\n",
       "      <td>M</td>\n",
       "      <td>1390.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 queries  \\\n",
       "40266  [13388, 10571, 122, 1961, 42946, 823, 3349, 10...   \n",
       "40267  [2655, 11, 1732, 2847, 15222, 884, 39, 1433, 2...   \n",
       "40268  [9, 33200, 5028, 357, 4, 233, 262, 2180, 376, ...   \n",
       "40269                                 [9, 276, 27, 1074]   \n",
       "40270  [6421, 11377, 6980, 852, 31, 185, 2348, 534, 4...   \n",
       "\n",
       "                                                    apps  \\\n",
       "40266  [9, 8, 17, 3, 25, 22, 6, 24, 12, 7, 14, 5, 4, ...   \n",
       "40267  [8, 11, 10, 10, 39, 17, 771, 48, 3, 25, 95, 22...   \n",
       "40268  [54, 9, 8, 10, 10, 39, 17, 48, 3, 25, 6, 21, 1...   \n",
       "40269  [9, 8, 17, 48, 54, 3, 25, 22, 6, 21, 7, 45, 14...   \n",
       "40270  [43, 8, 10, 10, 39, 17, 48, 54, 3, 25, 22, 6, ...   \n",
       "\n",
       "                                             games gender  birth_year  \n",
       "40266  [3, 55, 1115, 135, 410, 38, 1426, 107, 374]      M      1394.0  \n",
       "40267                                        [717]      M      1354.0  \n",
       "40268                                    [312, 22]      M      1364.0  \n",
       "40269                              [73, 2, 53, 75]      M      1365.0  \n",
       "40270                              [355, 278, 185]      M      1390.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f26f459",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40271, 5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f06c436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40271 entries, 0 to 40270\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   queries     40271 non-null  object \n",
      " 1   apps        40271 non-null  object \n",
      " 2   games       40271 non-null  object \n",
      " 3   gender      40271 non-null  object \n",
      " 4   birth_year  40271 non-null  float64\n",
      "dtypes: float64(1), object(4)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f96845c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"birth_year\"] = df[\"birth_year\"].astype(np.uint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e468ebd8",
   "metadata": {},
   "source": [
    "There is no `NaN` value heare as we can see in `birth_year` we have `0` which is not acceptable. So we should replace them with new values.\n",
    "\n",
    "In addition to `birth_year` we should make gender column numeric, although it is our goal column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44a2f8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_birth_year = df[\"birth_year\"][df[\"birth_year\"] != 0]\n",
    "mean_birth_year = round(valid_birth_year.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a031a07c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>queries</th>\n",
       "      <th>apps</th>\n",
       "      <th>games</th>\n",
       "      <th>gender</th>\n",
       "      <th>birth_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[216, 359, 12329, 3, 45, 4002, 2066, 32, 3931,...</td>\n",
       "      <td>[4, 4, 25, 7, 30, 58, 16, 19, 17, 21, 10, 10, ...</td>\n",
       "      <td>[9151, 208]</td>\n",
       "      <td>1</td>\n",
       "      <td>1366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[]</td>\n",
       "      <td>[129, 71, 9, 8, 11, 25, 18, 58, 6, 16, 125, 12...</td>\n",
       "      <td>[460, 4939, 14, 232, 6387, 1758, 5834, 3, 2]</td>\n",
       "      <td>0</td>\n",
       "      <td>1359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[23463, 18831]</td>\n",
       "      <td>[9, 174, 65, 8, 63, 97, 62, 103, 61, 116, 59, ...</td>\n",
       "      <td>[448, 723, 267, 9064, 10634, 166, 782, 224, 27...</td>\n",
       "      <td>1</td>\n",
       "      <td>1373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1634, 3609, 654]</td>\n",
       "      <td>[99, 73, 9, 8, 59, 37, 131, 3, 89, 6, 24, 16, ...</td>\n",
       "      <td>[78, 2607, 478, 435, 9, 192]</td>\n",
       "      <td>1</td>\n",
       "      <td>1371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[11064, 227, 623, 1301, 43999, 35411, 2492, 11...</td>\n",
       "      <td>[9, 8, 17, 54, 3, 25, 22, 6, 21, 7, 14, 5, 817...</td>\n",
       "      <td>[1702, 1, 53]</td>\n",
       "      <td>1</td>\n",
       "      <td>1364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             queries  \\\n",
       "0  [216, 359, 12329, 3, 45, 4002, 2066, 32, 3931,...   \n",
       "1                                                 []   \n",
       "2                                     [23463, 18831]   \n",
       "3                                  [1634, 3609, 654]   \n",
       "4  [11064, 227, 623, 1301, 43999, 35411, 2492, 11...   \n",
       "\n",
       "                                                apps  \\\n",
       "0  [4, 4, 25, 7, 30, 58, 16, 19, 17, 21, 10, 10, ...   \n",
       "1  [129, 71, 9, 8, 11, 25, 18, 58, 6, 16, 125, 12...   \n",
       "2  [9, 174, 65, 8, 63, 97, 62, 103, 61, 116, 59, ...   \n",
       "3  [99, 73, 9, 8, 59, 37, 131, 3, 89, 6, 24, 16, ...   \n",
       "4  [9, 8, 17, 54, 3, 25, 22, 6, 21, 7, 14, 5, 817...   \n",
       "\n",
       "                                               games  gender  birth_year  \n",
       "0                                        [9151, 208]       1        1366  \n",
       "1       [460, 4939, 14, 232, 6387, 1758, 5834, 3, 2]       0        1359  \n",
       "2  [448, 723, 267, 9064, 10634, 166, 782, 224, 27...       1        1373  \n",
       "3                       [78, 2607, 478, 435, 9, 192]       1        1371  \n",
       "4                                      [1702, 1, 53]       1        1364  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"birth_year\"] = df[\"birth_year\"].replace(0, mean_birth_year)\n",
    "df[\"gender\"] = df[\"gender\"].replace({'M': 1, 'F': 0})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af9518d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>birth_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>40271.000000</td>\n",
       "      <td>40271.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.742991</td>\n",
       "      <td>1370.967495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.436990</td>\n",
       "      <td>11.706620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1300.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1364.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1371.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1380.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1398.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             gender    birth_year\n",
       "count  40271.000000  40271.000000\n",
       "mean       0.742991   1370.967495\n",
       "std        0.436990     11.706620\n",
       "min        0.000000   1300.000000\n",
       "25%        0.000000   1364.000000\n",
       "50%        1.000000   1371.000000\n",
       "75%        1.000000   1380.000000\n",
       "max        1.000000   1398.000000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "attachments": {
    "image-2.png": {
     "image/png": "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"
    },
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "0f8f95bc",
   "metadata": {},
   "source": [
    "## Dealing with list values\n",
    "\n",
    "As it's clear hear that three of our main columns which are `queries`, `apps`, and `games` are lists so we should desl with them.\n",
    "\n",
    "Actually, if you look closely, you will find that lists are everywhere! Here are some practical problems, where you will probably encounter list values.\n",
    "\n",
    "* Audio-video tags\n",
    "* Open-ended questions in survey data\n",
    "* List of all authors, artists, producers, etc. invloved in a creative product\n",
    "\n",
    "### What is wrong with list values?\n",
    "List values mess up everything you know about data analysis. The simplest operations can not be performed without endless looping. \n",
    "\n",
    "An example of this is here:\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "![image-2.png](attachment:image-2.png)\n",
    "\n",
    "The reason this does not work is that Pandas does not have direct access to every individual element of the lists. Thus, Pandas is unable to apply functions like value_counts() properly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5511a30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_1D(series):\n",
    "    return pd.Series([x for _list in series for x in _list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69307769",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2        8229\n",
       "3        8174\n",
       "4        7870\n",
       "1        7816\n",
       "5        6605\n",
       "         ... \n",
       "43591       1\n",
       "49796       1\n",
       "36214       1\n",
       "37550       1\n",
       "41955       1\n",
       "Length: 47287, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_1D(df['queries']).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "383cb885",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4        41154\n",
       "1        40271\n",
       "2        40194\n",
       "3        38390\n",
       "10       37980\n",
       "         ...  \n",
       "22089        1\n",
       "19999        1\n",
       "16220        1\n",
       "12370        1\n",
       "30151        1\n",
       "Length: 36598, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_1D(df['apps']).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f31ac1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2        5534\n",
       "1        3662\n",
       "9        2324\n",
       "4        2131\n",
       "16       2045\n",
       "         ... \n",
       "3942        1\n",
       "30718       1\n",
       "8524        1\n",
       "8361        1\n",
       "14970       1\n",
       "Length: 15414, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_1D(df['games']).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2f6edb18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Query Ids')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize = (14,4))\n",
    "ax.bar(to_1D(df[\"queries\"]).value_counts().index,\n",
    "        to_1D(df[\"queries\"]).value_counts().values)\n",
    "ax.set_ylabel(\"Frequency\", size = 12)\n",
    "ax.set_title(\"Query Ids\", size = 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "93f55dd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'App Ids')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize = (14,4))\n",
    "ax.bar(to_1D(df[\"apps\"]).value_counts().index,\n",
    "        to_1D(df[\"apps\"]).value_counts().values)\n",
    "ax.set_ylabel(\"Frequency\", size = 12)\n",
    "ax.set_title(\"App Ids\", size = 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "78178353",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Game Ids')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize = (14,4))\n",
    "ax.bar(to_1D(df[\"games\"]).value_counts().index,\n",
    "        to_1D(df[\"games\"]).value_counts().values)\n",
    "ax.set_ylabel(\"Frequency\", size = 12)\n",
    "ax.set_title(\"Game Ids\", size = 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a65f94be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>gender</th>\n",
       "      <th>birth_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9151.0</td>\n",
       "      <td>208.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>460.0</td>\n",
       "      <td>4939.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>232.0</td>\n",
       "      <td>6387.0</td>\n",
       "      <td>1758.0</td>\n",
       "      <td>5834.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>448.0</td>\n",
       "      <td>723.0</td>\n",
       "      <td>267.0</td>\n",
       "      <td>9064.0</td>\n",
       "      <td>10634.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>782.0</td>\n",
       "      <td>224.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>4086.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>78.0</td>\n",
       "      <td>2607.0</td>\n",
       "      <td>478.0</td>\n",
       "      <td>435.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1702.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 932 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0       1      2       3        4       5       6      7      8  \\\n",
       "0  9151.0   208.0    0.0     0.0      0.0     0.0     0.0    0.0    0.0   \n",
       "1   460.0  4939.0   14.0   232.0   6387.0  1758.0  5834.0    3.0    2.0   \n",
       "2   448.0   723.0  267.0  9064.0  10634.0   166.0   782.0  224.0  273.0   \n",
       "3    78.0  2607.0  478.0   435.0      9.0   192.0     0.0    0.0    0.0   \n",
       "4  1702.0     1.0   53.0     0.0      0.0     0.0     0.0    0.0    0.0   \n",
       "\n",
       "        9  ...   88   89   90   91   92   93   94   95  gender  birth_year  \n",
       "0     0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0       1        1366  \n",
       "1     0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0       0        1359  \n",
       "2  4086.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0       1        1373  \n",
       "3     0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0       1        1371  \n",
       "4     0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0       1        1364  \n",
       "\n",
       "[5 rows x 932 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([df.pop('queries').apply(pd.Series), df], axis=1)\n",
    "df = pd.concat([df.pop('apps').apply(pd.Series), df], axis=1)\n",
    "df = pd.concat([df.pop('games').apply(pd.Series), df], axis=1)\n",
    "df.fillna(0, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa2dc977",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y =  df.drop(columns=[\"gender\"]), df[\"gender\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ad4f8ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e2d62d13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.63935444, 0.64276847, 0.63687151, 0.63842334, 0.62259466,\n",
       "       0.63749224, 0.63458553, 0.64141571, 0.63023906, 0.64452034])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "model = DecisionTreeClassifier(random_state=0)\n",
    "cross_val_score(model, X_train, y_train, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "367441f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)\n",
    "predicted = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "83c118d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "def evaluate(predicted, actual):\n",
    "    print(\"Accuracy: \", metrics.accuracy_score(actual, predicted))\n",
    "    print(\"Balanced Accuracy: \", metrics.balanced_accuracy_score(actual, predicted))\n",
    "    print(\"Precision: \", metrics.precision_score(actual, predicted))\n",
    "    print(\"Recall: \", metrics.recall_score(actual, predicted))\n",
    "    print(\"F1: \", metrics.f1_score(actual, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8d5143b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.6441961514587213\n",
      "Balanced Accuracy:  0.5421774831735213\n",
      "Precision:  0.7637474541751528\n",
      "Recall:  0.7532641446267158\n",
      "F1:  0.7584695769425248\n"
     ]
    }
   ],
   "source": [
    "evaluate(predicted, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2886a0b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.74332713, 0.74332713, 0.74332713, 0.74332713, 0.74332713,\n",
       "       0.74332713, 0.7435579 , 0.74324744, 0.74324744, 0.74324744])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier(random_state=0, max_depth=10)\n",
    "cross_val_score(model, X_train, y_train, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0e589fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)\n",
    "predicted = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c263becc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.741651148355059\n",
      "Balanced Accuracy:  0.5\n",
      "Precision:  0.741651148355059\n",
      "Recall:  1.0\n",
      "F1:  0.8516644094375936\n"
     ]
    }
   ],
   "source": [
    "evaluate(predicted, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "37f1b324",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=RandomForestClassifier(max_depth=10, random_state=0),\n",
       "             param_grid={'max_depth': [2, 5, 10, 20, 50, 100],\n",
       "                         'min_samples_leaf': [1, 2, 3],\n",
       "                         'min_samples_split': [2, 3],\n",
       "                         'n_estimators': [2, 5, 10, 20, 30, 50, 100, 200]})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = { 'n_estimators': [2, 5, 10, 20, 30, 50, 100, 200],\n",
    "                   'min_samples_split': [2, 3],\n",
    "                   'min_samples_leaf': [1, 2, 3],\n",
    "                   'max_depth': [2, 5, 10, 20, 50 ,100]\n",
    "                 }\n",
    "\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=parameters)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f94c22d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 20,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'n_estimators': 100}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ae4e01a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.74270639, 0.74301676, 0.74394786, 0.74332713, 0.74363749,\n",
       "       0.74301676, 0.74262651, 0.74324744, 0.74293698, 0.74231605])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestClassifier(random_state=0, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100)\n",
    "cross_val_score(model, X_train, y_train, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "54eee9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)\n",
    "predicted = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a7ef692f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7417752948479206\n",
      "Balanced Accuracy:  0.5007099883573654\n",
      "Precision:  0.7419234592445328\n",
      "Recall:  0.9994978239035822\n",
      "F1:  0.8516616745114819\n"
     ]
    }
   ],
   "source": [
    "evaluate(predicted, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65dc0d0e",
   "metadata": {},
   "source": [
    "As we can see although we have not-bad accuracy but balanced accuracy which is wanted for this task is not good so we should look for better moodels.\n",
    "\n",
    "By remember that with these parameters:\n",
    "```\n",
    "{'max_depth': 20,\n",
    " 'min_samples_leaf': 1,\n",
    " 'min_samples_split': 2,\n",
    " 'n_estimators': 100\n",
    "}\n",
    "```\n",
    " \n",
    "We got these results:\n",
    "```\n",
    "Accuracy:  0.7417752948479206\n",
    "Balanced Accuracy:  0.5007099883573654\n",
    "Precision:  0.7419234592445328\n",
    "Recall:  0.9994978239035822\n",
    "F1:  0.8516616745114819\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fc07d664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 88 candidates, totalling 440 fits\n",
      "[CV 1/5; 1/88] START leaf_size=20, n_neighbors=3, weights=uniform...............\n",
      "[CV 1/5; 1/88] END leaf_size=20, n_neighbors=3, weights=uniform;, score=0.504 total time=   4.5s\n",
      "[CV 2/5; 1/88] START leaf_size=20, n_neighbors=3, weights=uniform...............\n",
      "[CV 2/5; 1/88] END leaf_size=20, n_neighbors=3, weights=uniform;, score=0.510 total time=   4.1s\n",
      "[CV 3/5; 1/88] START leaf_size=20, n_neighbors=3, weights=uniform...............\n",
      "[CV 3/5; 1/88] END leaf_size=20, n_neighbors=3, weights=uniform;, score=0.504 total time=   4.1s\n",
      "[CV 4/5; 1/88] START leaf_size=20, n_neighbors=3, weights=uniform...............\n",
      "[CV 4/5; 1/88] END leaf_size=20, n_neighbors=3, weights=uniform;, score=0.506 total time=   4.3s\n",
      "[CV 5/5; 1/88] START leaf_size=20, n_neighbors=3, weights=uniform...............\n",
      "[CV 5/5; 1/88] END leaf_size=20, n_neighbors=3, weights=uniform;, score=0.501 total time=   4.1s\n",
      "[CV 1/5; 2/88] START leaf_size=20, n_neighbors=3, weights=distance..............\n",
      "[CV 1/5; 2/88] END leaf_size=20, n_neighbors=3, weights=distance;, score=0.504 total time=   4.3s\n",
      "[CV 2/5; 2/88] START leaf_size=20, n_neighbors=3, weights=distance..............\n",
      "[CV 2/5; 2/88] END leaf_size=20, n_neighbors=3, weights=distance;, score=0.510 total time=   4.3s\n",
      "[CV 3/5; 2/88] START leaf_size=20, n_neighbors=3, weights=distance..............\n",
      "[CV 3/5; 2/88] END leaf_size=20, n_neighbors=3, weights=distance;, score=0.504 total time=   4.4s\n",
      "[CV 4/5; 2/88] START leaf_size=20, n_neighbors=3, weights=distance..............\n",
      "[CV 4/5; 2/88] END leaf_size=20, n_neighbors=3, weights=distance;, score=0.506 total time=   4.2s\n",
      "[CV 5/5; 2/88] START leaf_size=20, n_neighbors=3, weights=distance..............\n",
      "[CV 5/5; 2/88] END leaf_size=20, n_neighbors=3, weights=distance;, score=0.500 total time=   4.0s\n",
      "[CV 1/5; 3/88] START leaf_size=20, n_neighbors=5, weights=uniform...............\n",
      "[CV 1/5; 3/88] END leaf_size=20, n_neighbors=5, weights=uniform;, score=0.500 total time=   5.5s\n",
      "[CV 2/5; 3/88] START leaf_size=20, n_neighbors=5, weights=uniform...............\n",
      "[CV 2/5; 3/88] END leaf_size=20, n_neighbors=5, weights=uniform;, score=0.515 total time=   5.1s\n",
      "[CV 3/5; 3/88] START leaf_size=20, n_neighbors=5, weights=uniform...............\n",
      "[CV 3/5; 3/88] END leaf_size=20, n_neighbors=5, weights=uniform;, score=0.507 total time=   5.5s\n",
      "[CV 4/5; 3/88] START leaf_size=20, n_neighbors=5, weights=uniform...............\n",
      "[CV 4/5; 3/88] END leaf_size=20, n_neighbors=5, weights=uniform;, score=0.506 total time=   5.1s\n",
      "[CV 5/5; 3/88] START leaf_size=20, n_neighbors=5, weights=uniform...............\n",
      "[CV 5/5; 3/88] END leaf_size=20, n_neighbors=5, weights=uniform;, score=0.498 total time=   5.1s\n",
      "[CV 1/5; 4/88] START leaf_size=20, n_neighbors=5, weights=distance..............\n",
      "[CV 1/5; 4/88] END leaf_size=20, n_neighbors=5, weights=distance;, score=0.500 total time=   4.8s\n",
      "[CV 2/5; 4/88] START leaf_size=20, n_neighbors=5, weights=distance..............\n",
      "[CV 2/5; 4/88] END leaf_size=20, n_neighbors=5, weights=distance;, score=0.515 total time=   5.0s\n",
      "[CV 3/5; 4/88] START leaf_size=20, n_neighbors=5, weights=distance..............\n",
      "[CV 3/5; 4/88] END leaf_size=20, n_neighbors=5, weights=distance;, score=0.506 total time=   4.8s\n",
      "[CV 4/5; 4/88] START leaf_size=20, n_neighbors=5, weights=distance..............\n",
      "[CV 4/5; 4/88] END leaf_size=20, n_neighbors=5, weights=distance;, score=0.506 total time=   5.4s\n",
      "[CV 5/5; 4/88] START leaf_size=20, n_neighbors=5, weights=distance..............\n",
      "[CV 5/5; 4/88] END leaf_size=20, n_neighbors=5, weights=distance;, score=0.498 total time=   5.3s\n",
      "[CV 1/5; 5/88] START leaf_size=20, n_neighbors=7, weights=uniform...............\n",
      "[CV 1/5; 5/88] END leaf_size=20, n_neighbors=7, weights=uniform;, score=0.503 total time=   5.8s\n",
      "[CV 2/5; 5/88] START leaf_size=20, n_neighbors=7, weights=uniform...............\n",
      "[CV 2/5; 5/88] END leaf_size=20, n_neighbors=7, weights=uniform;, score=0.506 total time=   5.5s\n",
      "[CV 3/5; 5/88] START leaf_size=20, n_neighbors=7, weights=uniform...............\n",
      "[CV 3/5; 5/88] END leaf_size=20, n_neighbors=7, weights=uniform;, score=0.502 total time=   6.2s\n",
      "[CV 4/5; 5/88] START leaf_size=20, n_neighbors=7, weights=uniform...............\n",
      "[CV 4/5; 5/88] END leaf_size=20, n_neighbors=7, weights=uniform;, score=0.505 total time=   7.0s\n",
      "[CV 5/5; 5/88] START leaf_size=20, n_neighbors=7, weights=uniform...............\n",
      "[CV 5/5; 5/88] END leaf_size=20, n_neighbors=7, weights=uniform;, score=0.507 total time=   6.3s\n",
      "[CV 1/5; 6/88] START leaf_size=20, n_neighbors=7, weights=distance..............\n",
      "[CV 1/5; 6/88] END leaf_size=20, n_neighbors=7, weights=distance;, score=0.503 total time=   6.0s\n",
      "[CV 2/5; 6/88] START leaf_size=20, n_neighbors=7, weights=distance..............\n",
      "[CV 2/5; 6/88] END leaf_size=20, n_neighbors=7, weights=distance;, score=0.506 total time=   5.3s\n",
      "[CV 3/5; 6/88] START leaf_size=20, n_neighbors=7, weights=distance..............\n",
      "[CV 3/5; 6/88] END leaf_size=20, n_neighbors=7, weights=distance;, score=0.502 total time=   6.1s\n",
      "[CV 4/5; 6/88] START leaf_size=20, n_neighbors=7, weights=distance..............\n",
      "[CV 4/5; 6/88] END leaf_size=20, n_neighbors=7, weights=distance;, score=0.504 total time=   5.2s\n",
      "[CV 5/5; 6/88] START leaf_size=20, n_neighbors=7, weights=distance..............\n",
      "[CV 5/5; 6/88] END leaf_size=20, n_neighbors=7, weights=distance;, score=0.507 total time=   5.1s\n",
      "[CV 1/5; 7/88] START leaf_size=20, n_neighbors=9, weights=uniform...............\n",
      "[CV 1/5; 7/88] END leaf_size=20, n_neighbors=9, weights=uniform;, score=0.505 total time=   5.9s\n",
      "[CV 2/5; 7/88] START leaf_size=20, n_neighbors=9, weights=uniform...............\n",
      "[CV 2/5; 7/88] END leaf_size=20, n_neighbors=9, weights=uniform;, score=0.507 total time=   5.6s\n",
      "[CV 3/5; 7/88] START leaf_size=20, n_neighbors=9, weights=uniform...............\n",
      "[CV 3/5; 7/88] END leaf_size=20, n_neighbors=9, weights=uniform;, score=0.504 total time=   5.7s\n",
      "[CV 4/5; 7/88] START leaf_size=20, n_neighbors=9, weights=uniform...............\n",
      "[CV 4/5; 7/88] END leaf_size=20, n_neighbors=9, weights=uniform;, score=0.500 total time=   5.3s\n",
      "[CV 5/5; 7/88] START leaf_size=20, n_neighbors=9, weights=uniform...............\n",
      "[CV 5/5; 7/88] END leaf_size=20, n_neighbors=9, weights=uniform;, score=0.507 total time=   5.2s\n",
      "[CV 1/5; 8/88] START leaf_size=20, n_neighbors=9, weights=distance..............\n",
      "[CV 1/5; 8/88] END leaf_size=20, n_neighbors=9, weights=distance;, score=0.505 total time=   5.1s\n",
      "[CV 2/5; 8/88] START leaf_size=20, n_neighbors=9, weights=distance..............\n",
      "[CV 2/5; 8/88] END leaf_size=20, n_neighbors=9, weights=distance;, score=0.508 total time=   5.0s\n",
      "[CV 3/5; 8/88] START leaf_size=20, n_neighbors=9, weights=distance..............\n",
      "[CV 3/5; 8/88] END leaf_size=20, n_neighbors=9, weights=distance;, score=0.504 total time=   5.0s\n",
      "[CV 4/5; 8/88] START leaf_size=20, n_neighbors=9, weights=distance..............\n",
      "[CV 4/5; 8/88] END leaf_size=20, n_neighbors=9, weights=distance;, score=0.500 total time=   4.9s\n",
      "[CV 5/5; 8/88] START leaf_size=20, n_neighbors=9, weights=distance..............\n",
      "[CV 5/5; 8/88] END leaf_size=20, n_neighbors=9, weights=distance;, score=0.507 total time=   5.3s\n",
      "[CV 1/5; 9/88] START leaf_size=20, n_neighbors=15, weights=uniform..............\n",
      "[CV 1/5; 9/88] END leaf_size=20, n_neighbors=15, weights=uniform;, score=0.503 total time=   5.7s\n",
      "[CV 2/5; 9/88] START leaf_size=20, n_neighbors=15, weights=uniform..............\n",
      "[CV 2/5; 9/88] END leaf_size=20, n_neighbors=15, weights=uniform;, score=0.503 total time=   5.5s\n",
      "[CV 3/5; 9/88] START leaf_size=20, n_neighbors=15, weights=uniform..............\n",
      "[CV 3/5; 9/88] END leaf_size=20, n_neighbors=15, weights=uniform;, score=0.500 total time=   5.2s\n",
      "[CV 4/5; 9/88] START leaf_size=20, n_neighbors=15, weights=uniform..............\n",
      "[CV 4/5; 9/88] END leaf_size=20, n_neighbors=15, weights=uniform;, score=0.500 total time=   5.0s\n",
      "[CV 5/5; 9/88] START leaf_size=20, n_neighbors=15, weights=uniform..............\n",
      "[CV 5/5; 9/88] END leaf_size=20, n_neighbors=15, weights=uniform;, score=0.503 total time=   6.0s\n",
      "[CV 1/5; 10/88] START leaf_size=20, n_neighbors=15, weights=distance............\n",
      "[CV 1/5; 10/88] END leaf_size=20, n_neighbors=15, weights=distance;, score=0.503 total time=   5.6s\n",
      "[CV 2/5; 10/88] START leaf_size=20, n_neighbors=15, weights=distance............\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 10/88] END leaf_size=20, n_neighbors=15, weights=distance;, score=0.503 total time=   5.1s\n",
      "[CV 3/5; 10/88] START leaf_size=20, n_neighbors=15, weights=distance............\n",
      "[CV 3/5; 10/88] END leaf_size=20, n_neighbors=15, weights=distance;, score=0.500 total time=   4.9s\n",
      "[CV 4/5; 10/88] START leaf_size=20, n_neighbors=15, weights=distance............\n",
      "[CV 4/5; 10/88] END leaf_size=20, n_neighbors=15, weights=distance;, score=0.501 total time=   5.0s\n",
      "[CV 5/5; 10/88] START leaf_size=20, n_neighbors=15, weights=distance............\n",
      "[CV 5/5; 10/88] END leaf_size=20, n_neighbors=15, weights=distance;, score=0.503 total time=   4.8s\n",
      "[CV 1/5; 11/88] START leaf_size=20, n_neighbors=19, weights=uniform.............\n",
      "[CV 1/5; 11/88] END leaf_size=20, n_neighbors=19, weights=uniform;, score=0.501 total time=   5.3s\n",
      "[CV 2/5; 11/88] START leaf_size=20, n_neighbors=19, weights=uniform.............\n",
      "[CV 2/5; 11/88] END leaf_size=20, n_neighbors=19, weights=uniform;, score=0.501 total time=   5.1s\n",
      "[CV 3/5; 11/88] START leaf_size=20, n_neighbors=19, weights=uniform.............\n",
      "[CV 3/5; 11/88] END leaf_size=20, n_neighbors=19, weights=uniform;, score=0.501 total time=   5.2s\n",
      "[CV 4/5; 11/88] START leaf_size=20, n_neighbors=19, weights=uniform.............\n",
      "[CV 4/5; 11/88] END leaf_size=20, n_neighbors=19, weights=uniform;, score=0.500 total time=   5.3s\n",
      "[CV 5/5; 11/88] START leaf_size=20, n_neighbors=19, weights=uniform.............\n",
      "[CV 5/5; 11/88] END leaf_size=20, n_neighbors=19, weights=uniform;, score=0.502 total time=   5.4s\n",
      "[CV 1/5; 12/88] START leaf_size=20, n_neighbors=19, weights=distance............\n",
      "[CV 1/5; 12/88] END leaf_size=20, n_neighbors=19, weights=distance;, score=0.501 total time=   4.9s\n",
      "[CV 2/5; 12/88] START leaf_size=20, n_neighbors=19, weights=distance............\n",
      "[CV 2/5; 12/88] END leaf_size=20, n_neighbors=19, weights=distance;, score=0.502 total time=   5.1s\n",
      "[CV 3/5; 12/88] START leaf_size=20, n_neighbors=19, weights=distance............\n",
      "[CV 3/5; 12/88] END leaf_size=20, n_neighbors=19, weights=distance;, score=0.501 total time=   5.0s\n",
      "[CV 4/5; 12/88] START leaf_size=20, n_neighbors=19, weights=distance............\n",
      "[CV 4/5; 12/88] END leaf_size=20, n_neighbors=19, weights=distance;, score=0.500 total time=   5.0s\n",
      "[CV 5/5; 12/88] START leaf_size=20, n_neighbors=19, weights=distance............\n",
      "[CV 5/5; 12/88] END leaf_size=20, n_neighbors=19, weights=distance;, score=0.502 total time=   4.9s\n",
      "[CV 1/5; 13/88] START leaf_size=20, n_neighbors=25, weights=uniform.............\n",
      "[CV 1/5; 13/88] END leaf_size=20, n_neighbors=25, weights=uniform;, score=0.499 total time=   5.5s\n",
      "[CV 2/5; 13/88] START leaf_size=20, n_neighbors=25, weights=uniform.............\n",
      "[CV 2/5; 13/88] END leaf_size=20, n_neighbors=25, weights=uniform;, score=0.501 total time=   5.2s\n",
      "[CV 3/5; 13/88] START leaf_size=20, n_neighbors=25, weights=uniform.............\n",
      "[CV 3/5; 13/88] END leaf_size=20, n_neighbors=25, weights=uniform;, score=0.499 total time=   5.3s\n",
      "[CV 4/5; 13/88] START leaf_size=20, n_neighbors=25, weights=uniform.............\n",
      "[CV 4/5; 13/88] END leaf_size=20, n_neighbors=25, weights=uniform;, score=0.502 total time=   5.5s\n",
      "[CV 5/5; 13/88] START leaf_size=20, n_neighbors=25, weights=uniform.............\n",
      "[CV 5/5; 13/88] END leaf_size=20, n_neighbors=25, weights=uniform;, score=0.501 total time=   5.4s\n",
      "[CV 1/5; 14/88] START leaf_size=20, n_neighbors=25, weights=distance............\n",
      "[CV 1/5; 14/88] END leaf_size=20, n_neighbors=25, weights=distance;, score=0.499 total time=   5.2s\n",
      "[CV 2/5; 14/88] START leaf_size=20, n_neighbors=25, weights=distance............\n",
      "[CV 2/5; 14/88] END leaf_size=20, n_neighbors=25, weights=distance;, score=0.501 total time=   5.3s\n",
      "[CV 3/5; 14/88] START leaf_size=20, n_neighbors=25, weights=distance............\n",
      "[CV 3/5; 14/88] END leaf_size=20, n_neighbors=25, weights=distance;, score=0.499 total time=   5.2s\n",
      "[CV 4/5; 14/88] START leaf_size=20, n_neighbors=25, weights=distance............\n",
      "[CV 4/5; 14/88] END leaf_size=20, n_neighbors=25, weights=distance;, score=0.501 total time=   5.3s\n",
      "[CV 5/5; 14/88] START leaf_size=20, n_neighbors=25, weights=distance............\n",
      "[CV 5/5; 14/88] END leaf_size=20, n_neighbors=25, weights=distance;, score=0.501 total time=   5.2s\n",
      "[CV 1/5; 15/88] START leaf_size=20, n_neighbors=35, weights=uniform.............\n",
      "[CV 1/5; 15/88] END leaf_size=20, n_neighbors=35, weights=uniform;, score=0.500 total time=   5.4s\n",
      "[CV 2/5; 15/88] START leaf_size=20, n_neighbors=35, weights=uniform.............\n",
      "[CV 2/5; 15/88] END leaf_size=20, n_neighbors=35, weights=uniform;, score=0.500 total time=   5.0s\n",
      "[CV 3/5; 15/88] START leaf_size=20, n_neighbors=35, weights=uniform.............\n",
      "[CV 3/5; 15/88] END leaf_size=20, n_neighbors=35, weights=uniform;, score=0.500 total time=   5.1s\n",
      "[CV 4/5; 15/88] START leaf_size=20, n_neighbors=35, weights=uniform.............\n",
      "[CV 4/5; 15/88] END leaf_size=20, n_neighbors=35, weights=uniform;, score=0.500 total time=   5.3s\n",
      "[CV 5/5; 15/88] START leaf_size=20, n_neighbors=35, weights=uniform.............\n",
      "[CV 5/5; 15/88] END leaf_size=20, n_neighbors=35, weights=uniform;, score=0.501 total time=   5.4s\n",
      "[CV 1/5; 16/88] START leaf_size=20, n_neighbors=35, weights=distance............\n",
      "[CV 1/5; 16/88] END leaf_size=20, n_neighbors=35, weights=distance;, score=0.500 total time=   5.6s\n",
      "[CV 2/5; 16/88] START leaf_size=20, n_neighbors=35, weights=distance............\n",
      "[CV 2/5; 16/88] END leaf_size=20, n_neighbors=35, weights=distance;, score=0.500 total time=   5.1s\n",
      "[CV 3/5; 16/88] START leaf_size=20, n_neighbors=35, weights=distance............\n",
      "[CV 3/5; 16/88] END leaf_size=20, n_neighbors=35, weights=distance;, score=0.500 total time=   5.0s\n",
      "[CV 4/5; 16/88] START leaf_size=20, n_neighbors=35, weights=distance............\n",
      "[CV 4/5; 16/88] END leaf_size=20, n_neighbors=35, weights=distance;, score=0.500 total time=   5.1s\n",
      "[CV 5/5; 16/88] START leaf_size=20, n_neighbors=35, weights=distance............\n",
      "[CV 5/5; 16/88] END leaf_size=20, n_neighbors=35, weights=distance;, score=0.501 total time=   5.0s\n",
      "[CV 1/5; 17/88] START leaf_size=20, n_neighbors=55, weights=uniform.............\n",
      "[CV 1/5; 17/88] END leaf_size=20, n_neighbors=55, weights=uniform;, score=0.500 total time=   5.3s\n",
      "[CV 2/5; 17/88] START leaf_size=20, n_neighbors=55, weights=uniform.............\n",
      "[CV 2/5; 17/88] END leaf_size=20, n_neighbors=55, weights=uniform;, score=0.500 total time=   5.2s\n",
      "[CV 3/5; 17/88] START leaf_size=20, n_neighbors=55, weights=uniform.............\n",
      "[CV 3/5; 17/88] END leaf_size=20, n_neighbors=55, weights=uniform;, score=0.501 total time=   5.0s\n",
      "[CV 4/5; 17/88] START leaf_size=20, n_neighbors=55, weights=uniform.............\n",
      "[CV 4/5; 17/88] END leaf_size=20, n_neighbors=55, weights=uniform;, score=0.500 total time=   5.2s\n",
      "[CV 5/5; 17/88] START leaf_size=20, n_neighbors=55, weights=uniform.............\n",
      "[CV 5/5; 17/88] END leaf_size=20, n_neighbors=55, weights=uniform;, score=0.500 total time=   4.9s\n",
      "[CV 1/5; 18/88] START leaf_size=20, n_neighbors=55, weights=distance............\n",
      "[CV 1/5; 18/88] END leaf_size=20, n_neighbors=55, weights=distance;, score=0.500 total time=   5.0s\n",
      "[CV 2/5; 18/88] START leaf_size=20, n_neighbors=55, weights=distance............\n",
      "[CV 2/5; 18/88] END leaf_size=20, n_neighbors=55, weights=distance;, score=0.500 total time=   5.0s\n",
      "[CV 3/5; 18/88] START leaf_size=20, n_neighbors=55, weights=distance............\n",
      "[CV 3/5; 18/88] END leaf_size=20, n_neighbors=55, weights=distance;, score=0.500 total time=   5.0s\n",
      "[CV 4/5; 18/88] START leaf_size=20, n_neighbors=55, weights=distance............\n",
      "[CV 4/5; 18/88] END leaf_size=20, n_neighbors=55, weights=distance;, score=0.500 total time=   4.9s\n",
      "[CV 5/5; 18/88] START leaf_size=20, n_neighbors=55, weights=distance............\n",
      "[CV 5/5; 18/88] END leaf_size=20, n_neighbors=55, weights=distance;, score=0.500 total time=   5.4s\n",
      "[CV 1/5; 19/88] START leaf_size=20, n_neighbors=75, weights=uniform.............\n",
      "[CV 1/5; 19/88] END leaf_size=20, n_neighbors=75, weights=uniform;, score=0.500 total time=   5.6s\n",
      "[CV 2/5; 19/88] START leaf_size=20, n_neighbors=75, weights=uniform.............\n",
      "[CV 2/5; 19/88] END leaf_size=20, n_neighbors=75, weights=uniform;, score=0.500 total time=   6.0s\n",
      "[CV 3/5; 19/88] START leaf_size=20, n_neighbors=75, weights=uniform.............\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 19/88] END leaf_size=20, n_neighbors=75, weights=uniform;, score=0.500 total time=   5.6s\n",
      "[CV 4/5; 19/88] START leaf_size=20, n_neighbors=75, weights=uniform.............\n",
      "[CV 4/5; 19/88] END leaf_size=20, n_neighbors=75, weights=uniform;, score=0.500 total time=   5.4s\n",
      "[CV 5/5; 19/88] START leaf_size=20, n_neighbors=75, weights=uniform.............\n",
      "[CV 5/5; 19/88] END leaf_size=20, n_neighbors=75, weights=uniform;, score=0.500 total time=   5.4s\n",
      "[CV 1/5; 20/88] START leaf_size=20, n_neighbors=75, weights=distance............\n",
      "[CV 1/5; 20/88] END leaf_size=20, n_neighbors=75, weights=distance;, score=0.500 total time=   5.7s\n",
      "[CV 2/5; 20/88] START leaf_size=20, n_neighbors=75, weights=distance............\n",
      "[CV 2/5; 20/88] END leaf_size=20, n_neighbors=75, weights=distance;, score=0.500 total time=   5.9s\n",
      "[CV 3/5; 20/88] START leaf_size=20, n_neighbors=75, weights=distance............\n",
      "[CV 3/5; 20/88] END leaf_size=20, n_neighbors=75, weights=distance;, score=0.500 total time=   5.2s\n",
      "[CV 4/5; 20/88] START leaf_size=20, n_neighbors=75, weights=distance............\n",
      "[CV 4/5; 20/88] END leaf_size=20, n_neighbors=75, weights=distance;, score=0.500 total time=   5.1s\n",
      "[CV 5/5; 20/88] START leaf_size=20, n_neighbors=75, weights=distance............\n",
      "[CV 5/5; 20/88] END leaf_size=20, n_neighbors=75, weights=distance;, score=0.500 total time=   4.6s\n",
      "[CV 1/5; 21/88] START leaf_size=20, n_neighbors=99, weights=uniform.............\n",
      "[CV 1/5; 21/88] END leaf_size=20, n_neighbors=99, weights=uniform;, score=0.500 total time=   5.9s\n",
      "[CV 2/5; 21/88] START leaf_size=20, n_neighbors=99, weights=uniform.............\n",
      "[CV 2/5; 21/88] END leaf_size=20, n_neighbors=99, weights=uniform;, score=0.500 total time=   5.7s\n",
      "[CV 3/5; 21/88] START leaf_size=20, n_neighbors=99, weights=uniform.............\n",
      "[CV 3/5; 21/88] END leaf_size=20, n_neighbors=99, weights=uniform;, score=0.500 total time=   5.5s\n",
      "[CV 4/5; 21/88] START leaf_size=20, n_neighbors=99, weights=uniform.............\n",
      "[CV 4/5; 21/88] END leaf_size=20, n_neighbors=99, weights=uniform;, score=0.500 total time=   6.5s\n",
      "[CV 5/5; 21/88] START leaf_size=20, n_neighbors=99, weights=uniform.............\n",
      "[CV 5/5; 21/88] END leaf_size=20, n_neighbors=99, weights=uniform;, score=0.500 total time=   4.8s\n",
      "[CV 1/5; 22/88] START leaf_size=20, n_neighbors=99, weights=distance............\n",
      "[CV 1/5; 22/88] END leaf_size=20, n_neighbors=99, weights=distance;, score=0.500 total time=   5.3s\n",
      "[CV 2/5; 22/88] START leaf_size=20, n_neighbors=99, weights=distance............\n",
      "[CV 2/5; 22/88] END leaf_size=20, n_neighbors=99, weights=distance;, score=0.500 total time=   6.5s\n",
      "[CV 3/5; 22/88] START leaf_size=20, n_neighbors=99, weights=distance............\n",
      "[CV 3/5; 22/88] END leaf_size=20, n_neighbors=99, weights=distance;, score=0.500 total time=   5.1s\n",
      "[CV 4/5; 22/88] START leaf_size=20, n_neighbors=99, weights=distance............\n",
      "[CV 4/5; 22/88] END leaf_size=20, n_neighbors=99, weights=distance;, score=0.500 total time=   4.9s\n",
      "[CV 5/5; 22/88] START leaf_size=20, n_neighbors=99, weights=distance............\n",
      "[CV 5/5; 22/88] END leaf_size=20, n_neighbors=99, weights=distance;, score=0.500 total time=   5.5s\n",
      "[CV 1/5; 23/88] START leaf_size=30, n_neighbors=3, weights=uniform..............\n",
      "[CV 1/5; 23/88] END leaf_size=30, n_neighbors=3, weights=uniform;, score=0.504 total time=   4.5s\n",
      "[CV 2/5; 23/88] START leaf_size=30, n_neighbors=3, weights=uniform..............\n",
      "[CV 2/5; 23/88] END leaf_size=30, n_neighbors=3, weights=uniform;, score=0.510 total time=   4.6s\n",
      "[CV 3/5; 23/88] START leaf_size=30, n_neighbors=3, weights=uniform..............\n",
      "[CV 3/5; 23/88] END leaf_size=30, n_neighbors=3, weights=uniform;, score=0.504 total time=   4.5s\n",
      "[CV 4/5; 23/88] START leaf_size=30, n_neighbors=3, weights=uniform..............\n",
      "[CV 4/5; 23/88] END leaf_size=30, n_neighbors=3, weights=uniform;, score=0.506 total time=   4.8s\n",
      "[CV 5/5; 23/88] START leaf_size=30, n_neighbors=3, weights=uniform..............\n",
      "[CV 5/5; 23/88] END leaf_size=30, n_neighbors=3, weights=uniform;, score=0.501 total time=   4.4s\n",
      "[CV 1/5; 24/88] START leaf_size=30, n_neighbors=3, weights=distance.............\n",
      "[CV 1/5; 24/88] END leaf_size=30, n_neighbors=3, weights=distance;, score=0.504 total time=   4.6s\n",
      "[CV 2/5; 24/88] START leaf_size=30, n_neighbors=3, weights=distance.............\n",
      "[CV 2/5; 24/88] END leaf_size=30, n_neighbors=3, weights=distance;, score=0.510 total time=   4.3s\n",
      "[CV 3/5; 24/88] START leaf_size=30, n_neighbors=3, weights=distance.............\n",
      "[CV 3/5; 24/88] END leaf_size=30, n_neighbors=3, weights=distance;, score=0.504 total time=   4.4s\n",
      "[CV 4/5; 24/88] START leaf_size=30, n_neighbors=3, weights=distance.............\n",
      "[CV 4/5; 24/88] END leaf_size=30, n_neighbors=3, weights=distance;, score=0.506 total time=   4.3s\n",
      "[CV 5/5; 24/88] START leaf_size=30, n_neighbors=3, weights=distance.............\n",
      "[CV 5/5; 24/88] END leaf_size=30, n_neighbors=3, weights=distance;, score=0.500 total time=   4.6s\n",
      "[CV 1/5; 25/88] START leaf_size=30, n_neighbors=5, weights=uniform..............\n",
      "[CV 1/5; 25/88] END leaf_size=30, n_neighbors=5, weights=uniform;, score=0.500 total time=   5.9s\n",
      "[CV 2/5; 25/88] START leaf_size=30, n_neighbors=5, weights=uniform..............\n",
      "[CV 2/5; 25/88] END leaf_size=30, n_neighbors=5, weights=uniform;, score=0.515 total time=   6.3s\n",
      "[CV 3/5; 25/88] START leaf_size=30, n_neighbors=5, weights=uniform..............\n",
      "[CV 3/5; 25/88] END leaf_size=30, n_neighbors=5, weights=uniform;, score=0.507 total time=   5.9s\n",
      "[CV 4/5; 25/88] START leaf_size=30, n_neighbors=5, weights=uniform..............\n",
      "[CV 4/5; 25/88] END leaf_size=30, n_neighbors=5, weights=uniform;, score=0.506 total time=   6.2s\n",
      "[CV 5/5; 25/88] START leaf_size=30, n_neighbors=5, weights=uniform..............\n",
      "[CV 5/5; 25/88] END leaf_size=30, n_neighbors=5, weights=uniform;, score=0.498 total time=   5.7s\n",
      "[CV 1/5; 26/88] START leaf_size=30, n_neighbors=5, weights=distance.............\n",
      "[CV 1/5; 26/88] END leaf_size=30, n_neighbors=5, weights=distance;, score=0.500 total time=   5.8s\n",
      "[CV 2/5; 26/88] START leaf_size=30, n_neighbors=5, weights=distance.............\n",
      "[CV 2/5; 26/88] END leaf_size=30, n_neighbors=5, weights=distance;, score=0.515 total time=   5.3s\n",
      "[CV 3/5; 26/88] START leaf_size=30, n_neighbors=5, weights=distance.............\n",
      "[CV 3/5; 26/88] END leaf_size=30, n_neighbors=5, weights=distance;, score=0.506 total time=   5.8s\n",
      "[CV 4/5; 26/88] START leaf_size=30, n_neighbors=5, weights=distance.............\n",
      "[CV 4/5; 26/88] END leaf_size=30, n_neighbors=5, weights=distance;, score=0.506 total time=   5.5s\n",
      "[CV 5/5; 26/88] START leaf_size=30, n_neighbors=5, weights=distance.............\n",
      "[CV 5/5; 26/88] END leaf_size=30, n_neighbors=5, weights=distance;, score=0.498 total time=   5.7s\n",
      "[CV 1/5; 27/88] START leaf_size=30, n_neighbors=7, weights=uniform..............\n",
      "[CV 1/5; 27/88] END leaf_size=30, n_neighbors=7, weights=uniform;, score=0.503 total time=   5.5s\n",
      "[CV 2/5; 27/88] START leaf_size=30, n_neighbors=7, weights=uniform..............\n",
      "[CV 2/5; 27/88] END leaf_size=30, n_neighbors=7, weights=uniform;, score=0.506 total time=   5.4s\n",
      "[CV 3/5; 27/88] START leaf_size=30, n_neighbors=7, weights=uniform..............\n",
      "[CV 3/5; 27/88] END leaf_size=30, n_neighbors=7, weights=uniform;, score=0.502 total time=   5.1s\n",
      "[CV 4/5; 27/88] START leaf_size=30, n_neighbors=7, weights=uniform..............\n",
      "[CV 4/5; 27/88] END leaf_size=30, n_neighbors=7, weights=uniform;, score=0.505 total time=   5.5s\n",
      "[CV 5/5; 27/88] START leaf_size=30, n_neighbors=7, weights=uniform..............\n",
      "[CV 5/5; 27/88] END leaf_size=30, n_neighbors=7, weights=uniform;, score=0.507 total time=   4.9s\n",
      "[CV 1/5; 28/88] START leaf_size=30, n_neighbors=7, weights=distance.............\n",
      "[CV 1/5; 28/88] END leaf_size=30, n_neighbors=7, weights=distance;, score=0.503 total time=   5.0s\n",
      "[CV 2/5; 28/88] START leaf_size=30, n_neighbors=7, weights=distance.............\n",
      "[CV 2/5; 28/88] END leaf_size=30, n_neighbors=7, weights=distance;, score=0.506 total time=   4.8s\n",
      "[CV 3/5; 28/88] START leaf_size=30, n_neighbors=7, weights=distance.............\n",
      "[CV 3/5; 28/88] END leaf_size=30, n_neighbors=7, weights=distance;, score=0.502 total time=   5.2s\n",
      "[CV 4/5; 28/88] START leaf_size=30, n_neighbors=7, weights=distance.............\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 28/88] END leaf_size=30, n_neighbors=7, weights=distance;, score=0.504 total time=   5.0s\n",
      "[CV 5/5; 28/88] START leaf_size=30, n_neighbors=7, weights=distance.............\n",
      "[CV 5/5; 28/88] END leaf_size=30, n_neighbors=7, weights=distance;, score=0.507 total time=   5.1s\n",
      "[CV 1/5; 29/88] START leaf_size=30, n_neighbors=9, weights=uniform..............\n",
      "[CV 1/5; 29/88] END leaf_size=30, n_neighbors=9, weights=uniform;, score=0.505 total time=   5.8s\n",
      "[CV 2/5; 29/88] START leaf_size=30, n_neighbors=9, weights=uniform..............\n",
      "[CV 2/5; 29/88] END leaf_size=30, n_neighbors=9, weights=uniform;, score=0.507 total time=   5.6s\n",
      "[CV 3/5; 29/88] START leaf_size=30, n_neighbors=9, weights=uniform..............\n",
      "[CV 3/5; 29/88] END leaf_size=30, n_neighbors=9, weights=uniform;, score=0.504 total time=   5.1s\n",
      "[CV 4/5; 29/88] START leaf_size=30, n_neighbors=9, weights=uniform..............\n",
      "[CV 4/5; 29/88] END leaf_size=30, n_neighbors=9, weights=uniform;, score=0.500 total time=   5.5s\n",
      "[CV 5/5; 29/88] START leaf_size=30, n_neighbors=9, weights=uniform..............\n",
      "[CV 5/5; 29/88] END leaf_size=30, n_neighbors=9, weights=uniform;, score=0.507 total time=   5.5s\n",
      "[CV 1/5; 30/88] START leaf_size=30, n_neighbors=9, weights=distance.............\n",
      "[CV 1/5; 30/88] END leaf_size=30, n_neighbors=9, weights=distance;, score=0.505 total time=   5.2s\n",
      "[CV 2/5; 30/88] START leaf_size=30, n_neighbors=9, weights=distance.............\n",
      "[CV 2/5; 30/88] END leaf_size=30, n_neighbors=9, weights=distance;, score=0.508 total time=   5.0s\n",
      "[CV 3/5; 30/88] START leaf_size=30, n_neighbors=9, weights=distance.............\n",
      "[CV 3/5; 30/88] END leaf_size=30, n_neighbors=9, weights=distance;, score=0.504 total time=   5.0s\n",
      "[CV 4/5; 30/88] START leaf_size=30, n_neighbors=9, weights=distance.............\n",
      "[CV 4/5; 30/88] END leaf_size=30, n_neighbors=9, weights=distance;, score=0.500 total time=   5.5s\n",
      "[CV 5/5; 30/88] START leaf_size=30, n_neighbors=9, weights=distance.............\n",
      "[CV 5/5; 30/88] END leaf_size=30, n_neighbors=9, weights=distance;, score=0.507 total time=   4.8s\n",
      "[CV 1/5; 31/88] START leaf_size=30, n_neighbors=15, weights=uniform.............\n",
      "[CV 1/5; 31/88] END leaf_size=30, n_neighbors=15, weights=uniform;, score=0.503 total time=   5.2s\n",
      "[CV 2/5; 31/88] START leaf_size=30, n_neighbors=15, weights=uniform.............\n",
      "[CV 2/5; 31/88] END leaf_size=30, n_neighbors=15, weights=uniform;, score=0.503 total time=   5.5s\n",
      "[CV 3/5; 31/88] START leaf_size=30, n_neighbors=15, weights=uniform.............\n",
      "[CV 3/5; 31/88] END leaf_size=30, n_neighbors=15, weights=uniform;, score=0.500 total time=   5.6s\n",
      "[CV 4/5; 31/88] START leaf_size=30, n_neighbors=15, weights=uniform.............\n",
      "[CV 4/5; 31/88] END leaf_size=30, n_neighbors=15, weights=uniform;, score=0.500 total time=   5.1s\n",
      "[CV 5/5; 31/88] START leaf_size=30, n_neighbors=15, weights=uniform.............\n",
      "[CV 5/5; 31/88] END leaf_size=30, n_neighbors=15, weights=uniform;, score=0.503 total time=   5.1s\n",
      "[CV 1/5; 32/88] START leaf_size=30, n_neighbors=15, weights=distance............\n",
      "[CV 1/5; 32/88] END leaf_size=30, n_neighbors=15, weights=distance;, score=0.503 total time=   5.0s\n",
      "[CV 2/5; 32/88] START leaf_size=30, n_neighbors=15, weights=distance............\n",
      "[CV 2/5; 32/88] END leaf_size=30, n_neighbors=15, weights=distance;, score=0.503 total time=   5.0s\n",
      "[CV 3/5; 32/88] START leaf_size=30, n_neighbors=15, weights=distance............\n",
      "[CV 3/5; 32/88] END leaf_size=30, n_neighbors=15, weights=distance;, score=0.500 total time=   4.9s\n",
      "[CV 4/5; 32/88] START leaf_size=30, n_neighbors=15, weights=distance............\n",
      "[CV 4/5; 32/88] END leaf_size=30, n_neighbors=15, weights=distance;, score=0.501 total time=   5.2s\n",
      "[CV 5/5; 32/88] START leaf_size=30, n_neighbors=15, weights=distance............\n",
      "[CV 5/5; 32/88] END leaf_size=30, n_neighbors=15, weights=distance;, score=0.503 total time=   5.5s\n",
      "[CV 1/5; 33/88] START leaf_size=30, n_neighbors=19, weights=uniform.............\n",
      "[CV 1/5; 33/88] END leaf_size=30, n_neighbors=19, weights=uniform;, score=0.501 total time=   5.5s\n",
      "[CV 2/5; 33/88] START leaf_size=30, n_neighbors=19, weights=uniform.............\n",
      "[CV 2/5; 33/88] END leaf_size=30, n_neighbors=19, weights=uniform;, score=0.501 total time=   5.5s\n",
      "[CV 3/5; 33/88] START leaf_size=30, n_neighbors=19, weights=uniform.............\n",
      "[CV 3/5; 33/88] END leaf_size=30, n_neighbors=19, weights=uniform;, score=0.501 total time=   5.5s\n",
      "[CV 4/5; 33/88] START leaf_size=30, n_neighbors=19, weights=uniform.............\n",
      "[CV 4/5; 33/88] END leaf_size=30, n_neighbors=19, weights=uniform;, score=0.500 total time=   5.5s\n",
      "[CV 5/5; 33/88] START leaf_size=30, n_neighbors=19, weights=uniform.............\n",
      "[CV 5/5; 33/88] END leaf_size=30, n_neighbors=19, weights=uniform;, score=0.502 total time=   5.5s\n",
      "[CV 1/5; 34/88] START leaf_size=30, n_neighbors=19, weights=distance............\n",
      "[CV 1/5; 34/88] END leaf_size=30, n_neighbors=19, weights=distance;, score=0.501 total time=   5.4s\n",
      "[CV 2/5; 34/88] START leaf_size=30, n_neighbors=19, weights=distance............\n",
      "[CV 2/5; 34/88] END leaf_size=30, n_neighbors=19, weights=distance;, score=0.502 total time=   5.1s\n",
      "[CV 3/5; 34/88] START leaf_size=30, n_neighbors=19, weights=distance............\n",
      "[CV 3/5; 34/88] END leaf_size=30, n_neighbors=19, weights=distance;, score=0.501 total time=   5.0s\n",
      "[CV 4/5; 34/88] START leaf_size=30, n_neighbors=19, weights=distance............\n",
      "[CV 4/5; 34/88] END leaf_size=30, n_neighbors=19, weights=distance;, score=0.500 total time=   4.9s\n",
      "[CV 5/5; 34/88] START leaf_size=30, n_neighbors=19, weights=distance............\n",
      "[CV 5/5; 34/88] END leaf_size=30, n_neighbors=19, weights=distance;, score=0.502 total time=   5.1s\n",
      "[CV 1/5; 35/88] START leaf_size=30, n_neighbors=25, weights=uniform.............\n",
      "[CV 1/5; 35/88] END leaf_size=30, n_neighbors=25, weights=uniform;, score=0.499 total time=   5.5s\n",
      "[CV 2/5; 35/88] START leaf_size=30, n_neighbors=25, weights=uniform.............\n",
      "[CV 2/5; 35/88] END leaf_size=30, n_neighbors=25, weights=uniform;, score=0.501 total time=   5.6s\n",
      "[CV 3/5; 35/88] START leaf_size=30, n_neighbors=25, weights=uniform.............\n",
      "[CV 3/5; 35/88] END leaf_size=30, n_neighbors=25, weights=uniform;, score=0.499 total time=   5.5s\n",
      "[CV 4/5; 35/88] START leaf_size=30, n_neighbors=25, weights=uniform.............\n",
      "[CV 4/5; 35/88] END leaf_size=30, n_neighbors=25, weights=uniform;, score=0.502 total time=   5.4s\n",
      "[CV 5/5; 35/88] START leaf_size=30, n_neighbors=25, weights=uniform.............\n",
      "[CV 5/5; 35/88] END leaf_size=30, n_neighbors=25, weights=uniform;, score=0.501 total time=   5.4s\n",
      "[CV 1/5; 36/88] START leaf_size=30, n_neighbors=25, weights=distance............\n",
      "[CV 1/5; 36/88] END leaf_size=30, n_neighbors=25, weights=distance;, score=0.499 total time=   5.4s\n",
      "[CV 2/5; 36/88] START leaf_size=30, n_neighbors=25, weights=distance............\n",
      "[CV 2/5; 36/88] END leaf_size=30, n_neighbors=25, weights=distance;, score=0.501 total time=   6.1s\n",
      "[CV 3/5; 36/88] START leaf_size=30, n_neighbors=25, weights=distance............\n",
      "[CV 3/5; 36/88] END leaf_size=30, n_neighbors=25, weights=distance;, score=0.499 total time=   5.9s\n",
      "[CV 4/5; 36/88] START leaf_size=30, n_neighbors=25, weights=distance............\n",
      "[CV 4/5; 36/88] END leaf_size=30, n_neighbors=25, weights=distance;, score=0.501 total time=   4.9s\n",
      "[CV 5/5; 36/88] START leaf_size=30, n_neighbors=25, weights=distance............\n",
      "[CV 5/5; 36/88] END leaf_size=30, n_neighbors=25, weights=distance;, score=0.501 total time=   6.2s\n",
      "[CV 1/5; 37/88] START leaf_size=30, n_neighbors=35, weights=uniform.............\n",
      "[CV 1/5; 37/88] END leaf_size=30, n_neighbors=35, weights=uniform;, score=0.500 total time=   7.1s\n",
      "[CV 2/5; 37/88] START leaf_size=30, n_neighbors=35, weights=uniform.............\n",
      "[CV 2/5; 37/88] END leaf_size=30, n_neighbors=35, weights=uniform;, score=0.500 total time=   6.4s\n",
      "[CV 3/5; 37/88] START leaf_size=30, n_neighbors=35, weights=uniform.............\n",
      "[CV 3/5; 37/88] END leaf_size=30, n_neighbors=35, weights=uniform;, score=0.500 total time=   6.9s\n",
      "[CV 4/5; 37/88] START leaf_size=30, n_neighbors=35, weights=uniform.............\n",
      "[CV 4/5; 37/88] END leaf_size=30, n_neighbors=35, weights=uniform;, score=0.500 total time=   6.4s\n",
      "[CV 5/5; 37/88] START leaf_size=30, n_neighbors=35, weights=uniform.............\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 37/88] END leaf_size=30, n_neighbors=35, weights=uniform;, score=0.501 total time=   6.2s\n",
      "[CV 1/5; 38/88] START leaf_size=30, n_neighbors=35, weights=distance............\n",
      "[CV 1/5; 38/88] END leaf_size=30, n_neighbors=35, weights=distance;, score=0.500 total time=   6.9s\n",
      "[CV 2/5; 38/88] START leaf_size=30, n_neighbors=35, weights=distance............\n",
      "[CV 2/5; 38/88] END leaf_size=30, n_neighbors=35, weights=distance;, score=0.500 total time=   6.8s\n",
      "[CV 3/5; 38/88] START leaf_size=30, n_neighbors=35, weights=distance............\n",
      "[CV 3/5; 38/88] END leaf_size=30, n_neighbors=35, weights=distance;, score=0.500 total time=   6.2s\n",
      "[CV 4/5; 38/88] START leaf_size=30, n_neighbors=35, weights=distance............\n",
      "[CV 4/5; 38/88] END leaf_size=30, n_neighbors=35, weights=distance;, score=0.500 total time=   5.5s\n",
      "[CV 5/5; 38/88] START leaf_size=30, n_neighbors=35, weights=distance............\n",
      "[CV 5/5; 38/88] END leaf_size=30, n_neighbors=35, weights=distance;, score=0.501 total time=   5.1s\n",
      "[CV 1/5; 39/88] START leaf_size=30, n_neighbors=55, weights=uniform.............\n",
      "[CV 1/5; 39/88] END leaf_size=30, n_neighbors=55, weights=uniform;, score=0.500 total time=   4.9s\n",
      "[CV 2/5; 39/88] START leaf_size=30, n_neighbors=55, weights=uniform.............\n",
      "[CV 2/5; 39/88] END leaf_size=30, n_neighbors=55, weights=uniform;, score=0.500 total time=   5.3s\n",
      "[CV 3/5; 39/88] START leaf_size=30, n_neighbors=55, weights=uniform.............\n",
      "[CV 3/5; 39/88] END leaf_size=30, n_neighbors=55, weights=uniform;, score=0.501 total time=   5.3s\n",
      "[CV 4/5; 39/88] START leaf_size=30, n_neighbors=55, weights=uniform.............\n",
      "[CV 4/5; 39/88] END leaf_size=30, n_neighbors=55, weights=uniform;, score=0.500 total time=   6.3s\n",
      "[CV 5/5; 39/88] START leaf_size=30, n_neighbors=55, weights=uniform.............\n",
      "[CV 5/5; 39/88] END leaf_size=30, n_neighbors=55, weights=uniform;, score=0.500 total time=   6.4s\n",
      "[CV 1/5; 40/88] START leaf_size=30, n_neighbors=55, weights=distance............\n",
      "[CV 1/5; 40/88] END leaf_size=30, n_neighbors=55, weights=distance;, score=0.500 total time=   6.2s\n",
      "[CV 2/5; 40/88] START leaf_size=30, n_neighbors=55, weights=distance............\n",
      "[CV 2/5; 40/88] END leaf_size=30, n_neighbors=55, weights=distance;, score=0.500 total time=   6.0s\n",
      "[CV 3/5; 40/88] START leaf_size=30, n_neighbors=55, weights=distance............\n",
      "[CV 3/5; 40/88] END leaf_size=30, n_neighbors=55, weights=distance;, score=0.500 total time=   6.0s\n",
      "[CV 4/5; 40/88] START leaf_size=30, n_neighbors=55, weights=distance............\n",
      "[CV 4/5; 40/88] END leaf_size=30, n_neighbors=55, weights=distance;, score=0.500 total time=   6.2s\n",
      "[CV 5/5; 40/88] START leaf_size=30, n_neighbors=55, weights=distance............\n",
      "[CV 5/5; 40/88] END leaf_size=30, n_neighbors=55, weights=distance;, score=0.500 total time=   5.7s\n",
      "[CV 1/5; 41/88] START leaf_size=30, n_neighbors=75, weights=uniform.............\n",
      "[CV 1/5; 41/88] END leaf_size=30, n_neighbors=75, weights=uniform;, score=0.500 total time=   6.3s\n",
      "[CV 2/5; 41/88] START leaf_size=30, n_neighbors=75, weights=uniform.............\n",
      "[CV 2/5; 41/88] END leaf_size=30, n_neighbors=75, weights=uniform;, score=0.500 total time=   6.0s\n",
      "[CV 3/5; 41/88] START leaf_size=30, n_neighbors=75, weights=uniform.............\n",
      "[CV 3/5; 41/88] END leaf_size=30, n_neighbors=75, weights=uniform;, score=0.500 total time=   6.6s\n",
      "[CV 4/5; 41/88] START leaf_size=30, n_neighbors=75, weights=uniform.............\n",
      "[CV 4/5; 41/88] END leaf_size=30, n_neighbors=75, weights=uniform;, score=0.500 total time=   6.4s\n",
      "[CV 5/5; 41/88] START leaf_size=30, n_neighbors=75, weights=uniform.............\n",
      "[CV 5/5; 41/88] END leaf_size=30, n_neighbors=75, weights=uniform;, score=0.500 total time=   6.1s\n",
      "[CV 1/5; 42/88] START leaf_size=30, n_neighbors=75, weights=distance............\n",
      "[CV 1/5; 42/88] END leaf_size=30, n_neighbors=75, weights=distance;, score=0.500 total time=   6.6s\n",
      "[CV 2/5; 42/88] START leaf_size=30, n_neighbors=75, weights=distance............\n",
      "[CV 2/5; 42/88] END leaf_size=30, n_neighbors=75, weights=distance;, score=0.500 total time=   6.6s\n",
      "[CV 3/5; 42/88] START leaf_size=30, n_neighbors=75, weights=distance............\n",
      "[CV 3/5; 42/88] END leaf_size=30, n_neighbors=75, weights=distance;, score=0.500 total time=   5.6s\n",
      "[CV 4/5; 42/88] START leaf_size=30, n_neighbors=75, weights=distance............\n",
      "[CV 4/5; 42/88] END leaf_size=30, n_neighbors=75, weights=distance;, score=0.500 total time=   5.8s\n",
      "[CV 5/5; 42/88] START leaf_size=30, n_neighbors=75, weights=distance............\n",
      "[CV 5/5; 42/88] END leaf_size=30, n_neighbors=75, weights=distance;, score=0.500 total time=   4.8s\n",
      "[CV 1/5; 43/88] START leaf_size=30, n_neighbors=99, weights=uniform.............\n",
      "[CV 1/5; 43/88] END leaf_size=30, n_neighbors=99, weights=uniform;, score=0.500 total time=   4.8s\n",
      "[CV 2/5; 43/88] START leaf_size=30, n_neighbors=99, weights=uniform.............\n",
      "[CV 2/5; 43/88] END leaf_size=30, n_neighbors=99, weights=uniform;, score=0.500 total time=   4.8s\n",
      "[CV 3/5; 43/88] START leaf_size=30, n_neighbors=99, weights=uniform.............\n",
      "[CV 3/5; 43/88] END leaf_size=30, n_neighbors=99, weights=uniform;, score=0.500 total time=   4.8s\n",
      "[CV 4/5; 43/88] START leaf_size=30, n_neighbors=99, weights=uniform.............\n",
      "[CV 4/5; 43/88] END leaf_size=30, n_neighbors=99, weights=uniform;, score=0.500 total time=   4.7s\n",
      "[CV 5/5; 43/88] START leaf_size=30, n_neighbors=99, weights=uniform.............\n",
      "[CV 5/5; 43/88] END leaf_size=30, n_neighbors=99, weights=uniform;, score=0.500 total time=   4.7s\n",
      "[CV 1/5; 44/88] START leaf_size=30, n_neighbors=99, weights=distance............\n",
      "[CV 1/5; 44/88] END leaf_size=30, n_neighbors=99, weights=distance;, score=0.500 total time=   5.3s\n",
      "[CV 2/5; 44/88] START leaf_size=30, n_neighbors=99, weights=distance............\n",
      "[CV 2/5; 44/88] END leaf_size=30, n_neighbors=99, weights=distance;, score=0.500 total time=   5.6s\n",
      "[CV 3/5; 44/88] START leaf_size=30, n_neighbors=99, weights=distance............\n",
      "[CV 3/5; 44/88] END leaf_size=30, n_neighbors=99, weights=distance;, score=0.500 total time=   5.9s\n",
      "[CV 4/5; 44/88] START leaf_size=30, n_neighbors=99, weights=distance............\n",
      "[CV 4/5; 44/88] END leaf_size=30, n_neighbors=99, weights=distance;, score=0.500 total time=   5.8s\n",
      "[CV 5/5; 44/88] START leaf_size=30, n_neighbors=99, weights=distance............\n",
      "[CV 5/5; 44/88] END leaf_size=30, n_neighbors=99, weights=distance;, score=0.500 total time=   6.2s\n",
      "[CV 1/5; 45/88] START leaf_size=50, n_neighbors=3, weights=uniform..............\n",
      "[CV 1/5; 45/88] END leaf_size=50, n_neighbors=3, weights=uniform;, score=0.504 total time=   4.7s\n",
      "[CV 2/5; 45/88] START leaf_size=50, n_neighbors=3, weights=uniform..............\n",
      "[CV 2/5; 45/88] END leaf_size=50, n_neighbors=3, weights=uniform;, score=0.510 total time=   5.1s\n",
      "[CV 3/5; 45/88] START leaf_size=50, n_neighbors=3, weights=uniform..............\n",
      "[CV 3/5; 45/88] END leaf_size=50, n_neighbors=3, weights=uniform;, score=0.504 total time=   4.6s\n",
      "[CV 4/5; 45/88] START leaf_size=50, n_neighbors=3, weights=uniform..............\n",
      "[CV 4/5; 45/88] END leaf_size=50, n_neighbors=3, weights=uniform;, score=0.506 total time=   4.8s\n",
      "[CV 5/5; 45/88] START leaf_size=50, n_neighbors=3, weights=uniform..............\n",
      "[CV 5/5; 45/88] END leaf_size=50, n_neighbors=3, weights=uniform;, score=0.501 total time=   4.5s\n",
      "[CV 1/5; 46/88] START leaf_size=50, n_neighbors=3, weights=distance.............\n",
      "[CV 1/5; 46/88] END leaf_size=50, n_neighbors=3, weights=distance;, score=0.504 total time=   3.7s\n",
      "[CV 2/5; 46/88] START leaf_size=50, n_neighbors=3, weights=distance.............\n",
      "[CV 2/5; 46/88] END leaf_size=50, n_neighbors=3, weights=distance;, score=0.510 total time=   4.2s\n",
      "[CV 3/5; 46/88] START leaf_size=50, n_neighbors=3, weights=distance.............\n",
      "[CV 3/5; 46/88] END leaf_size=50, n_neighbors=3, weights=distance;, score=0.504 total time=   3.8s\n",
      "[CV 4/5; 46/88] START leaf_size=50, n_neighbors=3, weights=distance.............\n",
      "[CV 4/5; 46/88] END leaf_size=50, n_neighbors=3, weights=distance;, score=0.506 total time=   3.8s\n",
      "[CV 5/5; 46/88] START leaf_size=50, n_neighbors=3, weights=distance.............\n",
      "[CV 5/5; 46/88] END leaf_size=50, n_neighbors=3, weights=distance;, score=0.500 total time=   4.1s\n",
      "[CV 1/5; 47/88] START leaf_size=50, n_neighbors=5, weights=uniform..............\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 47/88] END leaf_size=50, n_neighbors=5, weights=uniform;, score=0.500 total time=   4.8s\n",
      "[CV 2/5; 47/88] START leaf_size=50, n_neighbors=5, weights=uniform..............\n",
      "[CV 2/5; 47/88] END leaf_size=50, n_neighbors=5, weights=uniform;, score=0.515 total time=   4.8s\n",
      "[CV 3/5; 47/88] START leaf_size=50, n_neighbors=5, weights=uniform..............\n",
      "[CV 3/5; 47/88] END leaf_size=50, n_neighbors=5, weights=uniform;, score=0.507 total time=   4.9s\n",
      "[CV 4/5; 47/88] START leaf_size=50, n_neighbors=5, weights=uniform..............\n",
      "[CV 4/5; 47/88] END leaf_size=50, n_neighbors=5, weights=uniform;, score=0.506 total time=   4.7s\n",
      "[CV 5/5; 47/88] START leaf_size=50, n_neighbors=5, weights=uniform..............\n",
      "[CV 5/5; 47/88] END leaf_size=50, n_neighbors=5, weights=uniform;, score=0.498 total time=   4.9s\n",
      "[CV 1/5; 48/88] START leaf_size=50, n_neighbors=5, weights=distance.............\n",
      "[CV 1/5; 48/88] END leaf_size=50, n_neighbors=5, weights=distance;, score=0.500 total time=   4.9s\n",
      "[CV 2/5; 48/88] START leaf_size=50, n_neighbors=5, weights=distance.............\n",
      "[CV 2/5; 48/88] END leaf_size=50, n_neighbors=5, weights=distance;, score=0.515 total time=   4.6s\n",
      "[CV 3/5; 48/88] START leaf_size=50, n_neighbors=5, weights=distance.............\n",
      "[CV 3/5; 48/88] END leaf_size=50, n_neighbors=5, weights=distance;, score=0.506 total time=   4.6s\n",
      "[CV 4/5; 48/88] START leaf_size=50, n_neighbors=5, weights=distance.............\n",
      "[CV 4/5; 48/88] END leaf_size=50, n_neighbors=5, weights=distance;, score=0.506 total time=   4.7s\n",
      "[CV 5/5; 48/88] START leaf_size=50, n_neighbors=5, weights=distance.............\n",
      "[CV 5/5; 48/88] END leaf_size=50, n_neighbors=5, weights=distance;, score=0.498 total time=   4.5s\n",
      "[CV 1/5; 49/88] START leaf_size=50, n_neighbors=7, weights=uniform..............\n",
      "[CV 1/5; 49/88] END leaf_size=50, n_neighbors=7, weights=uniform;, score=0.503 total time=   4.9s\n",
      "[CV 2/5; 49/88] START leaf_size=50, n_neighbors=7, weights=uniform..............\n",
      "[CV 2/5; 49/88] END leaf_size=50, n_neighbors=7, weights=uniform;, score=0.506 total time=   5.3s\n",
      "[CV 3/5; 49/88] START leaf_size=50, n_neighbors=7, weights=uniform..............\n",
      "[CV 3/5; 49/88] END leaf_size=50, n_neighbors=7, weights=uniform;, score=0.502 total time=   4.9s\n",
      "[CV 4/5; 49/88] START leaf_size=50, n_neighbors=7, weights=uniform..............\n",
      "[CV 4/5; 49/88] END leaf_size=50, n_neighbors=7, weights=uniform;, score=0.505 total time=   4.9s\n",
      "[CV 5/5; 49/88] START leaf_size=50, n_neighbors=7, weights=uniform..............\n",
      "[CV 5/5; 49/88] END leaf_size=50, n_neighbors=7, weights=uniform;, score=0.507 total time=   4.8s\n",
      "[CV 1/5; 50/88] START leaf_size=50, n_neighbors=7, weights=distance.............\n",
      "[CV 1/5; 50/88] END leaf_size=50, n_neighbors=7, weights=distance;, score=0.503 total time=   4.5s\n",
      "[CV 2/5; 50/88] START leaf_size=50, n_neighbors=7, weights=distance.............\n",
      "[CV 2/5; 50/88] END leaf_size=50, n_neighbors=7, weights=distance;, score=0.506 total time=   4.7s\n",
      "[CV 3/5; 50/88] START leaf_size=50, n_neighbors=7, weights=distance.............\n",
      "[CV 3/5; 50/88] END leaf_size=50, n_neighbors=7, weights=distance;, score=0.502 total time=   4.9s\n",
      "[CV 4/5; 50/88] START leaf_size=50, n_neighbors=7, weights=distance.............\n",
      "[CV 4/5; 50/88] END leaf_size=50, n_neighbors=7, weights=distance;, score=0.504 total time=   5.0s\n",
      "[CV 5/5; 50/88] START leaf_size=50, n_neighbors=7, weights=distance.............\n",
      "[CV 5/5; 50/88] END leaf_size=50, n_neighbors=7, weights=distance;, score=0.507 total time=   4.6s\n",
      "[CV 1/5; 51/88] START leaf_size=50, n_neighbors=9, weights=uniform..............\n",
      "[CV 1/5; 51/88] END leaf_size=50, n_neighbors=9, weights=uniform;, score=0.505 total time=   5.0s\n",
      "[CV 2/5; 51/88] START leaf_size=50, n_neighbors=9, weights=uniform..............\n",
      "[CV 2/5; 51/88] END leaf_size=50, n_neighbors=9, weights=uniform;, score=0.507 total time=   5.3s\n",
      "[CV 3/5; 51/88] START leaf_size=50, n_neighbors=9, weights=uniform..............\n",
      "[CV 3/5; 51/88] END leaf_size=50, n_neighbors=9, weights=uniform;, score=0.504 total time=   5.3s\n",
      "[CV 4/5; 51/88] START leaf_size=50, n_neighbors=9, weights=uniform..............\n",
      "[CV 4/5; 51/88] END leaf_size=50, n_neighbors=9, weights=uniform;, score=0.500 total time=   6.6s\n",
      "[CV 5/5; 51/88] START leaf_size=50, n_neighbors=9, weights=uniform..............\n",
      "[CV 5/5; 51/88] END leaf_size=50, n_neighbors=9, weights=uniform;, score=0.507 total time=   6.7s\n",
      "[CV 1/5; 52/88] START leaf_size=50, n_neighbors=9, weights=distance.............\n",
      "[CV 1/5; 52/88] END leaf_size=50, n_neighbors=9, weights=distance;, score=0.505 total time=   6.2s\n",
      "[CV 2/5; 52/88] START leaf_size=50, n_neighbors=9, weights=distance.............\n",
      "[CV 2/5; 52/88] END leaf_size=50, n_neighbors=9, weights=distance;, score=0.508 total time=   6.5s\n",
      "[CV 3/5; 52/88] START leaf_size=50, n_neighbors=9, weights=distance.............\n",
      "[CV 3/5; 52/88] END leaf_size=50, n_neighbors=9, weights=distance;, score=0.504 total time=   6.5s\n",
      "[CV 4/5; 52/88] START leaf_size=50, n_neighbors=9, weights=distance.............\n",
      "[CV 4/5; 52/88] END leaf_size=50, n_neighbors=9, weights=distance;, score=0.500 total time=   6.2s\n",
      "[CV 5/5; 52/88] START leaf_size=50, n_neighbors=9, weights=distance.............\n",
      "[CV 5/5; 52/88] END leaf_size=50, n_neighbors=9, weights=distance;, score=0.507 total time=   6.3s\n",
      "[CV 1/5; 53/88] START leaf_size=50, n_neighbors=15, weights=uniform.............\n",
      "[CV 1/5; 53/88] END leaf_size=50, n_neighbors=15, weights=uniform;, score=0.503 total time=   6.2s\n",
      "[CV 2/5; 53/88] START leaf_size=50, n_neighbors=15, weights=uniform.............\n",
      "[CV 2/5; 53/88] END leaf_size=50, n_neighbors=15, weights=uniform;, score=0.503 total time=   6.8s\n",
      "[CV 3/5; 53/88] START leaf_size=50, n_neighbors=15, weights=uniform.............\n",
      "[CV 3/5; 53/88] END leaf_size=50, n_neighbors=15, weights=uniform;, score=0.500 total time=   7.4s\n",
      "[CV 4/5; 53/88] START leaf_size=50, n_neighbors=15, weights=uniform.............\n",
      "[CV 4/5; 53/88] END leaf_size=50, n_neighbors=15, weights=uniform;, score=0.500 total time=   6.8s\n",
      "[CV 5/5; 53/88] START leaf_size=50, n_neighbors=15, weights=uniform.............\n",
      "[CV 5/5; 53/88] END leaf_size=50, n_neighbors=15, weights=uniform;, score=0.503 total time=   6.5s\n",
      "[CV 1/5; 54/88] START leaf_size=50, n_neighbors=15, weights=distance............\n",
      "[CV 1/5; 54/88] END leaf_size=50, n_neighbors=15, weights=distance;, score=0.503 total time=   6.5s\n",
      "[CV 2/5; 54/88] START leaf_size=50, n_neighbors=15, weights=distance............\n",
      "[CV 2/5; 54/88] END leaf_size=50, n_neighbors=15, weights=distance;, score=0.503 total time=   6.9s\n",
      "[CV 3/5; 54/88] START leaf_size=50, n_neighbors=15, weights=distance............\n",
      "[CV 3/5; 54/88] END leaf_size=50, n_neighbors=15, weights=distance;, score=0.500 total time=   6.8s\n",
      "[CV 4/5; 54/88] START leaf_size=50, n_neighbors=15, weights=distance............\n",
      "[CV 4/5; 54/88] END leaf_size=50, n_neighbors=15, weights=distance;, score=0.501 total time=   6.5s\n",
      "[CV 5/5; 54/88] START leaf_size=50, n_neighbors=15, weights=distance............\n",
      "[CV 5/5; 54/88] END leaf_size=50, n_neighbors=15, weights=distance;, score=0.503 total time=   7.0s\n",
      "[CV 1/5; 55/88] START leaf_size=50, n_neighbors=19, weights=uniform.............\n",
      "[CV 1/5; 55/88] END leaf_size=50, n_neighbors=19, weights=uniform;, score=0.501 total time=   7.5s\n",
      "[CV 2/5; 55/88] START leaf_size=50, n_neighbors=19, weights=uniform.............\n",
      "[CV 2/5; 55/88] END leaf_size=50, n_neighbors=19, weights=uniform;, score=0.501 total time=   6.9s\n",
      "[CV 3/5; 55/88] START leaf_size=50, n_neighbors=19, weights=uniform.............\n",
      "[CV 3/5; 55/88] END leaf_size=50, n_neighbors=19, weights=uniform;, score=0.501 total time=   7.3s\n",
      "[CV 4/5; 55/88] START leaf_size=50, n_neighbors=19, weights=uniform.............\n",
      "[CV 4/5; 55/88] END leaf_size=50, n_neighbors=19, weights=uniform;, score=0.500 total time=   7.0s\n",
      "[CV 5/5; 55/88] START leaf_size=50, n_neighbors=19, weights=uniform.............\n",
      "[CV 5/5; 55/88] END leaf_size=50, n_neighbors=19, weights=uniform;, score=0.502 total time=   7.4s\n",
      "[CV 1/5; 56/88] START leaf_size=50, n_neighbors=19, weights=distance............\n",
      "[CV 1/5; 56/88] END leaf_size=50, n_neighbors=19, weights=distance;, score=0.501 total time=   7.0s\n",
      "[CV 2/5; 56/88] START leaf_size=50, n_neighbors=19, weights=distance............\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 56/88] END leaf_size=50, n_neighbors=19, weights=distance;, score=0.502 total time=   7.0s\n",
      "[CV 3/5; 56/88] START leaf_size=50, n_neighbors=19, weights=distance............\n",
      "[CV 3/5; 56/88] END leaf_size=50, n_neighbors=19, weights=distance;, score=0.501 total time=   6.1s\n",
      "[CV 4/5; 56/88] START leaf_size=50, n_neighbors=19, weights=distance............\n",
      "[CV 4/5; 56/88] END leaf_size=50, n_neighbors=19, weights=distance;, score=0.500 total time=   5.7s\n",
      "[CV 5/5; 56/88] START leaf_size=50, n_neighbors=19, weights=distance............\n",
      "[CV 5/5; 56/88] END leaf_size=50, n_neighbors=19, weights=distance;, score=0.502 total time=   6.1s\n",
      "[CV 1/5; 57/88] START leaf_size=50, n_neighbors=25, weights=uniform.............\n",
      "[CV 1/5; 57/88] END leaf_size=50, n_neighbors=25, weights=uniform;, score=0.499 total time=   5.8s\n",
      "[CV 2/5; 57/88] START leaf_size=50, n_neighbors=25, weights=uniform.............\n",
      "[CV 2/5; 57/88] END leaf_size=50, n_neighbors=25, weights=uniform;, score=0.501 total time=   7.3s\n",
      "[CV 3/5; 57/88] START leaf_size=50, n_neighbors=25, weights=uniform.............\n",
      "[CV 3/5; 57/88] END leaf_size=50, n_neighbors=25, weights=uniform;, score=0.499 total time=   7.2s\n",
      "[CV 4/5; 57/88] START leaf_size=50, n_neighbors=25, weights=uniform.............\n",
      "[CV 4/5; 57/88] END leaf_size=50, n_neighbors=25, weights=uniform;, score=0.502 total time=   7.3s\n",
      "[CV 5/5; 57/88] START leaf_size=50, n_neighbors=25, weights=uniform.............\n",
      "[CV 5/5; 57/88] END leaf_size=50, n_neighbors=25, weights=uniform;, score=0.501 total time=   7.5s\n",
      "[CV 1/5; 58/88] START leaf_size=50, n_neighbors=25, weights=distance............\n",
      "[CV 1/5; 58/88] END leaf_size=50, n_neighbors=25, weights=distance;, score=0.499 total time=   7.3s\n",
      "[CV 2/5; 58/88] START leaf_size=50, n_neighbors=25, weights=distance............\n",
      "[CV 2/5; 58/88] END leaf_size=50, n_neighbors=25, weights=distance;, score=0.501 total time=   6.2s\n",
      "[CV 3/5; 58/88] START leaf_size=50, n_neighbors=25, weights=distance............\n",
      "[CV 3/5; 58/88] END leaf_size=50, n_neighbors=25, weights=distance;, score=0.499 total time=   6.3s\n",
      "[CV 4/5; 58/88] START leaf_size=50, n_neighbors=25, weights=distance............\n",
      "[CV 4/5; 58/88] END leaf_size=50, n_neighbors=25, weights=distance;, score=0.501 total time=   6.5s\n",
      "[CV 5/5; 58/88] START leaf_size=50, n_neighbors=25, weights=distance............\n",
      "[CV 5/5; 58/88] END leaf_size=50, n_neighbors=25, weights=distance;, score=0.501 total time=   5.9s\n",
      "[CV 1/5; 59/88] START leaf_size=50, n_neighbors=35, weights=uniform.............\n",
      "[CV 1/5; 59/88] END leaf_size=50, n_neighbors=35, weights=uniform;, score=0.500 total time=   6.7s\n",
      "[CV 2/5; 59/88] START leaf_size=50, n_neighbors=35, weights=uniform.............\n",
      "[CV 2/5; 59/88] END leaf_size=50, n_neighbors=35, weights=uniform;, score=0.500 total time=   7.0s\n",
      "[CV 3/5; 59/88] START leaf_size=50, n_neighbors=35, weights=uniform.............\n",
      "[CV 3/5; 59/88] END leaf_size=50, n_neighbors=35, weights=uniform;, score=0.500 total time=   6.4s\n",
      "[CV 4/5; 59/88] START leaf_size=50, n_neighbors=35, weights=uniform.............\n",
      "[CV 4/5; 59/88] END leaf_size=50, n_neighbors=35, weights=uniform;, score=0.500 total time=   6.9s\n",
      "[CV 5/5; 59/88] START leaf_size=50, n_neighbors=35, weights=uniform.............\n",
      "[CV 5/5; 59/88] END leaf_size=50, n_neighbors=35, weights=uniform;, score=0.501 total time=   6.9s\n",
      "[CV 1/5; 60/88] START leaf_size=50, n_neighbors=35, weights=distance............\n",
      "[CV 1/5; 60/88] END leaf_size=50, n_neighbors=35, weights=distance;, score=0.500 total time=   7.2s\n",
      "[CV 2/5; 60/88] START leaf_size=50, n_neighbors=35, weights=distance............\n",
      "[CV 2/5; 60/88] END leaf_size=50, n_neighbors=35, weights=distance;, score=0.500 total time=   6.9s\n",
      "[CV 3/5; 60/88] START leaf_size=50, n_neighbors=35, weights=distance............\n",
      "[CV 3/5; 60/88] END leaf_size=50, n_neighbors=35, weights=distance;, score=0.500 total time=   6.3s\n",
      "[CV 4/5; 60/88] START leaf_size=50, n_neighbors=35, weights=distance............\n",
      "[CV 4/5; 60/88] END leaf_size=50, n_neighbors=35, weights=distance;, score=0.500 total time=   4.9s\n",
      "[CV 5/5; 60/88] START leaf_size=50, n_neighbors=35, weights=distance............\n",
      "[CV 5/5; 60/88] END leaf_size=50, n_neighbors=35, weights=distance;, score=0.501 total time=   4.9s\n",
      "[CV 1/5; 61/88] START leaf_size=50, n_neighbors=55, weights=uniform.............\n",
      "[CV 1/5; 61/88] END leaf_size=50, n_neighbors=55, weights=uniform;, score=0.500 total time=   4.8s\n",
      "[CV 2/5; 61/88] START leaf_size=50, n_neighbors=55, weights=uniform.............\n",
      "[CV 2/5; 61/88] END leaf_size=50, n_neighbors=55, weights=uniform;, score=0.500 total time=   5.0s\n",
      "[CV 3/5; 61/88] START leaf_size=50, n_neighbors=55, weights=uniform.............\n",
      "[CV 3/5; 61/88] END leaf_size=50, n_neighbors=55, weights=uniform;, score=0.501 total time=   4.9s\n",
      "[CV 4/5; 61/88] START leaf_size=50, n_neighbors=55, weights=uniform.............\n",
      "[CV 4/5; 61/88] END leaf_size=50, n_neighbors=55, weights=uniform;, score=0.500 total time=   5.0s\n",
      "[CV 5/5; 61/88] START leaf_size=50, n_neighbors=55, weights=uniform.............\n",
      "[CV 5/5; 61/88] END leaf_size=50, n_neighbors=55, weights=uniform;, score=0.500 total time=   4.8s\n",
      "[CV 1/5; 62/88] START leaf_size=50, n_neighbors=55, weights=distance............\n",
      "[CV 1/5; 62/88] END leaf_size=50, n_neighbors=55, weights=distance;, score=0.500 total time=   4.7s\n",
      "[CV 2/5; 62/88] START leaf_size=50, n_neighbors=55, weights=distance............\n",
      "[CV 2/5; 62/88] END leaf_size=50, n_neighbors=55, weights=distance;, score=0.500 total time=   4.8s\n",
      "[CV 3/5; 62/88] START leaf_size=50, n_neighbors=55, weights=distance............\n",
      "[CV 3/5; 62/88] END leaf_size=50, n_neighbors=55, weights=distance;, score=0.500 total time=   4.6s\n",
      "[CV 4/5; 62/88] START leaf_size=50, n_neighbors=55, weights=distance............\n",
      "[CV 4/5; 62/88] END leaf_size=50, n_neighbors=55, weights=distance;, score=0.500 total time=   5.3s\n",
      "[CV 5/5; 62/88] START leaf_size=50, n_neighbors=55, weights=distance............\n",
      "[CV 5/5; 62/88] END leaf_size=50, n_neighbors=55, weights=distance;, score=0.500 total time=   6.1s\n",
      "[CV 1/5; 63/88] START leaf_size=50, n_neighbors=75, weights=uniform.............\n",
      "[CV 1/5; 63/88] END leaf_size=50, n_neighbors=75, weights=uniform;, score=0.500 total time=   6.8s\n",
      "[CV 2/5; 63/88] START leaf_size=50, n_neighbors=75, weights=uniform.............\n",
      "[CV 2/5; 63/88] END leaf_size=50, n_neighbors=75, weights=uniform;, score=0.500 total time=   6.4s\n",
      "[CV 3/5; 63/88] START leaf_size=50, n_neighbors=75, weights=uniform.............\n",
      "[CV 3/5; 63/88] END leaf_size=50, n_neighbors=75, weights=uniform;, score=0.500 total time=   6.6s\n",
      "[CV 4/5; 63/88] START leaf_size=50, n_neighbors=75, weights=uniform.............\n",
      "[CV 4/5; 63/88] END leaf_size=50, n_neighbors=75, weights=uniform;, score=0.500 total time=   7.2s\n",
      "[CV 5/5; 63/88] START leaf_size=50, n_neighbors=75, weights=uniform.............\n",
      "[CV 5/5; 63/88] END leaf_size=50, n_neighbors=75, weights=uniform;, score=0.500 total time=   6.9s\n",
      "[CV 1/5; 64/88] START leaf_size=50, n_neighbors=75, weights=distance............\n",
      "[CV 1/5; 64/88] END leaf_size=50, n_neighbors=75, weights=distance;, score=0.500 total time=   6.5s\n",
      "[CV 2/5; 64/88] START leaf_size=50, n_neighbors=75, weights=distance............\n",
      "[CV 2/5; 64/88] END leaf_size=50, n_neighbors=75, weights=distance;, score=0.500 total time=   6.7s\n",
      "[CV 3/5; 64/88] START leaf_size=50, n_neighbors=75, weights=distance............\n",
      "[CV 3/5; 64/88] END leaf_size=50, n_neighbors=75, weights=distance;, score=0.500 total time=   6.9s\n",
      "[CV 4/5; 64/88] START leaf_size=50, n_neighbors=75, weights=distance............\n",
      "[CV 4/5; 64/88] END leaf_size=50, n_neighbors=75, weights=distance;, score=0.500 total time=   7.1s\n",
      "[CV 5/5; 64/88] START leaf_size=50, n_neighbors=75, weights=distance............\n",
      "[CV 5/5; 64/88] END leaf_size=50, n_neighbors=75, weights=distance;, score=0.500 total time=   6.3s\n",
      "[CV 1/5; 65/88] START leaf_size=50, n_neighbors=99, weights=uniform.............\n",
      "[CV 1/5; 65/88] END leaf_size=50, n_neighbors=99, weights=uniform;, score=0.500 total time=   6.8s\n",
      "[CV 2/5; 65/88] START leaf_size=50, n_neighbors=99, weights=uniform.............\n",
      "[CV 2/5; 65/88] END leaf_size=50, n_neighbors=99, weights=uniform;, score=0.500 total time=   6.4s\n",
      "[CV 3/5; 65/88] START leaf_size=50, n_neighbors=99, weights=uniform.............\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 65/88] END leaf_size=50, n_neighbors=99, weights=uniform;, score=0.500 total time=   6.6s\n",
      "[CV 4/5; 65/88] START leaf_size=50, n_neighbors=99, weights=uniform.............\n",
      "[CV 4/5; 65/88] END leaf_size=50, n_neighbors=99, weights=uniform;, score=0.500 total time=   6.7s\n",
      "[CV 5/5; 65/88] START leaf_size=50, n_neighbors=99, weights=uniform.............\n",
      "[CV 5/5; 65/88] END leaf_size=50, n_neighbors=99, weights=uniform;, score=0.500 total time=   7.1s\n",
      "[CV 1/5; 66/88] START leaf_size=50, n_neighbors=99, weights=distance............\n",
      "[CV 1/5; 66/88] END leaf_size=50, n_neighbors=99, weights=distance;, score=0.500 total time=   7.3s\n",
      "[CV 2/5; 66/88] START leaf_size=50, n_neighbors=99, weights=distance............\n",
      "[CV 2/5; 66/88] END leaf_size=50, n_neighbors=99, weights=distance;, score=0.500 total time=   6.2s\n",
      "[CV 3/5; 66/88] START leaf_size=50, n_neighbors=99, weights=distance............\n",
      "[CV 3/5; 66/88] END leaf_size=50, n_neighbors=99, weights=distance;, score=0.500 total time=   6.7s\n",
      "[CV 4/5; 66/88] START leaf_size=50, n_neighbors=99, weights=distance............\n",
      "[CV 4/5; 66/88] END leaf_size=50, n_neighbors=99, weights=distance;, score=0.500 total time=   7.0s\n",
      "[CV 5/5; 66/88] START leaf_size=50, n_neighbors=99, weights=distance............\n",
      "[CV 5/5; 66/88] END leaf_size=50, n_neighbors=99, weights=distance;, score=0.500 total time=   8.0s\n",
      "[CV 1/5; 67/88] START leaf_size=70, n_neighbors=3, weights=uniform..............\n",
      "[CV 1/5; 67/88] END leaf_size=70, n_neighbors=3, weights=uniform;, score=0.504 total time=   5.9s\n",
      "[CV 2/5; 67/88] START leaf_size=70, n_neighbors=3, weights=uniform..............\n",
      "[CV 2/5; 67/88] END leaf_size=70, n_neighbors=3, weights=uniform;, score=0.510 total time=   4.7s\n",
      "[CV 3/5; 67/88] START leaf_size=70, n_neighbors=3, weights=uniform..............\n",
      "[CV 3/5; 67/88] END leaf_size=70, n_neighbors=3, weights=uniform;, score=0.504 total time=   5.2s\n",
      "[CV 4/5; 67/88] START leaf_size=70, n_neighbors=3, weights=uniform..............\n",
      "[CV 4/5; 67/88] END leaf_size=70, n_neighbors=3, weights=uniform;, score=0.506 total time=   4.8s\n",
      "[CV 5/5; 67/88] START leaf_size=70, n_neighbors=3, weights=uniform..............\n",
      "[CV 5/5; 67/88] END leaf_size=70, n_neighbors=3, weights=uniform;, score=0.501 total time=   4.8s\n",
      "[CV 1/5; 68/88] START leaf_size=70, n_neighbors=3, weights=distance.............\n",
      "[CV 1/5; 68/88] END leaf_size=70, n_neighbors=3, weights=distance;, score=0.504 total time=   5.7s\n",
      "[CV 2/5; 68/88] START leaf_size=70, n_neighbors=3, weights=distance.............\n",
      "[CV 2/5; 68/88] END leaf_size=70, n_neighbors=3, weights=distance;, score=0.510 total time=   5.6s\n",
      "[CV 3/5; 68/88] START leaf_size=70, n_neighbors=3, weights=distance.............\n",
      "[CV 3/5; 68/88] END leaf_size=70, n_neighbors=3, weights=distance;, score=0.504 total time=   5.4s\n",
      "[CV 4/5; 68/88] START leaf_size=70, n_neighbors=3, weights=distance.............\n",
      "[CV 4/5; 68/88] END leaf_size=70, n_neighbors=3, weights=distance;, score=0.506 total time=   5.8s\n",
      "[CV 5/5; 68/88] START leaf_size=70, n_neighbors=3, weights=distance.............\n",
      "[CV 5/5; 68/88] END leaf_size=70, n_neighbors=3, weights=distance;, score=0.500 total time=   5.5s\n",
      "[CV 1/5; 69/88] START leaf_size=70, n_neighbors=5, weights=uniform..............\n",
      "[CV 1/5; 69/88] END leaf_size=70, n_neighbors=5, weights=uniform;, score=0.500 total time=   7.7s\n",
      "[CV 2/5; 69/88] START leaf_size=70, n_neighbors=5, weights=uniform..............\n",
      "[CV 2/5; 69/88] END leaf_size=70, n_neighbors=5, weights=uniform;, score=0.515 total time=   7.6s\n",
      "[CV 3/5; 69/88] START leaf_size=70, n_neighbors=5, weights=uniform..............\n",
      "[CV 3/5; 69/88] END leaf_size=70, n_neighbors=5, weights=uniform;, score=0.507 total time=   5.8s\n",
      "[CV 4/5; 69/88] START leaf_size=70, n_neighbors=5, weights=uniform..............\n",
      "[CV 4/5; 69/88] END leaf_size=70, n_neighbors=5, weights=uniform;, score=0.506 total time=   7.3s\n",
      "[CV 5/5; 69/88] START leaf_size=70, n_neighbors=5, weights=uniform..............\n",
      "[CV 5/5; 69/88] END leaf_size=70, n_neighbors=5, weights=uniform;, score=0.498 total time=   7.6s\n",
      "[CV 1/5; 70/88] START leaf_size=70, n_neighbors=5, weights=distance.............\n",
      "[CV 1/5; 70/88] END leaf_size=70, n_neighbors=5, weights=distance;, score=0.500 total time=   7.5s\n",
      "[CV 2/5; 70/88] START leaf_size=70, n_neighbors=5, weights=distance.............\n",
      "[CV 2/5; 70/88] END leaf_size=70, n_neighbors=5, weights=distance;, score=0.515 total time=   7.3s\n",
      "[CV 3/5; 70/88] START leaf_size=70, n_neighbors=5, weights=distance.............\n",
      "[CV 3/5; 70/88] END leaf_size=70, n_neighbors=5, weights=distance;, score=0.506 total time=   7.1s\n",
      "[CV 4/5; 70/88] START leaf_size=70, n_neighbors=5, weights=distance.............\n",
      "[CV 4/5; 70/88] END leaf_size=70, n_neighbors=5, weights=distance;, score=0.506 total time=   7.1s\n",
      "[CV 5/5; 70/88] START leaf_size=70, n_neighbors=5, weights=distance.............\n",
      "[CV 5/5; 70/88] END leaf_size=70, n_neighbors=5, weights=distance;, score=0.498 total time=   6.6s\n",
      "[CV 1/5; 71/88] START leaf_size=70, n_neighbors=7, weights=uniform..............\n",
      "[CV 1/5; 71/88] END leaf_size=70, n_neighbors=7, weights=uniform;, score=0.503 total time=   7.4s\n",
      "[CV 2/5; 71/88] START leaf_size=70, n_neighbors=7, weights=uniform..............\n",
      "[CV 2/5; 71/88] END leaf_size=70, n_neighbors=7, weights=uniform;, score=0.506 total time=   7.1s\n",
      "[CV 3/5; 71/88] START leaf_size=70, n_neighbors=7, weights=uniform..............\n",
      "[CV 3/5; 71/88] END leaf_size=70, n_neighbors=7, weights=uniform;, score=0.502 total time=   6.7s\n",
      "[CV 4/5; 71/88] START leaf_size=70, n_neighbors=7, weights=uniform..............\n",
      "[CV 4/5; 71/88] END leaf_size=70, n_neighbors=7, weights=uniform;, score=0.505 total time=   7.4s\n",
      "[CV 5/5; 71/88] START leaf_size=70, n_neighbors=7, weights=uniform..............\n",
      "[CV 5/5; 71/88] END leaf_size=70, n_neighbors=7, weights=uniform;, score=0.507 total time=   7.0s\n",
      "[CV 1/5; 72/88] START leaf_size=70, n_neighbors=7, weights=distance.............\n",
      "[CV 1/5; 72/88] END leaf_size=70, n_neighbors=7, weights=distance;, score=0.503 total time=   7.5s\n",
      "[CV 2/5; 72/88] START leaf_size=70, n_neighbors=7, weights=distance.............\n",
      "[CV 2/5; 72/88] END leaf_size=70, n_neighbors=7, weights=distance;, score=0.506 total time=   6.6s\n",
      "[CV 3/5; 72/88] START leaf_size=70, n_neighbors=7, weights=distance.............\n",
      "[CV 3/5; 72/88] END leaf_size=70, n_neighbors=7, weights=distance;, score=0.502 total time=   7.1s\n",
      "[CV 4/5; 72/88] START leaf_size=70, n_neighbors=7, weights=distance.............\n",
      "[CV 4/5; 72/88] END leaf_size=70, n_neighbors=7, weights=distance;, score=0.504 total time=   6.9s\n",
      "[CV 5/5; 72/88] START leaf_size=70, n_neighbors=7, weights=distance.............\n",
      "[CV 5/5; 72/88] END leaf_size=70, n_neighbors=7, weights=distance;, score=0.507 total time=   6.8s\n",
      "[CV 1/5; 73/88] START leaf_size=70, n_neighbors=9, weights=uniform..............\n",
      "[CV 1/5; 73/88] END leaf_size=70, n_neighbors=9, weights=uniform;, score=0.505 total time=   7.4s\n",
      "[CV 2/5; 73/88] START leaf_size=70, n_neighbors=9, weights=uniform..............\n",
      "[CV 2/5; 73/88] END leaf_size=70, n_neighbors=9, weights=uniform;, score=0.507 total time=   7.8s\n",
      "[CV 3/5; 73/88] START leaf_size=70, n_neighbors=9, weights=uniform..............\n",
      "[CV 3/5; 73/88] END leaf_size=70, n_neighbors=9, weights=uniform;, score=0.504 total time=   7.6s\n",
      "[CV 4/5; 73/88] START leaf_size=70, n_neighbors=9, weights=uniform..............\n",
      "[CV 4/5; 73/88] END leaf_size=70, n_neighbors=9, weights=uniform;, score=0.500 total time=   7.7s\n",
      "[CV 5/5; 73/88] START leaf_size=70, n_neighbors=9, weights=uniform..............\n",
      "[CV 5/5; 73/88] END leaf_size=70, n_neighbors=9, weights=uniform;, score=0.507 total time=   7.3s\n",
      "[CV 1/5; 74/88] START leaf_size=70, n_neighbors=9, weights=distance.............\n",
      "[CV 1/5; 74/88] END leaf_size=70, n_neighbors=9, weights=distance;, score=0.505 total time=   6.3s\n",
      "[CV 2/5; 74/88] START leaf_size=70, n_neighbors=9, weights=distance.............\n",
      "[CV 2/5; 74/88] END leaf_size=70, n_neighbors=9, weights=distance;, score=0.508 total time=   6.5s\n",
      "[CV 3/5; 74/88] START leaf_size=70, n_neighbors=9, weights=distance.............\n",
      "[CV 3/5; 74/88] END leaf_size=70, n_neighbors=9, weights=distance;, score=0.504 total time=   6.5s\n",
      "[CV 4/5; 74/88] START leaf_size=70, n_neighbors=9, weights=distance.............\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 74/88] END leaf_size=70, n_neighbors=9, weights=distance;, score=0.500 total time=   6.5s\n",
      "[CV 5/5; 74/88] START leaf_size=70, n_neighbors=9, weights=distance.............\n",
      "[CV 5/5; 74/88] END leaf_size=70, n_neighbors=9, weights=distance;, score=0.507 total time=   6.3s\n",
      "[CV 1/5; 75/88] START leaf_size=70, n_neighbors=15, weights=uniform.............\n",
      "[CV 1/5; 75/88] END leaf_size=70, n_neighbors=15, weights=uniform;, score=0.503 total time=   7.0s\n",
      "[CV 2/5; 75/88] START leaf_size=70, n_neighbors=15, weights=uniform.............\n",
      "[CV 2/5; 75/88] END leaf_size=70, n_neighbors=15, weights=uniform;, score=0.503 total time=   7.3s\n",
      "[CV 3/5; 75/88] START leaf_size=70, n_neighbors=15, weights=uniform.............\n",
      "[CV 3/5; 75/88] END leaf_size=70, n_neighbors=15, weights=uniform;, score=0.500 total time=   7.3s\n",
      "[CV 4/5; 75/88] START leaf_size=70, n_neighbors=15, weights=uniform.............\n",
      "[CV 4/5; 75/88] END leaf_size=70, n_neighbors=15, weights=uniform;, score=0.500 total time=   7.6s\n",
      "[CV 5/5; 75/88] START leaf_size=70, n_neighbors=15, weights=uniform.............\n",
      "[CV 5/5; 75/88] END leaf_size=70, n_neighbors=15, weights=uniform;, score=0.503 total time=   7.5s\n",
      "[CV 1/5; 76/88] START leaf_size=70, n_neighbors=15, weights=distance............\n",
      "[CV 1/5; 76/88] END leaf_size=70, n_neighbors=15, weights=distance;, score=0.503 total time=   7.2s\n",
      "[CV 2/5; 76/88] START leaf_size=70, n_neighbors=15, weights=distance............\n",
      "[CV 2/5; 76/88] END leaf_size=70, n_neighbors=15, weights=distance;, score=0.503 total time=   7.5s\n",
      "[CV 3/5; 76/88] START leaf_size=70, n_neighbors=15, weights=distance............\n",
      "[CV 3/5; 76/88] END leaf_size=70, n_neighbors=15, weights=distance;, score=0.500 total time=   7.3s\n",
      "[CV 4/5; 76/88] START leaf_size=70, n_neighbors=15, weights=distance............\n",
      "[CV 4/5; 76/88] END leaf_size=70, n_neighbors=15, weights=distance;, score=0.501 total time=   7.3s\n",
      "[CV 5/5; 76/88] START leaf_size=70, n_neighbors=15, weights=distance............\n",
      "[CV 5/5; 76/88] END leaf_size=70, n_neighbors=15, weights=distance;, score=0.503 total time=   7.2s\n",
      "[CV 1/5; 77/88] START leaf_size=70, n_neighbors=19, weights=uniform.............\n",
      "[CV 1/5; 77/88] END leaf_size=70, n_neighbors=19, weights=uniform;, score=0.501 total time=   7.9s\n",
      "[CV 2/5; 77/88] START leaf_size=70, n_neighbors=19, weights=uniform.............\n",
      "[CV 2/5; 77/88] END leaf_size=70, n_neighbors=19, weights=uniform;, score=0.501 total time=   7.3s\n",
      "[CV 3/5; 77/88] START leaf_size=70, n_neighbors=19, weights=uniform.............\n",
      "[CV 3/5; 77/88] END leaf_size=70, n_neighbors=19, weights=uniform;, score=0.501 total time=   7.1s\n",
      "[CV 4/5; 77/88] START leaf_size=70, n_neighbors=19, weights=uniform.............\n",
      "[CV 4/5; 77/88] END leaf_size=70, n_neighbors=19, weights=uniform;, score=0.500 total time=   6.9s\n",
      "[CV 5/5; 77/88] START leaf_size=70, n_neighbors=19, weights=uniform.............\n",
      "[CV 5/5; 77/88] END leaf_size=70, n_neighbors=19, weights=uniform;, score=0.502 total time=   6.8s\n",
      "[CV 1/5; 78/88] START leaf_size=70, n_neighbors=19, weights=distance............\n",
      "[CV 1/5; 78/88] END leaf_size=70, n_neighbors=19, weights=distance;, score=0.501 total time=   7.1s\n",
      "[CV 2/5; 78/88] START leaf_size=70, n_neighbors=19, weights=distance............\n",
      "[CV 2/5; 78/88] END leaf_size=70, n_neighbors=19, weights=distance;, score=0.502 total time=   6.9s\n",
      "[CV 3/5; 78/88] START leaf_size=70, n_neighbors=19, weights=distance............\n",
      "[CV 3/5; 78/88] END leaf_size=70, n_neighbors=19, weights=distance;, score=0.501 total time=   6.7s\n",
      "[CV 4/5; 78/88] START leaf_size=70, n_neighbors=19, weights=distance............\n",
      "[CV 4/5; 78/88] END leaf_size=70, n_neighbors=19, weights=distance;, score=0.500 total time=   7.4s\n",
      "[CV 5/5; 78/88] START leaf_size=70, n_neighbors=19, weights=distance............\n",
      "[CV 5/5; 78/88] END leaf_size=70, n_neighbors=19, weights=distance;, score=0.502 total time=   7.0s\n",
      "[CV 1/5; 79/88] START leaf_size=70, n_neighbors=25, weights=uniform.............\n",
      "[CV 1/5; 79/88] END leaf_size=70, n_neighbors=25, weights=uniform;, score=0.499 total time=   7.6s\n",
      "[CV 2/5; 79/88] START leaf_size=70, n_neighbors=25, weights=uniform.............\n",
      "[CV 2/5; 79/88] END leaf_size=70, n_neighbors=25, weights=uniform;, score=0.501 total time=   7.2s\n",
      "[CV 3/5; 79/88] START leaf_size=70, n_neighbors=25, weights=uniform.............\n",
      "[CV 3/5; 79/88] END leaf_size=70, n_neighbors=25, weights=uniform;, score=0.499 total time=   7.3s\n",
      "[CV 4/5; 79/88] START leaf_size=70, n_neighbors=25, weights=uniform.............\n",
      "[CV 4/5; 79/88] END leaf_size=70, n_neighbors=25, weights=uniform;, score=0.502 total time=   7.5s\n",
      "[CV 5/5; 79/88] START leaf_size=70, n_neighbors=25, weights=uniform.............\n",
      "[CV 5/5; 79/88] END leaf_size=70, n_neighbors=25, weights=uniform;, score=0.501 total time=   7.2s\n",
      "[CV 1/5; 80/88] START leaf_size=70, n_neighbors=25, weights=distance............\n",
      "[CV 1/5; 80/88] END leaf_size=70, n_neighbors=25, weights=distance;, score=0.499 total time=   7.0s\n",
      "[CV 2/5; 80/88] START leaf_size=70, n_neighbors=25, weights=distance............\n",
      "[CV 2/5; 80/88] END leaf_size=70, n_neighbors=25, weights=distance;, score=0.501 total time=   7.2s\n",
      "[CV 3/5; 80/88] START leaf_size=70, n_neighbors=25, weights=distance............\n",
      "[CV 3/5; 80/88] END leaf_size=70, n_neighbors=25, weights=distance;, score=0.499 total time=   6.7s\n",
      "[CV 4/5; 80/88] START leaf_size=70, n_neighbors=25, weights=distance............\n",
      "[CV 4/5; 80/88] END leaf_size=70, n_neighbors=25, weights=distance;, score=0.501 total time=   7.0s\n",
      "[CV 5/5; 80/88] START leaf_size=70, n_neighbors=25, weights=distance............\n",
      "[CV 5/5; 80/88] END leaf_size=70, n_neighbors=25, weights=distance;, score=0.501 total time=   6.5s\n",
      "[CV 1/5; 81/88] START leaf_size=70, n_neighbors=35, weights=uniform.............\n",
      "[CV 1/5; 81/88] END leaf_size=70, n_neighbors=35, weights=uniform;, score=0.500 total time=   7.3s\n",
      "[CV 2/5; 81/88] START leaf_size=70, n_neighbors=35, weights=uniform.............\n",
      "[CV 2/5; 81/88] END leaf_size=70, n_neighbors=35, weights=uniform;, score=0.500 total time=   7.4s\n",
      "[CV 3/5; 81/88] START leaf_size=70, n_neighbors=35, weights=uniform.............\n",
      "[CV 3/5; 81/88] END leaf_size=70, n_neighbors=35, weights=uniform;, score=0.500 total time=   7.4s\n",
      "[CV 4/5; 81/88] START leaf_size=70, n_neighbors=35, weights=uniform.............\n",
      "[CV 4/5; 81/88] END leaf_size=70, n_neighbors=35, weights=uniform;, score=0.500 total time=   7.1s\n",
      "[CV 5/5; 81/88] START leaf_size=70, n_neighbors=35, weights=uniform.............\n",
      "[CV 5/5; 81/88] END leaf_size=70, n_neighbors=35, weights=uniform;, score=0.501 total time=   7.1s\n",
      "[CV 1/5; 82/88] START leaf_size=70, n_neighbors=35, weights=distance............\n",
      "[CV 1/5; 82/88] END leaf_size=70, n_neighbors=35, weights=distance;, score=0.500 total time=   7.0s\n",
      "[CV 2/5; 82/88] START leaf_size=70, n_neighbors=35, weights=distance............\n",
      "[CV 2/5; 82/88] END leaf_size=70, n_neighbors=35, weights=distance;, score=0.500 total time=   7.0s\n",
      "[CV 3/5; 82/88] START leaf_size=70, n_neighbors=35, weights=distance............\n",
      "[CV 3/5; 82/88] END leaf_size=70, n_neighbors=35, weights=distance;, score=0.500 total time=   7.1s\n",
      "[CV 4/5; 82/88] START leaf_size=70, n_neighbors=35, weights=distance............\n",
      "[CV 4/5; 82/88] END leaf_size=70, n_neighbors=35, weights=distance;, score=0.500 total time=   7.0s\n",
      "[CV 5/5; 82/88] START leaf_size=70, n_neighbors=35, weights=distance............\n",
      "[CV 5/5; 82/88] END leaf_size=70, n_neighbors=35, weights=distance;, score=0.501 total time=   5.8s\n",
      "[CV 1/5; 83/88] START leaf_size=70, n_neighbors=55, weights=uniform.............\n",
      "[CV 1/5; 83/88] END leaf_size=70, n_neighbors=55, weights=uniform;, score=0.500 total time=   5.6s\n",
      "[CV 2/5; 83/88] START leaf_size=70, n_neighbors=55, weights=uniform.............\n",
      "[CV 2/5; 83/88] END leaf_size=70, n_neighbors=55, weights=uniform;, score=0.500 total time=   5.3s\n",
      "[CV 3/5; 83/88] START leaf_size=70, n_neighbors=55, weights=uniform.............\n",
      "[CV 3/5; 83/88] END leaf_size=70, n_neighbors=55, weights=uniform;, score=0.501 total time=   5.8s\n",
      "[CV 4/5; 83/88] START leaf_size=70, n_neighbors=55, weights=uniform.............\n",
      "[CV 4/5; 83/88] END leaf_size=70, n_neighbors=55, weights=uniform;, score=0.500 total time=   5.3s\n",
      "[CV 5/5; 83/88] START leaf_size=70, n_neighbors=55, weights=uniform.............\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 83/88] END leaf_size=70, n_neighbors=55, weights=uniform;, score=0.500 total time=   6.0s\n",
      "[CV 1/5; 84/88] START leaf_size=70, n_neighbors=55, weights=distance............\n",
      "[CV 1/5; 84/88] END leaf_size=70, n_neighbors=55, weights=distance;, score=0.500 total time=   5.3s\n",
      "[CV 2/5; 84/88] START leaf_size=70, n_neighbors=55, weights=distance............\n",
      "[CV 2/5; 84/88] END leaf_size=70, n_neighbors=55, weights=distance;, score=0.500 total time=   6.2s\n",
      "[CV 3/5; 84/88] START leaf_size=70, n_neighbors=55, weights=distance............\n",
      "[CV 3/5; 84/88] END leaf_size=70, n_neighbors=55, weights=distance;, score=0.500 total time=   5.7s\n",
      "[CV 4/5; 84/88] START leaf_size=70, n_neighbors=55, weights=distance............\n",
      "[CV 4/5; 84/88] END leaf_size=70, n_neighbors=55, weights=distance;, score=0.500 total time=   5.6s\n",
      "[CV 5/5; 84/88] START leaf_size=70, n_neighbors=55, weights=distance............\n",
      "[CV 5/5; 84/88] END leaf_size=70, n_neighbors=55, weights=distance;, score=0.500 total time=   5.8s\n",
      "[CV 1/5; 85/88] START leaf_size=70, n_neighbors=75, weights=uniform.............\n",
      "[CV 1/5; 85/88] END leaf_size=70, n_neighbors=75, weights=uniform;, score=0.500 total time=   5.8s\n",
      "[CV 2/5; 85/88] START leaf_size=70, n_neighbors=75, weights=uniform.............\n",
      "[CV 2/5; 85/88] END leaf_size=70, n_neighbors=75, weights=uniform;, score=0.500 total time=   5.3s\n",
      "[CV 3/5; 85/88] START leaf_size=70, n_neighbors=75, weights=uniform.............\n",
      "[CV 3/5; 85/88] END leaf_size=70, n_neighbors=75, weights=uniform;, score=0.500 total time=   5.5s\n",
      "[CV 4/5; 85/88] START leaf_size=70, n_neighbors=75, weights=uniform.............\n",
      "[CV 4/5; 85/88] END leaf_size=70, n_neighbors=75, weights=uniform;, score=0.500 total time=   5.6s\n",
      "[CV 5/5; 85/88] START leaf_size=70, n_neighbors=75, weights=uniform.............\n",
      "[CV 5/5; 85/88] END leaf_size=70, n_neighbors=75, weights=uniform;, score=0.500 total time=   6.1s\n",
      "[CV 1/5; 86/88] START leaf_size=70, n_neighbors=75, weights=distance............\n",
      "[CV 1/5; 86/88] END leaf_size=70, n_neighbors=75, weights=distance;, score=0.500 total time=   5.4s\n",
      "[CV 2/5; 86/88] START leaf_size=70, n_neighbors=75, weights=distance............\n",
      "[CV 2/5; 86/88] END leaf_size=70, n_neighbors=75, weights=distance;, score=0.500 total time=   6.1s\n",
      "[CV 3/5; 86/88] START leaf_size=70, n_neighbors=75, weights=distance............\n",
      "[CV 3/5; 86/88] END leaf_size=70, n_neighbors=75, weights=distance;, score=0.500 total time=   5.4s\n",
      "[CV 4/5; 86/88] START leaf_size=70, n_neighbors=75, weights=distance............\n",
      "[CV 4/5; 86/88] END leaf_size=70, n_neighbors=75, weights=distance;, score=0.500 total time=   5.8s\n",
      "[CV 5/5; 86/88] START leaf_size=70, n_neighbors=75, weights=distance............\n",
      "[CV 5/5; 86/88] END leaf_size=70, n_neighbors=75, weights=distance;, score=0.500 total time=   4.6s\n",
      "[CV 1/5; 87/88] START leaf_size=70, n_neighbors=99, weights=uniform.............\n",
      "[CV 1/5; 87/88] END leaf_size=70, n_neighbors=99, weights=uniform;, score=0.500 total time=   5.7s\n",
      "[CV 2/5; 87/88] START leaf_size=70, n_neighbors=99, weights=uniform.............\n",
      "[CV 2/5; 87/88] END leaf_size=70, n_neighbors=99, weights=uniform;, score=0.500 total time=   5.2s\n",
      "[CV 3/5; 87/88] START leaf_size=70, n_neighbors=99, weights=uniform.............\n",
      "[CV 3/5; 87/88] END leaf_size=70, n_neighbors=99, weights=uniform;, score=0.500 total time=   5.8s\n",
      "[CV 4/5; 87/88] START leaf_size=70, n_neighbors=99, weights=uniform.............\n",
      "[CV 4/5; 87/88] END leaf_size=70, n_neighbors=99, weights=uniform;, score=0.500 total time=   5.4s\n",
      "[CV 5/5; 87/88] START leaf_size=70, n_neighbors=99, weights=uniform.............\n",
      "[CV 5/5; 87/88] END leaf_size=70, n_neighbors=99, weights=uniform;, score=0.500 total time=   5.5s\n",
      "[CV 1/5; 88/88] START leaf_size=70, n_neighbors=99, weights=distance............\n",
      "[CV 1/5; 88/88] END leaf_size=70, n_neighbors=99, weights=distance;, score=0.500 total time=   5.8s\n",
      "[CV 2/5; 88/88] START leaf_size=70, n_neighbors=99, weights=distance............\n",
      "[CV 2/5; 88/88] END leaf_size=70, n_neighbors=99, weights=distance;, score=0.500 total time=   5.3s\n",
      "[CV 3/5; 88/88] START leaf_size=70, n_neighbors=99, weights=distance............\n",
      "[CV 3/5; 88/88] END leaf_size=70, n_neighbors=99, weights=distance;, score=0.500 total time=   6.2s\n",
      "[CV 4/5; 88/88] START leaf_size=70, n_neighbors=99, weights=distance............\n",
      "[CV 4/5; 88/88] END leaf_size=70, n_neighbors=99, weights=distance;, score=0.500 total time=   5.4s\n",
      "[CV 5/5; 88/88] START leaf_size=70, n_neighbors=99, weights=distance............\n",
      "[CV 5/5; 88/88] END leaf_size=70, n_neighbors=99, weights=distance;, score=0.500 total time=   5.2s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=KNeighborsClassifier(),\n",
       "             param_grid={'leaf_size': [20, 30, 50, 70],\n",
       "                         'n_neighbors': [3, 5, 7, 9, 15, 19, 25, 35, 55, 75,\n",
       "                                         99],\n",
       "                         'weights': ['uniform', 'distance']},\n",
       "             scoring='balanced_accuracy', verbose=10)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "parameters = { 'n_neighbors': [3, 5, 7, 9, 15, 19, 25, 35, 55,75, 99],\n",
    "                'leaf_size': [20, 30, 50, 70],\n",
    "              'weights': ['uniform', 'distance']\n",
    "                 }\n",
    "\n",
    "model = KNeighborsClassifier()\n",
    "\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=parameters, verbose=10, scoring=\"balanced_accuracy\")\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "17040147",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'leaf_size': 20, 'n_neighbors': 5, 'weights': 'uniform'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ec4e2398",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KNeighborsClassifier(n_neighbors=5, leaf_size=20, weights='uniform')\n",
    "model.fit(X_train, y_train)\n",
    "predicted = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f77d7671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7045313469894475\n",
      "Balanced Accuracy:  0.5156838933793998\n",
      "Precision:  0.7483416252072969\n",
      "Recall:  0.9064278540341479\n",
      "F1:  0.8198334595003786\n"
     ]
    }
   ],
   "source": [
    "evaluate(predicted, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f898fc9",
   "metadata": {},
   "source": [
    "As we can see although we have not-bad accuracy but balanced accuracy which is wanted for this task is not good so we should look for better moodels.\n",
    "\n",
    "By remember that with these parameters:\n",
    "```\n",
    "{'n_neighbors': 5,\n",
    " 'leaf_size': 20,\n",
    " 'weights': uniform\n",
    "}\n",
    "```\n",
    " \n",
    "We got these results:\n",
    "```\n",
    "Accuracy:  0.7045313469894475\n",
    "Balanced Accuracy:  0.5156838933793998\n",
    "Precision:  0.7483416252072969\n",
    "Recall:  0.9064278540341479\n",
    "F1:  0.8198334595003786\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f874ded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 240 candidates, totalling 1200 fits\n",
      "[CV 1/5; 1/240] START max_iter=50, penalty=l1, solver=newton-cg, tol=0.001......\n",
      "[CV 1/5; 1/240] END max_iter=50, penalty=l1, solver=newton-cg, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 2/5; 1/240] START max_iter=50, penalty=l1, solver=newton-cg, tol=0.001......\n",
      "[CV 2/5; 1/240] END max_iter=50, penalty=l1, solver=newton-cg, tol=0.001;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 1/240] START max_iter=50, penalty=l1, solver=newton-cg, tol=0.001......\n",
      "[CV 3/5; 1/240] END max_iter=50, penalty=l1, solver=newton-cg, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 4/5; 1/240] START max_iter=50, penalty=l1, solver=newton-cg, tol=0.001......\n",
      "[CV 4/5; 1/240] END max_iter=50, penalty=l1, solver=newton-cg, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 5/5; 1/240] START max_iter=50, penalty=l1, solver=newton-cg, tol=0.001......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 1/240] END max_iter=50, penalty=l1, solver=newton-cg, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 1/5; 2/240] START max_iter=50, penalty=l1, solver=newton-cg, tol=0.0001.....\n",
      "[CV 1/5; 2/240] END max_iter=50, penalty=l1, solver=newton-cg, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 2/5; 2/240] START max_iter=50, penalty=l1, solver=newton-cg, tol=0.0001.....\n",
      "[CV 2/5; 2/240] END max_iter=50, penalty=l1, solver=newton-cg, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 3/5; 2/240] START max_iter=50, penalty=l1, solver=newton-cg, tol=0.0001.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 2/240] END max_iter=50, penalty=l1, solver=newton-cg, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 4/5; 2/240] START max_iter=50, penalty=l1, solver=newton-cg, tol=0.0001.....\n",
      "[CV 4/5; 2/240] END max_iter=50, penalty=l1, solver=newton-cg, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 5/5; 2/240] START max_iter=50, penalty=l1, solver=newton-cg, tol=0.0001.....\n",
      "[CV 5/5; 2/240] END max_iter=50, penalty=l1, solver=newton-cg, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 1/5; 3/240] START max_iter=50, penalty=l1, solver=newton-cg, tol=1e-05......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 3/240] END max_iter=50, penalty=l1, solver=newton-cg, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 2/5; 3/240] START max_iter=50, penalty=l1, solver=newton-cg, tol=1e-05......\n",
      "[CV 2/5; 3/240] END max_iter=50, penalty=l1, solver=newton-cg, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 3/5; 3/240] START max_iter=50, penalty=l1, solver=newton-cg, tol=1e-05......\n",
      "[CV 3/5; 3/240] END max_iter=50, penalty=l1, solver=newton-cg, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 4/5; 3/240] START max_iter=50, penalty=l1, solver=newton-cg, tol=1e-05......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 3/240] END max_iter=50, penalty=l1, solver=newton-cg, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 5/5; 3/240] START max_iter=50, penalty=l1, solver=newton-cg, tol=1e-05......\n",
      "[CV 5/5; 3/240] END max_iter=50, penalty=l1, solver=newton-cg, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 1/5; 4/240] START max_iter=50, penalty=l1, solver=lbfgs, tol=0.001..........\n",
      "[CV 1/5; 4/240] END max_iter=50, penalty=l1, solver=lbfgs, tol=0.001;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 4/240] START max_iter=50, penalty=l1, solver=lbfgs, tol=0.001..........\n",
      "[CV 2/5; 4/240] END max_iter=50, penalty=l1, solver=lbfgs, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 3/5; 4/240] START max_iter=50, penalty=l1, solver=lbfgs, tol=0.001..........\n",
      "[CV 3/5; 4/240] END max_iter=50, penalty=l1, solver=lbfgs, tol=0.001;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 4/240] START max_iter=50, penalty=l1, solver=lbfgs, tol=0.001..........\n",
      "[CV 4/5; 4/240] END max_iter=50, penalty=l1, solver=lbfgs, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 5/5; 4/240] START max_iter=50, penalty=l1, solver=lbfgs, tol=0.001..........\n",
      "[CV 5/5; 4/240] END max_iter=50, penalty=l1, solver=lbfgs, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 1/5; 5/240] START max_iter=50, penalty=l1, solver=lbfgs, tol=0.0001.........\n",
      "[CV 1/5; 5/240] END max_iter=50, penalty=l1, solver=lbfgs, tol=0.0001;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 5/240] START max_iter=50, penalty=l1, solver=lbfgs, tol=0.0001.........\n",
      "[CV 2/5; 5/240] END max_iter=50, penalty=l1, solver=lbfgs, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 3/5; 5/240] START max_iter=50, penalty=l1, solver=lbfgs, tol=0.0001.........\n",
      "[CV 3/5; 5/240] END max_iter=50, penalty=l1, solver=lbfgs, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 4/5; 5/240] START max_iter=50, penalty=l1, solver=lbfgs, tol=0.0001.........\n",
      "[CV 4/5; 5/240] END max_iter=50, penalty=l1, solver=lbfgs, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 5/5; 5/240] START max_iter=50, penalty=l1, solver=lbfgs, tol=0.0001.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 5/240] END max_iter=50, penalty=l1, solver=lbfgs, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 1/5; 6/240] START max_iter=50, penalty=l1, solver=lbfgs, tol=1e-05..........\n",
      "[CV 1/5; 6/240] END max_iter=50, penalty=l1, solver=lbfgs, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 2/5; 6/240] START max_iter=50, penalty=l1, solver=lbfgs, tol=1e-05..........\n",
      "[CV 2/5; 6/240] END max_iter=50, penalty=l1, solver=lbfgs, tol=1e-05;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 6/240] START max_iter=50, penalty=l1, solver=lbfgs, tol=1e-05..........\n",
      "[CV 3/5; 6/240] END max_iter=50, penalty=l1, solver=lbfgs, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 4/5; 6/240] START max_iter=50, penalty=l1, solver=lbfgs, tol=1e-05..........\n",
      "[CV 4/5; 6/240] END max_iter=50, penalty=l1, solver=lbfgs, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 5/5; 6/240] START max_iter=50, penalty=l1, solver=lbfgs, tol=1e-05..........\n",
      "[CV 5/5; 6/240] END max_iter=50, penalty=l1, solver=lbfgs, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 1/5; 7/240] START max_iter=50, penalty=l1, solver=liblinear, tol=0.001......\n",
      "[CV 1/5; 7/240] END max_iter=50, penalty=l1, solver=liblinear, tol=0.001;, score=0.498 total time=   0.5s\n",
      "[CV 2/5; 7/240] START max_iter=50, penalty=l1, solver=liblinear, tol=0.001......\n",
      "[CV 2/5; 7/240] END max_iter=50, penalty=l1, solver=liblinear, tol=0.001;, score=0.499 total time=   0.7s\n",
      "[CV 3/5; 7/240] START max_iter=50, penalty=l1, solver=liblinear, tol=0.001......\n",
      "[CV 3/5; 7/240] END max_iter=50, penalty=l1, solver=liblinear, tol=0.001;, score=0.500 total time=   0.8s\n",
      "[CV 4/5; 7/240] START max_iter=50, penalty=l1, solver=liblinear, tol=0.001......\n",
      "[CV 4/5; 7/240] END max_iter=50, penalty=l1, solver=liblinear, tol=0.001;, score=0.499 total time=   0.7s\n",
      "[CV 5/5; 7/240] START max_iter=50, penalty=l1, solver=liblinear, tol=0.001......\n",
      "[CV 5/5; 7/240] END max_iter=50, penalty=l1, solver=liblinear, tol=0.001;, score=0.500 total time=   0.6s\n",
      "[CV 1/5; 8/240] START max_iter=50, penalty=l1, solver=liblinear, tol=0.0001.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 8/240] END max_iter=50, penalty=l1, solver=liblinear, tol=0.0001;, score=0.498 total time= 4.1min\n",
      "[CV 2/5; 8/240] START max_iter=50, penalty=l1, solver=liblinear, tol=0.0001.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 8/240] END max_iter=50, penalty=l1, solver=liblinear, tol=0.0001;, score=0.499 total time= 3.8min\n",
      "[CV 3/5; 8/240] START max_iter=50, penalty=l1, solver=liblinear, tol=0.0001.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 8/240] END max_iter=50, penalty=l1, solver=liblinear, tol=0.0001;, score=0.499 total time= 4.3min\n",
      "[CV 4/5; 8/240] START max_iter=50, penalty=l1, solver=liblinear, tol=0.0001.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 8/240] END max_iter=50, penalty=l1, solver=liblinear, tol=0.0001;, score=0.498 total time= 3.6min\n",
      "[CV 5/5; 8/240] START max_iter=50, penalty=l1, solver=liblinear, tol=0.0001.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 8/240] END max_iter=50, penalty=l1, solver=liblinear, tol=0.0001;, score=0.500 total time= 3.6min\n",
      "[CV 1/5; 9/240] START max_iter=50, penalty=l1, solver=liblinear, tol=1e-05......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 9/240] END max_iter=50, penalty=l1, solver=liblinear, tol=1e-05;, score=0.498 total time= 3.5min\n",
      "[CV 2/5; 9/240] START max_iter=50, penalty=l1, solver=liblinear, tol=1e-05......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 9/240] END max_iter=50, penalty=l1, solver=liblinear, tol=1e-05;, score=0.499 total time= 3.6min\n",
      "[CV 3/5; 9/240] START max_iter=50, penalty=l1, solver=liblinear, tol=1e-05......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 9/240] END max_iter=50, penalty=l1, solver=liblinear, tol=1e-05;, score=0.499 total time= 3.5min\n",
      "[CV 4/5; 9/240] START max_iter=50, penalty=l1, solver=liblinear, tol=1e-05......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 9/240] END max_iter=50, penalty=l1, solver=liblinear, tol=1e-05;, score=0.499 total time= 3.5min\n",
      "[CV 5/5; 9/240] START max_iter=50, penalty=l1, solver=liblinear, tol=1e-05......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 9/240] END max_iter=50, penalty=l1, solver=liblinear, tol=1e-05;, score=0.500 total time= 3.8min\n",
      "[CV 1/5; 10/240] START max_iter=50, penalty=l1, solver=sag, tol=0.001...........\n",
      "[CV 1/5; 10/240] END max_iter=50, penalty=l1, solver=sag, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 2/5; 10/240] START max_iter=50, penalty=l1, solver=sag, tol=0.001...........\n",
      "[CV 2/5; 10/240] END max_iter=50, penalty=l1, solver=sag, tol=0.001;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 10/240] START max_iter=50, penalty=l1, solver=sag, tol=0.001...........\n",
      "[CV 3/5; 10/240] END max_iter=50, penalty=l1, solver=sag, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 4/5; 10/240] START max_iter=50, penalty=l1, solver=sag, tol=0.001...........\n",
      "[CV 4/5; 10/240] END max_iter=50, penalty=l1, solver=sag, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 5/5; 10/240] START max_iter=50, penalty=l1, solver=sag, tol=0.001...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 10/240] END max_iter=50, penalty=l1, solver=sag, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 1/5; 11/240] START max_iter=50, penalty=l1, solver=sag, tol=0.0001..........\n",
      "[CV 1/5; 11/240] END max_iter=50, penalty=l1, solver=sag, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 2/5; 11/240] START max_iter=50, penalty=l1, solver=sag, tol=0.0001..........\n",
      "[CV 2/5; 11/240] END max_iter=50, penalty=l1, solver=sag, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 3/5; 11/240] START max_iter=50, penalty=l1, solver=sag, tol=0.0001..........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 11/240] END max_iter=50, penalty=l1, solver=sag, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 4/5; 11/240] START max_iter=50, penalty=l1, solver=sag, tol=0.0001..........\n",
      "[CV 4/5; 11/240] END max_iter=50, penalty=l1, solver=sag, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 5/5; 11/240] START max_iter=50, penalty=l1, solver=sag, tol=0.0001..........\n",
      "[CV 5/5; 11/240] END max_iter=50, penalty=l1, solver=sag, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 1/5; 12/240] START max_iter=50, penalty=l1, solver=sag, tol=1e-05...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 12/240] END max_iter=50, penalty=l1, solver=sag, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 2/5; 12/240] START max_iter=50, penalty=l1, solver=sag, tol=1e-05...........\n",
      "[CV 2/5; 12/240] END max_iter=50, penalty=l1, solver=sag, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 3/5; 12/240] START max_iter=50, penalty=l1, solver=sag, tol=1e-05...........\n",
      "[CV 3/5; 12/240] END max_iter=50, penalty=l1, solver=sag, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 4/5; 12/240] START max_iter=50, penalty=l1, solver=sag, tol=1e-05...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 12/240] END max_iter=50, penalty=l1, solver=sag, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 5/5; 12/240] START max_iter=50, penalty=l1, solver=sag, tol=1e-05...........\n",
      "[CV 5/5; 12/240] END max_iter=50, penalty=l1, solver=sag, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 1/5; 13/240] START max_iter=50, penalty=l1, solver=saga, tol=0.001..........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 13/240] END max_iter=50, penalty=l1, solver=saga, tol=0.001;, score=0.499 total time=  20.0s\n",
      "[CV 2/5; 13/240] START max_iter=50, penalty=l1, solver=saga, tol=0.001..........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 13/240] END max_iter=50, penalty=l1, solver=saga, tol=0.001;, score=0.500 total time=  19.3s\n",
      "[CV 3/5; 13/240] START max_iter=50, penalty=l1, solver=saga, tol=0.001..........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 13/240] END max_iter=50, penalty=l1, solver=saga, tol=0.001;, score=0.500 total time=  19.6s\n",
      "[CV 4/5; 13/240] START max_iter=50, penalty=l1, solver=saga, tol=0.001..........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 13/240] END max_iter=50, penalty=l1, solver=saga, tol=0.001;, score=0.499 total time=  20.5s\n",
      "[CV 5/5; 13/240] START max_iter=50, penalty=l1, solver=saga, tol=0.001..........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 13/240] END max_iter=50, penalty=l1, solver=saga, tol=0.001;, score=0.499 total time=  19.7s\n",
      "[CV 1/5; 14/240] START max_iter=50, penalty=l1, solver=saga, tol=0.0001.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 14/240] END max_iter=50, penalty=l1, solver=saga, tol=0.0001;, score=0.499 total time=  20.0s\n",
      "[CV 2/5; 14/240] START max_iter=50, penalty=l1, solver=saga, tol=0.0001.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 14/240] END max_iter=50, penalty=l1, solver=saga, tol=0.0001;, score=0.500 total time=  20.3s\n",
      "[CV 3/5; 14/240] START max_iter=50, penalty=l1, solver=saga, tol=0.0001.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 14/240] END max_iter=50, penalty=l1, solver=saga, tol=0.0001;, score=0.500 total time=  19.8s\n",
      "[CV 4/5; 14/240] START max_iter=50, penalty=l1, solver=saga, tol=0.0001.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 14/240] END max_iter=50, penalty=l1, solver=saga, tol=0.0001;, score=0.499 total time=  18.7s\n",
      "[CV 5/5; 14/240] START max_iter=50, penalty=l1, solver=saga, tol=0.0001.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 14/240] END max_iter=50, penalty=l1, solver=saga, tol=0.0001;, score=0.499 total time=  19.3s\n",
      "[CV 1/5; 15/240] START max_iter=50, penalty=l1, solver=saga, tol=1e-05..........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 15/240] END max_iter=50, penalty=l1, solver=saga, tol=1e-05;, score=0.499 total time=  20.4s\n",
      "[CV 2/5; 15/240] START max_iter=50, penalty=l1, solver=saga, tol=1e-05..........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 15/240] END max_iter=50, penalty=l1, solver=saga, tol=1e-05;, score=0.500 total time=  19.1s\n",
      "[CV 3/5; 15/240] START max_iter=50, penalty=l1, solver=saga, tol=1e-05..........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 15/240] END max_iter=50, penalty=l1, solver=saga, tol=1e-05;, score=0.500 total time=  19.6s\n",
      "[CV 4/5; 15/240] START max_iter=50, penalty=l1, solver=saga, tol=1e-05..........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 15/240] END max_iter=50, penalty=l1, solver=saga, tol=1e-05;, score=0.499 total time=  20.4s\n",
      "[CV 5/5; 15/240] START max_iter=50, penalty=l1, solver=saga, tol=1e-05..........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 15/240] END max_iter=50, penalty=l1, solver=saga, tol=1e-05;, score=0.499 total time=  20.1s\n",
      "[CV 1/5; 16/240] START max_iter=50, penalty=l2, solver=newton-cg, tol=0.001.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"newton-cg failed to converge. Increase the \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 16/240] END max_iter=50, penalty=l2, solver=newton-cg, tol=0.001;, score=0.497 total time= 1.7min\n",
      "[CV 2/5; 16/240] START max_iter=50, penalty=l2, solver=newton-cg, tol=0.001.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"newton-cg failed to converge. Increase the \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 16/240] END max_iter=50, penalty=l2, solver=newton-cg, tol=0.001;, score=0.499 total time= 1.6min\n",
      "[CV 3/5; 16/240] START max_iter=50, penalty=l2, solver=newton-cg, tol=0.001.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"newton-cg failed to converge. Increase the \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 16/240] END max_iter=50, penalty=l2, solver=newton-cg, tol=0.001;, score=0.498 total time= 1.6min\n",
      "[CV 4/5; 16/240] START max_iter=50, penalty=l2, solver=newton-cg, tol=0.001.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"newton-cg failed to converge. Increase the \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 16/240] END max_iter=50, penalty=l2, solver=newton-cg, tol=0.001;, score=0.498 total time= 1.7min\n",
      "[CV 5/5; 16/240] START max_iter=50, penalty=l2, solver=newton-cg, tol=0.001.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"newton-cg failed to converge. Increase the \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 16/240] END max_iter=50, penalty=l2, solver=newton-cg, tol=0.001;, score=0.500 total time= 1.6min\n",
      "[CV 1/5; 17/240] START max_iter=50, penalty=l2, solver=newton-cg, tol=0.0001....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"newton-cg failed to converge. Increase the \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 17/240] END max_iter=50, penalty=l2, solver=newton-cg, tol=0.0001;, score=0.497 total time= 1.7min\n",
      "[CV 2/5; 17/240] START max_iter=50, penalty=l2, solver=newton-cg, tol=0.0001....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"newton-cg failed to converge. Increase the \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 17/240] END max_iter=50, penalty=l2, solver=newton-cg, tol=0.0001;, score=0.499 total time= 1.6min\n",
      "[CV 3/5; 17/240] START max_iter=50, penalty=l2, solver=newton-cg, tol=0.0001....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"newton-cg failed to converge. Increase the \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 17/240] END max_iter=50, penalty=l2, solver=newton-cg, tol=0.0001;, score=0.498 total time= 1.6min\n",
      "[CV 4/5; 17/240] START max_iter=50, penalty=l2, solver=newton-cg, tol=0.0001....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"newton-cg failed to converge. Increase the \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 17/240] END max_iter=50, penalty=l2, solver=newton-cg, tol=0.0001;, score=0.498 total time= 1.8min\n",
      "[CV 5/5; 17/240] START max_iter=50, penalty=l2, solver=newton-cg, tol=0.0001....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"newton-cg failed to converge. Increase the \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 17/240] END max_iter=50, penalty=l2, solver=newton-cg, tol=0.0001;, score=0.500 total time= 1.6min\n",
      "[CV 1/5; 18/240] START max_iter=50, penalty=l2, solver=newton-cg, tol=1e-05.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"newton-cg failed to converge. Increase the \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 18/240] END max_iter=50, penalty=l2, solver=newton-cg, tol=1e-05;, score=0.497 total time= 1.7min\n",
      "[CV 2/5; 18/240] START max_iter=50, penalty=l2, solver=newton-cg, tol=1e-05.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"newton-cg failed to converge. Increase the \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 18/240] END max_iter=50, penalty=l2, solver=newton-cg, tol=1e-05;, score=0.499 total time= 1.6min\n",
      "[CV 3/5; 18/240] START max_iter=50, penalty=l2, solver=newton-cg, tol=1e-05.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"newton-cg failed to converge. Increase the \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 18/240] END max_iter=50, penalty=l2, solver=newton-cg, tol=1e-05;, score=0.498 total time= 1.8min\n",
      "[CV 4/5; 18/240] START max_iter=50, penalty=l2, solver=newton-cg, tol=1e-05.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"newton-cg failed to converge. Increase the \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 18/240] END max_iter=50, penalty=l2, solver=newton-cg, tol=1e-05;, score=0.498 total time= 2.3min\n",
      "[CV 5/5; 18/240] START max_iter=50, penalty=l2, solver=newton-cg, tol=1e-05.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"newton-cg failed to converge. Increase the \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 18/240] END max_iter=50, penalty=l2, solver=newton-cg, tol=1e-05;, score=0.500 total time= 2.1min\n",
      "[CV 1/5; 19/240] START max_iter=50, penalty=l2, solver=lbfgs, tol=0.001.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 19/240] END max_iter=50, penalty=l2, solver=lbfgs, tol=0.001;, score=0.499 total time=   1.7s\n",
      "[CV 2/5; 19/240] START max_iter=50, penalty=l2, solver=lbfgs, tol=0.001.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 19/240] END max_iter=50, penalty=l2, solver=lbfgs, tol=0.001;, score=0.500 total time=   1.6s\n",
      "[CV 3/5; 19/240] START max_iter=50, penalty=l2, solver=lbfgs, tol=0.001.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 19/240] END max_iter=50, penalty=l2, solver=lbfgs, tol=0.001;, score=0.501 total time=   1.6s\n",
      "[CV 4/5; 19/240] START max_iter=50, penalty=l2, solver=lbfgs, tol=0.001.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 19/240] END max_iter=50, penalty=l2, solver=lbfgs, tol=0.001;, score=0.500 total time=   1.6s\n",
      "[CV 5/5; 19/240] START max_iter=50, penalty=l2, solver=lbfgs, tol=0.001.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 19/240] END max_iter=50, penalty=l2, solver=lbfgs, tol=0.001;, score=0.500 total time=   1.6s\n",
      "[CV 1/5; 20/240] START max_iter=50, penalty=l2, solver=lbfgs, tol=0.0001........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 20/240] END max_iter=50, penalty=l2, solver=lbfgs, tol=0.0001;, score=0.499 total time=   1.6s\n",
      "[CV 2/5; 20/240] START max_iter=50, penalty=l2, solver=lbfgs, tol=0.0001........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 20/240] END max_iter=50, penalty=l2, solver=lbfgs, tol=0.0001;, score=0.500 total time=   1.6s\n",
      "[CV 3/5; 20/240] START max_iter=50, penalty=l2, solver=lbfgs, tol=0.0001........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 20/240] END max_iter=50, penalty=l2, solver=lbfgs, tol=0.0001;, score=0.501 total time=   1.6s\n",
      "[CV 4/5; 20/240] START max_iter=50, penalty=l2, solver=lbfgs, tol=0.0001........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 20/240] END max_iter=50, penalty=l2, solver=lbfgs, tol=0.0001;, score=0.500 total time=   1.6s\n",
      "[CV 5/5; 20/240] START max_iter=50, penalty=l2, solver=lbfgs, tol=0.0001........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 20/240] END max_iter=50, penalty=l2, solver=lbfgs, tol=0.0001;, score=0.500 total time=   1.6s\n",
      "[CV 1/5; 21/240] START max_iter=50, penalty=l2, solver=lbfgs, tol=1e-05.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 21/240] END max_iter=50, penalty=l2, solver=lbfgs, tol=1e-05;, score=0.499 total time=   1.5s\n",
      "[CV 2/5; 21/240] START max_iter=50, penalty=l2, solver=lbfgs, tol=1e-05.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 21/240] END max_iter=50, penalty=l2, solver=lbfgs, tol=1e-05;, score=0.500 total time=   1.6s\n",
      "[CV 3/5; 21/240] START max_iter=50, penalty=l2, solver=lbfgs, tol=1e-05.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 21/240] END max_iter=50, penalty=l2, solver=lbfgs, tol=1e-05;, score=0.501 total time=   1.6s\n",
      "[CV 4/5; 21/240] START max_iter=50, penalty=l2, solver=lbfgs, tol=1e-05.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 21/240] END max_iter=50, penalty=l2, solver=lbfgs, tol=1e-05;, score=0.500 total time=   1.6s\n",
      "[CV 5/5; 21/240] START max_iter=50, penalty=l2, solver=lbfgs, tol=1e-05.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 21/240] END max_iter=50, penalty=l2, solver=lbfgs, tol=1e-05;, score=0.500 total time=   1.6s\n",
      "[CV 1/5; 22/240] START max_iter=50, penalty=l2, solver=liblinear, tol=0.001.....\n",
      "[CV 1/5; 22/240] END max_iter=50, penalty=l2, solver=liblinear, tol=0.001;, score=0.498 total time=  18.1s\n",
      "[CV 2/5; 22/240] START max_iter=50, penalty=l2, solver=liblinear, tol=0.001.....\n",
      "[CV 2/5; 22/240] END max_iter=50, penalty=l2, solver=liblinear, tol=0.001;, score=0.499 total time=  17.2s\n",
      "[CV 3/5; 22/240] START max_iter=50, penalty=l2, solver=liblinear, tol=0.001.....\n",
      "[CV 3/5; 22/240] END max_iter=50, penalty=l2, solver=liblinear, tol=0.001;, score=0.499 total time=  17.9s\n",
      "[CV 4/5; 22/240] START max_iter=50, penalty=l2, solver=liblinear, tol=0.001.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 22/240] END max_iter=50, penalty=l2, solver=liblinear, tol=0.001;, score=0.498 total time=  22.4s\n",
      "[CV 5/5; 22/240] START max_iter=50, penalty=l2, solver=liblinear, tol=0.001.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 22/240] END max_iter=50, penalty=l2, solver=liblinear, tol=0.001;, score=0.499 total time=  11.8s\n",
      "[CV 1/5; 23/240] START max_iter=50, penalty=l2, solver=liblinear, tol=0.0001....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 23/240] END max_iter=50, penalty=l2, solver=liblinear, tol=0.0001;, score=0.497 total time=  53.2s\n",
      "[CV 2/5; 23/240] START max_iter=50, penalty=l2, solver=liblinear, tol=0.0001....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 23/240] END max_iter=50, penalty=l2, solver=liblinear, tol=0.0001;, score=0.500 total time= 2.3min\n",
      "[CV 3/5; 23/240] START max_iter=50, penalty=l2, solver=liblinear, tol=0.0001....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 23/240] END max_iter=50, penalty=l2, solver=liblinear, tol=0.0001;, score=0.499 total time= 2.5min\n",
      "[CV 4/5; 23/240] START max_iter=50, penalty=l2, solver=liblinear, tol=0.0001....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 23/240] END max_iter=50, penalty=l2, solver=liblinear, tol=0.0001;, score=0.498 total time=  21.0s\n",
      "[CV 5/5; 23/240] START max_iter=50, penalty=l2, solver=liblinear, tol=0.0001....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 23/240] END max_iter=50, penalty=l2, solver=liblinear, tol=0.0001;, score=0.499 total time=  10.9s\n",
      "[CV 1/5; 24/240] START max_iter=50, penalty=l2, solver=liblinear, tol=1e-05.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 24/240] END max_iter=50, penalty=l2, solver=liblinear, tol=1e-05;, score=0.497 total time=  51.2s\n",
      "[CV 2/5; 24/240] START max_iter=50, penalty=l2, solver=liblinear, tol=1e-05.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 24/240] END max_iter=50, penalty=l2, solver=liblinear, tol=1e-05;, score=0.500 total time= 2.5min\n",
      "[CV 3/5; 24/240] START max_iter=50, penalty=l2, solver=liblinear, tol=1e-05.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 24/240] END max_iter=50, penalty=l2, solver=liblinear, tol=1e-05;, score=0.499 total time= 2.7min\n",
      "[CV 4/5; 24/240] START max_iter=50, penalty=l2, solver=liblinear, tol=1e-05.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 24/240] END max_iter=50, penalty=l2, solver=liblinear, tol=1e-05;, score=0.498 total time=  25.5s\n",
      "[CV 5/5; 24/240] START max_iter=50, penalty=l2, solver=liblinear, tol=1e-05.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 24/240] END max_iter=50, penalty=l2, solver=liblinear, tol=1e-05;, score=0.499 total time=  13.2s\n",
      "[CV 1/5; 25/240] START max_iter=50, penalty=l2, solver=sag, tol=0.001...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 25/240] END max_iter=50, penalty=l2, solver=sag, tol=0.001;, score=0.499 total time=  13.8s\n",
      "[CV 2/5; 25/240] START max_iter=50, penalty=l2, solver=sag, tol=0.001...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 25/240] END max_iter=50, penalty=l2, solver=sag, tol=0.001;, score=0.500 total time=  13.6s\n",
      "[CV 3/5; 25/240] START max_iter=50, penalty=l2, solver=sag, tol=0.001...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 25/240] END max_iter=50, penalty=l2, solver=sag, tol=0.001;, score=0.500 total time=  12.3s\n",
      "[CV 4/5; 25/240] START max_iter=50, penalty=l2, solver=sag, tol=0.001...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 25/240] END max_iter=50, penalty=l2, solver=sag, tol=0.001;, score=0.500 total time=  12.1s\n",
      "[CV 5/5; 25/240] START max_iter=50, penalty=l2, solver=sag, tol=0.001...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 25/240] END max_iter=50, penalty=l2, solver=sag, tol=0.001;, score=0.500 total time=  12.1s\n",
      "[CV 1/5; 26/240] START max_iter=50, penalty=l2, solver=sag, tol=0.0001..........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 26/240] END max_iter=50, penalty=l2, solver=sag, tol=0.0001;, score=0.499 total time=  11.9s\n",
      "[CV 2/5; 26/240] START max_iter=50, penalty=l2, solver=sag, tol=0.0001..........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 26/240] END max_iter=50, penalty=l2, solver=sag, tol=0.0001;, score=0.500 total time=  11.8s\n",
      "[CV 3/5; 26/240] START max_iter=50, penalty=l2, solver=sag, tol=0.0001..........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 26/240] END max_iter=50, penalty=l2, solver=sag, tol=0.0001;, score=0.500 total time=  11.1s\n",
      "[CV 4/5; 26/240] START max_iter=50, penalty=l2, solver=sag, tol=0.0001..........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 26/240] END max_iter=50, penalty=l2, solver=sag, tol=0.0001;, score=0.500 total time=  11.8s\n",
      "[CV 5/5; 26/240] START max_iter=50, penalty=l2, solver=sag, tol=0.0001..........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 26/240] END max_iter=50, penalty=l2, solver=sag, tol=0.0001;, score=0.500 total time=  12.4s\n",
      "[CV 1/5; 27/240] START max_iter=50, penalty=l2, solver=sag, tol=1e-05...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 27/240] END max_iter=50, penalty=l2, solver=sag, tol=1e-05;, score=0.499 total time=  13.3s\n",
      "[CV 2/5; 27/240] START max_iter=50, penalty=l2, solver=sag, tol=1e-05...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 27/240] END max_iter=50, penalty=l2, solver=sag, tol=1e-05;, score=0.500 total time=  12.8s\n",
      "[CV 3/5; 27/240] START max_iter=50, penalty=l2, solver=sag, tol=1e-05...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 27/240] END max_iter=50, penalty=l2, solver=sag, tol=1e-05;, score=0.500 total time=  13.3s\n",
      "[CV 4/5; 27/240] START max_iter=50, penalty=l2, solver=sag, tol=1e-05...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 27/240] END max_iter=50, penalty=l2, solver=sag, tol=1e-05;, score=0.500 total time=  13.1s\n",
      "[CV 5/5; 27/240] START max_iter=50, penalty=l2, solver=sag, tol=1e-05...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 27/240] END max_iter=50, penalty=l2, solver=sag, tol=1e-05;, score=0.500 total time=  13.9s\n",
      "[CV 1/5; 28/240] START max_iter=50, penalty=l2, solver=saga, tol=0.001..........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 28/240] END max_iter=50, penalty=l2, solver=saga, tol=0.001;, score=0.499 total time=  15.5s\n",
      "[CV 2/5; 28/240] START max_iter=50, penalty=l2, solver=saga, tol=0.001..........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 28/240] END max_iter=50, penalty=l2, solver=saga, tol=0.001;, score=0.500 total time=  15.9s\n",
      "[CV 3/5; 28/240] START max_iter=50, penalty=l2, solver=saga, tol=0.001..........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 28/240] END max_iter=50, penalty=l2, solver=saga, tol=0.001;, score=0.500 total time=  16.1s\n",
      "[CV 4/5; 28/240] START max_iter=50, penalty=l2, solver=saga, tol=0.001..........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 28/240] END max_iter=50, penalty=l2, solver=saga, tol=0.001;, score=0.499 total time=  16.2s\n",
      "[CV 5/5; 28/240] START max_iter=50, penalty=l2, solver=saga, tol=0.001..........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 28/240] END max_iter=50, penalty=l2, solver=saga, tol=0.001;, score=0.499 total time=  15.7s\n",
      "[CV 1/5; 29/240] START max_iter=50, penalty=l2, solver=saga, tol=0.0001.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 29/240] END max_iter=50, penalty=l2, solver=saga, tol=0.0001;, score=0.499 total time=  15.6s\n",
      "[CV 2/5; 29/240] START max_iter=50, penalty=l2, solver=saga, tol=0.0001.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 29/240] END max_iter=50, penalty=l2, solver=saga, tol=0.0001;, score=0.500 total time=  15.6s\n",
      "[CV 3/5; 29/240] START max_iter=50, penalty=l2, solver=saga, tol=0.0001.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 29/240] END max_iter=50, penalty=l2, solver=saga, tol=0.0001;, score=0.500 total time=  15.5s\n",
      "[CV 4/5; 29/240] START max_iter=50, penalty=l2, solver=saga, tol=0.0001.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 29/240] END max_iter=50, penalty=l2, solver=saga, tol=0.0001;, score=0.499 total time=  14.9s\n",
      "[CV 5/5; 29/240] START max_iter=50, penalty=l2, solver=saga, tol=0.0001.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 29/240] END max_iter=50, penalty=l2, solver=saga, tol=0.0001;, score=0.499 total time=  15.4s\n",
      "[CV 1/5; 30/240] START max_iter=50, penalty=l2, solver=saga, tol=1e-05..........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 30/240] END max_iter=50, penalty=l2, solver=saga, tol=1e-05;, score=0.499 total time=  15.2s\n",
      "[CV 2/5; 30/240] START max_iter=50, penalty=l2, solver=saga, tol=1e-05..........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 30/240] END max_iter=50, penalty=l2, solver=saga, tol=1e-05;, score=0.500 total time=  15.4s\n",
      "[CV 3/5; 30/240] START max_iter=50, penalty=l2, solver=saga, tol=1e-05..........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 30/240] END max_iter=50, penalty=l2, solver=saga, tol=1e-05;, score=0.500 total time=  15.6s\n",
      "[CV 4/5; 30/240] START max_iter=50, penalty=l2, solver=saga, tol=1e-05..........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 30/240] END max_iter=50, penalty=l2, solver=saga, tol=1e-05;, score=0.499 total time=  15.5s\n",
      "[CV 5/5; 30/240] START max_iter=50, penalty=l2, solver=saga, tol=1e-05..........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 30/240] END max_iter=50, penalty=l2, solver=saga, tol=1e-05;, score=0.499 total time=  15.7s\n",
      "[CV 1/5; 31/240] START max_iter=50, penalty=elasticnet, solver=newton-cg, tol=0.001\n",
      "[CV 1/5; 31/240] END max_iter=50, penalty=elasticnet, solver=newton-cg, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 2/5; 31/240] START max_iter=50, penalty=elasticnet, solver=newton-cg, tol=0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 31/240] END max_iter=50, penalty=elasticnet, solver=newton-cg, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 3/5; 31/240] START max_iter=50, penalty=elasticnet, solver=newton-cg, tol=0.001\n",
      "[CV 3/5; 31/240] END max_iter=50, penalty=elasticnet, solver=newton-cg, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 4/5; 31/240] START max_iter=50, penalty=elasticnet, solver=newton-cg, tol=0.001\n",
      "[CV 4/5; 31/240] END max_iter=50, penalty=elasticnet, solver=newton-cg, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 5/5; 31/240] START max_iter=50, penalty=elasticnet, solver=newton-cg, tol=0.001\n",
      "[CV 5/5; 31/240] END max_iter=50, penalty=elasticnet, solver=newton-cg, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 1/5; 32/240] START max_iter=50, penalty=elasticnet, solver=newton-cg, tol=0.0001\n",
      "[CV 1/5; 32/240] END max_iter=50, penalty=elasticnet, solver=newton-cg, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 2/5; 32/240] START max_iter=50, penalty=elasticnet, solver=newton-cg, tol=0.0001"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV 2/5; 32/240] END max_iter=50, penalty=elasticnet, solver=newton-cg, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 3/5; 32/240] START max_iter=50, penalty=elasticnet, solver=newton-cg, tol=0.0001\n",
      "[CV 3/5; 32/240] END max_iter=50, penalty=elasticnet, solver=newton-cg, tol=0.0001;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 32/240] START max_iter=50, penalty=elasticnet, solver=newton-cg, tol=0.0001\n",
      "[CV 4/5; 32/240] END max_iter=50, penalty=elasticnet, solver=newton-cg, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 5/5; 32/240] START max_iter=50, penalty=elasticnet, solver=newton-cg, tol=0.0001\n",
      "[CV 5/5; 32/240] END max_iter=50, penalty=elasticnet, solver=newton-cg, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 1/5; 33/240] START max_iter=50, penalty=elasticnet, solver=newton-cg, tol=1e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV 1/5; 33/240] END max_iter=50, penalty=elasticnet, solver=newton-cg, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 2/5; 33/240] START max_iter=50, penalty=elasticnet, solver=newton-cg, tol=1e-05\n",
      "[CV 2/5; 33/240] END max_iter=50, penalty=elasticnet, solver=newton-cg, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 3/5; 33/240] START max_iter=50, penalty=elasticnet, solver=newton-cg, tol=1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 33/240] END max_iter=50, penalty=elasticnet, solver=newton-cg, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 4/5; 33/240] START max_iter=50, penalty=elasticnet, solver=newton-cg, tol=1e-05\n",
      "[CV 4/5; 33/240] END max_iter=50, penalty=elasticnet, solver=newton-cg, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 5/5; 33/240] START max_iter=50, penalty=elasticnet, solver=newton-cg, tol=1e-05\n",
      "[CV 5/5; 33/240] END max_iter=50, penalty=elasticnet, solver=newton-cg, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 1/5; 34/240] START max_iter=50, penalty=elasticnet, solver=lbfgs, tol=0.001."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV 1/5; 34/240] END max_iter=50, penalty=elasticnet, solver=lbfgs, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 2/5; 34/240] START max_iter=50, penalty=elasticnet, solver=lbfgs, tol=0.001.\n",
      "[CV 2/5; 34/240] END max_iter=50, penalty=elasticnet, solver=lbfgs, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 3/5; 34/240] START max_iter=50, penalty=elasticnet, solver=lbfgs, tol=0.001.\n",
      "[CV 3/5; 34/240] END max_iter=50, penalty=elasticnet, solver=lbfgs, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 4/5; 34/240] START max_iter=50, penalty=elasticnet, solver=lbfgs, tol=0.001."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV 4/5; 34/240] END max_iter=50, penalty=elasticnet, solver=lbfgs, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 5/5; 34/240] START max_iter=50, penalty=elasticnet, solver=lbfgs, tol=0.001.\n",
      "[CV 5/5; 34/240] END max_iter=50, penalty=elasticnet, solver=lbfgs, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 1/5; 35/240] START max_iter=50, penalty=elasticnet, solver=lbfgs, tol=0.0001\n",
      "[CV 1/5; 35/240] END max_iter=50, penalty=elasticnet, solver=lbfgs, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 2/5; 35/240] START max_iter=50, penalty=elasticnet, solver=lbfgs, tol=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 35/240] END max_iter=50, penalty=elasticnet, solver=lbfgs, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 3/5; 35/240] START max_iter=50, penalty=elasticnet, solver=lbfgs, tol=0.0001\n",
      "[CV 3/5; 35/240] END max_iter=50, penalty=elasticnet, solver=lbfgs, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 4/5; 35/240] START max_iter=50, penalty=elasticnet, solver=lbfgs, tol=0.0001\n",
      "[CV 4/5; 35/240] END max_iter=50, penalty=elasticnet, solver=lbfgs, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 5/5; 35/240] START max_iter=50, penalty=elasticnet, solver=lbfgs, tol=0.0001\n",
      "[CV 5/5; 35/240] END max_iter=50, penalty=elasticnet, solver=lbfgs, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 1/5; 36/240] START max_iter=50, penalty=elasticnet, solver=lbfgs, tol=1e-05.\n",
      "[CV 1/5; 36/240] END max_iter=50, penalty=elasticnet, solver=lbfgs, tol=1e-05;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 36/240] START max_iter=50, penalty=elasticnet, solver=lbfgs, tol=1e-05.\n",
      "[CV 2/5; 36/240] END max_iter=50, penalty=elasticnet, solver=lbfgs, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 3/5; 36/240] START max_iter=50, penalty=elasticnet, solver=lbfgs, tol=1e-05.\n",
      "[CV 3/5; 36/240] END max_iter=50, penalty=elasticnet, solver=lbfgs, tol=1e-05;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 36/240] START max_iter=50, penalty=elasticnet, solver=lbfgs, tol=1e-05.\n",
      "[CV 4/5; 36/240] END max_iter=50, penalty=elasticnet, solver=lbfgs, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 5/5; 36/240] START max_iter=50, penalty=elasticnet, solver=lbfgs, tol=1e-05.\n",
      "[CV 5/5; 36/240] END max_iter=50, penalty=elasticnet, solver=lbfgs, tol=1e-05;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 37/240] START max_iter=50, penalty=elasticnet, solver=liblinear, tol=0.001\n",
      "[CV 1/5; 37/240] END max_iter=50, penalty=elasticnet, solver=liblinear, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 2/5; 37/240] START max_iter=50, penalty=elasticnet, solver=liblinear, tol=0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 37/240] END max_iter=50, penalty=elasticnet, solver=liblinear, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 3/5; 37/240] START max_iter=50, penalty=elasticnet, solver=liblinear, tol=0.001\n",
      "[CV 3/5; 37/240] END max_iter=50, penalty=elasticnet, solver=liblinear, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 4/5; 37/240] START max_iter=50, penalty=elasticnet, solver=liblinear, tol=0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 37/240] END max_iter=50, penalty=elasticnet, solver=liblinear, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 5/5; 37/240] START max_iter=50, penalty=elasticnet, solver=liblinear, tol=0.001\n",
      "[CV 5/5; 37/240] END max_iter=50, penalty=elasticnet, solver=liblinear, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 1/5; 38/240] START max_iter=50, penalty=elasticnet, solver=liblinear, tol=0.0001\n",
      "[CV 1/5; 38/240] END max_iter=50, penalty=elasticnet, solver=liblinear, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 2/5; 38/240] START max_iter=50, penalty=elasticnet, solver=liblinear, tol=0.0001"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV 2/5; 38/240] END max_iter=50, penalty=elasticnet, solver=liblinear, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 3/5; 38/240] START max_iter=50, penalty=elasticnet, solver=liblinear, tol=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 38/240] END max_iter=50, penalty=elasticnet, solver=liblinear, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 4/5; 38/240] START max_iter=50, penalty=elasticnet, solver=liblinear, tol=0.0001\n",
      "[CV 4/5; 38/240] END max_iter=50, penalty=elasticnet, solver=liblinear, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 5/5; 38/240] START max_iter=50, penalty=elasticnet, solver=liblinear, tol=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 38/240] END max_iter=50, penalty=elasticnet, solver=liblinear, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 1/5; 39/240] START max_iter=50, penalty=elasticnet, solver=liblinear, tol=1e-05\n",
      "[CV 1/5; 39/240] END max_iter=50, penalty=elasticnet, solver=liblinear, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 2/5; 39/240] START max_iter=50, penalty=elasticnet, solver=liblinear, tol=1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 39/240] END max_iter=50, penalty=elasticnet, solver=liblinear, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 3/5; 39/240] START max_iter=50, penalty=elasticnet, solver=liblinear, tol=1e-05\n",
      "[CV 3/5; 39/240] END max_iter=50, penalty=elasticnet, solver=liblinear, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 4/5; 39/240] START max_iter=50, penalty=elasticnet, solver=liblinear, tol=1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 39/240] END max_iter=50, penalty=elasticnet, solver=liblinear, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 5/5; 39/240] START max_iter=50, penalty=elasticnet, solver=liblinear, tol=1e-05\n",
      "[CV 5/5; 39/240] END max_iter=50, penalty=elasticnet, solver=liblinear, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 1/5; 40/240] START max_iter=50, penalty=elasticnet, solver=sag, tol=0.001...\n",
      "[CV 1/5; 40/240] END max_iter=50, penalty=elasticnet, solver=sag, tol=0.001;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 40/240] START max_iter=50, penalty=elasticnet, solver=sag, tol=0.001...\n",
      "[CV 2/5; 40/240] END max_iter=50, penalty=elasticnet, solver=sag, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 3/5; 40/240] START max_iter=50, penalty=elasticnet, solver=sag, tol=0.001...\n",
      "[CV 3/5; 40/240] END max_iter=50, penalty=elasticnet, solver=sag, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 4/5; 40/240] START max_iter=50, penalty=elasticnet, solver=sag, tol=0.001...\n",
      "[CV 4/5; 40/240] END max_iter=50, penalty=elasticnet, solver=sag, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 5/5; 40/240] START max_iter=50, penalty=elasticnet, solver=sag, tol=0.001..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV 5/5; 40/240] END max_iter=50, penalty=elasticnet, solver=sag, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 1/5; 41/240] START max_iter=50, penalty=elasticnet, solver=sag, tol=0.0001..\n",
      "[CV 1/5; 41/240] END max_iter=50, penalty=elasticnet, solver=sag, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 2/5; 41/240] START max_iter=50, penalty=elasticnet, solver=sag, tol=0.0001..\n",
      "[CV 2/5; 41/240] END max_iter=50, penalty=elasticnet, solver=sag, tol=0.0001;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 41/240] START max_iter=50, penalty=elasticnet, solver=sag, tol=0.0001..\n",
      "[CV 3/5; 41/240] END max_iter=50, penalty=elasticnet, solver=sag, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 4/5; 41/240] START max_iter=50, penalty=elasticnet, solver=sag, tol=0.0001..\n",
      "[CV 4/5; 41/240] END max_iter=50, penalty=elasticnet, solver=sag, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 5/5; 41/240] START max_iter=50, penalty=elasticnet, solver=sag, tol=0.0001..\n",
      "[CV 5/5; 41/240] END max_iter=50, penalty=elasticnet, solver=sag, tol=0.0001;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 42/240] START max_iter=50, penalty=elasticnet, solver=sag, tol=1e-05...\n",
      "[CV 1/5; 42/240] END max_iter=50, penalty=elasticnet, solver=sag, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 2/5; 42/240] START max_iter=50, penalty=elasticnet, solver=sag, tol=1e-05...\n",
      "[CV 2/5; 42/240] END max_iter=50, penalty=elasticnet, solver=sag, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 3/5; 42/240] START max_iter=50, penalty=elasticnet, solver=sag, tol=1e-05...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 42/240] END max_iter=50, penalty=elasticnet, solver=sag, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 4/5; 42/240] START max_iter=50, penalty=elasticnet, solver=sag, tol=1e-05...\n",
      "[CV 4/5; 42/240] END max_iter=50, penalty=elasticnet, solver=sag, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 5/5; 42/240] START max_iter=50, penalty=elasticnet, solver=sag, tol=1e-05...\n",
      "[CV 5/5; 42/240] END max_iter=50, penalty=elasticnet, solver=sag, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 1/5; 43/240] START max_iter=50, penalty=elasticnet, solver=saga, tol=0.001..\n",
      "[CV 1/5; 43/240] END max_iter=50, penalty=elasticnet, solver=saga, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 2/5; 43/240] START max_iter=50, penalty=elasticnet, solver=saga, tol=0.001..\n",
      "[CV 2/5; 43/240] END max_iter=50, penalty=elasticnet, solver=saga, tol=0.001;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1314, in fit\n",
      "    raise ValueError(\"l1_ratio must be between 0 and 1;\"\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1314, in fit\n",
      "    raise ValueError(\"l1_ratio must be between 0 and 1;\"\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1314, in fit\n",
      "    raise ValueError(\"l1_ratio must be between 0 and 1;\"\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 43/240] START max_iter=50, penalty=elasticnet, solver=saga, tol=0.001..\n",
      "[CV 3/5; 43/240] END max_iter=50, penalty=elasticnet, solver=saga, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 4/5; 43/240] START max_iter=50, penalty=elasticnet, solver=saga, tol=0.001..\n",
      "[CV 4/5; 43/240] END max_iter=50, penalty=elasticnet, solver=saga, tol=0.001;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1314, in fit\n",
      "    raise ValueError(\"l1_ratio must be between 0 and 1;\"\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1314, in fit\n",
      "    raise ValueError(\"l1_ratio must be between 0 and 1;\"\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1314, in fit\n",
      "    raise ValueError(\"l1_ratio must be between 0 and 1;\"\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 43/240] START max_iter=50, penalty=elasticnet, solver=saga, tol=0.001..\n",
      "[CV 5/5; 43/240] END max_iter=50, penalty=elasticnet, solver=saga, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 1/5; 44/240] START max_iter=50, penalty=elasticnet, solver=saga, tol=0.0001.\n",
      "[CV 1/5; 44/240] END max_iter=50, penalty=elasticnet, solver=saga, tol=0.0001;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1314, in fit\n",
      "    raise ValueError(\"l1_ratio must be between 0 and 1;\"\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1314, in fit\n",
      "    raise ValueError(\"l1_ratio must be between 0 and 1;\"\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1314, in fit\n",
      "    raise ValueError(\"l1_ratio must be between 0 and 1;\"\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 44/240] START max_iter=50, penalty=elasticnet, solver=saga, tol=0.0001.\n",
      "[CV 2/5; 44/240] END max_iter=50, penalty=elasticnet, solver=saga, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 3/5; 44/240] START max_iter=50, penalty=elasticnet, solver=saga, tol=0.0001.\n",
      "[CV 3/5; 44/240] END max_iter=50, penalty=elasticnet, solver=saga, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 4/5; 44/240] START max_iter=50, penalty=elasticnet, solver=saga, tol=0.0001.\n",
      "[CV 4/5; 44/240] END max_iter=50, penalty=elasticnet, solver=saga, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 5/5; 44/240] START max_iter=50, penalty=elasticnet, solver=saga, tol=0.0001."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1314, in fit\n",
      "    raise ValueError(\"l1_ratio must be between 0 and 1;\"\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1314, in fit\n",
      "    raise ValueError(\"l1_ratio must be between 0 and 1;\"\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1314, in fit\n",
      "    raise ValueError(\"l1_ratio must be between 0 and 1;\"\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV 5/5; 44/240] END max_iter=50, penalty=elasticnet, solver=saga, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 1/5; 45/240] START max_iter=50, penalty=elasticnet, solver=saga, tol=1e-05..\n",
      "[CV 1/5; 45/240] END max_iter=50, penalty=elasticnet, solver=saga, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 2/5; 45/240] START max_iter=50, penalty=elasticnet, solver=saga, tol=1e-05..\n",
      "[CV 2/5; 45/240] END max_iter=50, penalty=elasticnet, solver=saga, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 3/5; 45/240] START max_iter=50, penalty=elasticnet, solver=saga, tol=1e-05.."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1314, in fit\n",
      "    raise ValueError(\"l1_ratio must be between 0 and 1;\"\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1314, in fit\n",
      "    raise ValueError(\"l1_ratio must be between 0 and 1;\"\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1314, in fit\n",
      "    raise ValueError(\"l1_ratio must be between 0 and 1;\"\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV 3/5; 45/240] END max_iter=50, penalty=elasticnet, solver=saga, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 4/5; 45/240] START max_iter=50, penalty=elasticnet, solver=saga, tol=1e-05..\n",
      "[CV 4/5; 45/240] END max_iter=50, penalty=elasticnet, solver=saga, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 5/5; 45/240] START max_iter=50, penalty=elasticnet, solver=saga, tol=1e-05..\n",
      "[CV 5/5; 45/240] END max_iter=50, penalty=elasticnet, solver=saga, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 1/5; 46/240] START max_iter=50, penalty=none, solver=newton-cg, tol=0.001..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"newton-cg failed to converge. Increase the \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV 1/5; 46/240] END max_iter=50, penalty=none, solver=newton-cg, tol=0.001;, score=0.497 total time= 2.3min\n",
      "[CV 2/5; 46/240] START max_iter=50, penalty=none, solver=newton-cg, tol=0.001...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"newton-cg failed to converge. Increase the \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 46/240] END max_iter=50, penalty=none, solver=newton-cg, tol=0.001;, score=0.499 total time= 2.4min\n",
      "[CV 3/5; 46/240] START max_iter=50, penalty=none, solver=newton-cg, tol=0.001...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"newton-cg failed to converge. Increase the \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 46/240] END max_iter=50, penalty=none, solver=newton-cg, tol=0.001;, score=0.498 total time= 2.4min\n",
      "[CV 4/5; 46/240] START max_iter=50, penalty=none, solver=newton-cg, tol=0.001...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"newton-cg failed to converge. Increase the \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 46/240] END max_iter=50, penalty=none, solver=newton-cg, tol=0.001;, score=0.499 total time= 2.1min\n",
      "[CV 5/5; 46/240] START max_iter=50, penalty=none, solver=newton-cg, tol=0.001...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"newton-cg failed to converge. Increase the \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 46/240] END max_iter=50, penalty=none, solver=newton-cg, tol=0.001;, score=0.500 total time= 2.4min\n",
      "[CV 1/5; 47/240] START max_iter=50, penalty=none, solver=newton-cg, tol=0.0001..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"newton-cg failed to converge. Increase the \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 47/240] END max_iter=50, penalty=none, solver=newton-cg, tol=0.0001;, score=0.497 total time= 2.3min\n",
      "[CV 2/5; 47/240] START max_iter=50, penalty=none, solver=newton-cg, tol=0.0001..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"newton-cg failed to converge. Increase the \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 47/240] END max_iter=50, penalty=none, solver=newton-cg, tol=0.0001;, score=0.499 total time= 2.2min\n",
      "[CV 3/5; 47/240] START max_iter=50, penalty=none, solver=newton-cg, tol=0.0001..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"newton-cg failed to converge. Increase the \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 47/240] END max_iter=50, penalty=none, solver=newton-cg, tol=0.0001;, score=0.498 total time= 2.2min\n",
      "[CV 4/5; 47/240] START max_iter=50, penalty=none, solver=newton-cg, tol=0.0001..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"newton-cg failed to converge. Increase the \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 47/240] END max_iter=50, penalty=none, solver=newton-cg, tol=0.0001;, score=0.499 total time= 2.2min\n",
      "[CV 5/5; 47/240] START max_iter=50, penalty=none, solver=newton-cg, tol=0.0001..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"newton-cg failed to converge. Increase the \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 47/240] END max_iter=50, penalty=none, solver=newton-cg, tol=0.0001;, score=0.500 total time= 2.4min\n",
      "[CV 1/5; 48/240] START max_iter=50, penalty=none, solver=newton-cg, tol=1e-05...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"newton-cg failed to converge. Increase the \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 48/240] END max_iter=50, penalty=none, solver=newton-cg, tol=1e-05;, score=0.497 total time= 2.3min\n",
      "[CV 2/5; 48/240] START max_iter=50, penalty=none, solver=newton-cg, tol=1e-05...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"newton-cg failed to converge. Increase the \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 48/240] END max_iter=50, penalty=none, solver=newton-cg, tol=1e-05;, score=0.499 total time= 2.3min\n",
      "[CV 3/5; 48/240] START max_iter=50, penalty=none, solver=newton-cg, tol=1e-05...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"newton-cg failed to converge. Increase the \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 48/240] END max_iter=50, penalty=none, solver=newton-cg, tol=1e-05;, score=0.498 total time= 2.3min\n",
      "[CV 4/5; 48/240] START max_iter=50, penalty=none, solver=newton-cg, tol=1e-05...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"newton-cg failed to converge. Increase the \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 48/240] END max_iter=50, penalty=none, solver=newton-cg, tol=1e-05;, score=0.499 total time= 2.2min\n",
      "[CV 5/5; 48/240] START max_iter=50, penalty=none, solver=newton-cg, tol=1e-05...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"newton-cg failed to converge. Increase the \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 48/240] END max_iter=50, penalty=none, solver=newton-cg, tol=1e-05;, score=0.500 total time= 2.3min\n",
      "[CV 1/5; 49/240] START max_iter=50, penalty=none, solver=lbfgs, tol=0.001.......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 49/240] END max_iter=50, penalty=none, solver=lbfgs, tol=0.001;, score=0.499 total time=   1.7s\n",
      "[CV 2/5; 49/240] START max_iter=50, penalty=none, solver=lbfgs, tol=0.001.......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 49/240] END max_iter=50, penalty=none, solver=lbfgs, tol=0.001;, score=0.500 total time=   1.7s\n",
      "[CV 3/5; 49/240] START max_iter=50, penalty=none, solver=lbfgs, tol=0.001.......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 49/240] END max_iter=50, penalty=none, solver=lbfgs, tol=0.001;, score=0.501 total time=   1.7s\n",
      "[CV 4/5; 49/240] START max_iter=50, penalty=none, solver=lbfgs, tol=0.001.......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 49/240] END max_iter=50, penalty=none, solver=lbfgs, tol=0.001;, score=0.500 total time=   1.7s\n",
      "[CV 5/5; 49/240] START max_iter=50, penalty=none, solver=lbfgs, tol=0.001.......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 49/240] END max_iter=50, penalty=none, solver=lbfgs, tol=0.001;, score=0.500 total time=   1.7s\n",
      "[CV 1/5; 50/240] START max_iter=50, penalty=none, solver=lbfgs, tol=0.0001......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 50/240] END max_iter=50, penalty=none, solver=lbfgs, tol=0.0001;, score=0.499 total time=   1.7s\n",
      "[CV 2/5; 50/240] START max_iter=50, penalty=none, solver=lbfgs, tol=0.0001......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 50/240] END max_iter=50, penalty=none, solver=lbfgs, tol=0.0001;, score=0.500 total time=   1.7s\n",
      "[CV 3/5; 50/240] START max_iter=50, penalty=none, solver=lbfgs, tol=0.0001......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 50/240] END max_iter=50, penalty=none, solver=lbfgs, tol=0.0001;, score=0.501 total time=   1.7s\n",
      "[CV 4/5; 50/240] START max_iter=50, penalty=none, solver=lbfgs, tol=0.0001......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 50/240] END max_iter=50, penalty=none, solver=lbfgs, tol=0.0001;, score=0.500 total time=   1.7s\n",
      "[CV 5/5; 50/240] START max_iter=50, penalty=none, solver=lbfgs, tol=0.0001......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 50/240] END max_iter=50, penalty=none, solver=lbfgs, tol=0.0001;, score=0.500 total time=   1.7s\n",
      "[CV 1/5; 51/240] START max_iter=50, penalty=none, solver=lbfgs, tol=1e-05.......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 51/240] END max_iter=50, penalty=none, solver=lbfgs, tol=1e-05;, score=0.499 total time=   1.7s\n",
      "[CV 2/5; 51/240] START max_iter=50, penalty=none, solver=lbfgs, tol=1e-05.......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 51/240] END max_iter=50, penalty=none, solver=lbfgs, tol=1e-05;, score=0.500 total time=   1.7s\n",
      "[CV 3/5; 51/240] START max_iter=50, penalty=none, solver=lbfgs, tol=1e-05.......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 51/240] END max_iter=50, penalty=none, solver=lbfgs, tol=1e-05;, score=0.501 total time=   1.7s\n",
      "[CV 4/5; 51/240] START max_iter=50, penalty=none, solver=lbfgs, tol=1e-05.......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 51/240] END max_iter=50, penalty=none, solver=lbfgs, tol=1e-05;, score=0.500 total time=   1.7s\n",
      "[CV 5/5; 51/240] START max_iter=50, penalty=none, solver=lbfgs, tol=1e-05.......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 454, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 51/240] END max_iter=50, penalty=none, solver=lbfgs, tol=1e-05;, score=0.500 total time=   1.7s\n",
      "[CV 1/5; 52/240] START max_iter=50, penalty=none, solver=liblinear, tol=0.001...\n",
      "[CV 1/5; 52/240] END max_iter=50, penalty=none, solver=liblinear, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 2/5; 52/240] START max_iter=50, penalty=none, solver=liblinear, tol=0.001...\n",
      "[CV 2/5; 52/240] END max_iter=50, penalty=none, solver=liblinear, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 3/5; 52/240] START max_iter=50, penalty=none, solver=liblinear, tol=0.001..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 454, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 454, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 454, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV 3/5; 52/240] END max_iter=50, penalty=none, solver=liblinear, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 4/5; 52/240] START max_iter=50, penalty=none, solver=liblinear, tol=0.001...\n",
      "[CV 4/5; 52/240] END max_iter=50, penalty=none, solver=liblinear, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 5/5; 52/240] START max_iter=50, penalty=none, solver=liblinear, tol=0.001...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 454, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 454, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 454, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 52/240] END max_iter=50, penalty=none, solver=liblinear, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 1/5; 53/240] START max_iter=50, penalty=none, solver=liblinear, tol=0.0001..\n",
      "[CV 1/5; 53/240] END max_iter=50, penalty=none, solver=liblinear, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 2/5; 53/240] START max_iter=50, penalty=none, solver=liblinear, tol=0.0001..\n",
      "[CV 2/5; 53/240] END max_iter=50, penalty=none, solver=liblinear, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 3/5; 53/240] START max_iter=50, penalty=none, solver=liblinear, tol=0.0001..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 454, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 454, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 454, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 53/240] END max_iter=50, penalty=none, solver=liblinear, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 4/5; 53/240] START max_iter=50, penalty=none, solver=liblinear, tol=0.0001..\n",
      "[CV 4/5; 53/240] END max_iter=50, penalty=none, solver=liblinear, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 5/5; 53/240] START max_iter=50, penalty=none, solver=liblinear, tol=0.0001..\n",
      "[CV 5/5; 53/240] END max_iter=50, penalty=none, solver=liblinear, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 1/5; 54/240] START max_iter=50, penalty=none, solver=liblinear, tol=1e-05...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 454, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 454, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 454, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 54/240] END max_iter=50, penalty=none, solver=liblinear, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 2/5; 54/240] START max_iter=50, penalty=none, solver=liblinear, tol=1e-05...\n",
      "[CV 2/5; 54/240] END max_iter=50, penalty=none, solver=liblinear, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 3/5; 54/240] START max_iter=50, penalty=none, solver=liblinear, tol=1e-05...\n",
      "[CV 3/5; 54/240] END max_iter=50, penalty=none, solver=liblinear, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 4/5; 54/240] START max_iter=50, penalty=none, solver=liblinear, tol=1e-05...\n",
      "[CV 4/5; 54/240] END max_iter=50, penalty=none, solver=liblinear, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 5/5; 54/240] START max_iter=50, penalty=none, solver=liblinear, tol=1e-05...\n",
      "[CV 5/5; 54/240] END max_iter=50, penalty=none, solver=liblinear, tol=1e-05;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 454, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 454, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 55/240] START max_iter=50, penalty=none, solver=sag, tol=0.001.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 55/240] END max_iter=50, penalty=none, solver=sag, tol=0.001;, score=0.499 total time=  11.9s\n",
      "[CV 2/5; 55/240] START max_iter=50, penalty=none, solver=sag, tol=0.001.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 55/240] END max_iter=50, penalty=none, solver=sag, tol=0.001;, score=0.500 total time=  11.6s\n",
      "[CV 3/5; 55/240] START max_iter=50, penalty=none, solver=sag, tol=0.001.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 55/240] END max_iter=50, penalty=none, solver=sag, tol=0.001;, score=0.500 total time=  11.3s\n",
      "[CV 4/5; 55/240] START max_iter=50, penalty=none, solver=sag, tol=0.001.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 55/240] END max_iter=50, penalty=none, solver=sag, tol=0.001;, score=0.500 total time=  11.8s\n",
      "[CV 5/5; 55/240] START max_iter=50, penalty=none, solver=sag, tol=0.001.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 55/240] END max_iter=50, penalty=none, solver=sag, tol=0.001;, score=0.500 total time=  11.2s\n",
      "[CV 1/5; 56/240] START max_iter=50, penalty=none, solver=sag, tol=0.0001........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 56/240] END max_iter=50, penalty=none, solver=sag, tol=0.0001;, score=0.499 total time=  11.2s\n",
      "[CV 2/5; 56/240] START max_iter=50, penalty=none, solver=sag, tol=0.0001........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 56/240] END max_iter=50, penalty=none, solver=sag, tol=0.0001;, score=0.500 total time=  11.4s\n",
      "[CV 3/5; 56/240] START max_iter=50, penalty=none, solver=sag, tol=0.0001........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 56/240] END max_iter=50, penalty=none, solver=sag, tol=0.0001;, score=0.500 total time=  11.4s\n",
      "[CV 4/5; 56/240] START max_iter=50, penalty=none, solver=sag, tol=0.0001........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 56/240] END max_iter=50, penalty=none, solver=sag, tol=0.0001;, score=0.500 total time=  11.1s\n",
      "[CV 5/5; 56/240] START max_iter=50, penalty=none, solver=sag, tol=0.0001........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 56/240] END max_iter=50, penalty=none, solver=sag, tol=0.0001;, score=0.500 total time=  11.2s\n",
      "[CV 1/5; 57/240] START max_iter=50, penalty=none, solver=sag, tol=1e-05.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 57/240] END max_iter=50, penalty=none, solver=sag, tol=1e-05;, score=0.499 total time=  11.1s\n",
      "[CV 2/5; 57/240] START max_iter=50, penalty=none, solver=sag, tol=1e-05.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 57/240] END max_iter=50, penalty=none, solver=sag, tol=1e-05;, score=0.500 total time=  11.3s\n",
      "[CV 3/5; 57/240] START max_iter=50, penalty=none, solver=sag, tol=1e-05.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 57/240] END max_iter=50, penalty=none, solver=sag, tol=1e-05;, score=0.500 total time=  11.2s\n",
      "[CV 4/5; 57/240] START max_iter=50, penalty=none, solver=sag, tol=1e-05.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 57/240] END max_iter=50, penalty=none, solver=sag, tol=1e-05;, score=0.500 total time=  11.1s\n",
      "[CV 5/5; 57/240] START max_iter=50, penalty=none, solver=sag, tol=1e-05.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 57/240] END max_iter=50, penalty=none, solver=sag, tol=1e-05;, score=0.500 total time=  11.4s\n",
      "[CV 1/5; 58/240] START max_iter=50, penalty=none, solver=saga, tol=0.001........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 58/240] END max_iter=50, penalty=none, solver=saga, tol=0.001;, score=0.499 total time=  12.4s\n",
      "[CV 2/5; 58/240] START max_iter=50, penalty=none, solver=saga, tol=0.001........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 58/240] END max_iter=50, penalty=none, solver=saga, tol=0.001;, score=0.500 total time=  12.7s\n",
      "[CV 3/5; 58/240] START max_iter=50, penalty=none, solver=saga, tol=0.001........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 58/240] END max_iter=50, penalty=none, solver=saga, tol=0.001;, score=0.500 total time=  12.8s\n",
      "[CV 4/5; 58/240] START max_iter=50, penalty=none, solver=saga, tol=0.001........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 58/240] END max_iter=50, penalty=none, solver=saga, tol=0.001;, score=0.499 total time=  12.5s\n",
      "[CV 5/5; 58/240] START max_iter=50, penalty=none, solver=saga, tol=0.001........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 58/240] END max_iter=50, penalty=none, solver=saga, tol=0.001;, score=0.499 total time=  12.5s\n",
      "[CV 1/5; 59/240] START max_iter=50, penalty=none, solver=saga, tol=0.0001.......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 59/240] END max_iter=50, penalty=none, solver=saga, tol=0.0001;, score=0.499 total time=  12.5s\n",
      "[CV 2/5; 59/240] START max_iter=50, penalty=none, solver=saga, tol=0.0001.......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 59/240] END max_iter=50, penalty=none, solver=saga, tol=0.0001;, score=0.500 total time=  12.7s\n",
      "[CV 3/5; 59/240] START max_iter=50, penalty=none, solver=saga, tol=0.0001.......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 59/240] END max_iter=50, penalty=none, solver=saga, tol=0.0001;, score=0.500 total time=  13.6s\n",
      "[CV 4/5; 59/240] START max_iter=50, penalty=none, solver=saga, tol=0.0001.......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 59/240] END max_iter=50, penalty=none, solver=saga, tol=0.0001;, score=0.499 total time=  12.7s\n",
      "[CV 5/5; 59/240] START max_iter=50, penalty=none, solver=saga, tol=0.0001.......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 59/240] END max_iter=50, penalty=none, solver=saga, tol=0.0001;, score=0.499 total time=  14.0s\n",
      "[CV 1/5; 60/240] START max_iter=50, penalty=none, solver=saga, tol=1e-05........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 60/240] END max_iter=50, penalty=none, solver=saga, tol=1e-05;, score=0.499 total time=  13.4s\n",
      "[CV 2/5; 60/240] START max_iter=50, penalty=none, solver=saga, tol=1e-05........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 60/240] END max_iter=50, penalty=none, solver=saga, tol=1e-05;, score=0.500 total time=  12.9s\n",
      "[CV 3/5; 60/240] START max_iter=50, penalty=none, solver=saga, tol=1e-05........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 60/240] END max_iter=50, penalty=none, solver=saga, tol=1e-05;, score=0.500 total time=  13.0s\n",
      "[CV 4/5; 60/240] START max_iter=50, penalty=none, solver=saga, tol=1e-05........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 60/240] END max_iter=50, penalty=none, solver=saga, tol=1e-05;, score=0.499 total time=  12.7s\n",
      "[CV 5/5; 60/240] START max_iter=50, penalty=none, solver=saga, tol=1e-05........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 60/240] END max_iter=50, penalty=none, solver=saga, tol=1e-05;, score=0.499 total time=  12.6s\n",
      "[CV 1/5; 61/240] START max_iter=100, penalty=l1, solver=newton-cg, tol=0.001....\n",
      "[CV 1/5; 61/240] END max_iter=100, penalty=l1, solver=newton-cg, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 2/5; 61/240] START max_iter=100, penalty=l1, solver=newton-cg, tol=0.001....\n",
      "[CV 2/5; 61/240] END max_iter=100, penalty=l1, solver=newton-cg, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 3/5; 61/240] START max_iter=100, penalty=l1, solver=newton-cg, tol=0.001....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 61/240] END max_iter=100, penalty=l1, solver=newton-cg, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 4/5; 61/240] START max_iter=100, penalty=l1, solver=newton-cg, tol=0.001....\n",
      "[CV 4/5; 61/240] END max_iter=100, penalty=l1, solver=newton-cg, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 5/5; 61/240] START max_iter=100, penalty=l1, solver=newton-cg, tol=0.001....\n",
      "[CV 5/5; 61/240] END max_iter=100, penalty=l1, solver=newton-cg, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 1/5; 62/240] START max_iter=100, penalty=l1, solver=newton-cg, tol=0.0001...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 62/240] END max_iter=100, penalty=l1, solver=newton-cg, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 2/5; 62/240] START max_iter=100, penalty=l1, solver=newton-cg, tol=0.0001...\n",
      "[CV 2/5; 62/240] END max_iter=100, penalty=l1, solver=newton-cg, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 3/5; 62/240] START max_iter=100, penalty=l1, solver=newton-cg, tol=0.0001...\n",
      "[CV 3/5; 62/240] END max_iter=100, penalty=l1, solver=newton-cg, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 4/5; 62/240] START max_iter=100, penalty=l1, solver=newton-cg, tol=0.0001...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 62/240] END max_iter=100, penalty=l1, solver=newton-cg, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 5/5; 62/240] START max_iter=100, penalty=l1, solver=newton-cg, tol=0.0001...\n",
      "[CV 5/5; 62/240] END max_iter=100, penalty=l1, solver=newton-cg, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 1/5; 63/240] START max_iter=100, penalty=l1, solver=newton-cg, tol=1e-05....\n",
      "[CV 1/5; 63/240] END max_iter=100, penalty=l1, solver=newton-cg, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 2/5; 63/240] START max_iter=100, penalty=l1, solver=newton-cg, tol=1e-05....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 63/240] END max_iter=100, penalty=l1, solver=newton-cg, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 3/5; 63/240] START max_iter=100, penalty=l1, solver=newton-cg, tol=1e-05....\n",
      "[CV 3/5; 63/240] END max_iter=100, penalty=l1, solver=newton-cg, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 4/5; 63/240] START max_iter=100, penalty=l1, solver=newton-cg, tol=1e-05....\n",
      "[CV 4/5; 63/240] END max_iter=100, penalty=l1, solver=newton-cg, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 5/5; 63/240] START max_iter=100, penalty=l1, solver=newton-cg, tol=1e-05....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 63/240] END max_iter=100, penalty=l1, solver=newton-cg, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 1/5; 64/240] START max_iter=100, penalty=l1, solver=lbfgs, tol=0.001........\n",
      "[CV 1/5; 64/240] END max_iter=100, penalty=l1, solver=lbfgs, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 2/5; 64/240] START max_iter=100, penalty=l1, solver=lbfgs, tol=0.001........\n",
      "[CV 2/5; 64/240] END max_iter=100, penalty=l1, solver=lbfgs, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 3/5; 64/240] START max_iter=100, penalty=l1, solver=lbfgs, tol=0.001........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 64/240] END max_iter=100, penalty=l1, solver=lbfgs, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 4/5; 64/240] START max_iter=100, penalty=l1, solver=lbfgs, tol=0.001........\n",
      "[CV 4/5; 64/240] END max_iter=100, penalty=l1, solver=lbfgs, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 5/5; 64/240] START max_iter=100, penalty=l1, solver=lbfgs, tol=0.001........\n",
      "[CV 5/5; 64/240] END max_iter=100, penalty=l1, solver=lbfgs, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 1/5; 65/240] START max_iter=100, penalty=l1, solver=lbfgs, tol=0.0001......."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV 1/5; 65/240] END max_iter=100, penalty=l1, solver=lbfgs, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 2/5; 65/240] START max_iter=100, penalty=l1, solver=lbfgs, tol=0.0001.......\n",
      "[CV 2/5; 65/240] END max_iter=100, penalty=l1, solver=lbfgs, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 3/5; 65/240] START max_iter=100, penalty=l1, solver=lbfgs, tol=0.0001.......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 65/240] END max_iter=100, penalty=l1, solver=lbfgs, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 4/5; 65/240] START max_iter=100, penalty=l1, solver=lbfgs, tol=0.0001.......\n",
      "[CV 4/5; 65/240] END max_iter=100, penalty=l1, solver=lbfgs, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 5/5; 65/240] START max_iter=100, penalty=l1, solver=lbfgs, tol=0.0001.......\n",
      "[CV 5/5; 65/240] END max_iter=100, penalty=l1, solver=lbfgs, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 1/5; 66/240] START max_iter=100, penalty=l1, solver=lbfgs, tol=1e-05........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 66/240] END max_iter=100, penalty=l1, solver=lbfgs, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 2/5; 66/240] START max_iter=100, penalty=l1, solver=lbfgs, tol=1e-05........\n",
      "[CV 2/5; 66/240] END max_iter=100, penalty=l1, solver=lbfgs, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 3/5; 66/240] START max_iter=100, penalty=l1, solver=lbfgs, tol=1e-05........\n",
      "[CV 3/5; 66/240] END max_iter=100, penalty=l1, solver=lbfgs, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 4/5; 66/240] START max_iter=100, penalty=l1, solver=lbfgs, tol=1e-05........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 66/240] END max_iter=100, penalty=l1, solver=lbfgs, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 5/5; 66/240] START max_iter=100, penalty=l1, solver=lbfgs, tol=1e-05........\n",
      "[CV 5/5; 66/240] END max_iter=100, penalty=l1, solver=lbfgs, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 1/5; 67/240] START max_iter=100, penalty=l1, solver=liblinear, tol=0.001....\n",
      "[CV 1/5; 67/240] END max_iter=100, penalty=l1, solver=liblinear, tol=0.001;, score=0.498 total time=   0.7s\n",
      "[CV 2/5; 67/240] START max_iter=100, penalty=l1, solver=liblinear, tol=0.001....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 67/240] END max_iter=100, penalty=l1, solver=liblinear, tol=0.001;, score=0.500 total time=10.8min\n",
      "[CV 3/5; 67/240] START max_iter=100, penalty=l1, solver=liblinear, tol=0.001....\n",
      "[CV 3/5; 67/240] END max_iter=100, penalty=l1, solver=liblinear, tol=0.001;, score=0.499 total time=   0.8s\n",
      "[CV 4/5; 67/240] START max_iter=100, penalty=l1, solver=liblinear, tol=0.001....\n",
      "[CV 4/5; 67/240] END max_iter=100, penalty=l1, solver=liblinear, tol=0.001;, score=0.498 total time=   0.6s\n",
      "[CV 5/5; 67/240] START max_iter=100, penalty=l1, solver=liblinear, tol=0.001....\n",
      "[CV 5/5; 67/240] END max_iter=100, penalty=l1, solver=liblinear, tol=0.001;, score=0.500 total time=   0.6s\n",
      "[CV 1/5; 68/240] START max_iter=100, penalty=l1, solver=liblinear, tol=0.0001...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 68/240] END max_iter=100, penalty=l1, solver=liblinear, tol=0.0001;, score=0.497 total time= 8.4min\n",
      "[CV 2/5; 68/240] START max_iter=100, penalty=l1, solver=liblinear, tol=0.0001...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 68/240] END max_iter=100, penalty=l1, solver=liblinear, tol=0.0001;, score=0.500 total time= 8.1min\n",
      "[CV 3/5; 68/240] START max_iter=100, penalty=l1, solver=liblinear, tol=0.0001...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 68/240] END max_iter=100, penalty=l1, solver=liblinear, tol=0.0001;, score=0.499 total time= 8.3min\n",
      "[CV 4/5; 68/240] START max_iter=100, penalty=l1, solver=liblinear, tol=0.0001...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 68/240] END max_iter=100, penalty=l1, solver=liblinear, tol=0.0001;, score=0.499 total time= 8.1min\n",
      "[CV 5/5; 68/240] START max_iter=100, penalty=l1, solver=liblinear, tol=0.0001...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 68/240] END max_iter=100, penalty=l1, solver=liblinear, tol=0.0001;, score=0.500 total time= 8.4min\n",
      "[CV 1/5; 69/240] START max_iter=100, penalty=l1, solver=liblinear, tol=1e-05....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 69/240] END max_iter=100, penalty=l1, solver=liblinear, tol=1e-05;, score=0.498 total time= 7.9min\n",
      "[CV 2/5; 69/240] START max_iter=100, penalty=l1, solver=liblinear, tol=1e-05....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 69/240] END max_iter=100, penalty=l1, solver=liblinear, tol=1e-05;, score=0.500 total time= 8.2min\n",
      "[CV 3/5; 69/240] START max_iter=100, penalty=l1, solver=liblinear, tol=1e-05....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 69/240] END max_iter=100, penalty=l1, solver=liblinear, tol=1e-05;, score=0.499 total time= 8.2min\n",
      "[CV 4/5; 69/240] START max_iter=100, penalty=l1, solver=liblinear, tol=1e-05....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 69/240] END max_iter=100, penalty=l1, solver=liblinear, tol=1e-05;, score=0.499 total time= 8.0min\n",
      "[CV 5/5; 69/240] START max_iter=100, penalty=l1, solver=liblinear, tol=1e-05....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 69/240] END max_iter=100, penalty=l1, solver=liblinear, tol=1e-05;, score=0.501 total time= 7.9min\n",
      "[CV 1/5; 70/240] START max_iter=100, penalty=l1, solver=sag, tol=0.001..........\n",
      "[CV 1/5; 70/240] END max_iter=100, penalty=l1, solver=sag, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 2/5; 70/240] START max_iter=100, penalty=l1, solver=sag, tol=0.001..........\n",
      "[CV 2/5; 70/240] END max_iter=100, penalty=l1, solver=sag, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 3/5; 70/240] START max_iter=100, penalty=l1, solver=sag, tol=0.001..........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 70/240] END max_iter=100, penalty=l1, solver=sag, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 4/5; 70/240] START max_iter=100, penalty=l1, solver=sag, tol=0.001..........\n",
      "[CV 4/5; 70/240] END max_iter=100, penalty=l1, solver=sag, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 5/5; 70/240] START max_iter=100, penalty=l1, solver=sag, tol=0.001..........\n",
      "[CV 5/5; 70/240] END max_iter=100, penalty=l1, solver=sag, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 1/5; 71/240] START max_iter=100, penalty=l1, solver=sag, tol=0.0001.........\n",
      "[CV 1/5; 71/240] END max_iter=100, penalty=l1, solver=sag, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 2/5; 71/240] START max_iter=100, penalty=l1, solver=sag, tol=0.0001.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 71/240] END max_iter=100, penalty=l1, solver=sag, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 3/5; 71/240] START max_iter=100, penalty=l1, solver=sag, tol=0.0001.........\n",
      "[CV 3/5; 71/240] END max_iter=100, penalty=l1, solver=sag, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 4/5; 71/240] START max_iter=100, penalty=l1, solver=sag, tol=0.0001.........\n",
      "[CV 4/5; 71/240] END max_iter=100, penalty=l1, solver=sag, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 5/5; 71/240] START max_iter=100, penalty=l1, solver=sag, tol=0.0001.........\n",
      "[CV 5/5; 71/240] END max_iter=100, penalty=l1, solver=sag, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 1/5; 72/240] START max_iter=100, penalty=l1, solver=sag, tol=1e-05..........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 72/240] END max_iter=100, penalty=l1, solver=sag, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 2/5; 72/240] START max_iter=100, penalty=l1, solver=sag, tol=1e-05..........\n",
      "[CV 2/5; 72/240] END max_iter=100, penalty=l1, solver=sag, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 3/5; 72/240] START max_iter=100, penalty=l1, solver=sag, tol=1e-05..........\n",
      "[CV 3/5; 72/240] END max_iter=100, penalty=l1, solver=sag, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 4/5; 72/240] START max_iter=100, penalty=l1, solver=sag, tol=1e-05..........\n",
      "[CV 4/5; 72/240] END max_iter=100, penalty=l1, solver=sag, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 5/5; 72/240] START max_iter=100, penalty=l1, solver=sag, tol=1e-05..........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 72/240] END max_iter=100, penalty=l1, solver=sag, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 1/5; 73/240] START max_iter=100, penalty=l1, solver=saga, tol=0.001.........\n",
      "[CV 1/5; 73/240] END max_iter=100, penalty=l1, solver=saga, tol=0.001;, score=0.499 total time=  36.8s\n",
      "[CV 2/5; 73/240] START max_iter=100, penalty=l1, solver=saga, tol=0.001.........\n",
      "[CV 2/5; 73/240] END max_iter=100, penalty=l1, solver=saga, tol=0.001;, score=0.500 total time=  35.4s\n",
      "[CV 3/5; 73/240] START max_iter=100, penalty=l1, solver=saga, tol=0.001.........\n",
      "[CV 3/5; 73/240] END max_iter=100, penalty=l1, solver=saga, tol=0.001;, score=0.500 total time=  36.5s\n",
      "[CV 4/5; 73/240] START max_iter=100, penalty=l1, solver=saga, tol=0.001.........\n",
      "[CV 4/5; 73/240] END max_iter=100, penalty=l1, solver=saga, tol=0.001;, score=0.499 total time=  35.4s\n",
      "[CV 5/5; 73/240] START max_iter=100, penalty=l1, solver=saga, tol=0.001.........\n",
      "[CV 5/5; 73/240] END max_iter=100, penalty=l1, solver=saga, tol=0.001;, score=0.500 total time=  36.7s\n",
      "[CV 1/5; 74/240] START max_iter=100, penalty=l1, solver=saga, tol=0.0001........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 74/240] END max_iter=100, penalty=l1, solver=saga, tol=0.0001;, score=0.499 total time=  36.3s\n",
      "[CV 2/5; 74/240] START max_iter=100, penalty=l1, solver=saga, tol=0.0001........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 74/240] END max_iter=100, penalty=l1, solver=saga, tol=0.0001;, score=0.500 total time=  35.5s\n",
      "[CV 3/5; 74/240] START max_iter=100, penalty=l1, solver=saga, tol=0.0001........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 74/240] END max_iter=100, penalty=l1, solver=saga, tol=0.0001;, score=0.500 total time=  38.1s\n",
      "[CV 4/5; 74/240] START max_iter=100, penalty=l1, solver=saga, tol=0.0001........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 74/240] END max_iter=100, penalty=l1, solver=saga, tol=0.0001;, score=0.499 total time=  38.3s\n",
      "[CV 5/5; 74/240] START max_iter=100, penalty=l1, solver=saga, tol=0.0001........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 74/240] END max_iter=100, penalty=l1, solver=saga, tol=0.0001;, score=0.500 total time=  38.0s\n",
      "[CV 1/5; 75/240] START max_iter=100, penalty=l1, solver=saga, tol=1e-05.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 75/240] END max_iter=100, penalty=l1, solver=saga, tol=1e-05;, score=0.499 total time=  38.6s\n",
      "[CV 2/5; 75/240] START max_iter=100, penalty=l1, solver=saga, tol=1e-05.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 75/240] END max_iter=100, penalty=l1, solver=saga, tol=1e-05;, score=0.500 total time=  39.6s\n",
      "[CV 3/5; 75/240] START max_iter=100, penalty=l1, solver=saga, tol=1e-05.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 75/240] END max_iter=100, penalty=l1, solver=saga, tol=1e-05;, score=0.500 total time=  40.6s\n",
      "[CV 4/5; 75/240] START max_iter=100, penalty=l1, solver=saga, tol=1e-05.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 75/240] END max_iter=100, penalty=l1, solver=saga, tol=1e-05;, score=0.499 total time=  41.6s\n",
      "[CV 5/5; 75/240] START max_iter=100, penalty=l1, solver=saga, tol=1e-05.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 75/240] END max_iter=100, penalty=l1, solver=saga, tol=1e-05;, score=0.500 total time=  40.5s\n",
      "[CV 1/5; 76/240] START max_iter=100, penalty=l2, solver=newton-cg, tol=0.001....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"newton-cg failed to converge. Increase the \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 76/240] END max_iter=100, penalty=l2, solver=newton-cg, tol=0.001;, score=0.497 total time= 3.7min\n",
      "[CV 2/5; 76/240] START max_iter=100, penalty=l2, solver=newton-cg, tol=0.001....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"newton-cg failed to converge. Increase the \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 76/240] END max_iter=100, penalty=l2, solver=newton-cg, tol=0.001;, score=0.500 total time= 3.6min\n",
      "[CV 3/5; 76/240] START max_iter=100, penalty=l2, solver=newton-cg, tol=0.001....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"newton-cg failed to converge. Increase the \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 76/240] END max_iter=100, penalty=l2, solver=newton-cg, tol=0.001;, score=0.499 total time= 3.3min\n",
      "[CV 4/5; 76/240] START max_iter=100, penalty=l2, solver=newton-cg, tol=0.001....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"newton-cg failed to converge. Increase the \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 76/240] END max_iter=100, penalty=l2, solver=newton-cg, tol=0.001;, score=0.499 total time= 3.9min\n",
      "[CV 5/5; 76/240] START max_iter=100, penalty=l2, solver=newton-cg, tol=0.001....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"newton-cg failed to converge. Increase the \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 76/240] END max_iter=100, penalty=l2, solver=newton-cg, tol=0.001;, score=0.500 total time= 3.7min\n",
      "[CV 1/5; 77/240] START max_iter=100, penalty=l2, solver=newton-cg, tol=0.0001...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"newton-cg failed to converge. Increase the \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 77/240] END max_iter=100, penalty=l2, solver=newton-cg, tol=0.0001;, score=0.497 total time= 3.8min\n",
      "[CV 2/5; 77/240] START max_iter=100, penalty=l2, solver=newton-cg, tol=0.0001...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"newton-cg failed to converge. Increase the \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 77/240] END max_iter=100, penalty=l2, solver=newton-cg, tol=0.0001;, score=0.500 total time= 3.7min\n",
      "[CV 3/5; 77/240] START max_iter=100, penalty=l2, solver=newton-cg, tol=0.0001...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"newton-cg failed to converge. Increase the \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 77/240] END max_iter=100, penalty=l2, solver=newton-cg, tol=0.0001;, score=0.499 total time= 3.8min\n",
      "[CV 4/5; 77/240] START max_iter=100, penalty=l2, solver=newton-cg, tol=0.0001...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"newton-cg failed to converge. Increase the \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 77/240] END max_iter=100, penalty=l2, solver=newton-cg, tol=0.0001;, score=0.499 total time= 3.6min\n",
      "[CV 5/5; 77/240] START max_iter=100, penalty=l2, solver=newton-cg, tol=0.0001...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"newton-cg failed to converge. Increase the \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 77/240] END max_iter=100, penalty=l2, solver=newton-cg, tol=0.0001;, score=0.500 total time= 3.4min\n",
      "[CV 1/5; 78/240] START max_iter=100, penalty=l2, solver=newton-cg, tol=1e-05....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"newton-cg failed to converge. Increase the \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 78/240] END max_iter=100, penalty=l2, solver=newton-cg, tol=1e-05;, score=0.497 total time= 3.7min\n",
      "[CV 2/5; 78/240] START max_iter=100, penalty=l2, solver=newton-cg, tol=1e-05....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"newton-cg failed to converge. Increase the \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 78/240] END max_iter=100, penalty=l2, solver=newton-cg, tol=1e-05;, score=0.500 total time= 3.6min\n",
      "[CV 3/5; 78/240] START max_iter=100, penalty=l2, solver=newton-cg, tol=1e-05....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"newton-cg failed to converge. Increase the \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 78/240] END max_iter=100, penalty=l2, solver=newton-cg, tol=1e-05;, score=0.499 total time= 3.4min\n",
      "[CV 4/5; 78/240] START max_iter=100, penalty=l2, solver=newton-cg, tol=1e-05....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"newton-cg failed to converge. Increase the \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 78/240] END max_iter=100, penalty=l2, solver=newton-cg, tol=1e-05;, score=0.499 total time= 3.8min\n",
      "[CV 5/5; 78/240] START max_iter=100, penalty=l2, solver=newton-cg, tol=1e-05....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"newton-cg failed to converge. Increase the \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 78/240] END max_iter=100, penalty=l2, solver=newton-cg, tol=1e-05;, score=0.500 total time= 3.5min\n",
      "[CV 1/5; 79/240] START max_iter=100, penalty=l2, solver=lbfgs, tol=0.001........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 79/240] END max_iter=100, penalty=l2, solver=lbfgs, tol=0.001;, score=0.498 total time=   2.1s\n",
      "[CV 2/5; 79/240] START max_iter=100, penalty=l2, solver=lbfgs, tol=0.001........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 79/240] END max_iter=100, penalty=l2, solver=lbfgs, tol=0.001;, score=0.500 total time=   2.0s\n",
      "[CV 3/5; 79/240] START max_iter=100, penalty=l2, solver=lbfgs, tol=0.001........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 79/240] END max_iter=100, penalty=l2, solver=lbfgs, tol=0.001;, score=0.500 total time=   2.1s\n",
      "[CV 4/5; 79/240] START max_iter=100, penalty=l2, solver=lbfgs, tol=0.001........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 79/240] END max_iter=100, penalty=l2, solver=lbfgs, tol=0.001;, score=0.499 total time=   2.1s\n",
      "[CV 5/5; 79/240] START max_iter=100, penalty=l2, solver=lbfgs, tol=0.001........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 79/240] END max_iter=100, penalty=l2, solver=lbfgs, tol=0.001;, score=0.500 total time=   2.0s\n",
      "[CV 1/5; 80/240] START max_iter=100, penalty=l2, solver=lbfgs, tol=0.0001.......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 80/240] END max_iter=100, penalty=l2, solver=lbfgs, tol=0.0001;, score=0.498 total time=   2.0s\n",
      "[CV 2/5; 80/240] START max_iter=100, penalty=l2, solver=lbfgs, tol=0.0001.......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 80/240] END max_iter=100, penalty=l2, solver=lbfgs, tol=0.0001;, score=0.500 total time=   2.0s\n",
      "[CV 3/5; 80/240] START max_iter=100, penalty=l2, solver=lbfgs, tol=0.0001.......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 80/240] END max_iter=100, penalty=l2, solver=lbfgs, tol=0.0001;, score=0.500 total time=   2.1s\n",
      "[CV 4/5; 80/240] START max_iter=100, penalty=l2, solver=lbfgs, tol=0.0001.......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 80/240] END max_iter=100, penalty=l2, solver=lbfgs, tol=0.0001;, score=0.499 total time=   2.1s\n",
      "[CV 5/5; 80/240] START max_iter=100, penalty=l2, solver=lbfgs, tol=0.0001.......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 80/240] END max_iter=100, penalty=l2, solver=lbfgs, tol=0.0001;, score=0.500 total time=   2.1s\n",
      "[CV 1/5; 81/240] START max_iter=100, penalty=l2, solver=lbfgs, tol=1e-05........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 81/240] END max_iter=100, penalty=l2, solver=lbfgs, tol=1e-05;, score=0.498 total time=   2.0s\n",
      "[CV 2/5; 81/240] START max_iter=100, penalty=l2, solver=lbfgs, tol=1e-05........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 81/240] END max_iter=100, penalty=l2, solver=lbfgs, tol=1e-05;, score=0.500 total time=   2.0s\n",
      "[CV 3/5; 81/240] START max_iter=100, penalty=l2, solver=lbfgs, tol=1e-05........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 81/240] END max_iter=100, penalty=l2, solver=lbfgs, tol=1e-05;, score=0.500 total time=   2.2s\n",
      "[CV 4/5; 81/240] START max_iter=100, penalty=l2, solver=lbfgs, tol=1e-05........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 81/240] END max_iter=100, penalty=l2, solver=lbfgs, tol=1e-05;, score=0.499 total time=   2.2s\n",
      "[CV 5/5; 81/240] START max_iter=100, penalty=l2, solver=lbfgs, tol=1e-05........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 81/240] END max_iter=100, penalty=l2, solver=lbfgs, tol=1e-05;, score=0.500 total time=   2.1s\n",
      "[CV 1/5; 82/240] START max_iter=100, penalty=l2, solver=liblinear, tol=0.001....\n",
      "[CV 1/5; 82/240] END max_iter=100, penalty=l2, solver=liblinear, tol=0.001;, score=0.498 total time=  17.0s\n",
      "[CV 2/5; 82/240] START max_iter=100, penalty=l2, solver=liblinear, tol=0.001....\n",
      "[CV 2/5; 82/240] END max_iter=100, penalty=l2, solver=liblinear, tol=0.001;, score=0.499 total time=  14.6s\n",
      "[CV 3/5; 82/240] START max_iter=100, penalty=l2, solver=liblinear, tol=0.001....\n",
      "[CV 3/5; 82/240] END max_iter=100, penalty=l2, solver=liblinear, tol=0.001;, score=0.499 total time=  14.9s\n",
      "[CV 4/5; 82/240] START max_iter=100, penalty=l2, solver=liblinear, tol=0.001....\n",
      "[CV 4/5; 82/240] END max_iter=100, penalty=l2, solver=liblinear, tol=0.001;, score=0.499 total time=  31.1s\n",
      "[CV 5/5; 82/240] START max_iter=100, penalty=l2, solver=liblinear, tol=0.001....\n",
      "[CV 5/5; 82/240] END max_iter=100, penalty=l2, solver=liblinear, tol=0.001;, score=0.500 total time=  24.1s\n",
      "[CV 1/5; 83/240] START max_iter=100, penalty=l2, solver=liblinear, tol=0.0001...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 83/240] END max_iter=100, penalty=l2, solver=liblinear, tol=0.0001;, score=0.497 total time= 3.1min\n",
      "[CV 2/5; 83/240] START max_iter=100, penalty=l2, solver=liblinear, tol=0.0001...\n",
      "[CV 2/5; 83/240] END max_iter=100, penalty=l2, solver=liblinear, tol=0.0001;, score=0.499 total time= 5.2min\n",
      "[CV 3/5; 83/240] START max_iter=100, penalty=l2, solver=liblinear, tol=0.0001...\n",
      "[CV 3/5; 83/240] END max_iter=100, penalty=l2, solver=liblinear, tol=0.0001;, score=0.499 total time= 4.3min\n",
      "[CV 4/5; 83/240] START max_iter=100, penalty=l2, solver=liblinear, tol=0.0001...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 83/240] END max_iter=100, penalty=l2, solver=liblinear, tol=0.0001;, score=0.499 total time= 2.6min\n",
      "[CV 5/5; 83/240] START max_iter=100, penalty=l2, solver=liblinear, tol=0.0001...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 83/240] END max_iter=100, penalty=l2, solver=liblinear, tol=0.0001;, score=0.500 total time= 1.4min\n",
      "[CV 1/5; 84/240] START max_iter=100, penalty=l2, solver=liblinear, tol=1e-05....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 84/240] END max_iter=100, penalty=l2, solver=liblinear, tol=1e-05;, score=0.497 total time= 3.0min\n",
      "[CV 2/5; 84/240] START max_iter=100, penalty=l2, solver=liblinear, tol=1e-05....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 84/240] END max_iter=100, penalty=l2, solver=liblinear, tol=1e-05;, score=0.499 total time= 7.6min\n",
      "[CV 3/5; 84/240] START max_iter=100, penalty=l2, solver=liblinear, tol=1e-05....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 84/240] END max_iter=100, penalty=l2, solver=liblinear, tol=1e-05;, score=0.499 total time= 7.3min\n",
      "[CV 4/5; 84/240] START max_iter=100, penalty=l2, solver=liblinear, tol=1e-05....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 84/240] END max_iter=100, penalty=l2, solver=liblinear, tol=1e-05;, score=0.499 total time= 2.6min\n",
      "[CV 5/5; 84/240] START max_iter=100, penalty=l2, solver=liblinear, tol=1e-05....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 84/240] END max_iter=100, penalty=l2, solver=liblinear, tol=1e-05;, score=0.500 total time= 1.5min\n",
      "[CV 1/5; 85/240] START max_iter=100, penalty=l2, solver=sag, tol=0.001..........\n",
      "[CV 1/5; 85/240] END max_iter=100, penalty=l2, solver=sag, tol=0.001;, score=0.499 total time=  11.3s\n",
      "[CV 2/5; 85/240] START max_iter=100, penalty=l2, solver=sag, tol=0.001..........\n",
      "[CV 2/5; 85/240] END max_iter=100, penalty=l2, solver=sag, tol=0.001;, score=0.500 total time=  11.2s\n",
      "[CV 3/5; 85/240] START max_iter=100, penalty=l2, solver=sag, tol=0.001..........\n",
      "[CV 3/5; 85/240] END max_iter=100, penalty=l2, solver=sag, tol=0.001;, score=0.500 total time=  11.7s\n",
      "[CV 4/5; 85/240] START max_iter=100, penalty=l2, solver=sag, tol=0.001..........\n",
      "[CV 4/5; 85/240] END max_iter=100, penalty=l2, solver=sag, tol=0.001;, score=0.499 total time=  11.6s\n",
      "[CV 5/5; 85/240] START max_iter=100, penalty=l2, solver=sag, tol=0.001..........\n",
      "[CV 5/5; 85/240] END max_iter=100, penalty=l2, solver=sag, tol=0.001;, score=0.500 total time=  11.5s\n",
      "[CV 1/5; 86/240] START max_iter=100, penalty=l2, solver=sag, tol=0.0001.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 86/240] END max_iter=100, penalty=l2, solver=sag, tol=0.0001;, score=0.499 total time=  20.2s\n",
      "[CV 2/5; 86/240] START max_iter=100, penalty=l2, solver=sag, tol=0.0001.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 86/240] END max_iter=100, penalty=l2, solver=sag, tol=0.0001;, score=0.499 total time=  20.1s\n",
      "[CV 3/5; 86/240] START max_iter=100, penalty=l2, solver=sag, tol=0.0001.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 86/240] END max_iter=100, penalty=l2, solver=sag, tol=0.0001;, score=0.500 total time=  20.0s\n",
      "[CV 4/5; 86/240] START max_iter=100, penalty=l2, solver=sag, tol=0.0001.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 86/240] END max_iter=100, penalty=l2, solver=sag, tol=0.0001;, score=0.500 total time=  20.3s\n",
      "[CV 5/5; 86/240] START max_iter=100, penalty=l2, solver=sag, tol=0.0001.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 86/240] END max_iter=100, penalty=l2, solver=sag, tol=0.0001;, score=0.500 total time=  20.5s\n",
      "[CV 1/5; 87/240] START max_iter=100, penalty=l2, solver=sag, tol=1e-05..........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 87/240] END max_iter=100, penalty=l2, solver=sag, tol=1e-05;, score=0.499 total time=  20.0s\n",
      "[CV 2/5; 87/240] START max_iter=100, penalty=l2, solver=sag, tol=1e-05..........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 87/240] END max_iter=100, penalty=l2, solver=sag, tol=1e-05;, score=0.499 total time=  20.3s\n",
      "[CV 3/5; 87/240] START max_iter=100, penalty=l2, solver=sag, tol=1e-05..........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 87/240] END max_iter=100, penalty=l2, solver=sag, tol=1e-05;, score=0.500 total time=  20.1s\n",
      "[CV 4/5; 87/240] START max_iter=100, penalty=l2, solver=sag, tol=1e-05..........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 87/240] END max_iter=100, penalty=l2, solver=sag, tol=1e-05;, score=0.500 total time=  20.0s\n",
      "[CV 5/5; 87/240] START max_iter=100, penalty=l2, solver=sag, tol=1e-05..........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 87/240] END max_iter=100, penalty=l2, solver=sag, tol=1e-05;, score=0.500 total time=  20.3s\n",
      "[CV 1/5; 88/240] START max_iter=100, penalty=l2, solver=saga, tol=0.001.........\n",
      "[CV 1/5; 88/240] END max_iter=100, penalty=l2, solver=saga, tol=0.001;, score=0.499 total time=  21.9s\n",
      "[CV 2/5; 88/240] START max_iter=100, penalty=l2, solver=saga, tol=0.001.........\n",
      "[CV 2/5; 88/240] END max_iter=100, penalty=l2, solver=saga, tol=0.001;, score=0.500 total time=  21.5s\n",
      "[CV 3/5; 88/240] START max_iter=100, penalty=l2, solver=saga, tol=0.001.........\n",
      "[CV 3/5; 88/240] END max_iter=100, penalty=l2, solver=saga, tol=0.001;, score=0.500 total time=  22.1s\n",
      "[CV 4/5; 88/240] START max_iter=100, penalty=l2, solver=saga, tol=0.001.........\n",
      "[CV 4/5; 88/240] END max_iter=100, penalty=l2, solver=saga, tol=0.001;, score=0.499 total time=  22.1s\n",
      "[CV 5/5; 88/240] START max_iter=100, penalty=l2, solver=saga, tol=0.001.........\n",
      "[CV 5/5; 88/240] END max_iter=100, penalty=l2, solver=saga, tol=0.001;, score=0.500 total time=  23.2s\n",
      "[CV 1/5; 89/240] START max_iter=100, penalty=l2, solver=saga, tol=0.0001........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 89/240] END max_iter=100, penalty=l2, solver=saga, tol=0.0001;, score=0.499 total time=  24.9s\n",
      "[CV 2/5; 89/240] START max_iter=100, penalty=l2, solver=saga, tol=0.0001........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 89/240] END max_iter=100, penalty=l2, solver=saga, tol=0.0001;, score=0.500 total time=  29.0s\n",
      "[CV 3/5; 89/240] START max_iter=100, penalty=l2, solver=saga, tol=0.0001........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 89/240] END max_iter=100, penalty=l2, solver=saga, tol=0.0001;, score=0.500 total time=  28.8s\n",
      "[CV 4/5; 89/240] START max_iter=100, penalty=l2, solver=saga, tol=0.0001........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 89/240] END max_iter=100, penalty=l2, solver=saga, tol=0.0001;, score=0.499 total time=  27.0s\n",
      "[CV 5/5; 89/240] START max_iter=100, penalty=l2, solver=saga, tol=0.0001........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 89/240] END max_iter=100, penalty=l2, solver=saga, tol=0.0001;, score=0.500 total time=  27.4s\n",
      "[CV 1/5; 90/240] START max_iter=100, penalty=l2, solver=saga, tol=1e-05.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 90/240] END max_iter=100, penalty=l2, solver=saga, tol=1e-05;, score=0.499 total time=  24.6s\n",
      "[CV 2/5; 90/240] START max_iter=100, penalty=l2, solver=saga, tol=1e-05.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 90/240] END max_iter=100, penalty=l2, solver=saga, tol=1e-05;, score=0.500 total time=  26.2s\n",
      "[CV 3/5; 90/240] START max_iter=100, penalty=l2, solver=saga, tol=1e-05.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 90/240] END max_iter=100, penalty=l2, solver=saga, tol=1e-05;, score=0.500 total time=  25.7s\n",
      "[CV 4/5; 90/240] START max_iter=100, penalty=l2, solver=saga, tol=1e-05.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 90/240] END max_iter=100, penalty=l2, solver=saga, tol=1e-05;, score=0.499 total time=  26.0s\n",
      "[CV 5/5; 90/240] START max_iter=100, penalty=l2, solver=saga, tol=1e-05.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 90/240] END max_iter=100, penalty=l2, solver=saga, tol=1e-05;, score=0.500 total time=  26.4s\n",
      "[CV 1/5; 91/240] START max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.001\n",
      "[CV 1/5; 91/240] END max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 2/5; 91/240] START max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.001\n",
      "[CV 2/5; 91/240] END max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.001;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 91/240] START max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.001\n",
      "[CV 3/5; 91/240] END max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 4/5; 91/240] START max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.001\n",
      "[CV 4/5; 91/240] END max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 5/5; 91/240] START max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 91/240] END max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 1/5; 92/240] START max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.0001\n",
      "[CV 1/5; 92/240] END max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 2/5; 92/240] START max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.0001\n",
      "[CV 2/5; 92/240] END max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 3/5; 92/240] START max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 92/240] END max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 4/5; 92/240] START max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.0001\n",
      "[CV 4/5; 92/240] END max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 5/5; 92/240] START max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.0001\n",
      "[CV 5/5; 92/240] END max_iter=100, penalty=elasticnet, solver=newton-cg, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 1/5; 93/240] START max_iter=100, penalty=elasticnet, solver=newton-cg, tol=1e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV 1/5; 93/240] END max_iter=100, penalty=elasticnet, solver=newton-cg, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 2/5; 93/240] START max_iter=100, penalty=elasticnet, solver=newton-cg, tol=1e-05\n",
      "[CV 2/5; 93/240] END max_iter=100, penalty=elasticnet, solver=newton-cg, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 3/5; 93/240] START max_iter=100, penalty=elasticnet, solver=newton-cg, tol=1e-05\n",
      "[CV 3/5; 93/240] END max_iter=100, penalty=elasticnet, solver=newton-cg, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 4/5; 93/240] START max_iter=100, penalty=elasticnet, solver=newton-cg, tol=1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 93/240] END max_iter=100, penalty=elasticnet, solver=newton-cg, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 5/5; 93/240] START max_iter=100, penalty=elasticnet, solver=newton-cg, tol=1e-05\n",
      "[CV 5/5; 93/240] END max_iter=100, penalty=elasticnet, solver=newton-cg, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 1/5; 94/240] START max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.001\n",
      "[CV 1/5; 94/240] END max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.001;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 94/240] START max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.001\n",
      "[CV 2/5; 94/240] END max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 3/5; 94/240] START max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.001\n",
      "[CV 3/5; 94/240] END max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 4/5; 94/240] START max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.001\n",
      "[CV 4/5; 94/240] END max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 5/5; 94/240] START max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.001"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV 5/5; 94/240] END max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 1/5; 95/240] START max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.0001\n",
      "[CV 1/5; 95/240] END max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 2/5; 95/240] START max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.0001\n",
      "[CV 2/5; 95/240] END max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 3/5; 95/240] START max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 95/240] END max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 4/5; 95/240] START max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.0001\n",
      "[CV 4/5; 95/240] END max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 5/5; 95/240] START max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.0001\n",
      "[CV 5/5; 95/240] END max_iter=100, penalty=elasticnet, solver=lbfgs, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 1/5; 96/240] START max_iter=100, penalty=elasticnet, solver=lbfgs, tol=1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 96/240] END max_iter=100, penalty=elasticnet, solver=lbfgs, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 2/5; 96/240] START max_iter=100, penalty=elasticnet, solver=lbfgs, tol=1e-05\n",
      "[CV 2/5; 96/240] END max_iter=100, penalty=elasticnet, solver=lbfgs, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 3/5; 96/240] START max_iter=100, penalty=elasticnet, solver=lbfgs, tol=1e-05\n",
      "[CV 3/5; 96/240] END max_iter=100, penalty=elasticnet, solver=lbfgs, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 4/5; 96/240] START max_iter=100, penalty=elasticnet, solver=lbfgs, tol=1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 96/240] END max_iter=100, penalty=elasticnet, solver=lbfgs, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 5/5; 96/240] START max_iter=100, penalty=elasticnet, solver=lbfgs, tol=1e-05\n",
      "[CV 5/5; 96/240] END max_iter=100, penalty=elasticnet, solver=lbfgs, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 1/5; 97/240] START max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.001\n",
      "[CV 1/5; 97/240] END max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.001;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 97/240] START max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.001\n",
      "[CV 2/5; 97/240] END max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 3/5; 97/240] START max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.001\n",
      "[CV 3/5; 97/240] END max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 4/5; 97/240] START max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.001\n",
      "[CV 4/5; 97/240] END max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 5/5; 97/240] START max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 97/240] END max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 1/5; 98/240] START max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.0001\n",
      "[CV 1/5; 98/240] END max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 2/5; 98/240] START max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.0001\n",
      "[CV 2/5; 98/240] END max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 3/5; 98/240] START max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 98/240] END max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 4/5; 98/240] START max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.0001\n",
      "[CV 4/5; 98/240] END max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 5/5; 98/240] START max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.0001\n",
      "[CV 5/5; 98/240] END max_iter=100, penalty=elasticnet, solver=liblinear, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 1/5; 99/240] START max_iter=100, penalty=elasticnet, solver=liblinear, tol=1e-05\n",
      "[CV 1/5; 99/240] END max_iter=100, penalty=elasticnet, solver=liblinear, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 2/5; 99/240] START max_iter=100, penalty=elasticnet, solver=liblinear, tol=1e-05\n",
      "[CV 2/5; 99/240] END max_iter=100, penalty=elasticnet, solver=liblinear, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 3/5; 99/240] START max_iter=100, penalty=elasticnet, solver=liblinear, tol=1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 99/240] END max_iter=100, penalty=elasticnet, solver=liblinear, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 4/5; 99/240] START max_iter=100, penalty=elasticnet, solver=liblinear, tol=1e-05\n",
      "[CV 4/5; 99/240] END max_iter=100, penalty=elasticnet, solver=liblinear, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 5/5; 99/240] START max_iter=100, penalty=elasticnet, solver=liblinear, tol=1e-05\n",
      "[CV 5/5; 99/240] END max_iter=100, penalty=elasticnet, solver=liblinear, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 1/5; 100/240] START max_iter=100, penalty=elasticnet, solver=sag, tol=0.001."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 450, in _check_solver\n",
      "    raise ValueError(\"Only 'saga' solver supports elasticnet penalty,\"\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV 1/5; 100/240] END max_iter=100, penalty=elasticnet, solver=sag, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 2/5; 100/240] START max_iter=100, penalty=elasticnet, solver=sag, tol=0.001.\n",
      "[CV 2/5; 100/240] END max_iter=100, penalty=elasticnet, solver=sag, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 3/5; 100/240] START max_iter=100, penalty=elasticnet, solver=sag, tol=0.001."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV 3/5; 100/240] END max_iter=100, penalty=elasticnet, solver=sag, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 4/5; 100/240] START max_iter=100, penalty=elasticnet, solver=sag, tol=0.001.\n",
      "[CV 4/5; 100/240] END max_iter=100, penalty=elasticnet, solver=sag, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 5/5; 100/240] START max_iter=100, penalty=elasticnet, solver=sag, tol=0.001.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 100/240] END max_iter=100, penalty=elasticnet, solver=sag, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 1/5; 101/240] START max_iter=100, penalty=elasticnet, solver=sag, tol=0.0001\n",
      "[CV 1/5; 101/240] END max_iter=100, penalty=elasticnet, solver=sag, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 2/5; 101/240] START max_iter=100, penalty=elasticnet, solver=sag, tol=0.0001\n",
      "[CV 2/5; 101/240] END max_iter=100, penalty=elasticnet, solver=sag, tol=0.0001;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 101/240] START max_iter=100, penalty=elasticnet, solver=sag, tol=0.0001\n",
      "[CV 3/5; 101/240] END max_iter=100, penalty=elasticnet, solver=sag, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 4/5; 101/240] START max_iter=100, penalty=elasticnet, solver=sag, tol=0.0001\n",
      "[CV 4/5; 101/240] END max_iter=100, penalty=elasticnet, solver=sag, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 5/5; 101/240] START max_iter=100, penalty=elasticnet, solver=sag, tol=0.0001\n",
      "[CV 5/5; 101/240] END max_iter=100, penalty=elasticnet, solver=sag, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 1/5; 102/240] START max_iter=100, penalty=elasticnet, solver=sag, tol=1e-05.\n",
      "[CV 1/5; 102/240] END max_iter=100, penalty=elasticnet, solver=sag, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 2/5; 102/240] START max_iter=100, penalty=elasticnet, solver=sag, tol=1e-05.\n",
      "[CV 2/5; 102/240] END max_iter=100, penalty=elasticnet, solver=sag, tol=1e-05;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 102/240] START max_iter=100, penalty=elasticnet, solver=sag, tol=1e-05.\n",
      "[CV 3/5; 102/240] END max_iter=100, penalty=elasticnet, solver=sag, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 4/5; 102/240] START max_iter=100, penalty=elasticnet, solver=sag, tol=1e-05.\n",
      "[CV 4/5; 102/240] END max_iter=100, penalty=elasticnet, solver=sag, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 5/5; 102/240] START max_iter=100, penalty=elasticnet, solver=sag, tol=1e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1314, in fit\n",
      "    raise ValueError(\"l1_ratio must be between 0 and 1;\"\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 102/240] END max_iter=100, penalty=elasticnet, solver=sag, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 1/5; 103/240] START max_iter=100, penalty=elasticnet, solver=saga, tol=0.001\n",
      "[CV 1/5; 103/240] END max_iter=100, penalty=elasticnet, solver=saga, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 2/5; 103/240] START max_iter=100, penalty=elasticnet, solver=saga, tol=0.001\n",
      "[CV 2/5; 103/240] END max_iter=100, penalty=elasticnet, solver=saga, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 3/5; 103/240] START max_iter=100, penalty=elasticnet, solver=saga, tol=0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1314, in fit\n",
      "    raise ValueError(\"l1_ratio must be between 0 and 1;\"\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1314, in fit\n",
      "    raise ValueError(\"l1_ratio must be between 0 and 1;\"\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1314, in fit\n",
      "    raise ValueError(\"l1_ratio must be between 0 and 1;\"\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 103/240] END max_iter=100, penalty=elasticnet, solver=saga, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 4/5; 103/240] START max_iter=100, penalty=elasticnet, solver=saga, tol=0.001\n",
      "[CV 4/5; 103/240] END max_iter=100, penalty=elasticnet, solver=saga, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 5/5; 103/240] START max_iter=100, penalty=elasticnet, solver=saga, tol=0.001\n",
      "[CV 5/5; 103/240] END max_iter=100, penalty=elasticnet, solver=saga, tol=0.001;, score=nan total time=   0.0s\n",
      "[CV 1/5; 104/240] START max_iter=100, penalty=elasticnet, solver=saga, tol=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1314, in fit\n",
      "    raise ValueError(\"l1_ratio must be between 0 and 1;\"\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1314, in fit\n",
      "    raise ValueError(\"l1_ratio must be between 0 and 1;\"\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1314, in fit\n",
      "    raise ValueError(\"l1_ratio must be between 0 and 1;\"\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 104/240] END max_iter=100, penalty=elasticnet, solver=saga, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 2/5; 104/240] START max_iter=100, penalty=elasticnet, solver=saga, tol=0.0001\n",
      "[CV 2/5; 104/240] END max_iter=100, penalty=elasticnet, solver=saga, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 3/5; 104/240] START max_iter=100, penalty=elasticnet, solver=saga, tol=0.0001\n",
      "[CV 3/5; 104/240] END max_iter=100, penalty=elasticnet, solver=saga, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 4/5; 104/240] START max_iter=100, penalty=elasticnet, solver=saga, tol=0.0001"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1314, in fit\n",
      "    raise ValueError(\"l1_ratio must be between 0 and 1;\"\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1314, in fit\n",
      "    raise ValueError(\"l1_ratio must be between 0 and 1;\"\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1314, in fit\n",
      "    raise ValueError(\"l1_ratio must be between 0 and 1;\"\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV 4/5; 104/240] END max_iter=100, penalty=elasticnet, solver=saga, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 5/5; 104/240] START max_iter=100, penalty=elasticnet, solver=saga, tol=0.0001\n",
      "[CV 5/5; 104/240] END max_iter=100, penalty=elasticnet, solver=saga, tol=0.0001;, score=nan total time=   0.0s\n",
      "[CV 1/5; 105/240] START max_iter=100, penalty=elasticnet, solver=saga, tol=1e-05\n",
      "[CV 1/5; 105/240] END max_iter=100, penalty=elasticnet, solver=saga, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 2/5; 105/240] START max_iter=100, penalty=elasticnet, solver=saga, tol=1e-05\n",
      "[CV 2/5; 105/240] END max_iter=100, penalty=elasticnet, solver=saga, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 3/5; 105/240] START max_iter=100, penalty=elasticnet, solver=saga, tol=1e-05\n",
      "[CV 3/5; 105/240] END max_iter=100, penalty=elasticnet, solver=saga, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 4/5; 105/240] START max_iter=100, penalty=elasticnet, solver=saga, tol=1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1314, in fit\n",
      "    raise ValueError(\"l1_ratio must be between 0 and 1;\"\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1314, in fit\n",
      "    raise ValueError(\"l1_ratio must be between 0 and 1;\"\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1314, in fit\n",
      "    raise ValueError(\"l1_ratio must be between 0 and 1;\"\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1314, in fit\n",
      "    raise ValueError(\"l1_ratio must be between 0 and 1;\"\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1314, in fit\n",
      "    raise ValueError(\"l1_ratio must be between 0 and 1;\"\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 105/240] END max_iter=100, penalty=elasticnet, solver=saga, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 5/5; 105/240] START max_iter=100, penalty=elasticnet, solver=saga, tol=1e-05\n",
      "[CV 5/5; 105/240] END max_iter=100, penalty=elasticnet, solver=saga, tol=1e-05;, score=nan total time=   0.0s\n",
      "[CV 1/5; 106/240] START max_iter=100, penalty=none, solver=newton-cg, tol=0.001.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"newton-cg failed to converge. Increase the \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 106/240] END max_iter=100, penalty=none, solver=newton-cg, tol=0.001;, score=0.497 total time= 5.0min\n",
      "[CV 2/5; 106/240] START max_iter=100, penalty=none, solver=newton-cg, tol=0.001.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"newton-cg failed to converge. Increase the \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 106/240] END max_iter=100, penalty=none, solver=newton-cg, tol=0.001;, score=0.500 total time= 5.0min\n",
      "[CV 3/5; 106/240] START max_iter=100, penalty=none, solver=newton-cg, tol=0.001.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"newton-cg failed to converge. Increase the \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 106/240] END max_iter=100, penalty=none, solver=newton-cg, tol=0.001;, score=0.499 total time= 4.9min\n",
      "[CV 4/5; 106/240] START max_iter=100, penalty=none, solver=newton-cg, tol=0.001.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"newton-cg failed to converge. Increase the \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 106/240] END max_iter=100, penalty=none, solver=newton-cg, tol=0.001;, score=0.499 total time= 4.7min\n",
      "[CV 5/5; 106/240] START max_iter=100, penalty=none, solver=newton-cg, tol=0.001.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"newton-cg failed to converge. Increase the \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 106/240] END max_iter=100, penalty=none, solver=newton-cg, tol=0.001;, score=0.500 total time= 4.9min\n",
      "[CV 1/5; 107/240] START max_iter=100, penalty=none, solver=newton-cg, tol=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"newton-cg failed to converge. Increase the \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 107/240] END max_iter=100, penalty=none, solver=newton-cg, tol=0.0001;, score=0.497 total time= 4.4min\n",
      "[CV 2/5; 107/240] START max_iter=100, penalty=none, solver=newton-cg, tol=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"newton-cg failed to converge. Increase the \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 107/240] END max_iter=100, penalty=none, solver=newton-cg, tol=0.0001;, score=0.500 total time= 3.4min\n",
      "[CV 3/5; 107/240] START max_iter=100, penalty=none, solver=newton-cg, tol=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"newton-cg failed to converge. Increase the \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 107/240] END max_iter=100, penalty=none, solver=newton-cg, tol=0.0001;, score=0.499 total time= 3.3min\n",
      "[CV 4/5; 107/240] START max_iter=100, penalty=none, solver=newton-cg, tol=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"newton-cg failed to converge. Increase the \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 107/240] END max_iter=100, penalty=none, solver=newton-cg, tol=0.0001;, score=0.499 total time= 3.1min\n",
      "[CV 5/5; 107/240] START max_iter=100, penalty=none, solver=newton-cg, tol=0.0001\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "parameters = {  'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
    "                'tol': [1e-3, 1e-4, 1e-5],\n",
    "                'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "                'max_iter': [50, 100, 150, 200]\n",
    "                 }\n",
    "\n",
    "model = LogisticRegression()\n",
    "\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=parameters, verbose=10, scoring=\"balanced_accuracy\")\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ceab849",
   "metadata": {},
   "source": [
    "Logistic regression didn't have good result on the dataset. It doesn't converge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "14ae7a68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(max_iter=200, penalty='l2', solver='lbfgs', tol=0.0001)\n",
    "model.fit(X_train, y_train)\n",
    "predicted = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54596e7",
   "metadata": {},
   "source": [
    "As we are not getting the wanted result let's check the `learning curve`.\n",
    "\n",
    "We will check it for KNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7f44a728",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-43bacc7f4e84>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKNeighborsClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mleaf_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'uniform'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlearning_curve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlearning_curve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'balanced_accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m__repr__\u001b[1;34m(self, N_CHAR_MAX)\u001b[0m\n\u001b[0;32m    258\u001b[0m             n_max_elements_to_show=N_MAX_ELEMENTS_TO_SHOW)\n\u001b[0;32m    259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 260\u001b[1;33m         \u001b[0mrepr_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    261\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m         \u001b[1;31m# Use bruteforce ellipsis when there are a lot of non-blank characters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\pprint.py\u001b[0m in \u001b[0;36mpformat\u001b[1;34m(self, object)\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m         \u001b[0msio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_StringIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_format\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    154\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0msio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\pprint.py\u001b[0m in \u001b[0;36m_format\u001b[1;34m(self, object, stream, indent, allowance, context, level)\u001b[0m\n\u001b[0;32m    168\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_readable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 170\u001b[1;33m         \u001b[0mrep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    171\u001b[0m         \u001b[0mmax_width\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_width\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mindent\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mallowance\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrep\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mmax_width\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\pprint.py\u001b[0m in \u001b[0;36m_repr\u001b[1;34m(self, object, context, level)\u001b[0m\n\u001b[0;32m    402\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    403\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 404\u001b[1;33m         repr, readable, recursive = self.format(object, context.copy(),\n\u001b[0m\u001b[0;32m    405\u001b[0m                                                 self._depth, level)\n\u001b[0;32m    406\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mreadable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_pprint.py\u001b[0m in \u001b[0;36mformat\u001b[1;34m(self, object, context, maxlevels, level)\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxlevels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 180\u001b[1;33m         return _safe_repr(object, context, maxlevels, level,\n\u001b[0m\u001b[0;32m    181\u001b[0m                           changed_only=self._changed_only)\n\u001b[0;32m    182\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_pprint.py\u001b[0m in \u001b[0;36m_safe_repr\u001b[1;34m(object, context, maxlevels, level, changed_only)\u001b[0m\n\u001b[0;32m    423\u001b[0m         \u001b[0mrecursive\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    424\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mchanged_only\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 425\u001b[1;33m             \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_changed_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    426\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    427\u001b[0m             \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_pprint.py\u001b[0m in \u001b[0;36m_changed_params\u001b[1;34m(estimator)\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 112\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mhas_changed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_pprint.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 112\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mhas_changed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_pprint.py\u001b[0m in \u001b[0;36mhas_changed\u001b[1;34m(k, v)\u001b[0m\n\u001b[0;32m     98\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minit_params\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# happens if k is part of a **kwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0minit_params\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0minspect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_empty\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# k has no default value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m         \u001b[1;31m# try to avoid calling repr on nested estimators\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "from yellowbrick.model_selection import learning_curve\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=5, leaf_size=20, weights='uniform')\n",
    "print(learning_curve(model, X_train, y_train, cv=10, scoring='accuracy'))\n",
    "print(learning_curve(model, X_train, y_train, cv=10, scoring='balanced_accuracy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0bffc0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(100, input_dim=931, activation='relu'))\n",
    "model.add(Dense(60, activation='relu'))\n",
    "model.add(Dense(45, activation='relu'))\n",
    "model.add(Dense(30, activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1de204c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "343241c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ohe = OneHotEncoder()\n",
    "\n",
    "y_train = np.asarray(y_train).reshape((-1,1))\n",
    "y_test = np.asarray(y_test).reshape((-1,1))\n",
    "\n",
    "y_train = ohe.fit_transform(y_train).toarray()\n",
    "y_test = ohe.fit_transform(y_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "67317bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "504/504 [==============================] - 2s 1ms/step - loss: 10.8064 - accuracy: 0.7126\n",
      "Epoch 2/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.6040 - accuracy: 0.7409\n",
      "Epoch 3/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5759 - accuracy: 0.7462\n",
      "Epoch 4/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5683 - accuracy: 0.7465\n",
      "Epoch 5/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5687 - accuracy: 0.7444\n",
      "Epoch 6/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5685 - accuracy: 0.7444\n",
      "Epoch 7/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5676 - accuracy: 0.7452\n",
      "Epoch 8/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5661 - accuracy: 0.7466\n",
      "Epoch 9/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5725 - accuracy: 0.7406\n",
      "Epoch 10/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5675 - accuracy: 0.7453\n",
      "Epoch 11/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5711 - accuracy: 0.7418\n",
      "Epoch 12/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5735 - accuracy: 0.7396\n",
      "Epoch 13/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5666 - accuracy: 0.7461\n",
      "Epoch 14/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5644 - accuracy: 0.7482\n",
      "Epoch 15/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5702 - accuracy: 0.7427\n",
      "Epoch 16/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5654 - accuracy: 0.7472\n",
      "Epoch 17/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5713 - accuracy: 0.7416\n",
      "Epoch 18/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5674 - accuracy: 0.7453\n",
      "Epoch 19/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5662 - accuracy: 0.7465\n",
      "Epoch 20/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5679 - accuracy: 0.7449\n",
      "Epoch 21/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5675 - accuracy: 0.7453\n",
      "Epoch 22/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5679 - accuracy: 0.7449\n",
      "Epoch 23/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5688 - accuracy: 0.7440\n",
      "Epoch 24/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5714 - accuracy: 0.7416\n",
      "Epoch 25/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5665 - accuracy: 0.7462\n",
      "Epoch 26/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5711 - accuracy: 0.7419\n",
      "Epoch 27/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5718 - accuracy: 0.7412\n",
      "Epoch 28/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5686 - accuracy: 0.7443\n",
      "Epoch 29/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5687 - accuracy: 0.7441\n",
      "Epoch 30/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5680 - accuracy: 0.7448\n",
      "Epoch 31/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5695 - accuracy: 0.7434\n",
      "Epoch 32/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5695 - accuracy: 0.7434\n",
      "Epoch 33/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5687 - accuracy: 0.7442\n",
      "Epoch 34/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5677 - accuracy: 0.7451\n",
      "Epoch 35/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5672 - accuracy: 0.7456\n",
      "Epoch 36/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5717 - accuracy: 0.7414\n",
      "Epoch 37/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5664 - accuracy: 0.7462\n",
      "Epoch 38/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5687 - accuracy: 0.7441\n",
      "Epoch 39/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5683 - accuracy: 0.7445\n",
      "Epoch 40/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5701 - accuracy: 0.7429\n",
      "Epoch 41/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5659 - accuracy: 0.7468\n",
      "Epoch 42/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5697 - accuracy: 0.7432\n",
      "Epoch 43/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5668 - accuracy: 0.7460\n",
      "Epoch 44/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5703 - accuracy: 0.7426\n",
      "Epoch 45/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5676 - accuracy: 0.7452\n",
      "Epoch 46/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5685 - accuracy: 0.7443\n",
      "Epoch 47/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5721 - accuracy: 0.7409\n",
      "Epoch 48/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5693 - accuracy: 0.7435\n",
      "Epoch 49/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5658 - accuracy: 0.7469\n",
      "Epoch 50/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5694 - accuracy: 0.7434\n",
      "Epoch 51/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5692 - accuracy: 0.7437\n",
      "Epoch 52/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5708 - accuracy: 0.7422\n",
      "Epoch 53/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5701 - accuracy: 0.7428\n",
      "Epoch 54/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5703 - accuracy: 0.7426\n",
      "Epoch 55/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5666 - accuracy: 0.7461\n",
      "Epoch 56/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5690 - accuracy: 0.7438\n",
      "Epoch 57/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5657 - accuracy: 0.7469\n",
      "Epoch 58/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5757 - accuracy: 0.7375\n",
      "Epoch 59/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5683 - accuracy: 0.7445\n",
      "Epoch 60/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5717 - accuracy: 0.7413\n",
      "Epoch 61/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5696 - accuracy: 0.7433\n",
      "Epoch 62/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5699 - accuracy: 0.7430\n",
      "Epoch 63/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5705 - accuracy: 0.7424\n",
      "Epoch 64/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5717 - accuracy: 0.7413\n",
      "Epoch 65/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5721 - accuracy: 0.7409\n",
      "Epoch 66/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5689 - accuracy: 0.7439\n",
      "Epoch 67/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5660 - accuracy: 0.7466\n",
      "Epoch 68/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5640 - accuracy: 0.7485\n",
      "Epoch 69/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5671 - accuracy: 0.7456\n",
      "Epoch 70/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5690 - accuracy: 0.7438\n",
      "Epoch 71/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5719 - accuracy: 0.7411\n",
      "Epoch 72/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5708 - accuracy: 0.7421\n",
      "Epoch 73/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5720 - accuracy: 0.7410\n",
      "Epoch 74/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5685 - accuracy: 0.7444\n",
      "Epoch 75/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5708 - accuracy: 0.7421\n",
      "Epoch 76/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5654 - accuracy: 0.7472\n",
      "Epoch 77/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5708 - accuracy: 0.7422\n",
      "Epoch 78/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5680 - accuracy: 0.7448\n",
      "Epoch 79/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5725 - accuracy: 0.7405\n",
      "Epoch 80/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5656 - accuracy: 0.7470\n",
      "Epoch 81/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5730 - accuracy: 0.7401: 0s - loss: 0.5742 - accuracy\n",
      "Epoch 82/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5674 - accuracy: 0.7453\n",
      "Epoch 83/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5690 - accuracy: 0.7438\n",
      "Epoch 84/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5656 - accuracy: 0.7470\n",
      "Epoch 85/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5711 - accuracy: 0.7419\n",
      "Epoch 86/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5710 - accuracy: 0.7419\n",
      "Epoch 87/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5641 - accuracy: 0.7484\n",
      "Epoch 88/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5686 - accuracy: 0.7442\n",
      "Epoch 89/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5741 - accuracy: 0.7390\n",
      "Epoch 90/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5700 - accuracy: 0.7429\n",
      "Epoch 91/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5718 - accuracy: 0.7412\n",
      "Epoch 92/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5716 - accuracy: 0.7414\n",
      "Epoch 93/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5687 - accuracy: 0.7441\n",
      "Epoch 94/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5691 - accuracy: 0.7438\n",
      "Epoch 95/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5735 - accuracy: 0.7396\n",
      "Epoch 96/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5697 - accuracy: 0.7432\n",
      "Epoch 97/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5739 - accuracy: 0.7392\n",
      "Epoch 98/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5716 - accuracy: 0.7414\n",
      "Epoch 99/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5669 - accuracy: 0.7458\n",
      "Epoch 100/100\n",
      "504/504 [==============================] - 1s 1ms/step - loss: 0.5677 - accuracy: 0.7451\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=100, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6cb8635d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>queries</th>\n",
       "      <th>apps</th>\n",
       "      <th>games</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[216, 359, 12329, 3, 45, 4002, 2066, 32, 3931,...</td>\n",
       "      <td>[4, 4, 25, 7, 30, 58, 16, 19, 17, 21, 10, 10, ...</td>\n",
       "      <td>[9151, 208]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[]</td>\n",
       "      <td>[129, 71, 9, 8, 11, 25, 18, 58, 6, 16, 125, 12...</td>\n",
       "      <td>[460, 4939, 14, 232, 6387, 1758, 5834, 3, 2]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[23463, 18831]</td>\n",
       "      <td>[9, 174, 65, 8, 63, 97, 62, 103, 61, 116, 59, ...</td>\n",
       "      <td>[448, 723, 267, 9064, 10634, 166, 782, 224, 27...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1634, 3609, 654]</td>\n",
       "      <td>[99, 73, 9, 8, 59, 37, 131, 3, 89, 6, 24, 16, ...</td>\n",
       "      <td>[78, 2607, 478, 435, 9, 192]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[11064, 227, 623, 1301, 43999, 35411, 2492, 11...</td>\n",
       "      <td>[9, 8, 17, 54, 3, 25, 22, 6, 21, 7, 14, 5, 817...</td>\n",
       "      <td>[1702, 1, 53]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             queries  \\\n",
       "0  [216, 359, 12329, 3, 45, 4002, 2066, 32, 3931,...   \n",
       "1                                                 []   \n",
       "2                                     [23463, 18831]   \n",
       "3                                  [1634, 3609, 654]   \n",
       "4  [11064, 227, 623, 1301, 43999, 35411, 2492, 11...   \n",
       "\n",
       "                                                apps  \\\n",
       "0  [4, 4, 25, 7, 30, 58, 16, 19, 17, 21, 10, 10, ...   \n",
       "1  [129, 71, 9, 8, 11, 25, 18, 58, 6, 16, 125, 12...   \n",
       "2  [9, 174, 65, 8, 63, 97, 62, 103, 61, 116, 59, ...   \n",
       "3  [99, 73, 9, 8, 59, 37, 131, 3, 89, 6, 24, 16, ...   \n",
       "4  [9, 8, 17, 54, 3, 25, 22, 6, 21, 7, 14, 5, 817...   \n",
       "\n",
       "                                               games  gender  \n",
       "0                                        [9151, 208]       1  \n",
       "1       [460, 4939, 14, 232, 6387, 1758, 5834, 3, 2]       0  \n",
       "2  [448, 723, 267, 9064, 10634, 166, 782, 224, 27...       1  \n",
       "3                       [78, 2607, 478, 435, 9, 192]       1  \n",
       "4                                      [1702, 1, 53]       1  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet(DATA_DIR, engine=\"pyarrow\")\n",
    "df[\"birth_year\"] = df[\"birth_year\"].astype(np.uint)\n",
    "valid_birth_year = df[\"birth_year\"][df[\"birth_year\"] != 0]\n",
    "mean_birth_year = round(valid_birth_year.mean())\n",
    "df[\"birth_year\"] = df[\"birth_year\"].replace(0, mean_birth_year)\n",
    "df[\"gender\"] = df[\"gender\"].replace({'M': 1, 'F': 0})\n",
    "df.drop(columns=['birth_year'], inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "02772ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df.pop('apps').apply(pd.Series), df], axis=1)\n",
    "df = pd.concat([df.pop('games').apply(pd.Series), df], axis=1)\n",
    "df = pd.concat([df.pop('queries').apply(pd.Series), df], axis=1)\n",
    "df.fillna(0, inplace=True)\n",
    "\n",
    "X, y =  df.drop(columns=[\"gender\"]), df[\"gender\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2835b4d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32216, 930)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "db72e880",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(100, input_dim=930, activation='relu'))\n",
    "model.add(Dense(60, activation='relu'))\n",
    "model.add(Dense(45, activation='relu'))\n",
    "model.add(Dense(30, activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e3211fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder()\n",
    "\n",
    "y_train = np.asarray(y_train).reshape((-1,1))\n",
    "y_test = np.asarray(y_test).reshape((-1,1))\n",
    "\n",
    "y_train = ohe.fit_transform(y_train).toarray()\n",
    "y_test = ohe.fit_transform(y_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b7b82306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "338/338 [==============================] - 2s 2ms/step - loss: 25.7407 - accuracy: 0.6838 - val_loss: 0.6485 - val_accuracy: 0.7368\n",
      "Epoch 2/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.6222 - accuracy: 0.7432 - val_loss: 0.6089 - val_accuracy: 0.7369\n",
      "Epoch 3/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5889 - accuracy: 0.7503 - val_loss: 0.5943 - val_accuracy: 0.7369\n",
      "Epoch 4/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5735 - accuracy: 0.7485 - val_loss: 0.5882 - val_accuracy: 0.7369\n",
      "Epoch 5/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5721 - accuracy: 0.7433 - val_loss: 0.5863 - val_accuracy: 0.7369\n",
      "Epoch 6/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5668 - accuracy: 0.7467 - val_loss: 0.5858 - val_accuracy: 0.7369\n",
      "Epoch 7/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5663 - accuracy: 0.7466 - val_loss: 0.5859 - val_accuracy: 0.7369\n",
      "Epoch 8/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5662 - accuracy: 0.7465 - val_loss: 0.5859 - val_accuracy: 0.7369\n",
      "Epoch 9/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5602 - accuracy: 0.7520 - val_loss: 0.5860 - val_accuracy: 0.7369\n",
      "Epoch 10/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5650 - accuracy: 0.7476 - val_loss: 0.5859 - val_accuracy: 0.7369\n",
      "Epoch 11/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5612 - accuracy: 0.7511 - val_loss: 0.5859 - val_accuracy: 0.7369\n",
      "Epoch 12/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5649 - accuracy: 0.7476 - val_loss: 0.5860 - val_accuracy: 0.7369\n",
      "Epoch 13/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5684 - accuracy: 0.7444 - val_loss: 0.5860 - val_accuracy: 0.7369\n",
      "Epoch 14/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5652 - accuracy: 0.7473 - val_loss: 0.5859 - val_accuracy: 0.7369\n",
      "Epoch 15/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5642 - accuracy: 0.7483 - val_loss: 0.5859 - val_accuracy: 0.7369\n",
      "Epoch 16/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5656 - accuracy: 0.7470 - val_loss: 0.5859 - val_accuracy: 0.7369\n",
      "Epoch 17/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5713 - accuracy: 0.7419 - val_loss: 0.5842 - val_accuracy: 0.7370\n",
      "Epoch 18/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5636 - accuracy: 0.7489 - val_loss: 0.5839 - val_accuracy: 0.7370\n",
      "Epoch 19/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5666 - accuracy: 0.7461 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 20/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5685 - accuracy: 0.7443 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 21/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5665 - accuracy: 0.7462 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 22/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5651 - accuracy: 0.7475 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 23/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5633 - accuracy: 0.7491 - val_loss: 0.5839 - val_accuracy: 0.7370\n",
      "Epoch 24/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5614 - accuracy: 0.7509 - val_loss: 0.5839 - val_accuracy: 0.7370\n",
      "Epoch 25/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5675 - accuracy: 0.7453 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 26/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5644 - accuracy: 0.7482 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 27/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5689 - accuracy: 0.7440 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 28/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5654 - accuracy: 0.7472 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 29/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5670 - accuracy: 0.7457 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 30/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5736 - accuracy: 0.7396 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 31/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5664 - accuracy: 0.7463 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 32/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5688 - accuracy: 0.7440 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 33/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5576 - accuracy: 0.7543 - val_loss: 0.5839 - val_accuracy: 0.7370\n",
      "Epoch 34/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5572 - accuracy: 0.7548 - val_loss: 0.5839 - val_accuracy: 0.7370\n",
      "Epoch 35/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5634 - accuracy: 0.7491 - val_loss: 0.5839 - val_accuracy: 0.7370\n",
      "Epoch 36/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5717 - accuracy: 0.7413 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 37/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5657 - accuracy: 0.7469 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 38/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5664 - accuracy: 0.7463 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 39/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5639 - accuracy: 0.7486 - val_loss: 0.5839 - val_accuracy: 0.7370\n",
      "Epoch 40/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5659 - accuracy: 0.7467 - val_loss: 0.5839 - val_accuracy: 0.7370\n",
      "Epoch 41/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5711 - accuracy: 0.7420 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 42/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5642 - accuracy: 0.7483 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 43/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5651 - accuracy: 0.7475 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 44/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5653 - accuracy: 0.7473 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 45/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5619 - accuracy: 0.7504 - val_loss: 0.5839 - val_accuracy: 0.7370\n",
      "Epoch 46/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5642 - accuracy: 0.7483 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 47/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5638 - accuracy: 0.7487 - val_loss: 0.5839 - val_accuracy: 0.7370\n",
      "Epoch 48/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5675 - accuracy: 0.7452 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 49/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5677 - accuracy: 0.7451 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 50/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5642 - accuracy: 0.7483 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 51/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5656 - accuracy: 0.7470 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 52/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5654 - accuracy: 0.7472 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 53/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.5656 - accuracy: 0.7470 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 54/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5665 - accuracy: 0.7462 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 55/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5694 - accuracy: 0.7435 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 56/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5689 - accuracy: 0.7440 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 57/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5655 - accuracy: 0.7471 - val_loss: 0.5840 - val_accuracy: 0.7370\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5628 - accuracy: 0.7496 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 59/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5699 - accuracy: 0.7431 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 60/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5691 - accuracy: 0.7437 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 61/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5645 - accuracy: 0.7481 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 62/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5637 - accuracy: 0.7488 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 63/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5680 - accuracy: 0.7448 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 64/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5714 - accuracy: 0.7417 - val_loss: 0.5841 - val_accuracy: 0.7370\n",
      "Epoch 65/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5657 - accuracy: 0.7469 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 66/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5657 - accuracy: 0.7469 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 67/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.5672 - accuracy: 0.7456 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 68/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.5656 - accuracy: 0.7470 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 69/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5619 - accuracy: 0.7504 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 70/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5662 - accuracy: 0.7465 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 71/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5643 - accuracy: 0.7483 - val_loss: 0.5839 - val_accuracy: 0.7370\n",
      "Epoch 72/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5712 - accuracy: 0.7418 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 73/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5663 - accuracy: 0.7464 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 74/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5620 - accuracy: 0.7503 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 75/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5667 - accuracy: 0.7460 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 76/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5676 - accuracy: 0.7452 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 77/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5666 - accuracy: 0.7461 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 78/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5661 - accuracy: 0.7465 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 79/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5683 - accuracy: 0.7445 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 80/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5700 - accuracy: 0.7429 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 81/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5662 - accuracy: 0.7465 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 82/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5659 - accuracy: 0.7467 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 83/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5655 - accuracy: 0.7471 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 84/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5628 - accuracy: 0.7497 - val_loss: 0.5839 - val_accuracy: 0.7370\n",
      "Epoch 85/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5644 - accuracy: 0.7482 - val_loss: 0.5839 - val_accuracy: 0.7370\n",
      "Epoch 86/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5663 - accuracy: 0.7464 - val_loss: 0.5839 - val_accuracy: 0.7370\n",
      "Epoch 87/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.5621 - accuracy: 0.7503 - val_loss: 0.5839 - val_accuracy: 0.7370\n",
      "Epoch 88/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5667 - accuracy: 0.7460 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 89/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5678 - accuracy: 0.7450 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 90/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.5657 - accuracy: 0.7469 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 91/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5645 - accuracy: 0.7481 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 92/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5679 - accuracy: 0.7449 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 93/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.5665 - accuracy: 0.7462 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 94/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.5692 - accuracy: 0.7437 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 95/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5638 - accuracy: 0.7487 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 96/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5670 - accuracy: 0.7458 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 97/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5649 - accuracy: 0.7476 - val_loss: 0.5839 - val_accuracy: 0.7370\n",
      "Epoch 98/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5659 - accuracy: 0.7467 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 99/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.5669 - accuracy: 0.7458 - val_loss: 0.5840 - val_accuracy: 0.7370\n",
      "Epoch 100/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5606 - accuracy: 0.7517 - val_loss: 0.5839 - val_accuracy: 0.7370\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, validation_split=0.33, epochs=100, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "33dfe728",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "97f3f2f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1a07d8c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>apps</th>\n",
       "      <th>games</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[4, 4, 25, 7, 30, 58, 16, 19, 17, 21, 10, 10, ...</td>\n",
       "      <td>[9151, 208]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[129, 71, 9, 8, 11, 25, 18, 58, 6, 16, 125, 12...</td>\n",
       "      <td>[460, 4939, 14, 232, 6387, 1758, 5834, 3, 2]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[9, 174, 65, 8, 63, 97, 62, 103, 61, 116, 59, ...</td>\n",
       "      <td>[448, 723, 267, 9064, 10634, 166, 782, 224, 27...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[99, 73, 9, 8, 59, 37, 131, 3, 89, 6, 24, 16, ...</td>\n",
       "      <td>[78, 2607, 478, 435, 9, 192]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[9, 8, 17, 54, 3, 25, 22, 6, 21, 7, 14, 5, 817...</td>\n",
       "      <td>[1702, 1, 53]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                apps  \\\n",
       "0  [4, 4, 25, 7, 30, 58, 16, 19, 17, 21, 10, 10, ...   \n",
       "1  [129, 71, 9, 8, 11, 25, 18, 58, 6, 16, 125, 12...   \n",
       "2  [9, 174, 65, 8, 63, 97, 62, 103, 61, 116, 59, ...   \n",
       "3  [99, 73, 9, 8, 59, 37, 131, 3, 89, 6, 24, 16, ...   \n",
       "4  [9, 8, 17, 54, 3, 25, 22, 6, 21, 7, 14, 5, 817...   \n",
       "\n",
       "                                               games  gender  \n",
       "0                                        [9151, 208]       1  \n",
       "1       [460, 4939, 14, 232, 6387, 1758, 5834, 3, 2]       0  \n",
       "2  [448, 723, 267, 9064, 10634, 166, 782, 224, 27...       1  \n",
       "3                       [78, 2607, 478, 435, 9, 192]       1  \n",
       "4                                      [1702, 1, 53]       1  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet(DATA_DIR, engine=\"pyarrow\")\n",
    "df[\"birth_year\"] = df[\"birth_year\"].astype(np.uint)\n",
    "valid_birth_year = df[\"birth_year\"][df[\"birth_year\"] != 0]\n",
    "mean_birth_year = round(valid_birth_year.mean())\n",
    "df[\"birth_year\"] = df[\"birth_year\"].replace(0, mean_birth_year)\n",
    "df[\"gender\"] = df[\"gender\"].replace({'M': 1, 'F': 0})\n",
    "df.drop(columns=['birth_year', 'queries'], inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "88c4a73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df.pop('apps').apply(pd.Series), df], axis=1)\n",
    "df = pd.concat([df.pop('games').apply(pd.Series), df], axis=1)\n",
    "df.fillna(0, inplace=True)\n",
    "\n",
    "X, y =  df.drop(columns=[\"gender\"]), df[\"gender\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c9671591",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(100, input_dim=834, activation='relu'))\n",
    "model.add(Dense(60, activation='relu'))\n",
    "model.add(Dense(45, activation='relu'))\n",
    "model.add(Dense(30, activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8dc3c8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder()\n",
    "\n",
    "y_train = np.asarray(y_train).reshape((-1,1))\n",
    "y_test = np.asarray(y_test).reshape((-1,1))\n",
    "\n",
    "y_train = ohe.fit_transform(y_train).toarray()\n",
    "y_test = ohe.fit_transform(y_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8f15b477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "338/338 [==============================] - 2s 2ms/step - loss: 28.8057 - accuracy: 0.6787 - val_loss: 0.9474 - val_accuracy: 0.7367\n",
      "Epoch 2/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.7826 - accuracy: 0.7343 - val_loss: 0.6396 - val_accuracy: 0.7371\n",
      "Epoch 3/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.7634 - accuracy: 0.7271 - val_loss: 0.7065 - val_accuracy: 0.7369\n",
      "Epoch 4/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.6757 - accuracy: 0.7304 - val_loss: 0.6433 - val_accuracy: 0.7369\n",
      "Epoch 5/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.6375 - accuracy: 0.7367 - val_loss: 0.7294 - val_accuracy: 0.7369\n",
      "Epoch 6/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.6136 - accuracy: 0.7345 - val_loss: 0.5884 - val_accuracy: 0.7366\n",
      "Epoch 7/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.6386 - accuracy: 0.7371 - val_loss: 0.6286 - val_accuracy: 0.7370\n",
      "Epoch 8/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.6176 - accuracy: 0.7410 - val_loss: 0.6603 - val_accuracy: 0.6810\n",
      "Epoch 9/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.6648 - accuracy: 0.7324 - val_loss: 0.6140 - val_accuracy: 0.7255\n",
      "Epoch 10/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5806 - accuracy: 0.7411 - val_loss: 1.0220 - val_accuracy: 0.5456\n",
      "Epoch 11/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.6374 - accuracy: 0.7344 - val_loss: 0.6814 - val_accuracy: 0.7369\n",
      "Epoch 12/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5931 - accuracy: 0.7449 - val_loss: 0.5968 - val_accuracy: 0.7314\n",
      "Epoch 13/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5811 - accuracy: 0.7423 - val_loss: 0.6049 - val_accuracy: 0.7149\n",
      "Epoch 14/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5807 - accuracy: 0.7418 - val_loss: 0.6300 - val_accuracy: 0.7369\n",
      "Epoch 15/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5794 - accuracy: 0.7447 - val_loss: 1.4932 - val_accuracy: 0.6118\n",
      "Epoch 16/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.6762 - accuracy: 0.7344 - val_loss: 0.5778 - val_accuracy: 0.7369\n",
      "Epoch 17/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.5970 - accuracy: 0.7453 - val_loss: 0.5764 - val_accuracy: 0.7370\n",
      "Epoch 18/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5726 - accuracy: 0.7407 - val_loss: 0.5766 - val_accuracy: 0.7370\n",
      "Epoch 19/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5696 - accuracy: 0.7433 - val_loss: 0.5765 - val_accuracy: 0.7370\n",
      "Epoch 20/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.5664 - accuracy: 0.7463 - val_loss: 0.5764 - val_accuracy: 0.7370\n",
      "Epoch 21/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5630 - accuracy: 0.7493 - val_loss: 0.5764 - val_accuracy: 0.7370\n",
      "Epoch 22/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5702 - accuracy: 0.7428 - val_loss: 0.5766 - val_accuracy: 0.7370\n",
      "Epoch 23/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5688 - accuracy: 0.7443 - val_loss: 0.5766 - val_accuracy: 0.7369\n",
      "Epoch 24/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5702 - accuracy: 0.7429 - val_loss: 0.5765 - val_accuracy: 0.7370\n",
      "Epoch 25/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5673 - accuracy: 0.7455 - val_loss: 0.5765 - val_accuracy: 0.7369\n",
      "Epoch 26/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5682 - accuracy: 0.7446 - val_loss: 0.5764 - val_accuracy: 0.7370\n",
      "Epoch 27/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5624 - accuracy: 0.7508 - val_loss: 0.5763 - val_accuracy: 0.7370\n",
      "Epoch 28/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5637 - accuracy: 0.7488 - val_loss: 0.5767 - val_accuracy: 0.7368\n",
      "Epoch 29/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.5636 - accuracy: 0.7490 - val_loss: 0.5763 - val_accuracy: 0.7370\n",
      "Epoch 30/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5677 - accuracy: 0.7451 - val_loss: 0.5765 - val_accuracy: 0.7370\n",
      "Epoch 31/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5655 - accuracy: 0.7471 - val_loss: 0.5764 - val_accuracy: 0.7370\n",
      "Epoch 32/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5666 - accuracy: 0.7461 - val_loss: 0.5764 - val_accuracy: 0.7370\n",
      "Epoch 33/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5697 - accuracy: 0.7432 - val_loss: 0.5765 - val_accuracy: 0.7370\n",
      "Epoch 34/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5670 - accuracy: 0.7458 - val_loss: 0.5765 - val_accuracy: 0.7370\n",
      "Epoch 35/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5665 - accuracy: 0.7462 - val_loss: 0.5763 - val_accuracy: 0.7370\n",
      "Epoch 36/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5652 - accuracy: 0.7474 - val_loss: 0.5763 - val_accuracy: 0.7370\n",
      "Epoch 37/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5641 - accuracy: 0.7484 - val_loss: 0.5763 - val_accuracy: 0.7370\n",
      "Epoch 38/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5637 - accuracy: 0.7488 - val_loss: 0.5763 - val_accuracy: 0.7370\n",
      "Epoch 39/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5667 - accuracy: 0.7460 - val_loss: 0.5764 - val_accuracy: 0.7370\n",
      "Epoch 40/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5624 - accuracy: 0.7500 - val_loss: 0.5763 - val_accuracy: 0.7370\n",
      "Epoch 41/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.5685 - accuracy: 0.7444 - val_loss: 0.5767 - val_accuracy: 0.7370\n",
      "Epoch 42/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5633 - accuracy: 0.7492 - val_loss: 0.5764 - val_accuracy: 0.7370\n",
      "Epoch 43/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5657 - accuracy: 0.7469 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 44/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5664 - accuracy: 0.7462 - val_loss: 0.5764 - val_accuracy: 0.7370\n",
      "Epoch 45/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.5696 - accuracy: 0.7433 - val_loss: 0.5767 - val_accuracy: 0.7370\n",
      "Epoch 46/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5640 - accuracy: 0.7485 - val_loss: 0.5763 - val_accuracy: 0.7370\n",
      "Epoch 47/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5740 - accuracy: 0.7391 - val_loss: 0.5768 - val_accuracy: 0.7370\n",
      "Epoch 48/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.5657 - accuracy: 0.7469 - val_loss: 0.5764 - val_accuracy: 0.7370\n",
      "Epoch 49/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5680 - accuracy: 0.7447 - val_loss: 0.5763 - val_accuracy: 0.7370\n",
      "Epoch 50/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5620 - accuracy: 0.7505 - val_loss: 0.5763 - val_accuracy: 0.7370\n",
      "Epoch 51/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5663 - accuracy: 0.7464 - val_loss: 0.5765 - val_accuracy: 0.7370\n",
      "Epoch 52/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5668 - accuracy: 0.7459 - val_loss: 0.5764 - val_accuracy: 0.7370\n",
      "Epoch 53/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5700 - accuracy: 0.7430 - val_loss: 0.5764 - val_accuracy: 0.7370\n",
      "Epoch 54/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5686 - accuracy: 0.7442 - val_loss: 0.5765 - val_accuracy: 0.7370\n",
      "Epoch 55/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5644 - accuracy: 0.7482 - val_loss: 0.5764 - val_accuracy: 0.7370\n",
      "Epoch 56/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5640 - accuracy: 0.7485 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 57/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5642 - accuracy: 0.7484 - val_loss: 0.5763 - val_accuracy: 0.7370\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5723 - accuracy: 0.7408 - val_loss: 0.5765 - val_accuracy: 0.7370\n",
      "Epoch 59/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5660 - accuracy: 0.7468 - val_loss: 0.5763 - val_accuracy: 0.7370\n",
      "Epoch 60/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.5642 - accuracy: 0.7484 - val_loss: 0.5763 - val_accuracy: 0.7370\n",
      "Epoch 61/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5711 - accuracy: 0.7418 - val_loss: 0.5769 - val_accuracy: 0.7370\n",
      "Epoch 62/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5686 - accuracy: 0.7444 - val_loss: 0.5765 - val_accuracy: 0.7370\n",
      "Epoch 63/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.5630 - accuracy: 0.7494 - val_loss: 0.5763 - val_accuracy: 0.7370\n",
      "Epoch 64/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.5651 - accuracy: 0.7475 - val_loss: 0.5763 - val_accuracy: 0.7370\n",
      "Epoch 65/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5699 - accuracy: 0.7430 - val_loss: 0.5765 - val_accuracy: 0.7370\n",
      "Epoch 66/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5657 - accuracy: 0.7469 - val_loss: 0.5764 - val_accuracy: 0.7370\n",
      "Epoch 67/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5677 - accuracy: 0.7451 - val_loss: 0.5764 - val_accuracy: 0.7370\n",
      "Epoch 68/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5656 - accuracy: 0.7477 - val_loss: 0.6131 - val_accuracy: 0.7365\n",
      "Epoch 69/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.5736 - accuracy: 0.7476 - val_loss: 0.5763 - val_accuracy: 0.7370\n",
      "Epoch 70/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5631 - accuracy: 0.7494 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 71/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5642 - accuracy: 0.7484 - val_loss: 0.5763 - val_accuracy: 0.7370\n",
      "Epoch 72/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5622 - accuracy: 0.7502 - val_loss: 0.5763 - val_accuracy: 0.7370\n",
      "Epoch 73/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5672 - accuracy: 0.7456 - val_loss: 0.5765 - val_accuracy: 0.7370\n",
      "Epoch 74/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5686 - accuracy: 0.7442 - val_loss: 0.5766 - val_accuracy: 0.7370\n",
      "Epoch 75/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5626 - accuracy: 0.7498 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 76/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5691 - accuracy: 0.7438 - val_loss: 0.5764 - val_accuracy: 0.7370\n",
      "Epoch 77/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5710 - accuracy: 0.7421 - val_loss: 0.5764 - val_accuracy: 0.7370\n",
      "Epoch 78/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5632 - accuracy: 0.7492 - val_loss: 0.5763 - val_accuracy: 0.7370\n",
      "Epoch 79/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5650 - accuracy: 0.7477 - val_loss: 0.5763 - val_accuracy: 0.7370\n",
      "Epoch 80/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5704 - accuracy: 0.7426 - val_loss: 0.5766 - val_accuracy: 0.7370\n",
      "Epoch 81/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5681 - accuracy: 0.7448 - val_loss: 0.5763 - val_accuracy: 0.7370\n",
      "Epoch 82/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5673 - accuracy: 0.7454 - val_loss: 0.5763 - val_accuracy: 0.7370\n",
      "Epoch 83/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5639 - accuracy: 0.7485 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 84/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5651 - accuracy: 0.7475 - val_loss: 0.5764 - val_accuracy: 0.7370\n",
      "Epoch 85/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5645 - accuracy: 0.7481 - val_loss: 0.5763 - val_accuracy: 0.7370\n",
      "Epoch 86/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5663 - accuracy: 0.7464 - val_loss: 0.5764 - val_accuracy: 0.7370\n",
      "Epoch 87/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5668 - accuracy: 0.7460 - val_loss: 0.5767 - val_accuracy: 0.7370\n",
      "Epoch 88/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5764 - val_accuracy: 0.7370\n",
      "Epoch 89/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5760 - accuracy: 0.7472 - val_loss: 0.5763 - val_accuracy: 0.7370\n",
      "Epoch 90/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5683 - accuracy: 0.7445 - val_loss: 0.5764 - val_accuracy: 0.7370\n",
      "Epoch 91/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5687 - accuracy: 0.7442 - val_loss: 0.5767 - val_accuracy: 0.7370\n",
      "Epoch 92/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5676 - accuracy: 0.7452 - val_loss: 0.5764 - val_accuracy: 0.7370\n",
      "Epoch 93/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5656 - accuracy: 0.7470 - val_loss: 0.5763 - val_accuracy: 0.7370\n",
      "Epoch 94/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5737 - accuracy: 0.7395 - val_loss: 0.5766 - val_accuracy: 0.7370\n",
      "Epoch 95/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5614 - accuracy: 0.7509 - val_loss: 0.5763 - val_accuracy: 0.7370\n",
      "Epoch 96/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5705 - accuracy: 0.7424 - val_loss: 0.5766 - val_accuracy: 0.7370\n",
      "Epoch 97/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5630 - accuracy: 0.7494 - val_loss: 0.5764 - val_accuracy: 0.7370\n",
      "Epoch 98/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5658 - accuracy: 0.7469 - val_loss: 0.5763 - val_accuracy: 0.7370\n",
      "Epoch 99/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5655 - accuracy: 0.7471 - val_loss: 0.5765 - val_accuracy: 0.7370\n",
      "Epoch 100/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5640 - accuracy: 0.7485 - val_loss: 0.5764 - val_accuracy: 0.7370\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, validation_split=0.33, epochs=100, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "482bb803",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "3a4ab44d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "27760484",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>411</th>\n",
       "      <th>412</th>\n",
       "      <th>413</th>\n",
       "      <th>414</th>\n",
       "      <th>415</th>\n",
       "      <th>416</th>\n",
       "      <th>417</th>\n",
       "      <th>418</th>\n",
       "      <th>419</th>\n",
       "      <th>420</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9391</th>\n",
       "      <td>336.0</td>\n",
       "      <td>822.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36089</th>\n",
       "      <td>1.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38820</th>\n",
       "      <td>78.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>2726.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33815</th>\n",
       "      <td>771.0</td>\n",
       "      <td>3198.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31187</th>\n",
       "      <td>689.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6265</th>\n",
       "      <td>23.0</td>\n",
       "      <td>947.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>435.0</td>\n",
       "      <td>1327.0</td>\n",
       "      <td>2694.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11284</th>\n",
       "      <td>64.0</td>\n",
       "      <td>361.0</td>\n",
       "      <td>2093.0</td>\n",
       "      <td>2708.0</td>\n",
       "      <td>1228.0</td>\n",
       "      <td>318.0</td>\n",
       "      <td>711.0</td>\n",
       "      <td>1844.0</td>\n",
       "      <td>2392.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38158</th>\n",
       "      <td>35.0</td>\n",
       "      <td>4697.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15795</th>\n",
       "      <td>2.0</td>\n",
       "      <td>889.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32216 rows × 834 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0       1       2       3       4       5      6       7       8    \\\n",
       "9391   336.0   822.0    14.0     0.0     0.0     0.0    0.0     0.0     0.0   \n",
       "36089    1.0   145.0     0.0     0.0     0.0     0.0    0.0     0.0     0.0   \n",
       "38820   78.0    11.0   122.0   113.0   192.0  2726.0   34.0    44.0    17.0   \n",
       "33815  771.0  3198.0     0.0     0.0     0.0     0.0    0.0     0.0     0.0   \n",
       "31187  689.0    45.0     0.0     0.0     0.0     0.0    0.0     0.0     0.0   \n",
       "...      ...     ...     ...     ...     ...     ...    ...     ...     ...   \n",
       "6265    23.0   947.0    35.0   435.0  1327.0  2694.0    2.0     0.0     0.0   \n",
       "11284   64.0   361.0  2093.0  2708.0  1228.0   318.0  711.0  1844.0  2392.0   \n",
       "38158   35.0  4697.0     3.0    47.0     0.0     0.0    0.0     0.0     0.0   \n",
       "860      0.0     0.0     0.0     0.0     0.0     0.0    0.0     0.0     0.0   \n",
       "15795    2.0   889.0     0.0     0.0     0.0     0.0    0.0     0.0     0.0   \n",
       "\n",
       "       9    ...  411  412  413  414  415  416  417  418  419  420  \n",
       "9391   0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "36089  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "38820  4.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "33815  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "31187  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "...    ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  \n",
       "6265   0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "11284  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "38158  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "860    0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "15795  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[32216 rows x 834 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "274cb261",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>825</th>\n",
       "      <th>826</th>\n",
       "      <th>827</th>\n",
       "      <th>828</th>\n",
       "      <th>829</th>\n",
       "      <th>830</th>\n",
       "      <th>831</th>\n",
       "      <th>832</th>\n",
       "      <th>833</th>\n",
       "      <th>834</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.184073</td>\n",
       "      <td>0.004199</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.009253</td>\n",
       "      <td>0.099703</td>\n",
       "      <td>0.000280</td>\n",
       "      <td>0.004739</td>\n",
       "      <td>0.130517</td>\n",
       "      <td>0.035448</td>\n",
       "      <td>0.124714</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.009012</td>\n",
       "      <td>0.014595</td>\n",
       "      <td>0.005346</td>\n",
       "      <td>0.185161</td>\n",
       "      <td>0.217304</td>\n",
       "      <td>0.003347</td>\n",
       "      <td>0.016717</td>\n",
       "      <td>0.004492</td>\n",
       "      <td>0.005472</td>\n",
       "      <td>0.082066</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001569</td>\n",
       "      <td>0.052627</td>\n",
       "      <td>0.009570</td>\n",
       "      <td>0.008886</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>0.003871</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.034236</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.001061</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 835 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0  0.184073  0.004199  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1  0.009253  0.099703  0.000280  0.004739  0.130517  0.035448  0.124714   \n",
       "2  0.009012  0.014595  0.005346  0.185161  0.217304  0.003347  0.016717   \n",
       "3  0.001569  0.052627  0.009570  0.008886  0.000184  0.003871  0.000000   \n",
       "4  0.034236  0.000020  0.001061  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "        7         8         9    ...  825  826  827  828  829  830  831  832  \\\n",
       "0  0.000000  0.000000  0.000000  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1  0.000060  0.000040  0.000000  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2  0.004492  0.005472  0.082066  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "3  0.000000  0.000000  0.000000  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "4  0.000000  0.000000  0.000000  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "   833  834  \n",
       "0  0.0  1.0  \n",
       "1  0.0  0.0  \n",
       "2  0.0  1.0  \n",
       "3  0.0  1.0  \n",
       "4  0.0  1.0  \n",
       "\n",
       "[5 rows x 835 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "x = df.values\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "df = pd.DataFrame(x_scaled)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b8c07cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(100, input_dim=834, activation='relu'))\n",
    "model.add(Dense(60, activation='relu'))\n",
    "model.add(Dense(45, activation='relu'))\n",
    "model.add(Dense(30, activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "fe7bf3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder()\n",
    "\n",
    "y_train = np.asarray(y_train).reshape((-1,1))\n",
    "y_test = np.asarray(y_test).reshape((-1,1))\n",
    "\n",
    "y_train = ohe.fit_transform(y_train).toarray()\n",
    "y_test = ohe.fit_transform(y_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ece33a32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "338/338 [==============================] - 2s 2ms/step - loss: 5.5669 - accuracy: 0.4944 - val_loss: 0.7017 - val_accuracy: 0.5006\n",
      "Epoch 2/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.6940 - accuracy: 0.5091 - val_loss: 0.6960 - val_accuracy: 0.5001\n",
      "Epoch 3/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.4909 - val_loss: 0.6961 - val_accuracy: 0.4999\n",
      "Epoch 4/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5028 - val_loss: 0.6959 - val_accuracy: 0.5001\n",
      "Epoch 5/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.4974 - val_loss: 0.6951 - val_accuracy: 0.4999\n",
      "Epoch 6/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.6937 - accuracy: 0.4955 - val_loss: 0.6984 - val_accuracy: 0.4999\n",
      "Epoch 7/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.6930 - accuracy: 0.5008 - val_loss: 0.6986 - val_accuracy: 0.5000\n",
      "Epoch 8/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.4978 - val_loss: 0.7126 - val_accuracy: 0.4998\n",
      "Epoch 9/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.4986 - val_loss: 0.7127 - val_accuracy: 0.5002\n",
      "Epoch 10/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5004 - val_loss: 0.7126 - val_accuracy: 0.5001\n",
      "Epoch 11/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.6930 - accuracy: 0.4994 - val_loss: 0.7110 - val_accuracy: 0.5001\n",
      "Epoch 12/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.6929 - accuracy: 0.4948 - val_loss: 0.7149 - val_accuracy: 0.5001\n",
      "Epoch 13/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.6931 - accuracy: 0.5009 - val_loss: 0.7183 - val_accuracy: 0.4998\n",
      "Epoch 14/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.6930 - accuracy: 0.4956 - val_loss: 0.7045 - val_accuracy: 0.4999\n",
      "Epoch 15/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.6929 - accuracy: 0.4952 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 16/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.6930 - accuracy: 0.5042 - val_loss: 0.6931 - val_accuracy: 0.5002\n",
      "Epoch 17/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.6930 - accuracy: 0.4992 - val_loss: 0.6961 - val_accuracy: 0.5000\n",
      "Epoch 18/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.6932 - accuracy: 0.5020 - val_loss: 0.6961 - val_accuracy: 0.5000\n",
      "Epoch 19/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5064 - val_loss: 0.6961 - val_accuracy: 0.4999\n",
      "Epoch 20/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.6932 - accuracy: 0.5023 - val_loss: 0.6961 - val_accuracy: 0.5000\n",
      "Epoch 21/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.6932 - accuracy: 0.5021 - val_loss: 0.6961 - val_accuracy: 0.4999\n",
      "Epoch 22/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.4905 - val_loss: 0.6961 - val_accuracy: 0.4999\n",
      "Epoch 23/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.4987 - val_loss: 0.6961 - val_accuracy: 0.4999\n",
      "Epoch 24/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.6932 - accuracy: 0.4929 - val_loss: 0.6961 - val_accuracy: 0.4999\n",
      "Epoch 25/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.6931 - accuracy: 0.5060 - val_loss: 0.6961 - val_accuracy: 0.5000\n",
      "Epoch 26/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5028 - val_loss: 0.6961 - val_accuracy: 0.4999\n",
      "Epoch 27/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.6932 - accuracy: 0.4939 - val_loss: 0.6961 - val_accuracy: 0.4999\n",
      "Epoch 28/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.6932 - accuracy: 0.5048 - val_loss: 0.6961 - val_accuracy: 0.5000\n",
      "Epoch 29/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.6932 - accuracy: 0.5012 - val_loss: 0.6961 - val_accuracy: 0.4999\n",
      "Epoch 30/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.6932 - accuracy: 0.5023 - val_loss: 0.6961 - val_accuracy: 0.4999\n",
      "Epoch 31/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.6932 - accuracy: 0.5021 - val_loss: 0.6961 - val_accuracy: 0.5000\n",
      "Epoch 32/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.4950 - val_loss: 0.6961 - val_accuracy: 0.5000\n",
      "Epoch 33/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.6932 - accuracy: 0.5015 - val_loss: 0.6961 - val_accuracy: 0.4999\n",
      "Epoch 34/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.6932 - accuracy: 0.4935 - val_loss: 0.6961 - val_accuracy: 0.4999\n",
      "Epoch 35/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.4956 - val_loss: 0.6961 - val_accuracy: 0.5000\n",
      "Epoch 36/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.6932 - accuracy: 0.4973 - val_loss: 0.6961 - val_accuracy: 0.4999\n",
      "Epoch 37/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5010 - val_loss: 0.6961 - val_accuracy: 0.4999\n",
      "Epoch 38/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.6932 - accuracy: 0.4947 - val_loss: 0.6961 - val_accuracy: 0.4999\n",
      "Epoch 39/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.6932 - accuracy: 0.5019 - val_loss: 0.6961 - val_accuracy: 0.5000\n",
      "Epoch 40/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5004 - val_loss: 0.6961 - val_accuracy: 0.5000\n",
      "Epoch 41/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.6932 - accuracy: 0.5003 - val_loss: 0.6961 - val_accuracy: 0.5000\n",
      "Epoch 42/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.4955 - val_loss: 0.6961 - val_accuracy: 0.4999\n",
      "Epoch 43/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.6932 - accuracy: 0.5008 - val_loss: 0.6961 - val_accuracy: 0.4999\n",
      "Epoch 44/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.4972 - val_loss: 0.6961 - val_accuracy: 0.4999\n",
      "Epoch 45/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.4844 - val_loss: 0.6961 - val_accuracy: 0.4999\n",
      "Epoch 46/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.4935 - val_loss: 0.6961 - val_accuracy: 0.4999\n",
      "Epoch 47/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5034 - val_loss: 0.6961 - val_accuracy: 0.4999\n",
      "Epoch 48/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5041 - val_loss: 0.6961 - val_accuracy: 0.5000\n",
      "Epoch 49/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.6932 - accuracy: 0.4934 - val_loss: 0.6961 - val_accuracy: 0.4999\n",
      "Epoch 50/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.6932 - accuracy: 0.5004 - val_loss: 0.6961 - val_accuracy: 0.4999\n",
      "Epoch 51/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5029 - val_loss: 0.6961 - val_accuracy: 0.5000\n",
      "Epoch 52/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5058 - val_loss: 0.6961 - val_accuracy: 0.4999\n",
      "Epoch 53/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.6932 - accuracy: 0.4957 - val_loss: 0.6961 - val_accuracy: 0.4999\n",
      "Epoch 54/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.4965 - val_loss: 0.6961 - val_accuracy: 0.4999\n",
      "Epoch 55/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.4944 - val_loss: 0.6961 - val_accuracy: 0.5000\n",
      "Epoch 56/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.6931 - accuracy: 0.5051 - val_loss: 0.6961 - val_accuracy: 0.4999\n",
      "Epoch 57/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5083 - val_loss: 0.6961 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.6931 - accuracy: 0.5063 - val_loss: 0.6961 - val_accuracy: 0.4999\n",
      "Epoch 59/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.6931 - accuracy: 0.5027 - val_loss: 0.6961 - val_accuracy: 0.5000\n",
      "Epoch 60/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.4942 - val_loss: 0.6961 - val_accuracy: 0.5000\n",
      "Epoch 61/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.6932 - accuracy: 0.5024 - val_loss: 0.6961 - val_accuracy: 0.5000\n",
      "Epoch 62/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.6932 - accuracy: 0.4975 - val_loss: 0.6961 - val_accuracy: 0.5000\n",
      "Epoch 63/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.4947 - val_loss: 0.6961 - val_accuracy: 0.4999\n",
      "Epoch 64/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.4956 - val_loss: 0.6961 - val_accuracy: 0.4999\n",
      "Epoch 65/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.6932 - accuracy: 0.4970 - val_loss: 0.6961 - val_accuracy: 0.4999\n",
      "Epoch 66/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.6932 - accuracy: 0.5002 - val_loss: 0.6961 - val_accuracy: 0.5000\n",
      "Epoch 67/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.6932 - accuracy: 0.5024 - val_loss: 0.6961 - val_accuracy: 0.4999\n",
      "Epoch 68/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.6932 - accuracy: 0.5017 - val_loss: 0.6961 - val_accuracy: 0.4999\n",
      "Epoch 69/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.6932 - accuracy: 0.4998 - val_loss: 0.6961 - val_accuracy: 0.5000\n",
      "Epoch 70/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.6932 - accuracy: 0.4979 - val_loss: 0.6961 - val_accuracy: 0.5000\n",
      "Epoch 71/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.6932 - accuracy: 0.5025 - val_loss: 0.6961 - val_accuracy: 0.4999\n",
      "Epoch 72/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.6931 - accuracy: 0.5051 - val_loss: 0.6961 - val_accuracy: 0.5000\n",
      "Epoch 73/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.6932 - accuracy: 0.4985 - val_loss: 0.6961 - val_accuracy: 0.5000\n",
      "Epoch 74/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.6932 - accuracy: 0.4994 - val_loss: 0.6961 - val_accuracy: 0.5000\n",
      "Epoch 75/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.6932 - accuracy: 0.4985 - val_loss: 0.6961 - val_accuracy: 0.5000\n",
      "Epoch 76/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.6932 - accuracy: 0.4947 - val_loss: 0.6961 - val_accuracy: 0.5000\n",
      "Epoch 77/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.6932 - accuracy: 0.5015 - val_loss: 0.6961 - val_accuracy: 0.5000\n",
      "Epoch 78/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.6932 - accuracy: 0.4968 - val_loss: 0.6961 - val_accuracy: 0.5000\n",
      "Epoch 79/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.6932 - accuracy: 0.4966 - val_loss: 0.6961 - val_accuracy: 0.5000\n",
      "Epoch 80/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.6932 - accuracy: 0.4911 - val_loss: 0.6961 - val_accuracy: 0.5000\n",
      "Epoch 81/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.6932 - accuracy: 0.4995 - val_loss: 0.6961 - val_accuracy: 0.5000\n",
      "Epoch 82/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.6931 - accuracy: 0.5100 - val_loss: 0.6961 - val_accuracy: 0.4999\n",
      "Epoch 83/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.6932 - accuracy: 0.4889 - val_loss: 0.6961 - val_accuracy: 0.4999\n",
      "Epoch 84/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.6932 - accuracy: 0.4972 - val_loss: 0.6961 - val_accuracy: 0.4999\n",
      "Epoch 85/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.6932 - accuracy: 0.4974 - val_loss: 0.6961 - val_accuracy: 0.4999\n",
      "Epoch 86/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.6932 - accuracy: 0.4966 - val_loss: 0.6961 - val_accuracy: 0.5000\n",
      "Epoch 87/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.6932 - accuracy: 0.4970 - val_loss: 0.6961 - val_accuracy: 0.5000\n",
      "Epoch 88/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.4986 - val_loss: 0.6961 - val_accuracy: 0.5000\n",
      "Epoch 89/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.6932 - accuracy: 0.4965 - val_loss: 0.6961 - val_accuracy: 0.5000\n",
      "Epoch 90/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.6932 - accuracy: 0.5036 - val_loss: 0.6961 - val_accuracy: 0.5000\n",
      "Epoch 91/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.6932 - accuracy: 0.4970 - val_loss: 0.6961 - val_accuracy: 0.5000\n",
      "Epoch 92/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5015 - val_loss: 0.6961 - val_accuracy: 0.4999\n",
      "Epoch 93/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.4960 - val_loss: 0.6961 - val_accuracy: 0.4999\n",
      "Epoch 94/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.6932 - accuracy: 0.4980 - val_loss: 0.6961 - val_accuracy: 0.5000\n",
      "Epoch 95/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.6932 - accuracy: 0.5003 - val_loss: 0.6961 - val_accuracy: 0.5000\n",
      "Epoch 96/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.6932 - accuracy: 0.5015 - val_loss: 0.6961 - val_accuracy: 0.4999\n",
      "Epoch 97/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.6931 - accuracy: 0.5041 - val_loss: 0.6961 - val_accuracy: 0.5000\n",
      "Epoch 98/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.6932 - accuracy: 0.4968 - val_loss: 0.6961 - val_accuracy: 0.5000\n",
      "Epoch 99/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.6932 - accuracy: 0.4958 - val_loss: 0.6961 - val_accuracy: 0.5000\n",
      "Epoch 100/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.6932 - accuracy: 0.4974 - val_loss: 0.6961 - val_accuracy: 0.4999\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, validation_split=0.33, epochs=100, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954ec411",
   "metadata": {},
   "source": [
    "As it was expected it is not a good idea to normalize columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "8566a4dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    6813\n",
      "0       0\n",
      "dtype: int64\n",
      "10    28302\n",
      "10       28\n",
      "dtype: int64\n",
      "100    32171\n",
      "100    30621\n",
      "dtype: int64\n",
      "400    32215\n",
      "400    32215\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print((X_train[0] == 0).sum())\n",
    "print((X_train[10] == 0).sum())\n",
    "print((X_train[100] == 0).sum())\n",
    "print((X_train[400] == 0).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "82f8f489",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>queries</th>\n",
       "      <th>apps</th>\n",
       "      <th>games</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[216, 359, 12329, 3, 45, 4002, 2066, 32, 3931,...</td>\n",
       "      <td>[4, 4, 25, 7, 30, 58, 16, 19, 17, 21, 10, 10, ...</td>\n",
       "      <td>[9151, 208]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[]</td>\n",
       "      <td>[129, 71, 9, 8, 11, 25, 18, 58, 6, 16, 125, 12...</td>\n",
       "      <td>[460, 4939, 14, 232, 6387, 1758, 5834, 3, 2]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[23463, 18831]</td>\n",
       "      <td>[9, 174, 65, 8, 63, 97, 62, 103, 61, 116, 59, ...</td>\n",
       "      <td>[448, 723, 267, 9064, 10634, 166, 782, 224, 27...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1634, 3609, 654]</td>\n",
       "      <td>[99, 73, 9, 8, 59, 37, 131, 3, 89, 6, 24, 16, ...</td>\n",
       "      <td>[78, 2607, 478, 435, 9, 192]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[11064, 227, 623, 1301, 43999, 35411, 2492, 11...</td>\n",
       "      <td>[9, 8, 17, 54, 3, 25, 22, 6, 21, 7, 14, 5, 817...</td>\n",
       "      <td>[1702, 1, 53]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             queries  \\\n",
       "0  [216, 359, 12329, 3, 45, 4002, 2066, 32, 3931,...   \n",
       "1                                                 []   \n",
       "2                                     [23463, 18831]   \n",
       "3                                  [1634, 3609, 654]   \n",
       "4  [11064, 227, 623, 1301, 43999, 35411, 2492, 11...   \n",
       "\n",
       "                                                apps  \\\n",
       "0  [4, 4, 25, 7, 30, 58, 16, 19, 17, 21, 10, 10, ...   \n",
       "1  [129, 71, 9, 8, 11, 25, 18, 58, 6, 16, 125, 12...   \n",
       "2  [9, 174, 65, 8, 63, 97, 62, 103, 61, 116, 59, ...   \n",
       "3  [99, 73, 9, 8, 59, 37, 131, 3, 89, 6, 24, 16, ...   \n",
       "4  [9, 8, 17, 54, 3, 25, 22, 6, 21, 7, 14, 5, 817...   \n",
       "\n",
       "                                               games  gender  \n",
       "0                                        [9151, 208]       1  \n",
       "1       [460, 4939, 14, 232, 6387, 1758, 5834, 3, 2]       0  \n",
       "2  [448, 723, 267, 9064, 10634, 166, 782, 224, 27...       1  \n",
       "3                       [78, 2607, 478, 435, 9, 192]       1  \n",
       "4                                      [1702, 1, 53]       1  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet(DATA_DIR, engine=\"pyarrow\")\n",
    "df[\"birth_year\"] = df[\"birth_year\"].astype(np.uint)\n",
    "valid_birth_year = df[\"birth_year\"][df[\"birth_year\"] != 0]\n",
    "mean_birth_year = round(valid_birth_year.mean())\n",
    "df[\"birth_year\"] = df[\"birth_year\"].replace(0, mean_birth_year)\n",
    "df[\"gender\"] = df[\"gender\"].replace({'M': 1, 'F': 0})\n",
    "df.drop(columns=['birth_year'], inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7a5befe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df.pop('apps').apply(pd.Series), df], axis=1)\n",
    "df = pd.concat([df.pop('games').apply(pd.Series), df], axis=1)\n",
    "df = pd.concat([df.pop('queries').apply(pd.Series), df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9e716255",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>412</th>\n",
       "      <th>413</th>\n",
       "      <th>414</th>\n",
       "      <th>415</th>\n",
       "      <th>416</th>\n",
       "      <th>417</th>\n",
       "      <th>418</th>\n",
       "      <th>419</th>\n",
       "      <th>420</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>216.0</td>\n",
       "      <td>359.0</td>\n",
       "      <td>12329.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>4002.0</td>\n",
       "      <td>2066.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>3931.0</td>\n",
       "      <td>17104.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23463.0</td>\n",
       "      <td>18831.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1634.0</td>\n",
       "      <td>3609.0</td>\n",
       "      <td>654.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11064.0</td>\n",
       "      <td>227.0</td>\n",
       "      <td>623.0</td>\n",
       "      <td>1301.0</td>\n",
       "      <td>43999.0</td>\n",
       "      <td>35411.0</td>\n",
       "      <td>2492.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>1652.0</td>\n",
       "      <td>27068.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 931 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0        1        2       3        4        5       6      7       8  \\\n",
       "0    216.0    359.0  12329.0     3.0     45.0   4002.0  2066.0   32.0  3931.0   \n",
       "1      NaN      NaN      NaN     NaN      NaN      NaN     NaN    NaN     NaN   \n",
       "2  23463.0  18831.0      NaN     NaN      NaN      NaN     NaN    NaN     NaN   \n",
       "3   1634.0   3609.0    654.0     NaN      NaN      NaN     NaN    NaN     NaN   \n",
       "4  11064.0    227.0    623.0  1301.0  43999.0  35411.0  2492.0  112.0  1652.0   \n",
       "\n",
       "         9  ...  412  413  414  415  416  417  418  419  420  gender  \n",
       "0  17104.0  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN       1  \n",
       "1      NaN  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN       0  \n",
       "2      NaN  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN       1  \n",
       "3      NaN  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN       1  \n",
       "4  27068.0  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN       1  \n",
       "\n",
       "[5 rows x 931 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "710313ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         0.017407\n",
       "1         0.041643\n",
       "2         0.070373\n",
       "3         0.098036\n",
       "4         0.127312\n",
       "            ...   \n",
       "417       0.999975\n",
       "418       0.999975\n",
       "419       0.999975\n",
       "420       0.999975\n",
       "gender    0.000000\n",
       "Length: 931, dtype: float64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ee7169c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([       0,        1,        2,        3,        4,        5,        6,\n",
       "              7,        8,        9,\n",
       "       ...\n",
       "             62,       63,       64,       65,       66,       67,       68,\n",
       "             69,       70, 'gender'],\n",
       "      dtype='object', length=119)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns[df.isnull().mean() < 0.8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "26a2091e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.columns[df.isnull().mean() < 0.8]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b4c31ea9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40271, 355)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9d2af3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "dc1b48b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y =  df.drop(columns=[\"gender\"]), df[\"gender\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b4f94c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder()\n",
    "\n",
    "y_train = np.asarray(y_train).reshape((-1,1))\n",
    "y_test = np.asarray(y_test).reshape((-1,1))\n",
    "\n",
    "y_train = ohe.fit_transform(y_train).toarray()\n",
    "y_test = ohe.fit_transform(y_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "53e44d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(100, input_dim=354, activation='relu'))\n",
    "model.add(Dense(60, activation='relu'))\n",
    "model.add(Dense(45, activation='relu'))\n",
    "model.add(Dense(30, activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "94c20431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "338/338 [==============================] - 2s 2ms/step - loss: 18.2793 - accuracy: 0.7150 - val_loss: 0.6518 - val_accuracy: 0.7369\n",
      "Epoch 2/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.6233 - accuracy: 0.7420 - val_loss: 0.6184 - val_accuracy: 0.7369\n",
      "Epoch 3/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5895 - accuracy: 0.7486 - val_loss: 0.6030 - val_accuracy: 0.7369\n",
      "Epoch 4/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5746 - accuracy: 0.7490 - val_loss: 0.5927 - val_accuracy: 0.7370\n",
      "Epoch 5/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5723 - accuracy: 0.7436 - val_loss: 0.5894 - val_accuracy: 0.7369\n",
      "Epoch 6/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5683 - accuracy: 0.7454 - val_loss: 0.5888 - val_accuracy: 0.7369\n",
      "Epoch 7/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5630 - accuracy: 0.7497 - val_loss: 0.5888 - val_accuracy: 0.7369\n",
      "Epoch 8/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5674 - accuracy: 0.7454 - val_loss: 0.5889 - val_accuracy: 0.7369\n",
      "Epoch 9/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5691 - accuracy: 0.7437 - val_loss: 0.5889 - val_accuracy: 0.7369\n",
      "Epoch 10/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5698 - accuracy: 0.7431 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 11/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5658 - accuracy: 0.7468 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 12/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.5639 - accuracy: 0.7486 - val_loss: 0.5889 - val_accuracy: 0.7369\n",
      "Epoch 13/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5638 - accuracy: 0.7486 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 14/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5693 - accuracy: 0.7436 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 15/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5659 - accuracy: 0.7467 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 16/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5647 - accuracy: 0.7478 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 17/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5663 - accuracy: 0.7464 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 18/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5669 - accuracy: 0.7457 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 19/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5627 - accuracy: 0.7497 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 20/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5697 - accuracy: 0.7432 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 21/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5613 - accuracy: 0.7509 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 22/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5663 - accuracy: 0.7463 - val_loss: 0.5889 - val_accuracy: 0.7369\n",
      "Epoch 23/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5641 - accuracy: 0.7484 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 24/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.5672 - accuracy: 0.7455 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 25/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5680 - accuracy: 0.7448 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 26/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5672 - accuracy: 0.7455 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 27/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5629 - accuracy: 0.7495 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 28/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5684 - accuracy: 0.7444 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 29/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5694 - accuracy: 0.7435 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 30/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5674 - accuracy: 0.7453 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 31/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5664 - accuracy: 0.7463 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 32/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5678 - accuracy: 0.7450 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 33/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5625 - accuracy: 0.7499 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 34/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5674 - accuracy: 0.7453 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 35/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5675 - accuracy: 0.7453 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 36/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5632 - accuracy: 0.7492 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 37/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5634 - accuracy: 0.7490 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 38/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.5610 - accuracy: 0.7513 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 39/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5654 - accuracy: 0.7471 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 40/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5656 - accuracy: 0.7470 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 41/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5634 - accuracy: 0.7491 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 42/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5645 - accuracy: 0.7480 - val_loss: 0.5889 - val_accuracy: 0.7369\n",
      "Epoch 43/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5572 - accuracy: 0.7548 - val_loss: 0.5889 - val_accuracy: 0.7369\n",
      "Epoch 44/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5679 - accuracy: 0.7448 - val_loss: 0.5889 - val_accuracy: 0.7369\n",
      "Epoch 45/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5684 - accuracy: 0.7444 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 46/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.5666 - accuracy: 0.7461 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 47/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5705 - accuracy: 0.7425 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 48/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5681 - accuracy: 0.7447 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 49/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5654 - accuracy: 0.7471 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 50/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.5611 - accuracy: 0.7511 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 51/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5643 - accuracy: 0.7481 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 52/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5691 - accuracy: 0.7437 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 53/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5654 - accuracy: 0.7472 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 54/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5654 - accuracy: 0.7472 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 55/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.5661 - accuracy: 0.7466 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 56/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5672 - accuracy: 0.7455 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 57/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5612 - accuracy: 0.7510 - val_loss: 0.5889 - val_accuracy: 0.7369\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5696 - accuracy: 0.7432 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 59/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5603 - accuracy: 0.7519 - val_loss: 0.5889 - val_accuracy: 0.7369\n",
      "Epoch 60/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5606 - accuracy: 0.7516 - val_loss: 0.5889 - val_accuracy: 0.7369\n",
      "Epoch 61/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5664 - accuracy: 0.7463 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 62/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5647 - accuracy: 0.7478 - val_loss: 0.5889 - val_accuracy: 0.7369\n",
      "Epoch 63/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5684 - accuracy: 0.7443 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 64/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5645 - accuracy: 0.7481 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 65/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5679 - accuracy: 0.7448 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 66/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5660 - accuracy: 0.7466 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 67/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5659 - accuracy: 0.7467 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 68/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.5622 - accuracy: 0.7501 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 69/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.5635 - accuracy: 0.7489 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 70/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5665 - accuracy: 0.7462 - val_loss: 0.5889 - val_accuracy: 0.7369\n",
      "Epoch 71/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.5690 - accuracy: 0.7438 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 72/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5685 - accuracy: 0.7442 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 73/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5730 - accuracy: 0.7402 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 74/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5652 - accuracy: 0.7473 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 75/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5653 - accuracy: 0.7472 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 76/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5702 - accuracy: 0.7427 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 77/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5656 - accuracy: 0.7470 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 78/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5716 - accuracy: 0.7415 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 79/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.5683 - accuracy: 0.7445 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 80/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5681 - accuracy: 0.7446 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 81/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5625 - accuracy: 0.7498 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 82/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5632 - accuracy: 0.7492 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 83/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5666 - accuracy: 0.7461 - val_loss: 0.5889 - val_accuracy: 0.7369\n",
      "Epoch 84/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5667 - accuracy: 0.7460 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 85/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5567 - accuracy: 0.7552 - val_loss: 0.5889 - val_accuracy: 0.7369\n",
      "Epoch 86/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5704 - accuracy: 0.7425 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 87/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5658 - accuracy: 0.7468 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 88/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5572 - accuracy: 0.7547 - val_loss: 0.5889 - val_accuracy: 0.7369\n",
      "Epoch 89/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5658 - accuracy: 0.7467 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 90/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5666 - accuracy: 0.7461 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 91/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5664 - accuracy: 0.7462 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 92/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5603 - accuracy: 0.7519 - val_loss: 0.5889 - val_accuracy: 0.7369\n",
      "Epoch 93/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5598 - accuracy: 0.7524 - val_loss: 0.5889 - val_accuracy: 0.7369\n",
      "Epoch 94/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5630 - accuracy: 0.7494 - val_loss: 0.5889 - val_accuracy: 0.7369\n",
      "Epoch 95/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5609 - accuracy: 0.7513 - val_loss: 0.5889 - val_accuracy: 0.7369\n",
      "Epoch 96/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5679 - accuracy: 0.7448 - val_loss: 0.5889 - val_accuracy: 0.7369\n",
      "Epoch 97/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5594 - accuracy: 0.7527 - val_loss: 0.5889 - val_accuracy: 0.7369\n",
      "Epoch 98/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5700 - accuracy: 0.7429 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 99/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.5667 - accuracy: 0.7460 - val_loss: 0.5890 - val_accuracy: 0.7369\n",
      "Epoch 100/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5643 - accuracy: 0.7481 - val_loss: 0.5889 - val_accuracy: 0.7369\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, validation_split=0.33, epochs=100, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "702f7022",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>queries</th>\n",
       "      <th>apps</th>\n",
       "      <th>games</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[216, 359, 12329, 3, 45, 4002, 2066, 32, 3931,...</td>\n",
       "      <td>[4, 4, 25, 7, 30, 58, 16, 19, 17, 21, 10, 10, ...</td>\n",
       "      <td>[9151, 208]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[]</td>\n",
       "      <td>[129, 71, 9, 8, 11, 25, 18, 58, 6, 16, 125, 12...</td>\n",
       "      <td>[460, 4939, 14, 232, 6387, 1758, 5834, 3, 2]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[23463, 18831]</td>\n",
       "      <td>[9, 174, 65, 8, 63, 97, 62, 103, 61, 116, 59, ...</td>\n",
       "      <td>[448, 723, 267, 9064, 10634, 166, 782, 224, 27...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1634, 3609, 654]</td>\n",
       "      <td>[99, 73, 9, 8, 59, 37, 131, 3, 89, 6, 24, 16, ...</td>\n",
       "      <td>[78, 2607, 478, 435, 9, 192]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[11064, 227, 623, 1301, 43999, 35411, 2492, 11...</td>\n",
       "      <td>[9, 8, 17, 54, 3, 25, 22, 6, 21, 7, 14, 5, 817...</td>\n",
       "      <td>[1702, 1, 53]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             queries  \\\n",
       "0  [216, 359, 12329, 3, 45, 4002, 2066, 32, 3931,...   \n",
       "1                                                 []   \n",
       "2                                     [23463, 18831]   \n",
       "3                                  [1634, 3609, 654]   \n",
       "4  [11064, 227, 623, 1301, 43999, 35411, 2492, 11...   \n",
       "\n",
       "                                                apps  \\\n",
       "0  [4, 4, 25, 7, 30, 58, 16, 19, 17, 21, 10, 10, ...   \n",
       "1  [129, 71, 9, 8, 11, 25, 18, 58, 6, 16, 125, 12...   \n",
       "2  [9, 174, 65, 8, 63, 97, 62, 103, 61, 116, 59, ...   \n",
       "3  [99, 73, 9, 8, 59, 37, 131, 3, 89, 6, 24, 16, ...   \n",
       "4  [9, 8, 17, 54, 3, 25, 22, 6, 21, 7, 14, 5, 817...   \n",
       "\n",
       "                                               games  gender  \n",
       "0                                        [9151, 208]       1  \n",
       "1       [460, 4939, 14, 232, 6387, 1758, 5834, 3, 2]       0  \n",
       "2  [448, 723, 267, 9064, 10634, 166, 782, 224, 27...       1  \n",
       "3                       [78, 2607, 478, 435, 9, 192]       1  \n",
       "4                                      [1702, 1, 53]       1  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet(DATA_DIR, engine=\"pyarrow\")\n",
    "df[\"birth_year\"] = df[\"birth_year\"].astype(np.uint)\n",
    "valid_birth_year = df[\"birth_year\"][df[\"birth_year\"] != 0]\n",
    "mean_birth_year = round(valid_birth_year.mean())\n",
    "df[\"birth_year\"] = df[\"birth_year\"].replace(0, mean_birth_year)\n",
    "df[\"gender\"] = df[\"gender\"].replace({'M': 1, 'F': 0})\n",
    "df.drop(columns=['birth_year'], inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7d4c1ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df.pop('apps').apply(pd.Series), df], axis=1)\n",
    "df = pd.concat([df.pop('games').apply(pd.Series), df], axis=1)\n",
    "df = pd.concat([df.pop('queries').apply(pd.Series), df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d3010937",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.columns[df.isnull().mean() < 0.7]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fae8735f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7cfef3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y =  df.drop(columns=[\"gender\"]), df[\"gender\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "144aea61",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder()\n",
    "\n",
    "y_train = np.asarray(y_train).reshape((-1,1))\n",
    "y_test = np.asarray(y_test).reshape((-1,1))\n",
    "\n",
    "y_train = ohe.fit_transform(y_train).toarray()\n",
    "y_test = ohe.fit_transform(y_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "58aa45c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(100, input_dim=291, activation='relu'))\n",
    "model.add(Dense(60, activation='relu'))\n",
    "model.add(Dense(45, activation='relu'))\n",
    "model.add(Dense(30, activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d793764b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "338/338 [==============================] - 2s 2ms/step - loss: 30.9248 - accuracy: 0.6959 - val_loss: 0.6455 - val_accuracy: 0.7371\n",
      "Epoch 2/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.6248 - accuracy: 0.7446 - val_loss: 0.6125 - val_accuracy: 0.7372\n",
      "Epoch 3/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.5937 - accuracy: 0.7395 - val_loss: 0.5944 - val_accuracy: 0.7370\n",
      "Epoch 4/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.5756 - accuracy: 0.7455 - val_loss: 0.5870 - val_accuracy: 0.7370\n",
      "Epoch 5/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5740 - accuracy: 0.7409 - val_loss: 0.5862 - val_accuracy: 0.7371\n",
      "Epoch 6/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5637 - accuracy: 0.7499 - val_loss: 0.5763 - val_accuracy: 0.7370\n",
      "Epoch 7/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5628 - accuracy: 0.7501 - val_loss: 0.5770 - val_accuracy: 0.7371\n",
      "Epoch 8/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5679 - accuracy: 0.7454 - val_loss: 0.5764 - val_accuracy: 0.7370\n",
      "Epoch 9/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.5610 - accuracy: 0.7512 - val_loss: 0.5770 - val_accuracy: 0.7370\n",
      "Epoch 10/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5664 - accuracy: 0.7462 - val_loss: 0.5783 - val_accuracy: 0.7370\n",
      "Epoch 11/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5680 - accuracy: 0.7446 - val_loss: 0.5765 - val_accuracy: 0.7371\n",
      "Epoch 12/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.5690 - accuracy: 0.7438 - val_loss: 0.5766 - val_accuracy: 0.7371\n",
      "Epoch 13/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5684 - accuracy: 0.7444 - val_loss: 0.5766 - val_accuracy: 0.7371\n",
      "Epoch 14/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5673 - accuracy: 0.7454 - val_loss: 0.5766 - val_accuracy: 0.7371\n",
      "Epoch 15/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5701 - accuracy: 0.7428 - val_loss: 0.5766 - val_accuracy: 0.7371\n",
      "Epoch 16/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.5668 - accuracy: 0.7459 - val_loss: 0.5766 - val_accuracy: 0.7371\n",
      "Epoch 17/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5714 - accuracy: 0.7417 - val_loss: 0.5766 - val_accuracy: 0.7371\n",
      "Epoch 18/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5662 - accuracy: 0.7465 - val_loss: 0.5765 - val_accuracy: 0.7371\n",
      "Epoch 19/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5643 - accuracy: 0.7482 - val_loss: 0.5765 - val_accuracy: 0.7371\n",
      "Epoch 20/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5697 - accuracy: 0.7432 - val_loss: 0.5765 - val_accuracy: 0.7371\n",
      "Epoch 21/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5663 - accuracy: 0.7463 - val_loss: 0.5765 - val_accuracy: 0.7371\n",
      "Epoch 22/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5664 - accuracy: 0.7462 - val_loss: 0.5765 - val_accuracy: 0.7371\n",
      "Epoch 23/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5668 - accuracy: 0.7459 - val_loss: 0.5765 - val_accuracy: 0.7371\n",
      "Epoch 24/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5652 - accuracy: 0.7474 - val_loss: 0.5765 - val_accuracy: 0.7371\n",
      "Epoch 25/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5684 - accuracy: 0.7444 - val_loss: 0.5765 - val_accuracy: 0.7371\n",
      "Epoch 26/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5704 - accuracy: 0.7426 - val_loss: 0.5766 - val_accuracy: 0.7371\n",
      "Epoch 27/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5669 - accuracy: 0.7458 - val_loss: 0.5765 - val_accuracy: 0.7371\n",
      "Epoch 28/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5666 - accuracy: 0.7461 - val_loss: 0.5765 - val_accuracy: 0.7371\n",
      "Epoch 29/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5647 - accuracy: 0.7478 - val_loss: 0.5765 - val_accuracy: 0.7371\n",
      "Epoch 30/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5638 - accuracy: 0.7487 - val_loss: 0.5765 - val_accuracy: 0.7371\n",
      "Epoch 31/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5659 - accuracy: 0.7467 - val_loss: 0.5765 - val_accuracy: 0.7371\n",
      "Epoch 32/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5660 - accuracy: 0.7467 - val_loss: 0.5765 - val_accuracy: 0.7371\n",
      "Epoch 33/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.5694 - accuracy: 0.7435 - val_loss: 0.5766 - val_accuracy: 0.7371\n",
      "Epoch 34/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5633 - accuracy: 0.7491 - val_loss: 0.5765 - val_accuracy: 0.7371\n",
      "Epoch 35/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5597 - accuracy: 0.7525 - val_loss: 0.5765 - val_accuracy: 0.7371\n",
      "Epoch 36/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5668 - accuracy: 0.7459 - val_loss: 0.5765 - val_accuracy: 0.7371\n",
      "Epoch 37/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5703 - accuracy: 0.7426 - val_loss: 0.5766 - val_accuracy: 0.7371\n",
      "Epoch 38/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5673 - accuracy: 0.7455 - val_loss: 0.5765 - val_accuracy: 0.7371\n",
      "Epoch 39/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5603 - accuracy: 0.7519 - val_loss: 0.5765 - val_accuracy: 0.7371\n",
      "Epoch 40/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.5665 - accuracy: 0.7461 - val_loss: 0.5765 - val_accuracy: 0.7371\n",
      "Epoch 41/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5677 - accuracy: 0.7451 - val_loss: 0.5765 - val_accuracy: 0.7371\n",
      "Epoch 42/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5685 - accuracy: 0.7443 - val_loss: 0.5766 - val_accuracy: 0.7371\n",
      "Epoch 43/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5642 - accuracy: 0.7483 - val_loss: 0.5766 - val_accuracy: 0.7371\n",
      "Epoch 44/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5671 - accuracy: 0.7456 - val_loss: 0.5766 - val_accuracy: 0.7371\n",
      "Epoch 45/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5618 - accuracy: 0.7505 - val_loss: 0.5765 - val_accuracy: 0.7371\n",
      "Epoch 46/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5649 - accuracy: 0.7477 - val_loss: 0.5765 - val_accuracy: 0.7371\n",
      "Epoch 47/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5663 - accuracy: 0.7464 - val_loss: 0.5765 - val_accuracy: 0.7371\n",
      "Epoch 48/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5663 - accuracy: 0.7463 - val_loss: 0.5765 - val_accuracy: 0.7371\n",
      "Epoch 49/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5696 - accuracy: 0.7433 - val_loss: 0.5765 - val_accuracy: 0.7371\n",
      "Epoch 50/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5654 - accuracy: 0.7472 - val_loss: 0.5765 - val_accuracy: 0.7371\n",
      "Epoch 51/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5620 - accuracy: 0.7503 - val_loss: 0.5765 - val_accuracy: 0.7371\n",
      "Epoch 52/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5677 - accuracy: 0.7451 - val_loss: 0.5765 - val_accuracy: 0.7371\n",
      "Epoch 53/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5712 - accuracy: 0.7418 - val_loss: 0.5766 - val_accuracy: 0.7371\n",
      "Epoch 54/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5677 - accuracy: 0.7450 - val_loss: 0.5765 - val_accuracy: 0.7371\n",
      "Epoch 55/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5654 - accuracy: 0.7472 - val_loss: 0.5765 - val_accuracy: 0.7371\n",
      "Epoch 56/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.5718 - accuracy: 0.7413 - val_loss: 0.5766 - val_accuracy: 0.7371\n",
      "Epoch 57/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5616 - accuracy: 0.7507 - val_loss: 0.5765 - val_accuracy: 0.7371\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5702 - accuracy: 0.7428 - val_loss: 0.5766 - val_accuracy: 0.7371\n",
      "Epoch 59/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5680 - accuracy: 0.7447 - val_loss: 0.5765 - val_accuracy: 0.7371\n",
      "Epoch 60/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5699 - accuracy: 0.7430 - val_loss: 0.5766 - val_accuracy: 0.7371\n",
      "Epoch 61/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5661 - accuracy: 0.7466 - val_loss: 0.5765 - val_accuracy: 0.7371\n",
      "Epoch 62/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5676 - accuracy: 0.7451 - val_loss: 0.5765 - val_accuracy: 0.7371\n",
      "Epoch 63/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5691 - accuracy: 0.7437 - val_loss: 0.5765 - val_accuracy: 0.7371\n",
      "Epoch 64/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5689 - accuracy: 0.7440 - val_loss: 0.5765 - val_accuracy: 0.7371\n",
      "Epoch 65/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.5683 - accuracy: 0.7445 - val_loss: 0.5766 - val_accuracy: 0.7371\n",
      "Epoch 66/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5700 - accuracy: 0.7429 - val_loss: 0.5766 - val_accuracy: 0.7371\n",
      "Epoch 67/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.5635 - accuracy: 0.7489 - val_loss: 0.5766 - val_accuracy: 0.7371\n",
      "Epoch 68/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5685 - accuracy: 0.7443 - val_loss: 0.5766 - val_accuracy: 0.7371\n",
      "Epoch 69/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5594 - accuracy: 0.7528 - val_loss: 0.5765 - val_accuracy: 0.7371\n",
      "Epoch 70/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.5652 - accuracy: 0.7474 - val_loss: 0.5765 - val_accuracy: 0.7371\n",
      "Epoch 71/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5658 - accuracy: 0.7469 - val_loss: 0.5765 - val_accuracy: 0.7371\n",
      "Epoch 72/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5669 - accuracy: 0.7458 - val_loss: 0.5766 - val_accuracy: 0.7371\n",
      "Epoch 73/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5641 - accuracy: 0.7484 - val_loss: 0.5765 - val_accuracy: 0.7371\n",
      "Epoch 74/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.5685 - accuracy: 0.7443 - val_loss: 0.5766 - val_accuracy: 0.7371\n",
      "Epoch 75/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5650 - accuracy: 0.7476 - val_loss: 0.5765 - val_accuracy: 0.7371\n",
      "Epoch 76/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5691 - accuracy: 0.7438 - val_loss: 0.5765 - val_accuracy: 0.7371\n",
      "Epoch 77/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5639 - accuracy: 0.7486 - val_loss: 0.5765 - val_accuracy: 0.7371\n",
      "Epoch 78/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.5649 - accuracy: 0.7476 - val_loss: 0.5765 - val_accuracy: 0.7371\n",
      "Epoch 79/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.5691 - accuracy: 0.7438 - val_loss: 0.5766 - val_accuracy: 0.7371\n",
      "Epoch 80/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.5648 - accuracy: 0.7478 - val_loss: 0.5765 - val_accuracy: 0.7371\n",
      "Epoch 81/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5675 - accuracy: 0.7452 - val_loss: 0.5765 - val_accuracy: 0.7371\n",
      "Epoch 82/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5659 - accuracy: 0.7467 - val_loss: 0.5765 - val_accuracy: 0.7371\n",
      "Epoch 83/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5625 - accuracy: 0.7499 - val_loss: 0.5765 - val_accuracy: 0.7371\n",
      "Epoch 84/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5718 - accuracy: 0.7413 - val_loss: 0.5766 - val_accuracy: 0.7371\n",
      "Epoch 85/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5618 - accuracy: 0.7505 - val_loss: 0.5765 - val_accuracy: 0.7371\n",
      "Epoch 86/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.5658 - accuracy: 0.7468 - val_loss: 0.5765 - val_accuracy: 0.7371\n",
      "Epoch 87/100\n",
      "338/338 [==============================] - 1s 2ms/step - loss: 0.5657 - accuracy: 0.7469 - val_loss: 0.5765 - val_accuracy: 0.7371\n",
      "Epoch 88/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5663 - accuracy: 0.7464 - val_loss: 0.5766 - val_accuracy: 0.7371\n",
      "Epoch 89/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5689 - accuracy: 0.7439 - val_loss: 0.5766 - val_accuracy: 0.7371\n",
      "Epoch 90/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5617 - accuracy: 0.7506 - val_loss: 0.5765 - val_accuracy: 0.7371\n",
      "Epoch 91/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5669 - accuracy: 0.7458 - val_loss: 0.5765 - val_accuracy: 0.7371\n",
      "Epoch 92/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.5674 - accuracy: 0.7453 - val_loss: 0.5765 - val_accuracy: 0.7371\n",
      "Epoch 93/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5646 - accuracy: 0.7479 - val_loss: 0.5765 - val_accuracy: 0.7371\n",
      "Epoch 94/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5666 - accuracy: 0.7461 - val_loss: 0.5765 - val_accuracy: 0.7371\n",
      "Epoch 95/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5706 - accuracy: 0.7424 - val_loss: 0.5765 - val_accuracy: 0.7371\n",
      "Epoch 96/100\n",
      "338/338 [==============================] - 1s 1ms/step - loss: 0.5609 - accuracy: 0.7514 - val_loss: 0.5765 - val_accuracy: 0.7371\n",
      "Epoch 97/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5639 - accuracy: 0.7486 - val_loss: 0.5765 - val_accuracy: 0.7371\n",
      "Epoch 98/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5676 - accuracy: 0.7452 - val_loss: 0.5765 - val_accuracy: 0.7371\n",
      "Epoch 99/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5685 - accuracy: 0.7443 - val_loss: 0.5765 - val_accuracy: 0.7371\n",
      "Epoch 100/100\n",
      "338/338 [==============================] - 0s 1ms/step - loss: 0.5681 - accuracy: 0.7447 - val_loss: 0.5766 - val_accuracy: 0.7371\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, validation_split=0.33, epochs=100, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b5cb6f2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e1cb1f",
   "metadata": {},
   "source": [
    "It seems that my model has lot of problem. Let's find it out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "75f0e523",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y =  df.drop(columns=[\"gender\"]), df[\"gender\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5ae7baaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kerastuner.engine.hyperparameters import HyperParameters\n",
    "from kerastuner.tuners import RandomSearch\n",
    "import time\n",
    "\n",
    "LOG_DIR = f\"{int(time.time())}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "3db49daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "def build_model(hp):\n",
    "    \n",
    "    model = keras.models.Sequential()\n",
    "    \n",
    "    model.add(Dense(hp.Int(\"input_units\", min_value=100, max_value=500, step=20), input_dim=291, activation='relu'))\n",
    "    \n",
    "    for i in range(hp.Int('n_layers', 1, 4)):\n",
    "        model.add(Dense(hp.Int(\"dense_units\", min_value=10, max_value=300, step=10), activation='relu'))\n",
    "    \n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8618b8a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1 Complete [00h 06m 05s]\n",
      "val_accuracy: 0.741651177406311\n",
      "\n",
      "Best val_accuracy So Far: 0.741651177406311\n",
      "Total elapsed time: 00h 06m 05s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective = \"val_accuracy\",\n",
    "    max_trials = 1,\n",
    "    executions_per_trial = 1,\n",
    "    directory = LOG_DIR\n",
    ")\n",
    "\n",
    "tuner.search(x=X_train, y=y_train, epochs=100, batch_size=10,validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "75ce74a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(f\"tuner_{int(time.time())}.pkl\", \"wb\") as f:\n",
    "    pickle.dump(tuner, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1037e149",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = pickle.load(open(\"tuner_1627669198.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "0335a06c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_units': 260, 'n_layers': 3, 'dense_units': 110}\n",
      "Results summary\n",
      "Results in 1627666980\\untitled_project\n",
      "Showing 10 best trials\n",
      "Objective(name='val_accuracy', direction='max')\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "input_units: 260\n",
      "n_layers: 3\n",
      "dense_units: 110\n",
      "Score: 0.741651177406311\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(tuner.get_best_hyperparameters()[0].values)\n",
    "print(tuner.results_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "04474c4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-0._module.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-0._module.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-1._module.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-1._module.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-2._module.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-2._module.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-3._module.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-3._module.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-4._module.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-4._module.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0._module.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0._module.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1._module.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1._module.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2._module.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2._module.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-3._module.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-3._module.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-4._module.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-4._module.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0._module.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0._module.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1._module.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1._module.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2._module.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2._module.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-3._module.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-3._module.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-4._module.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-4._module.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Epoch 1/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.6063 - accuracy: 0.7459 - val_loss: 0.5990 - val_accuracy: 0.7366\n",
      "Epoch 2/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5933 - accuracy: 0.7462 - val_loss: 0.5815 - val_accuracy: 0.7371\n",
      "Epoch 3/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5813 - val_accuracy: 0.7371\n",
      "Epoch 4/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.6328 - accuracy: 0.7460 - val_loss: 0.5855 - val_accuracy: 0.7368\n",
      "Epoch 5/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5790 - accuracy: 0.7463 - val_loss: 0.5761 - val_accuracy: 0.7370\n",
      "Epoch 6/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5666 - accuracy: 0.7464 - val_loss: 0.5765 - val_accuracy: 0.7370\n",
      "Epoch 7/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5668 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 8/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5667 - accuracy: 0.7464 - val_loss: 0.5768 - val_accuracy: 0.7370\n",
      "Epoch 9/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5667 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 10/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5666 - accuracy: 0.7464 - val_loss: 0.5764 - val_accuracy: 0.7370\n",
      "Epoch 11/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 12/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5772 - val_accuracy: 0.7370\n",
      "Epoch 13/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5667 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 14/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5764 - val_accuracy: 0.7370\n",
      "Epoch 15/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5775 - val_accuracy: 0.7370\n",
      "Epoch 16/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5666 - accuracy: 0.7464 - val_loss: 0.5772 - val_accuracy: 0.7370\n",
      "Epoch 17/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 18/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5666 - accuracy: 0.7464 - val_loss: 0.5763 - val_accuracy: 0.7370\n",
      "Epoch 19/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5666 - accuracy: 0.7464 - val_loss: 0.5771 - val_accuracy: 0.7370\n",
      "Epoch 20/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5666 - accuracy: 0.7464 - val_loss: 0.5773 - val_accuracy: 0.7370\n",
      "Epoch 21/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 22/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5666 - accuracy: 0.7464 - val_loss: 0.5766 - val_accuracy: 0.7370\n",
      "Epoch 23/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5666 - accuracy: 0.7464 - val_loss: 0.5765 - val_accuracy: 0.7370\n",
      "Epoch 24/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5667 - accuracy: 0.7464 - val_loss: 0.5766 - val_accuracy: 0.7370\n",
      "Epoch 25/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5768 - val_accuracy: 0.7370\n",
      "Epoch 26/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 27/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5766 - val_accuracy: 0.7370\n",
      "Epoch 28/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5764 - val_accuracy: 0.7370\n",
      "Epoch 29/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5764 - val_accuracy: 0.7370\n",
      "Epoch 30/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 31/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5769 - val_accuracy: 0.7370\n",
      "Epoch 32/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5663 - accuracy: 0.7464 - val_loss: 0.5763 - val_accuracy: 0.7370\n",
      "Epoch 33/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5767 - val_accuracy: 0.7370\n",
      "Epoch 34/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5773 - val_accuracy: 0.7370\n",
      "Epoch 35/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5764 - val_accuracy: 0.7370\n",
      "Epoch 36/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 37/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 38/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 39/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5761 - val_accuracy: 0.7370\n",
      "Epoch 40/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5764 - val_accuracy: 0.7370\n",
      "Epoch 41/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5767 - val_accuracy: 0.7370\n",
      "Epoch 42/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5763 - val_accuracy: 0.7370\n",
      "Epoch 43/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 44/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 45/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5765 - val_accuracy: 0.7370\n",
      "Epoch 46/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5770 - val_accuracy: 0.7370\n",
      "Epoch 47/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 48/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 49/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5763 - val_accuracy: 0.7370\n",
      "Epoch 50/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 51/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5663 - accuracy: 0.7464 - val_loss: 0.5768 - val_accuracy: 0.7370\n",
      "Epoch 52/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5770 - val_accuracy: 0.7370\n",
      "Epoch 53/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5770 - val_accuracy: 0.7370\n",
      "Epoch 54/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 55/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 56/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5765 - val_accuracy: 0.7370\n",
      "Epoch 57/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5768 - val_accuracy: 0.7370\n",
      "Epoch 58/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5775 - val_accuracy: 0.7370\n",
      "Epoch 59/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 60/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5666 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 61/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5761 - val_accuracy: 0.7370\n",
      "Epoch 62/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 63/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5765 - val_accuracy: 0.7370\n",
      "Epoch 64/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5663 - accuracy: 0.7464 - val_loss: 0.5770 - val_accuracy: 0.7370\n",
      "Epoch 65/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5763 - val_accuracy: 0.7370\n",
      "Epoch 66/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5767 - val_accuracy: 0.7370\n",
      "Epoch 67/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5764 - val_accuracy: 0.7370\n",
      "Epoch 68/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5761 - val_accuracy: 0.7370\n",
      "Epoch 69/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5765 - val_accuracy: 0.7370\n",
      "Epoch 70/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5776 - val_accuracy: 0.7370\n",
      "Epoch 71/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5662 - accuracy: 0.7464 - val_loss: 0.5767 - val_accuracy: 0.7370\n",
      "Epoch 72/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5763 - val_accuracy: 0.7370\n",
      "Epoch 73/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5767 - val_accuracy: 0.7370\n",
      "Epoch 74/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 75/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5764 - val_accuracy: 0.7370\n",
      "Epoch 76/100\n",
      "2159/2159 [==============================] - 3s 2ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5767 - val_accuracy: 0.7370\n",
      "Epoch 77/100\n",
      "2159/2159 [==============================] - 4s 2ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 78/100\n",
      "2159/2159 [==============================] - 4s 2ms/step - loss: 0.5663 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 79/100\n",
      "2159/2159 [==============================] - 4s 2ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5766 - val_accuracy: 0.7370\n",
      "Epoch 80/100\n",
      "2159/2159 [==============================] - 4s 2ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 81/100\n",
      "2159/2159 [==============================] - 4s 2ms/step - loss: 0.5663 - accuracy: 0.7464 - val_loss: 0.5775 - val_accuracy: 0.7370\n",
      "Epoch 82/100\n",
      "2159/2159 [==============================] - 4s 2ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2159/2159 [==============================] - 4s 2ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5766 - val_accuracy: 0.7370\n",
      "Epoch 84/100\n",
      "2159/2159 [==============================] - 4s 2ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5767 - val_accuracy: 0.7370\n",
      "Epoch 85/100\n",
      "2159/2159 [==============================] - 4s 2ms/step - loss: 0.5663 - accuracy: 0.7464 - val_loss: 0.5773 - val_accuracy: 0.7370\n",
      "Epoch 86/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 87/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5663 - accuracy: 0.7464 - val_loss: 0.5771 - val_accuracy: 0.7370\n",
      "Epoch 88/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5663 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 89/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5767 - val_accuracy: 0.7370\n",
      "Epoch 90/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5663 - accuracy: 0.7464 - val_loss: 0.5763 - val_accuracy: 0.7370\n",
      "Epoch 91/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5768 - val_accuracy: 0.7370\n",
      "Epoch 92/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5764 - val_accuracy: 0.7370\n",
      "Epoch 93/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 94/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5764 - val_accuracy: 0.7370\n",
      "Epoch 95/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5763 - val_accuracy: 0.7370\n",
      "Epoch 96/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 97/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5763 - val_accuracy: 0.7370\n",
      "Epoch 98/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5761 - val_accuracy: 0.7370\n",
      "Epoch 99/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5767 - val_accuracy: 0.7370\n",
      "Epoch 100/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5773 - val_accuracy: 0.7370\n"
     ]
    }
   ],
   "source": [
    "model = tuner.get_best_models()[0]\n",
    "history = model.fit(X_train, y_train, validation_split=0.33, epochs=100, batch_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d2121c",
   "metadata": {},
   "source": [
    "Accuracy is not changing one reason can be because of `optimizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "9e1610d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import SGD\n",
    "opt = SGD(learning_rate=0.01)\n",
    "\n",
    "def build_model2(hp):\n",
    "    \n",
    "    model = keras.models.Sequential()\n",
    "    \n",
    "    model.add(Dense(hp.Int(\"input_units\", min_value=100, max_value=500, step=20), input_dim=291, activation='relu'))\n",
    "    \n",
    "    for i in range(hp.Int('n_layers', 1, 4)):\n",
    "        model.add(Dense(hp.Int(\"dense_units\", min_value=10, max_value=300, step=10), activation='relu'))\n",
    "    \n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d401929a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1 Complete [00h 06m 33s]\n",
      "val_accuracy: 0.741651177406311\n",
      "\n",
      "Best val_accuracy So Far: 0.741651177406311\n",
      "Total elapsed time: 00h 06m 33s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "LOG_DIR = f\"{int(time.time())}\"\n",
    "\n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective = \"val_accuracy\",\n",
    "    max_trials = 1,\n",
    "    executions_per_trial = 1,\n",
    "    directory = LOG_DIR\n",
    ")\n",
    "\n",
    "tuner.search(x=X_train, y=y_train, epochs=100, batch_size=10,validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "6739cda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"tuner_{int(time.time())}.pkl\", \"wb\") as f:\n",
    "    pickle.dump(tuner, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "e4b946fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = pickle.load(open(\"tuner_1627670879.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "dd81838a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_units': 140, 'n_layers': 3, 'dense_units': 170}\n",
      "Results summary\n",
      "Results in 1627670169\\untitled_project\n",
      "Showing 10 best trials\n",
      "Objective(name='val_accuracy', direction='max')\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "input_units: 140\n",
      "n_layers: 3\n",
      "dense_units: 170\n",
      "Score: 0.741651177406311\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(tuner.get_best_hyperparameters()[0].values)\n",
    "print(tuner.results_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "7e5ebda1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5675 - accuracy: 0.7463 - val_loss: 0.5761 - val_accuracy: 0.7371\n",
      "Epoch 2/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5686 - accuracy: 0.7463 - val_loss: 0.5762 - val_accuracy: 0.7371\n",
      "Epoch 3/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5704 - accuracy: 0.7462 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 4/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5711 - accuracy: 0.7463 - val_loss: 0.5763 - val_accuracy: 0.7370\n",
      "Epoch 5/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5666 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 6/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5668 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 7/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5668 - accuracy: 0.7464 - val_loss: 0.5763 - val_accuracy: 0.7370\n",
      "Epoch 8/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5666 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 9/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5667 - accuracy: 0.7464 - val_loss: 0.5763 - val_accuracy: 0.7370\n",
      "Epoch 10/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5668 - accuracy: 0.7464 - val_loss: 0.5765 - val_accuracy: 0.7370\n",
      "Epoch 11/100\n",
      "2159/2159 [==============================] - 3s 2ms/step - loss: 0.5667 - accuracy: 0.7464 - val_loss: 0.5768 - val_accuracy: 0.7370\n",
      "Epoch 12/100\n",
      "2159/2159 [==============================] - 4s 2ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5773 - val_accuracy: 0.7370\n",
      "Epoch 13/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5763 - val_accuracy: 0.7370\n",
      "Epoch 14/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5667 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 15/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5667 - accuracy: 0.7464 - val_loss: 0.5766 - val_accuracy: 0.7370\n",
      "Epoch 16/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5666 - accuracy: 0.7464 - val_loss: 0.5768 - val_accuracy: 0.7370\n",
      "Epoch 17/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5666 - accuracy: 0.7464 - val_loss: 0.5764 - val_accuracy: 0.7370\n",
      "Epoch 18/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5663 - accuracy: 0.7464 - val_loss: 0.5770 - val_accuracy: 0.7370\n",
      "Epoch 19/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5666 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 20/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5667 - accuracy: 0.7464 - val_loss: 0.5766 - val_accuracy: 0.7370\n",
      "Epoch 21/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5666 - accuracy: 0.7464 - val_loss: 0.5773 - val_accuracy: 0.7370\n",
      "Epoch 22/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5775 - val_accuracy: 0.7370\n",
      "Epoch 23/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5666 - accuracy: 0.7464 - val_loss: 0.5766 - val_accuracy: 0.7370\n",
      "Epoch 24/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5666 - accuracy: 0.7464 - val_loss: 0.5764 - val_accuracy: 0.7370\n",
      "Epoch 25/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 26/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5794 - val_accuracy: 0.7370\n",
      "Epoch 27/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5666 - accuracy: 0.7464 - val_loss: 0.5783 - val_accuracy: 0.7370\n",
      "Epoch 28/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5767 - val_accuracy: 0.7370\n",
      "Epoch 29/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5666 - accuracy: 0.7464 - val_loss: 0.5763 - val_accuracy: 0.7370\n",
      "Epoch 30/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5770 - val_accuracy: 0.7370\n",
      "Epoch 31/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5666 - accuracy: 0.7464 - val_loss: 0.5764 - val_accuracy: 0.7370\n",
      "Epoch 32/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5666 - accuracy: 0.7464 - val_loss: 0.5761 - val_accuracy: 0.7370\n",
      "Epoch 33/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 34/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 35/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5666 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 36/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5763 - val_accuracy: 0.7370\n",
      "Epoch 37/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5666 - accuracy: 0.7464 - val_loss: 0.5765 - val_accuracy: 0.7370\n",
      "Epoch 38/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5666 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 39/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5765 - val_accuracy: 0.7370\n",
      "Epoch 40/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5666 - accuracy: 0.7464 - val_loss: 0.5765 - val_accuracy: 0.7370\n",
      "Epoch 41/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 42/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5666 - accuracy: 0.7464 - val_loss: 0.5766 - val_accuracy: 0.7370\n",
      "Epoch 43/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5768 - val_accuracy: 0.7370\n",
      "Epoch 44/100\n",
      "2159/2159 [==============================] - 3s 2ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5775 - val_accuracy: 0.7370\n",
      "Epoch 45/100\n",
      "2159/2159 [==============================] - 4s 2ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5770 - val_accuracy: 0.7370\n",
      "Epoch 46/100\n",
      "2159/2159 [==============================] - 4s 2ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5779 - val_accuracy: 0.7370\n",
      "Epoch 47/100\n",
      "2159/2159 [==============================] - 4s 2ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 48/100\n",
      "2159/2159 [==============================] - 4s 2ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 49/100\n",
      "2159/2159 [==============================] - 3s 2ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5769 - val_accuracy: 0.7370\n",
      "Epoch 50/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 51/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5773 - val_accuracy: 0.7370\n",
      "Epoch 52/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5767 - val_accuracy: 0.7370\n",
      "Epoch 53/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 54/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5663 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 55/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 56/100\n",
      "2159/2159 [==============================] - 3s 2ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5769 - val_accuracy: 0.7370\n",
      "Epoch 57/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5765 - val_accuracy: 0.7370\n",
      "Epoch 58/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5764 - val_accuracy: 0.7370\n",
      "Epoch 59/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5763 - val_accuracy: 0.7370\n",
      "Epoch 60/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5766 - val_accuracy: 0.7370\n",
      "Epoch 61/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5663 - accuracy: 0.7464 - val_loss: 0.5765 - val_accuracy: 0.7370\n",
      "Epoch 62/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5763 - val_accuracy: 0.7370\n",
      "Epoch 63/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5663 - accuracy: 0.7464 - val_loss: 0.5770 - val_accuracy: 0.7370\n",
      "Epoch 64/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5769 - val_accuracy: 0.7370\n",
      "Epoch 65/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5663 - accuracy: 0.7464 - val_loss: 0.5765 - val_accuracy: 0.7370\n",
      "Epoch 66/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5764 - val_accuracy: 0.7370\n",
      "Epoch 67/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 68/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 69/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5663 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 70/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 71/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5768 - val_accuracy: 0.7370\n",
      "Epoch 72/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5763 - val_accuracy: 0.7370\n",
      "Epoch 73/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 74/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5769 - val_accuracy: 0.7370\n",
      "Epoch 75/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5765 - val_accuracy: 0.7370\n",
      "Epoch 76/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5773 - val_accuracy: 0.7370\n",
      "Epoch 77/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5768 - val_accuracy: 0.7370\n",
      "Epoch 78/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 79/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5764 - val_accuracy: 0.7370\n",
      "Epoch 80/100\n",
      "2159/2159 [==============================] - 3s 2ms/step - loss: 0.5663 - accuracy: 0.7464 - val_loss: 0.5769 - val_accuracy: 0.7370\n",
      "Epoch 81/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5766 - val_accuracy: 0.7370\n",
      "Epoch 82/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 83/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5767 - val_accuracy: 0.7370\n",
      "Epoch 84/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5663 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 85/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5663 - accuracy: 0.7464 - val_loss: 0.5764 - val_accuracy: 0.7370\n",
      "Epoch 86/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5766 - val_accuracy: 0.7370\n",
      "Epoch 87/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5663 - accuracy: 0.7464 - val_loss: 0.5763 - val_accuracy: 0.7370\n",
      "Epoch 88/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5763 - val_accuracy: 0.7370\n",
      "Epoch 89/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5767 - val_accuracy: 0.7370\n",
      "Epoch 90/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5765 - val_accuracy: 0.7370\n",
      "Epoch 91/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5763 - val_accuracy: 0.7370\n",
      "Epoch 92/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 93/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 94/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5663 - accuracy: 0.7464 - val_loss: 0.5773 - val_accuracy: 0.7370\n",
      "Epoch 95/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7464 - val_loss: 0.5766 - val_accuracy: 0.7370\n",
      "Epoch 96/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 97/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 98/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5762 - val_accuracy: 0.7370\n",
      "Epoch 99/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5767 - val_accuracy: 0.7370\n",
      "Epoch 100/100\n",
      "2159/2159 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7464 - val_loss: 0.5771 - val_accuracy: 0.7370\n"
     ]
    }
   ],
   "source": [
    "model = tuner.get_best_models()[0]\n",
    "history = model.fit(X_train, y_train, validation_split=0.33, epochs=100, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "e46691be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheRealRondon\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.741651148355059\n",
      "Balanced Accuracy:  0.5\n",
      "Precision:  0.741651148355059\n",
      "Recall:  1.0\n",
      "F1:  0.8516644094375936\n"
     ]
    }
   ],
   "source": [
    "predicted = model.predict_classes(X_test)\n",
    "evaluate(predicted, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "75cf718f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There 0 0 values in prediction.\n",
      "There 8055 1 values in prediction.\n",
      "There 2081 0 values in test dataset.\n",
      "There 5974 1 values in test dataset.\n"
     ]
    }
   ],
   "source": [
    "count_0_predicted = 0\n",
    "count_1_predicted = 0\n",
    "count_0_actual = 0\n",
    "count_1_actual = 0\n",
    "for i in range(len(predicted)):\n",
    "    if predicted[i] == 0:\n",
    "        count_0_predicted += 1\n",
    "    else:\n",
    "        count_1_predicted += 1\n",
    "    if y_test.iloc[i] == 0:\n",
    "        count_0_actual += 1\n",
    "    else:\n",
    "        count_1_actual += 1\n",
    "print(f\"There {count_0_predicted} 0 values in prediction.\")\n",
    "print(f\"There {count_1_predicted} 1 values in prediction.\")\n",
    "\n",
    "print(f\"There {count_0_actual} 0 values in test dataset.\")\n",
    "print(f\"There {count_1_actual} 1 values in test dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "0e5c7d18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.74301676, 0.74518932, 0.74239603, 0.74239603, 0.74332713,\n",
       "       0.74208566, 0.74262651, 0.74293698, 0.74293698, 0.74138466])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "model = RandomForestClassifier(random_state=0, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100)\n",
    "cross_val_score(model, X_train, y_train, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "a0ab8ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)\n",
    "predicted = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "77758b29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7415270018621974\n",
      "Balanced Accuracy:  0.5017951810078175\n",
      "Precision:  0.7423412204234122\n",
      "Recall:  0.9978239035821895\n",
      "F1:  0.8513281919451585\n"
     ]
    }
   ],
   "source": [
    "evaluate(predicted, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "c55815a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There 25 0 values in prediction.\n",
      "There 8030 1 values in prediction.\n",
      "There 2081 0 values in test dataset.\n",
      "There 5974 1 values in test dataset.\n"
     ]
    }
   ],
   "source": [
    "count_0_predicted = 0\n",
    "count_1_predicted = 0\n",
    "count_0_actual = 0\n",
    "count_1_actual = 0\n",
    "for i in range(len(predicted)):\n",
    "    if predicted[i] == 0:\n",
    "        count_0_predicted += 1\n",
    "    else:\n",
    "        count_1_predicted += 1\n",
    "    if y_test.iloc[i] == 0:\n",
    "        count_0_actual += 1\n",
    "    else:\n",
    "        count_1_actual += 1\n",
    "print(f\"There {count_0_predicted} 0 values in prediction.\")\n",
    "print(f\"There {count_1_predicted} 1 values in prediction.\")\n",
    "\n",
    "print(f\"There {count_0_actual} 0 values in test dataset.\")\n",
    "print(f\"There {count_1_actual} 1 values in test dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad05cc84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>queries</th>\n",
       "      <th>apps</th>\n",
       "      <th>games</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[216, 359, 12329, 3, 45, 4002, 2066, 32, 3931,...</td>\n",
       "      <td>[4, 4, 25, 7, 30, 58, 16, 19, 17, 21, 10, 10, ...</td>\n",
       "      <td>[9151, 208]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[]</td>\n",
       "      <td>[129, 71, 9, 8, 11, 25, 18, 58, 6, 16, 125, 12...</td>\n",
       "      <td>[460, 4939, 14, 232, 6387, 1758, 5834, 3, 2]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[23463, 18831]</td>\n",
       "      <td>[9, 174, 65, 8, 63, 97, 62, 103, 61, 116, 59, ...</td>\n",
       "      <td>[448, 723, 267, 9064, 10634, 166, 782, 224, 27...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1634, 3609, 654]</td>\n",
       "      <td>[99, 73, 9, 8, 59, 37, 131, 3, 89, 6, 24, 16, ...</td>\n",
       "      <td>[78, 2607, 478, 435, 9, 192]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[11064, 227, 623, 1301, 43999, 35411, 2492, 11...</td>\n",
       "      <td>[9, 8, 17, 54, 3, 25, 22, 6, 21, 7, 14, 5, 817...</td>\n",
       "      <td>[1702, 1, 53]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             queries  \\\n",
       "0  [216, 359, 12329, 3, 45, 4002, 2066, 32, 3931,...   \n",
       "1                                                 []   \n",
       "2                                     [23463, 18831]   \n",
       "3                                  [1634, 3609, 654]   \n",
       "4  [11064, 227, 623, 1301, 43999, 35411, 2492, 11...   \n",
       "\n",
       "                                                apps  \\\n",
       "0  [4, 4, 25, 7, 30, 58, 16, 19, 17, 21, 10, 10, ...   \n",
       "1  [129, 71, 9, 8, 11, 25, 18, 58, 6, 16, 125, 12...   \n",
       "2  [9, 174, 65, 8, 63, 97, 62, 103, 61, 116, 59, ...   \n",
       "3  [99, 73, 9, 8, 59, 37, 131, 3, 89, 6, 24, 16, ...   \n",
       "4  [9, 8, 17, 54, 3, 25, 22, 6, 21, 7, 14, 5, 817...   \n",
       "\n",
       "                                               games  gender  \n",
       "0                                        [9151, 208]       1  \n",
       "1       [460, 4939, 14, 232, 6387, 1758, 5834, 3, 2]       0  \n",
       "2  [448, 723, 267, 9064, 10634, 166, 782, 224, 27...       1  \n",
       "3                       [78, 2607, 478, 435, 9, 192]       1  \n",
       "4                                      [1702, 1, 53]       1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(columns=['birth_year'], inplace=True)\n",
    "df[\"gender\"] = df[\"gender\"].replace({'M': 1, 'F': 0})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15b8af3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y =  df.drop(columns=[\"gender\"]), df[\"gender\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05f2a522",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>queries</th>\n",
       "      <th>apps</th>\n",
       "      <th>games</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9391</th>\n",
       "      <td>[2504, 30655, 32035, 3, 4]</td>\n",
       "      <td>[9, 10, 10, 39, 17, 3, 21, 12, 7, 41, 58, 6, 1...</td>\n",
       "      <td>[336, 822, 14]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36089</th>\n",
       "      <td>[1400, 4, 9, 18236, 16200, 10739, 9713, 70, 14...</td>\n",
       "      <td>[9, 8, 10, 10, 39, 17, 48, 54, 3, 25, 22, 6, 2...</td>\n",
       "      <td>[1, 145]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38820</th>\n",
       "      <td>[5327, 12, 3, 10462, 30102, 921, 1247, 6869, 7...</td>\n",
       "      <td>[9, 17, 3, 25, 22, 6, 21, 7, 14, 23, 2, 19, 10...</td>\n",
       "      <td>[78, 11, 122, 113, 192, 2726, 34, 44, 17, 4, 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33815</th>\n",
       "      <td>[479, 1717, 1205, 875, 3570, 4]</td>\n",
       "      <td>[73, 9, 8, 59, 37, 131, 3, 89, 6, 16, 85, 12, ...</td>\n",
       "      <td>[771, 3198]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31187</th>\n",
       "      <td>[163, 18284, 143, 1082, 258, 28721]</td>\n",
       "      <td>[25, 71, 125, 16, 7, 5, 10, 10, 48, 3, 79, 47,...</td>\n",
       "      <td>[689, 45]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6265</th>\n",
       "      <td>[824, 197, 42, 259, 4127, 894, 719, 344]</td>\n",
       "      <td>[9, 8, 105, 10, 10, 17, 54, 3, 25, 95, 22, 6, ...</td>\n",
       "      <td>[23, 947, 35, 435, 1327, 2694, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11284</th>\n",
       "      <td>[1565, 712, 24838, 39622, 20862, 22, 238, 599,...</td>\n",
       "      <td>[9, 8, 105, 10, 10, 39, 17, 3, 25, 22, 6, 24, ...</td>\n",
       "      <td>[64, 361, 2093, 2708, 1228, 318, 711, 1844, 2392]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38158</th>\n",
       "      <td>[4118, 12355, 723, 41687, 1678, 30560, 184, 85...</td>\n",
       "      <td>[9, 8, 17, 3, 25, 22, 6, 21, 7, 14, 5, 23, 2, ...</td>\n",
       "      <td>[35, 4697, 3, 47]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>[134, 12, 16458, 459, 118, 13249, 241, 10469, ...</td>\n",
       "      <td>[9, 8, 17, 3, 25, 22, 6, 24, 21, 7, 14, 5, 23,...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15795</th>\n",
       "      <td>[12904, 2555, 39, 976, 3716, 10283, 10193, 102...</td>\n",
       "      <td>[9, 8, 105, 10, 10, 39, 17, 3, 25, 22, 6, 24, ...</td>\n",
       "      <td>[2, 889]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32216 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 queries  \\\n",
       "9391                          [2504, 30655, 32035, 3, 4]   \n",
       "36089  [1400, 4, 9, 18236, 16200, 10739, 9713, 70, 14...   \n",
       "38820  [5327, 12, 3, 10462, 30102, 921, 1247, 6869, 7...   \n",
       "33815                    [479, 1717, 1205, 875, 3570, 4]   \n",
       "31187                [163, 18284, 143, 1082, 258, 28721]   \n",
       "...                                                  ...   \n",
       "6265            [824, 197, 42, 259, 4127, 894, 719, 344]   \n",
       "11284  [1565, 712, 24838, 39622, 20862, 22, 238, 599,...   \n",
       "38158  [4118, 12355, 723, 41687, 1678, 30560, 184, 85...   \n",
       "860    [134, 12, 16458, 459, 118, 13249, 241, 10469, ...   \n",
       "15795  [12904, 2555, 39, 976, 3716, 10283, 10193, 102...   \n",
       "\n",
       "                                                    apps  \\\n",
       "9391   [9, 10, 10, 39, 17, 3, 21, 12, 7, 41, 58, 6, 1...   \n",
       "36089  [9, 8, 10, 10, 39, 17, 48, 54, 3, 25, 22, 6, 2...   \n",
       "38820  [9, 17, 3, 25, 22, 6, 21, 7, 14, 23, 2, 19, 10...   \n",
       "33815  [73, 9, 8, 59, 37, 131, 3, 89, 6, 16, 85, 12, ...   \n",
       "31187  [25, 71, 125, 16, 7, 5, 10, 10, 48, 3, 79, 47,...   \n",
       "...                                                  ...   \n",
       "6265   [9, 8, 105, 10, 10, 17, 54, 3, 25, 95, 22, 6, ...   \n",
       "11284  [9, 8, 105, 10, 10, 39, 17, 3, 25, 22, 6, 24, ...   \n",
       "38158  [9, 8, 17, 3, 25, 22, 6, 21, 7, 14, 5, 23, 2, ...   \n",
       "860    [9, 8, 17, 3, 25, 22, 6, 24, 21, 7, 14, 5, 23,...   \n",
       "15795  [9, 8, 105, 10, 10, 39, 17, 3, 25, 22, 6, 24, ...   \n",
       "\n",
       "                                                   games  \n",
       "9391                                      [336, 822, 14]  \n",
       "36089                                           [1, 145]  \n",
       "38820  [78, 11, 122, 113, 192, 2726, 34, 44, 17, 4, 9...  \n",
       "33815                                        [771, 3198]  \n",
       "31187                                          [689, 45]  \n",
       "...                                                  ...  \n",
       "6265                   [23, 947, 35, 435, 1327, 2694, 2]  \n",
       "11284  [64, 361, 2093, 2708, 1228, 318, 711, 1844, 2392]  \n",
       "38158                                  [35, 4697, 3, 47]  \n",
       "860                                                   []  \n",
       "15795                                           [2, 889]  \n",
       "\n",
       "[32216 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ad72d499",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;31mTypeError\u001b[0m: only size-1 arrays can be converted to Python scalars",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-866bb70b5a7c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_samples_leaf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_samples_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    302\u001b[0m                 \u001b[1;34m\"sparse multilabel-indicator for y is not supported.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    303\u001b[0m             )\n\u001b[1;32m--> 304\u001b[1;33m         X, y = self._validate_data(X, y, multi_output=True,\n\u001b[0m\u001b[0;32m    305\u001b[0m                                    accept_sparse=\"csc\", dtype=DTYPE)\n\u001b[0;32m    306\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    431\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    432\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 433\u001b[1;33m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    434\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    435\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m    869\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"y cannot be None\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    870\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 871\u001b[1;33m     X = check_array(X, accept_sparse=accept_sparse,\n\u001b[0m\u001b[0;32m    872\u001b[0m                     \u001b[0maccept_large_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_large_sparse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    873\u001b[0m                     \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    671\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"unsafe\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    672\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 673\u001b[1;33m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    674\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    675\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m     \"\"\"\n\u001b[1;32m---> 83\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   1988\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1989\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mNpDtype\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1990\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1991\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1992\u001b[0m     def __array_wrap__(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m     \"\"\"\n\u001b[1;32m---> 83\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "model = RandomForestClassifier(random_state=0, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b2023c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_1D(series):\n",
    "    return pd.Series([x for _list in series for x in _list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54fa37e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = to_1D(df['queries'])\n",
    "apps = to_1D(df['apps'])\n",
    "games = to_1D(df['games'])\n",
    "\n",
    "queries_value_count = queries.value_counts()\n",
    "games_value_count = games.value_counts()\n",
    "apps_value_count = apps.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7beec0cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queries completed\n",
      "Apps completed\n",
      "Games completed\n"
     ]
    }
   ],
   "source": [
    "features = dict()\n",
    "\n",
    "for query in queries:\n",
    "    if (queries_value_count[query] > len(df) * 0.05):\n",
    "        features[f\"q{query}\"] = 0 \n",
    "print(\"Queries completed\")\n",
    "for app in apps:\n",
    "    if (apps_value_count[app] > len(df) * 0.05):\n",
    "        features[f\"a{app}\"] = 0\n",
    "print(\"Apps completed\")\n",
    "for game in games:\n",
    "    if (games_value_count[game] > len(df) * 0.05):\n",
    "        features[f\"g{game}\"] = 0\n",
    "print(\"Games completed\")\n",
    "    \n",
    "features[\"gender\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2d52e949",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_key(dict, key):\n",
    "    if key in dict.keys():\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "517a0784",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 40271/40271 [00:04<00:00, 8271.07it/s]\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "from tqdm import tqdm\n",
    "\n",
    "new_dataset = []\n",
    "for index, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "    new_item = copy.copy(features)\n",
    "    for query in row['queries']:\n",
    "        if check_key(new_item, f\"q{query}\"):\n",
    "            new_item[f\"q{query}\"] = 1\n",
    "    for game in row['games']:\n",
    "        if check_key(new_item, f\"g{game}\"):\n",
    "            new_item[f\"g{game}\"] = 1\n",
    "    for app in row['apps']:\n",
    "        if check_key(new_item, f\"a{app}\"):\n",
    "            new_item[f\"a{app}\"] = 1\n",
    "    new_item['gender'] = row['gender']\n",
    "    assert len(new_item) == len(features), \"Featues count error\"\n",
    "    new_dataset.append(copy.copy(new_item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "99c22c8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q3</th>\n",
       "      <th>q1</th>\n",
       "      <th>q15</th>\n",
       "      <th>q2</th>\n",
       "      <th>q12</th>\n",
       "      <th>q8</th>\n",
       "      <th>q40</th>\n",
       "      <th>q21</th>\n",
       "      <th>q27</th>\n",
       "      <th>q13</th>\n",
       "      <th>...</th>\n",
       "      <th>a33</th>\n",
       "      <th>a152</th>\n",
       "      <th>g3</th>\n",
       "      <th>g2</th>\n",
       "      <th>g9</th>\n",
       "      <th>g1</th>\n",
       "      <th>g16</th>\n",
       "      <th>g4</th>\n",
       "      <th>g5</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 220 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   q3  q1  q15  q2  q12  q8  q40  q21  q27  q13  ...  a33  a152  g3  g2  g9  \\\n",
       "0   1   1    1   1    1   1    1    1    0    0  ...    0     0   0   0   0   \n",
       "1   0   0    0   0    0   0    0    0    0    0  ...    0     0   1   1   0   \n",
       "2   0   0    0   0    0   0    0    0    0    0  ...    0     0   0   0   0   \n",
       "3   0   0    0   0    0   0    0    0    0    0  ...    0     0   0   0   1   \n",
       "4   0   0    0   0    0   0    0    0    1    1  ...    0     0   0   0   0   \n",
       "\n",
       "   g1  g16  g4  g5  gender  \n",
       "0   0    0   0   0       1  \n",
       "1   0    0   0   0       0  \n",
       "2   0    0   0   0       1  \n",
       "3   0    0   0   0       1  \n",
       "4   1    0   0   0       1  \n",
       "\n",
       "[5 rows x 220 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df = pd.DataFrame.from_dict(new_dataset, orient='columns')\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2030d0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y =  new_df.drop(columns=[\"gender\"]), new_df[\"gender\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "64dd5cc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.80633147, 0.81315953, 0.81750466, 0.80726257, 0.80819367,\n",
       "       0.82091868, 0.80565042, 0.81527476, 0.81837939, 0.80844458])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "model = RandomForestClassifier(random_state=0, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100)\n",
    "cross_val_score(model, X_train, y_train, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67163ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)\n",
    "predicted = model.predict(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
